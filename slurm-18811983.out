
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


[INFO] PyTorch Version: 1.7.0

Configurations:
backbone                       resnet50_imgnet
batch_size                     128
data_root                      /scratch/nuislam/ChestXRay14_images/
debug_mode                     False
device                         cuda
epochs                         1000
gpu                            0
log_writter                    <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
lr                             0.0002
method                         nih14_resnet50_imgnet_run205
model_path                     saved_models/nih14_resnet50_imgnet_run205
num_workers                    10
patience                       50
run                            205
server                         agave
test_list                      data/nih_xray14/official/test_official.txt
train_list                     data/nih_xray14/official/train_official.txt
valid_list                     data/nih_xray14/official/val_official.txt
weight                         None


DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=14, bias=True)
      (1): Sigmoid()
    )
  )
)
Train: [1][10/589]	BT 0.358 (1.438)	DT 0.000 (0.868)	lr 0.0002	loss 0.216 (0.394)
Train: [1][20/589]	BT 0.357 (1.075)	DT 0.000 (0.611)	lr 0.0002	loss 0.188 (0.285)
Train: [1][30/589]	BT 0.357 (0.956)	DT 0.000 (0.527)	lr 0.0002	loss 0.143 (0.243)
Train: [1][40/589]	BT 0.360 (0.905)	DT 0.000 (0.493)	lr 0.0002	loss 0.196 (0.221)
Train: [1][50/589]	BT 0.357 (0.869)	DT 0.000 (0.468)	lr 0.0002	loss 0.182 (0.208)
Train: [1][60/589]	BT 0.360 (0.841)	DT 0.000 (0.446)	lr 0.0002	loss 0.179 (0.200)
Train: [1][70/589]	BT 0.360 (0.831)	DT 0.000 (0.441)	lr 0.0002	loss 0.137 (0.193)
Train: [1][80/589]	BT 0.357 (0.811)	DT 0.000 (0.425)	lr 0.0002	loss 0.170 (0.189)
Train: [1][90/589]	BT 0.358 (0.796)	DT 0.000 (0.413)	lr 0.0002	loss 0.154 (0.185)
Train: [1][100/589]	BT 0.359 (0.796)	DT 0.000 (0.416)	lr 0.0002	loss 0.152 (0.182)
Train: [1][110/589]	BT 0.359 (0.786)	DT 0.000 (0.407)	lr 0.0002	loss 0.115 (0.179)
Train: [1][120/589]	BT 0.357 (0.774)	DT 0.000 (0.397)	lr 0.0002	loss 0.153 (0.177)
Train: [1][130/589]	BT 0.359 (0.770)	DT 0.000 (0.394)	lr 0.0002	loss 0.114 (0.175)
Train: [1][140/589]	BT 0.362 (0.773)	DT 0.000 (0.398)	lr 0.0002	loss 0.149 (0.173)
Train: [1][150/589]	BT 0.360 (0.773)	DT 0.000 (0.399)	lr 0.0002	loss 0.149 (0.172)
Train: [1][160/589]	BT 0.359 (0.769)	DT 0.000 (0.396)	lr 0.0002	loss 0.138 (0.170)
Train: [1][170/589]	BT 0.357 (0.768)	DT 0.000 (0.396)	lr 0.0002	loss 0.136 (0.169)
Train: [1][180/589]	BT 0.357 (0.763)	DT 0.000 (0.392)	lr 0.0002	loss 0.155 (0.168)
Train: [1][190/589]	BT 0.361 (0.760)	DT 0.000 (0.389)	lr 0.0002	loss 0.151 (0.167)
Train: [1][200/589]	BT 0.358 (0.760)	DT 0.000 (0.390)	lr 0.0002	loss 0.126 (0.166)
Train: [1][210/589]	BT 0.363 (0.759)	DT 0.000 (0.390)	lr 0.0002	loss 0.153 (0.166)
Train: [1][220/589]	BT 0.357 (0.754)	DT 0.000 (0.384)	lr 0.0002	loss 0.172 (0.165)
Train: [1][230/589]	BT 0.358 (0.754)	DT 0.000 (0.385)	lr 0.0002	loss 0.146 (0.165)
Train: [1][240/589]	BT 0.359 (0.757)	DT 0.000 (0.388)	lr 0.0002	loss 0.164 (0.164)
Train: [1][250/589]	BT 0.359 (0.754)	DT 0.000 (0.386)	lr 0.0002	loss 0.152 (0.163)
Train: [1][260/589]	BT 0.357 (0.752)	DT 0.000 (0.384)	lr 0.0002	loss 0.148 (0.163)
Train: [1][270/589]	BT 0.362 (0.753)	DT 0.000 (0.385)	lr 0.0002	loss 0.167 (0.163)
Train: [1][280/589]	BT 0.359 (0.757)	DT 0.000 (0.389)	lr 0.0002	loss 0.151 (0.162)
Train: [1][290/589]	BT 0.362 (0.757)	DT 0.000 (0.390)	lr 0.0002	loss 0.137 (0.162)
Train: [1][300/589]	BT 0.372 (0.759)	DT 0.000 (0.392)	lr 0.0002	loss 0.137 (0.161)
Train: [1][310/589]	BT 0.361 (0.756)	DT 0.000 (0.390)	lr 0.0002	loss 0.130 (0.161)
Train: [1][320/589]	BT 0.395 (0.754)	DT 0.000 (0.387)	lr 0.0002	loss 0.132 (0.160)
Train: [1][330/589]	BT 0.359 (0.753)	DT 0.000 (0.387)	lr 0.0002	loss 0.163 (0.160)
Train: [1][340/589]	BT 0.360 (0.750)	DT 0.000 (0.384)	lr 0.0002	loss 0.138 (0.159)
Train: [1][350/589]	BT 0.357 (0.755)	DT 0.000 (0.389)	lr 0.0002	loss 0.148 (0.159)
Train: [1][360/589]	BT 0.359 (0.759)	DT 0.000 (0.393)	lr 0.0002	loss 0.143 (0.158)
Train: [1][370/589]	BT 0.382 (0.757)	DT 0.001 (0.391)	lr 0.0002	loss 0.142 (0.158)
Train: [1][380/589]	BT 0.366 (0.756)	DT 0.000 (0.390)	lr 0.0002	loss 0.173 (0.158)
Train: [1][390/589]	BT 0.710 (0.758)	DT 0.350 (0.392)	lr 0.0002	loss 0.145 (0.158)
Train: [1][400/589]	BT 0.387 (0.761)	DT 0.026 (0.395)	lr 0.0002	loss 0.141 (0.158)
Train: [1][410/589]	BT 0.357 (0.762)	DT 0.000 (0.396)	lr 0.0002	loss 0.159 (0.157)
Train: [1][420/589]	BT 0.358 (0.762)	DT 0.000 (0.397)	lr 0.0002	loss 0.134 (0.157)
Train: [1][430/589]	BT 0.359 (0.762)	DT 0.000 (0.397)	lr 0.0002	loss 0.127 (0.157)
Train: [1][440/589]	BT 0.357 (0.769)	DT 0.000 (0.404)	lr 0.0002	loss 0.157 (0.157)
Train: [1][450/589]	BT 0.358 (0.770)	DT 0.000 (0.405)	lr 0.0002	loss 0.172 (0.156)
Train: [1][460/589]	BT 0.359 (0.771)	DT 0.000 (0.406)	lr 0.0002	loss 0.119 (0.156)
Train: [1][470/589]	BT 0.360 (0.771)	DT 0.000 (0.407)	lr 0.0002	loss 0.174 (0.156)
Train: [1][480/589]	BT 0.358 (0.771)	DT 0.000 (0.407)	lr 0.0002	loss 0.140 (0.156)
Train: [1][490/589]	BT 0.358 (0.771)	DT 0.000 (0.406)	lr 0.0002	loss 0.166 (0.156)
Train: [1][500/589]	BT 0.358 (0.769)	DT 0.000 (0.405)	lr 0.0002	loss 0.173 (0.155)
Train: [1][510/589]	BT 0.357 (0.769)	DT 0.000 (0.405)	lr 0.0002	loss 0.140 (0.155)
Train: [1][520/589]	BT 0.358 (0.769)	DT 0.000 (0.405)	lr 0.0002	loss 0.152 (0.155)
Train: [1][530/589]	BT 0.358 (0.770)	DT 0.000 (0.406)	lr 0.0002	loss 0.132 (0.155)
Train: [1][540/589]	BT 0.356 (0.770)	DT 0.000 (0.406)	lr 0.0002	loss 0.141 (0.155)
Train: [1][550/589]	BT 0.358 (0.770)	DT 0.000 (0.406)	lr 0.0002	loss 0.178 (0.155)
Train: [1][560/589]	BT 0.358 (0.770)	DT 0.000 (0.407)	lr 0.0002	loss 0.137 (0.154)
Train: [1][570/589]	BT 0.358 (0.769)	DT 0.000 (0.405)	lr 0.0002	loss 0.148 (0.154)
Train: [1][580/589]	BT 0.358 (0.774)	DT 0.000 (0.411)	lr 0.0002	loss 0.157 (0.154)
epoch 1, total time 458.47
loss: 0.15414420778213955@Epoch: 1
learning_rate: 0.0002,1
Valid: [1][10/88]	BT 0.110 (1.068)	DT 0.000 (0.958)	loss 0.155 (0.156)
Valid: [1][20/88]	BT 0.109 (0.961)	DT 0.000 (0.851)	loss 0.152 (0.158)
Valid: [1][30/88]	BT 0.109 (0.956)	DT 0.000 (0.847)	loss 0.155 (0.153)
Valid: [1][40/88]	BT 0.109 (0.938)	DT 0.000 (0.828)	loss 0.141 (0.151)
Valid: [1][50/88]	BT 0.110 (0.914)	DT 0.000 (0.804)	loss 0.140 (0.150)
Valid: [1][60/88]	BT 0.109 (0.907)	DT 0.000 (0.798)	loss 0.159 (0.149)
Valid: [1][70/88]	BT 0.110 (0.891)	DT 0.000 (0.781)	loss 0.152 (0.148)
Valid: [1][80/88]	BT 0.109 (0.880)	DT 0.000 (0.771)	loss 0.148 (0.148)
Epoch 0001: val_loss improved from 100000.00000 to 0.14778, saving model
==> Saving...
Train: [2][10/589]	BT 0.359 (1.040)	DT 0.001 (0.544)	lr 0.0002	loss 0.150 (0.154)
Train: [2][20/589]	BT 0.384 (0.701)	DT 0.000 (0.272)	lr 0.0002	loss 0.153 (0.153)
Train: [2][30/589]	BT 0.384 (0.589)	DT 0.001 (0.182)	lr 0.0002	loss 0.139 (0.149)
Train: [2][40/589]	BT 0.361 (0.555)	DT 0.000 (0.159)	lr 0.0002	loss 0.150 (0.149)
Train: [2][50/589]	BT 0.357 (0.531)	DT 0.000 (0.142)	lr 0.0002	loss 0.122 (0.149)
Train: [2][60/589]	BT 0.359 (0.520)	DT 0.000 (0.135)	lr 0.0002	loss 0.152 (0.149)
Train: [2][70/589]	BT 0.383 (0.499)	DT 0.000 (0.117)	lr 0.0002	loss 0.129 (0.148)
Train: [2][80/589]	BT 0.357 (0.499)	DT 0.000 (0.119)	lr 0.0002	loss 0.142 (0.147)
Train: [2][90/589]	BT 0.369 (0.490)	DT 0.000 (0.112)	lr 0.0002	loss 0.127 (0.147)
Train: [2][100/589]	BT 0.369 (0.498)	DT 0.000 (0.122)	lr 0.0002	loss 0.161 (0.147)
Train: [2][110/589]	BT 0.360 (0.491)	DT 0.000 (0.116)	lr 0.0002	loss 0.141 (0.146)
Train: [2][120/589]	BT 0.399 (0.486)	DT 0.000 (0.112)	lr 0.0002	loss 0.141 (0.146)
Train: [2][130/589]	BT 0.359 (0.478)	DT 0.001 (0.105)	lr 0.0002	loss 0.125 (0.145)
Train: [2][140/589]	BT 0.374 (0.477)	DT 0.000 (0.104)	lr 0.0002	loss 0.164 (0.146)
Train: [2][150/589]	BT 0.367 (0.469)	DT 0.000 (0.098)	lr 0.0002	loss 0.132 (0.146)
Train: [2][160/589]	BT 0.375 (0.466)	DT 0.000 (0.095)	lr 0.0002	loss 0.137 (0.146)
Train: [2][170/589]	BT 0.359 (0.462)	DT 0.000 (0.091)	lr 0.0002	loss 0.130 (0.146)
Train: [2][180/589]	BT 0.378 (0.460)	DT 0.000 (0.090)	lr 0.0002	loss 0.127 (0.146)
Train: [2][190/589]	BT 0.359 (0.458)	DT 0.000 (0.088)	lr 0.0002	loss 0.143 (0.146)
Train: [2][200/589]	BT 0.358 (0.454)	DT 0.000 (0.085)	lr 0.0002	loss 0.143 (0.146)
Train: [2][210/589]	BT 0.362 (0.450)	DT 0.000 (0.081)	lr 0.0002	loss 0.149 (0.146)
Train: [2][220/589]	BT 0.362 (0.447)	DT 0.000 (0.078)	lr 0.0002	loss 0.122 (0.146)
Train: [2][230/589]	BT 0.374 (0.446)	DT 0.000 (0.077)	lr 0.0002	loss 0.132 (0.146)
Train: [2][240/589]	BT 0.359 (0.447)	DT 0.000 (0.079)	lr 0.0002	loss 0.154 (0.146)
Train: [2][250/589]	BT 0.357 (0.444)	DT 0.000 (0.076)	lr 0.0002	loss 0.142 (0.146)
Train: [2][260/589]	BT 0.360 (0.442)	DT 0.000 (0.075)	lr 0.0002	loss 0.142 (0.146)
Train: [2][270/589]	BT 0.359 (0.445)	DT 0.000 (0.078)	lr 0.0002	loss 0.121 (0.146)
Train: [2][280/589]	BT 0.363 (0.445)	DT 0.000 (0.078)	lr 0.0002	loss 0.129 (0.146)
Train: [2][290/589]	BT 0.357 (0.444)	DT 0.000 (0.078)	lr 0.0002	loss 0.140 (0.145)
Train: [2][300/589]	BT 0.359 (0.443)	DT 0.000 (0.076)	lr 0.0002	loss 0.150 (0.145)
Train: [2][310/589]	BT 0.358 (0.443)	DT 0.000 (0.077)	lr 0.0002	loss 0.131 (0.145)
Train: [2][320/589]	BT 0.359 (0.444)	DT 0.000 (0.078)	lr 0.0002	loss 0.125 (0.145)
Train: [2][330/589]	BT 0.382 (0.444)	DT 0.000 (0.078)	lr 0.0002	loss 0.142 (0.145)
Train: [2][340/589]	BT 0.358 (0.448)	DT 0.000 (0.081)	lr 0.0002	loss 0.165 (0.145)
Train: [2][350/589]	BT 0.359 (0.447)	DT 0.000 (0.081)	lr 0.0002	loss 0.173 (0.145)
Train: [2][360/589]	BT 0.360 (0.447)	DT 0.000 (0.081)	lr 0.0002	loss 0.155 (0.145)
Train: [2][370/589]	BT 0.359 (0.445)	DT 0.000 (0.079)	lr 0.0002	loss 0.154 (0.145)
Train: [2][380/589]	BT 0.358 (0.444)	DT 0.000 (0.079)	lr 0.0002	loss 0.140 (0.145)
Train: [2][390/589]	BT 0.400 (0.444)	DT 0.000 (0.078)	lr 0.0002	loss 0.138 (0.145)
Train: [2][400/589]	BT 0.362 (0.442)	DT 0.000 (0.076)	lr 0.0002	loss 0.150 (0.145)
Train: [2][410/589]	BT 0.359 (0.442)	DT 0.000 (0.076)	lr 0.0002	loss 0.146 (0.145)
Train: [2][420/589]	BT 0.364 (0.444)	DT 0.000 (0.079)	lr 0.0002	loss 0.140 (0.145)
Train: [2][430/589]	BT 0.358 (0.446)	DT 0.000 (0.080)	lr 0.0002	loss 0.153 (0.145)
Train: [2][440/589]	BT 0.361 (0.447)	DT 0.000 (0.081)	lr 0.0002	loss 0.163 (0.145)
Train: [2][450/589]	BT 0.359 (0.449)	DT 0.000 (0.083)	lr 0.0002	loss 0.156 (0.145)
Train: [2][460/589]	BT 0.360 (0.449)	DT 0.000 (0.084)	lr 0.0002	loss 0.149 (0.145)
Train: [2][470/589]	BT 0.360 (0.451)	DT 0.000 (0.085)	lr 0.0002	loss 0.133 (0.145)
Train: [2][480/589]	BT 0.360 (0.454)	DT 0.000 (0.088)	lr 0.0002	loss 0.128 (0.145)
Train: [2][490/589]	BT 0.361 (0.455)	DT 0.000 (0.089)	lr 0.0002	loss 0.162 (0.145)
Train: [2][500/589]	BT 0.359 (0.456)	DT 0.000 (0.091)	lr 0.0002	loss 0.138 (0.145)
Train: [2][510/589]	BT 0.357 (0.457)	DT 0.000 (0.092)	lr 0.0002	loss 0.163 (0.145)
Train: [2][520/589]	BT 0.358 (0.459)	DT 0.000 (0.094)	lr 0.0002	loss 0.154 (0.145)
Train: [2][530/589]	BT 0.388 (0.461)	DT 0.000 (0.096)	lr 0.0002	loss 0.146 (0.145)
Train: [2][540/589]	BT 0.357 (0.462)	DT 0.000 (0.097)	lr 0.0002	loss 0.124 (0.145)
Train: [2][550/589]	BT 0.359 (0.464)	DT 0.000 (0.099)	lr 0.0002	loss 0.158 (0.145)
Train: [2][560/589]	BT 0.358 (0.465)	DT 0.000 (0.100)	lr 0.0002	loss 0.156 (0.145)
Train: [2][570/589]	BT 0.385 (0.466)	DT 0.000 (0.101)	lr 0.0002	loss 0.131 (0.145)
Train: [2][580/589]	BT 0.358 (0.470)	DT 0.000 (0.105)	lr 0.0002	loss 0.133 (0.144)
epoch 2, total time 279.00
loss: 0.1443661108315434@Epoch: 2
learning_rate: 0.0002,2
Valid: [2][10/88]	BT 0.109 (0.729)	DT 0.000 (0.619)	loss 0.112 (0.135)
Valid: [2][20/88]	BT 0.109 (0.582)	DT 0.000 (0.471)	loss 0.131 (0.139)
Valid: [2][30/88]	BT 0.109 (0.543)	DT 0.000 (0.431)	loss 0.123 (0.138)
Valid: [2][40/88]	BT 0.110 (0.527)	DT 0.000 (0.415)	loss 0.150 (0.139)
Valid: [2][50/88]	BT 0.110 (0.522)	DT 0.000 (0.410)	loss 0.153 (0.139)
Valid: [2][60/88]	BT 0.128 (0.514)	DT 0.018 (0.402)	loss 0.140 (0.139)
Valid: [2][70/88]	BT 0.109 (0.518)	DT 0.000 (0.406)	loss 0.120 (0.139)
Valid: [2][80/88]	BT 0.109 (0.514)	DT 0.000 (0.402)	loss 0.141 (0.138)
Epoch 0002: val_loss improved from 0.14778 to 0.13849, saving model
==> Saving...
Train: [3][10/589]	BT 0.358 (0.837)	DT 0.000 (0.478)	lr 0.0002	loss 0.144 (0.146)
Train: [3][20/589]	BT 0.357 (0.618)	DT 0.000 (0.260)	lr 0.0002	loss 0.149 (0.146)
Train: [3][30/589]	BT 0.368 (0.590)	DT 0.000 (0.231)	lr 0.0002	loss 0.167 (0.145)
Train: [3][40/589]	BT 0.362 (0.567)	DT 0.000 (0.206)	lr 0.0002	loss 0.131 (0.143)
Train: [3][50/589]	BT 0.359 (0.526)	DT 0.000 (0.165)	lr 0.0002	loss 0.144 (0.143)
Train: [3][60/589]	BT 0.358 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.125 (0.143)
Train: [3][70/589]	BT 0.395 (0.491)	DT 0.000 (0.129)	lr 0.0002	loss 0.148 (0.143)
Train: [3][80/589]	BT 0.360 (0.479)	DT 0.000 (0.117)	lr 0.0002	loss 0.133 (0.143)
Train: [3][90/589]	BT 0.359 (0.474)	DT 0.000 (0.111)	lr 0.0002	loss 0.132 (0.142)
Train: [3][100/589]	BT 0.397 (0.477)	DT 0.000 (0.114)	lr 0.0002	loss 0.134 (0.142)
Train: [3][110/589]	BT 0.361 (0.472)	DT 0.000 (0.109)	lr 0.0002	loss 0.147 (0.142)
Train: [3][120/589]	BT 0.371 (0.467)	DT 0.000 (0.103)	lr 0.0002	loss 0.134 (0.142)
Train: [3][130/589]	BT 0.361 (0.465)	DT 0.000 (0.101)	lr 0.0002	loss 0.151 (0.142)
Train: [3][140/589]	BT 0.359 (0.463)	DT 0.000 (0.100)	lr 0.0002	loss 0.135 (0.142)
Train: [3][150/589]	BT 0.358 (0.471)	DT 0.000 (0.108)	lr 0.0002	loss 0.165 (0.142)
Train: [3][160/589]	BT 0.361 (0.470)	DT 0.000 (0.106)	lr 0.0002	loss 0.149 (0.142)
Train: [3][170/589]	BT 0.357 (0.470)	DT 0.000 (0.107)	lr 0.0002	loss 0.134 (0.142)
Train: [3][180/589]	BT 0.358 (0.480)	DT 0.000 (0.117)	lr 0.0002	loss 0.136 (0.142)
Train: [3][190/589]	BT 0.357 (0.482)	DT 0.000 (0.119)	lr 0.0002	loss 0.141 (0.142)
Train: [3][200/589]	BT 0.361 (0.480)	DT 0.000 (0.117)	lr 0.0002	loss 0.171 (0.142)
Train: [3][210/589]	BT 0.358 (0.480)	DT 0.000 (0.117)	lr 0.0002	loss 0.149 (0.142)
Train: [3][220/589]	BT 0.359 (0.478)	DT 0.000 (0.116)	lr 0.0002	loss 0.155 (0.142)
Train: [3][230/589]	BT 0.400 (0.483)	DT 0.000 (0.120)	lr 0.0002	loss 0.139 (0.141)
Train: [3][240/589]	BT 0.400 (0.482)	DT 0.000 (0.120)	lr 0.0002	loss 0.139 (0.141)
Train: [3][250/589]	BT 0.360 (0.482)	DT 0.000 (0.120)	lr 0.0002	loss 0.150 (0.141)
Train: [3][260/589]	BT 0.359 (0.482)	DT 0.000 (0.120)	lr 0.0002	loss 0.129 (0.141)
Train: [3][270/589]	BT 0.358 (0.483)	DT 0.000 (0.120)	lr 0.0002	loss 0.148 (0.141)
Train: [3][280/589]	BT 0.360 (0.482)	DT 0.000 (0.120)	lr 0.0002	loss 0.132 (0.141)
Train: [3][290/589]	BT 0.358 (0.482)	DT 0.000 (0.120)	lr 0.0002	loss 0.180 (0.141)
Train: [3][300/589]	BT 0.359 (0.479)	DT 0.000 (0.117)	lr 0.0002	loss 0.140 (0.141)
Train: [3][310/589]	BT 0.362 (0.479)	DT 0.000 (0.117)	lr 0.0002	loss 0.121 (0.142)
Train: [3][320/589]	BT 0.359 (0.477)	DT 0.000 (0.115)	lr 0.0002	loss 0.189 (0.142)
Train: [3][330/589]	BT 0.360 (0.476)	DT 0.000 (0.114)	lr 0.0002	loss 0.135 (0.142)
Train: [3][340/589]	BT 0.358 (0.474)	DT 0.000 (0.111)	lr 0.0002	loss 0.131 (0.142)
Train: [3][350/589]	BT 0.360 (0.472)	DT 0.000 (0.109)	lr 0.0002	loss 0.132 (0.142)
Train: [3][360/589]	BT 0.358 (0.469)	DT 0.001 (0.106)	lr 0.0002	loss 0.133 (0.142)
Train: [3][370/589]	BT 0.362 (0.468)	DT 0.000 (0.105)	lr 0.0002	loss 0.129 (0.142)
Train: [3][380/589]	BT 0.360 (0.469)	DT 0.000 (0.106)	lr 0.0002	loss 0.133 (0.142)
Train: [3][390/589]	BT 0.362 (0.468)	DT 0.000 (0.106)	lr 0.0002	loss 0.146 (0.142)
Train: [3][400/589]	BT 0.359 (0.467)	DT 0.000 (0.104)	lr 0.0002	loss 0.144 (0.142)
Train: [3][410/589]	BT 0.358 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.133 (0.142)
Train: [3][420/589]	BT 0.361 (0.465)	DT 0.000 (0.102)	lr 0.0002	loss 0.165 (0.142)
Train: [3][430/589]	BT 0.359 (0.465)	DT 0.000 (0.102)	lr 0.0002	loss 0.159 (0.142)
Train: [3][440/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.125 (0.142)
Train: [3][450/589]	BT 0.364 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.147 (0.142)
Train: [3][460/589]	BT 0.361 (0.467)	DT 0.000 (0.105)	lr 0.0002	loss 0.136 (0.142)
Train: [3][470/589]	BT 0.398 (0.467)	DT 0.000 (0.104)	lr 0.0002	loss 0.133 (0.142)
Train: [3][480/589]	BT 0.361 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.137 (0.142)
Train: [3][490/589]	BT 0.356 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.175 (0.142)
Train: [3][500/589]	BT 0.362 (0.465)	DT 0.001 (0.103)	lr 0.0002	loss 0.134 (0.142)
Train: [3][510/589]	BT 0.358 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.140 (0.142)
Train: [3][520/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.142 (0.142)
Train: [3][530/589]	BT 0.360 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.137 (0.142)
Train: [3][540/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.129 (0.142)
Train: [3][550/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.131 (0.142)
Train: [3][560/589]	BT 0.360 (0.468)	DT 0.000 (0.106)	lr 0.0002	loss 0.122 (0.142)
Train: [3][570/589]	BT 0.394 (0.467)	DT 0.000 (0.106)	lr 0.0002	loss 0.141 (0.142)
Train: [3][580/589]	BT 0.357 (0.467)	DT 0.000 (0.105)	lr 0.0002	loss 0.146 (0.142)
epoch 3, total time 275.86
loss: 0.14167120029573257@Epoch: 3
learning_rate: 0.0002,3
Valid: [3][10/88]	BT 0.110 (0.723)	DT 0.000 (0.612)	loss 0.149 (0.138)
Valid: [3][20/88]	BT 0.110 (0.617)	DT 0.000 (0.507)	loss 0.119 (0.139)
Valid: [3][30/88]	BT 0.110 (0.558)	DT 0.000 (0.448)	loss 0.130 (0.138)
Valid: [3][40/88]	BT 0.110 (0.527)	DT 0.000 (0.417)	loss 0.123 (0.137)
Valid: [3][50/88]	BT 0.110 (0.503)	DT 0.000 (0.392)	loss 0.147 (0.137)
Valid: [3][60/88]	BT 0.110 (0.489)	DT 0.000 (0.379)	loss 0.133 (0.136)
Valid: [3][70/88]	BT 0.109 (0.473)	DT 0.000 (0.363)	loss 0.122 (0.137)
Valid: [3][80/88]	BT 0.110 (0.468)	DT 0.000 (0.358)	loss 0.133 (0.136)
Epoch 0003: val_loss improved from 0.13849 to 0.13497, saving model
==> Saving...
Train: [4][10/589]	BT 0.360 (0.910)	DT 0.000 (0.543)	lr 0.0002	loss 0.139 (0.139)
Train: [4][20/589]	BT 0.358 (0.638)	DT 0.000 (0.273)	lr 0.0002	loss 0.126 (0.137)
Train: [4][30/589]	BT 0.359 (0.556)	DT 0.000 (0.193)	lr 0.0002	loss 0.139 (0.140)
Train: [4][40/589]	BT 0.372 (0.527)	DT 0.000 (0.163)	lr 0.0002	loss 0.148 (0.140)
Train: [4][50/589]	BT 0.400 (0.499)	DT 0.000 (0.136)	lr 0.0002	loss 0.158 (0.141)
Train: [4][60/589]	BT 0.359 (0.481)	DT 0.000 (0.118)	lr 0.0002	loss 0.121 (0.140)
Train: [4][70/589]	BT 0.401 (0.472)	DT 0.000 (0.108)	lr 0.0002	loss 0.152 (0.139)
Train: [4][80/589]	BT 0.357 (0.460)	DT 0.000 (0.097)	lr 0.0002	loss 0.125 (0.140)
Train: [4][90/589]	BT 0.358 (0.459)	DT 0.000 (0.097)	lr 0.0002	loss 0.150 (0.140)
Train: [4][100/589]	BT 0.397 (0.458)	DT 0.000 (0.095)	lr 0.0002	loss 0.151 (0.141)
Train: [4][110/589]	BT 0.369 (0.455)	DT 0.000 (0.092)	lr 0.0002	loss 0.149 (0.142)
Train: [4][120/589]	BT 0.362 (0.461)	DT 0.000 (0.098)	lr 0.0002	loss 0.136 (0.142)
Train: [4][130/589]	BT 0.358 (0.458)	DT 0.000 (0.096)	lr 0.0002	loss 0.144 (0.142)
Train: [4][140/589]	BT 0.358 (0.454)	DT 0.000 (0.091)	lr 0.0002	loss 0.131 (0.141)
Train: [4][150/589]	BT 0.357 (0.453)	DT 0.000 (0.091)	lr 0.0002	loss 0.169 (0.142)
Train: [4][160/589]	BT 0.357 (0.449)	DT 0.000 (0.087)	lr 0.0002	loss 0.122 (0.142)
Train: [4][170/589]	BT 0.360 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.144 (0.142)
Train: [4][180/589]	BT 0.359 (0.442)	DT 0.000 (0.080)	lr 0.0002	loss 0.156 (0.142)
Train: [4][190/589]	BT 0.361 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.125 (0.142)
Train: [4][200/589]	BT 0.393 (0.439)	DT 0.000 (0.076)	lr 0.0002	loss 0.150 (0.141)
Train: [4][210/589]	BT 0.360 (0.436)	DT 0.000 (0.074)	lr 0.0002	loss 0.135 (0.141)
Train: [4][220/589]	BT 0.360 (0.442)	DT 0.000 (0.080)	lr 0.0002	loss 0.177 (0.141)
Train: [4][230/589]	BT 0.363 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.158 (0.141)
Train: [4][240/589]	BT 0.394 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.155 (0.141)
Train: [4][250/589]	BT 0.362 (0.435)	DT 0.000 (0.073)	lr 0.0002	loss 0.136 (0.141)
Train: [4][260/589]	BT 0.367 (0.434)	DT 0.000 (0.071)	lr 0.0002	loss 0.135 (0.141)
Train: [4][270/589]	BT 0.356 (0.434)	DT 0.000 (0.072)	lr 0.0002	loss 0.174 (0.141)
Train: [4][280/589]	BT 0.359 (0.431)	DT 0.000 (0.069)	lr 0.0002	loss 0.159 (0.141)
Train: [4][290/589]	BT 0.379 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.142 (0.141)
Train: [4][300/589]	BT 0.361 (0.429)	DT 0.000 (0.066)	lr 0.0002	loss 0.124 (0.141)
Train: [4][310/589]	BT 0.387 (0.429)	DT 0.000 (0.066)	lr 0.0002	loss 0.116 (0.141)
Train: [4][320/589]	BT 0.358 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.126 (0.141)
Train: [4][330/589]	BT 0.359 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.141 (0.141)
Train: [4][340/589]	BT 0.360 (0.423)	DT 0.000 (0.060)	lr 0.0002	loss 0.121 (0.141)
Train: [4][350/589]	BT 0.363 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.145 (0.141)
Train: [4][360/589]	BT 0.368 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.128 (0.141)
Train: [4][370/589]	BT 0.358 (0.419)	DT 0.000 (0.056)	lr 0.0002	loss 0.160 (0.141)
Train: [4][380/589]	BT 0.359 (0.419)	DT 0.000 (0.056)	lr 0.0002	loss 0.148 (0.141)
Train: [4][390/589]	BT 0.360 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.142 (0.141)
Train: [4][400/589]	BT 0.363 (0.419)	DT 0.000 (0.056)	lr 0.0002	loss 0.147 (0.141)
Train: [4][410/589]	BT 0.361 (0.418)	DT 0.000 (0.055)	lr 0.0002	loss 0.144 (0.141)
Train: [4][420/589]	BT 0.361 (0.418)	DT 0.000 (0.055)	lr 0.0002	loss 0.161 (0.141)
Train: [4][430/589]	BT 0.361 (0.418)	DT 0.000 (0.055)	lr 0.0002	loss 0.164 (0.141)
Train: [4][440/589]	BT 0.358 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.127 (0.141)
Train: [4][450/589]	BT 0.360 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.133 (0.141)
Train: [4][460/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.157 (0.141)
Train: [4][470/589]	BT 0.360 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.155 (0.141)
Train: [4][480/589]	BT 0.362 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.135 (0.141)
Train: [4][490/589]	BT 0.359 (0.418)	DT 0.000 (0.055)	lr 0.0002	loss 0.132 (0.141)
Train: [4][500/589]	BT 0.369 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.124 (0.141)
Train: [4][510/589]	BT 0.359 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.154 (0.141)
Train: [4][520/589]	BT 0.362 (0.416)	DT 0.000 (0.053)	lr 0.0002	loss 0.171 (0.141)
Train: [4][530/589]	BT 0.360 (0.416)	DT 0.000 (0.053)	lr 0.0002	loss 0.152 (0.141)
Train: [4][540/589]	BT 0.363 (0.416)	DT 0.000 (0.053)	lr 0.0002	loss 0.133 (0.141)
Train: [4][550/589]	BT 0.360 (0.415)	DT 0.000 (0.052)	lr 0.0002	loss 0.136 (0.141)
Train: [4][560/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.133 (0.141)
Train: [4][570/589]	BT 0.361 (0.417)	DT 0.000 (0.054)	lr 0.0002	loss 0.162 (0.141)
Train: [4][580/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.160 (0.141)
epoch 4, total time 248.38
loss: 0.1404526339978809@Epoch: 4
learning_rate: 0.0002,4
Valid: [4][10/88]	BT 0.109 (0.629)	DT 0.000 (0.517)	loss 0.119 (0.127)
Valid: [4][20/88]	BT 0.109 (0.526)	DT 0.000 (0.413)	loss 0.146 (0.133)
Valid: [4][30/88]	BT 0.110 (0.490)	DT 0.000 (0.378)	loss 0.147 (0.135)
Valid: [4][40/88]	BT 0.110 (0.478)	DT 0.000 (0.367)	loss 0.146 (0.134)
Valid: [4][50/88]	BT 0.110 (0.471)	DT 0.000 (0.361)	loss 0.121 (0.133)
Valid: [4][60/88]	BT 0.110 (0.470)	DT 0.000 (0.360)	loss 0.129 (0.133)
Valid: [4][70/88]	BT 0.110 (0.486)	DT 0.000 (0.375)	loss 0.137 (0.133)
Valid: [4][80/88]	BT 0.110 (0.494)	DT 0.000 (0.384)	loss 0.146 (0.134)
Epoch 0004: val_loss improved from 0.13497 to 0.13492, saving model
==> Saving...
Train: [5][10/589]	BT 0.392 (1.005)	DT 0.000 (0.639)	lr 0.0002	loss 0.133 (0.138)
Train: [5][20/589]	BT 0.359 (0.701)	DT 0.000 (0.336)	lr 0.0002	loss 0.129 (0.139)
Train: [5][30/589]	BT 0.358 (0.588)	DT 0.000 (0.224)	lr 0.0002	loss 0.101 (0.139)
Train: [5][40/589]	BT 0.359 (0.536)	DT 0.000 (0.174)	lr 0.0002	loss 0.122 (0.139)
Train: [5][50/589]	BT 0.359 (0.525)	DT 0.000 (0.163)	lr 0.0002	loss 0.132 (0.140)
Train: [5][60/589]	BT 0.359 (0.499)	DT 0.000 (0.137)	lr 0.0002	loss 0.147 (0.139)
Train: [5][70/589]	BT 0.359 (0.489)	DT 0.000 (0.126)	lr 0.0002	loss 0.160 (0.140)
Train: [5][80/589]	BT 0.357 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.157 (0.139)
Train: [5][90/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.135 (0.139)
Train: [5][100/589]	BT 0.363 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.135 (0.138)
Train: [5][110/589]	BT 0.359 (0.461)	DT 0.000 (0.099)	lr 0.0002	loss 0.131 (0.138)
Train: [5][120/589]	BT 0.359 (0.454)	DT 0.000 (0.091)	lr 0.0002	loss 0.146 (0.139)
Train: [5][130/589]	BT 0.361 (0.448)	DT 0.000 (0.085)	lr 0.0002	loss 0.171 (0.139)
Train: [5][140/589]	BT 0.358 (0.445)	DT 0.000 (0.082)	lr 0.0002	loss 0.139 (0.139)
Train: [5][150/589]	BT 0.358 (0.440)	DT 0.000 (0.077)	lr 0.0002	loss 0.129 (0.139)
Train: [5][160/589]	BT 0.360 (0.442)	DT 0.000 (0.079)	lr 0.0002	loss 0.135 (0.139)
Train: [5][170/589]	BT 0.392 (0.441)	DT 0.000 (0.077)	lr 0.0002	loss 0.119 (0.139)
Train: [5][180/589]	BT 0.363 (0.439)	DT 0.000 (0.076)	lr 0.0002	loss 0.131 (0.139)
Train: [5][190/589]	BT 0.359 (0.436)	DT 0.000 (0.073)	lr 0.0002	loss 0.135 (0.140)
Train: [5][200/589]	BT 0.365 (0.435)	DT 0.000 (0.072)	lr 0.0002	loss 0.116 (0.139)
Train: [5][210/589]	BT 0.362 (0.436)	DT 0.000 (0.073)	lr 0.0002	loss 0.129 (0.139)
Train: [5][220/589]	BT 0.362 (0.433)	DT 0.000 (0.070)	lr 0.0002	loss 0.140 (0.139)
Train: [5][230/589]	BT 0.359 (0.430)	DT 0.000 (0.067)	lr 0.0002	loss 0.110 (0.139)
Train: [5][240/589]	BT 0.365 (0.428)	DT 0.000 (0.065)	lr 0.0002	loss 0.128 (0.139)
Train: [5][250/589]	BT 0.362 (0.428)	DT 0.000 (0.065)	lr 0.0002	loss 0.150 (0.139)
Train: [5][260/589]	BT 0.360 (0.426)	DT 0.000 (0.063)	lr 0.0002	loss 0.130 (0.139)
Train: [5][270/589]	BT 0.361 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.135 (0.139)
Train: [5][280/589]	BT 0.360 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.173 (0.139)
Train: [5][290/589]	BT 0.360 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.153 (0.139)
Train: [5][300/589]	BT 0.361 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.130 (0.139)
Train: [5][310/589]	BT 0.359 (0.426)	DT 0.000 (0.063)	lr 0.0002	loss 0.160 (0.139)
Train: [5][320/589]	BT 0.360 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.148 (0.139)
Train: [5][330/589]	BT 0.359 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.162 (0.139)
Train: [5][340/589]	BT 0.361 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.130 (0.139)
Train: [5][350/589]	BT 0.359 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.149 (0.139)
Train: [5][360/589]	BT 0.360 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.143 (0.139)
Train: [5][370/589]	BT 0.359 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.130 (0.139)
Train: [5][380/589]	BT 0.358 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.145 (0.139)
Train: [5][390/589]	BT 0.393 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.149 (0.139)
Train: [5][400/589]	BT 0.361 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.154 (0.139)
Train: [5][410/589]	BT 0.359 (0.421)	DT 0.000 (0.058)	lr 0.0002	loss 0.131 (0.139)
Train: [5][420/589]	BT 0.361 (0.420)	DT 0.000 (0.057)	lr 0.0002	loss 0.116 (0.139)
Train: [5][430/589]	BT 0.359 (0.422)	DT 0.000 (0.059)	lr 0.0002	loss 0.142 (0.139)
Train: [5][440/589]	BT 0.359 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.138 (0.139)
Train: [5][450/589]	BT 0.358 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.107 (0.139)
Train: [5][460/589]	BT 0.359 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.142 (0.139)
Train: [5][470/589]	BT 0.400 (0.424)	DT 0.000 (0.061)	lr 0.0002	loss 0.145 (0.139)
Train: [5][480/589]	BT 0.395 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.163 (0.139)
Train: [5][490/589]	BT 0.373 (0.422)	DT 0.000 (0.059)	lr 0.0002	loss 0.147 (0.139)
Train: [5][500/589]	BT 0.363 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.147 (0.139)
Train: [5][510/589]	BT 0.360 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.133 (0.139)
Train: [5][520/589]	BT 0.361 (0.421)	DT 0.000 (0.058)	lr 0.0002	loss 0.146 (0.139)
Train: [5][530/589]	BT 0.361 (0.421)	DT 0.000 (0.058)	lr 0.0002	loss 0.119 (0.139)
Train: [5][540/589]	BT 0.359 (0.420)	DT 0.000 (0.057)	lr 0.0002	loss 0.164 (0.139)
Train: [5][550/589]	BT 0.359 (0.420)	DT 0.000 (0.057)	lr 0.0002	loss 0.144 (0.139)
Train: [5][560/589]	BT 0.361 (0.419)	DT 0.000 (0.056)	lr 0.0002	loss 0.144 (0.139)
Train: [5][570/589]	BT 0.362 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.119 (0.139)
Train: [5][580/589]	BT 0.358 (0.420)	DT 0.000 (0.057)	lr 0.0002	loss 0.140 (0.139)
epoch 5, total time 247.43
loss: 0.13914554118983477@Epoch: 5
learning_rate: 0.0002,5
Valid: [5][10/88]	BT 0.110 (0.674)	DT 0.000 (0.563)	loss 0.122 (0.126)
Valid: [5][20/88]	BT 0.110 (0.566)	DT 0.000 (0.456)	loss 0.130 (0.129)
Valid: [5][30/88]	BT 0.110 (0.518)	DT 0.000 (0.408)	loss 0.131 (0.131)
Valid: [5][40/88]	BT 0.110 (0.484)	DT 0.000 (0.375)	loss 0.133 (0.131)
Valid: [5][50/88]	BT 0.109 (0.465)	DT 0.000 (0.355)	loss 0.132 (0.130)
Valid: [5][60/88]	BT 0.110 (0.454)	DT 0.000 (0.344)	loss 0.114 (0.131)
Valid: [5][70/88]	BT 0.110 (0.445)	DT 0.000 (0.335)	loss 0.142 (0.133)
Valid: [5][80/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.147 (0.133)
Epoch 0005: val_loss improved from 0.13492 to 0.13410, saving model
==> Saving...
Train: [6][10/589]	BT 0.380 (0.880)	DT 0.000 (0.520)	lr 0.0002	loss 0.179 (0.143)
Train: [6][20/589]	BT 0.405 (0.630)	DT 0.000 (0.268)	lr 0.0002	loss 0.140 (0.141)
Train: [6][30/589]	BT 0.362 (0.541)	DT 0.000 (0.179)	lr 0.0002	loss 0.135 (0.140)
Train: [6][40/589]	BT 0.362 (0.498)	DT 0.000 (0.135)	lr 0.0002	loss 0.135 (0.139)
Train: [6][50/589]	BT 0.389 (0.471)	DT 0.000 (0.108)	lr 0.0002	loss 0.135 (0.139)
Train: [6][60/589]	BT 0.363 (0.452)	DT 0.000 (0.090)	lr 0.0002	loss 0.128 (0.140)
Train: [6][70/589]	BT 0.360 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.138 (0.140)
Train: [6][80/589]	BT 0.362 (0.431)	DT 0.000 (0.068)	lr 0.0002	loss 0.108 (0.139)
Train: [6][90/589]	BT 0.363 (0.433)	DT 0.000 (0.070)	lr 0.0002	loss 0.124 (0.138)
Train: [6][100/589]	BT 0.393 (0.426)	DT 0.000 (0.063)	lr 0.0002	loss 0.127 (0.138)
Train: [6][110/589]	BT 0.361 (0.420)	DT 0.000 (0.058)	lr 0.0002	loss 0.132 (0.138)
Train: [6][120/589]	BT 0.359 (0.416)	DT 0.000 (0.053)	lr 0.0002	loss 0.139 (0.138)
Train: [6][130/589]	BT 0.358 (0.415)	DT 0.000 (0.052)	lr 0.0002	loss 0.150 (0.138)
Train: [6][140/589]	BT 0.361 (0.412)	DT 0.000 (0.048)	lr 0.0002	loss 0.135 (0.138)
Train: [6][150/589]	BT 0.360 (0.408)	DT 0.000 (0.045)	lr 0.0002	loss 0.136 (0.138)
Train: [6][160/589]	BT 0.359 (0.405)	DT 0.000 (0.042)	lr 0.0002	loss 0.140 (0.138)
Train: [6][170/589]	BT 0.362 (0.403)	DT 0.000 (0.040)	lr 0.0002	loss 0.135 (0.138)
Train: [6][180/589]	BT 0.363 (0.401)	DT 0.000 (0.037)	lr 0.0002	loss 0.150 (0.139)
Train: [6][190/589]	BT 0.360 (0.399)	DT 0.000 (0.035)	lr 0.0002	loss 0.121 (0.138)
Train: [6][200/589]	BT 0.360 (0.398)	DT 0.000 (0.034)	lr 0.0002	loss 0.132 (0.138)
Train: [6][210/589]	BT 0.360 (0.398)	DT 0.000 (0.034)	lr 0.0002	loss 0.119 (0.139)
Train: [6][220/589]	BT 0.358 (0.399)	DT 0.000 (0.035)	lr 0.0002	loss 0.148 (0.139)
Train: [6][230/589]	BT 0.361 (0.398)	DT 0.000 (0.033)	lr 0.0002	loss 0.149 (0.139)
Train: [6][240/589]	BT 0.362 (0.396)	DT 0.000 (0.032)	lr 0.0002	loss 0.157 (0.139)
Train: [6][250/589]	BT 0.377 (0.395)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.139)
Train: [6][260/589]	BT 0.383 (0.395)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.139)
Train: [6][270/589]	BT 0.360 (0.394)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.139)
Train: [6][280/589]	BT 0.360 (0.394)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.139)
Train: [6][290/589]	BT 0.359 (0.394)	DT 0.000 (0.030)	lr 0.0002	loss 0.164 (0.139)
Train: [6][300/589]	BT 0.362 (0.394)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.138)
Train: [6][310/589]	BT 0.361 (0.395)	DT 0.000 (0.030)	lr 0.0002	loss 0.144 (0.138)
Train: [6][320/589]	BT 0.358 (0.393)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.138)
Train: [6][330/589]	BT 0.362 (0.395)	DT 0.000 (0.031)	lr 0.0002	loss 0.133 (0.138)
Train: [6][340/589]	BT 0.358 (0.401)	DT 0.000 (0.037)	lr 0.0002	loss 0.121 (0.138)
Train: [6][350/589]	BT 0.364 (0.406)	DT 0.000 (0.042)	lr 0.0002	loss 0.144 (0.138)
Train: [6][360/589]	BT 0.359 (0.411)	DT 0.000 (0.047)	lr 0.0002	loss 0.136 (0.138)
Train: [6][370/589]	BT 0.357 (0.413)	DT 0.000 (0.049)	lr 0.0002	loss 0.144 (0.138)
Train: [6][380/589]	BT 0.358 (0.414)	DT 0.000 (0.051)	lr 0.0002	loss 0.160 (0.138)
Train: [6][390/589]	BT 0.361 (0.418)	DT 0.000 (0.055)	lr 0.0002	loss 0.125 (0.138)
Train: [6][400/589]	BT 0.361 (0.421)	DT 0.000 (0.057)	lr 0.0002	loss 0.135 (0.138)
Train: [6][410/589]	BT 0.362 (0.423)	DT 0.000 (0.059)	lr 0.0002	loss 0.136 (0.138)
Train: [6][420/589]	BT 0.361 (0.424)	DT 0.000 (0.060)	lr 0.0002	loss 0.142 (0.138)
Train: [6][430/589]	BT 0.357 (0.426)	DT 0.000 (0.063)	lr 0.0002	loss 0.139 (0.138)
Train: [6][440/589]	BT 0.389 (0.428)	DT 0.000 (0.064)	lr 0.0002	loss 0.146 (0.138)
Train: [6][450/589]	BT 0.358 (0.432)	DT 0.000 (0.068)	lr 0.0002	loss 0.153 (0.138)
Train: [6][460/589]	BT 0.360 (0.432)	DT 0.000 (0.069)	lr 0.0002	loss 0.121 (0.138)
Train: [6][470/589]	BT 0.370 (0.435)	DT 0.000 (0.072)	lr 0.0002	loss 0.146 (0.138)
Train: [6][480/589]	BT 0.369 (0.437)	DT 0.000 (0.074)	lr 0.0002	loss 0.138 (0.138)
Train: [6][490/589]	BT 0.358 (0.439)	DT 0.000 (0.076)	lr 0.0002	loss 0.125 (0.138)
Train: [6][500/589]	BT 0.360 (0.440)	DT 0.000 (0.077)	lr 0.0002	loss 0.113 (0.138)
Train: [6][510/589]	BT 0.358 (0.441)	DT 0.000 (0.078)	lr 0.0002	loss 0.122 (0.138)
Train: [6][520/589]	BT 0.359 (0.443)	DT 0.000 (0.080)	lr 0.0002	loss 0.152 (0.138)
Train: [6][530/589]	BT 0.361 (0.444)	DT 0.000 (0.081)	lr 0.0002	loss 0.136 (0.138)
Train: [6][540/589]	BT 0.359 (0.445)	DT 0.000 (0.082)	lr 0.0002	loss 0.147 (0.138)
Train: [6][550/589]	BT 0.358 (0.445)	DT 0.000 (0.082)	lr 0.0002	loss 0.133 (0.138)
Train: [6][560/589]	BT 0.359 (0.448)	DT 0.000 (0.085)	lr 0.0002	loss 0.151 (0.138)
Train: [6][570/589]	BT 0.361 (0.449)	DT 0.000 (0.086)	lr 0.0002	loss 0.118 (0.138)
Train: [6][580/589]	BT 0.360 (0.449)	DT 0.000 (0.086)	lr 0.0002	loss 0.149 (0.138)
epoch 6, total time 266.80
loss: 0.1382484187270923@Epoch: 6
learning_rate: 0.0002,6
Valid: [6][10/88]	BT 0.109 (0.707)	DT 0.000 (0.593)	loss 0.148 (0.134)
Valid: [6][20/88]	BT 0.110 (0.593)	DT 0.000 (0.480)	loss 0.124 (0.131)
Valid: [6][30/88]	BT 0.110 (0.559)	DT 0.000 (0.446)	loss 0.138 (0.133)
Valid: [6][40/88]	BT 0.110 (0.560)	DT 0.000 (0.448)	loss 0.141 (0.134)
Valid: [6][50/88]	BT 0.109 (0.540)	DT 0.000 (0.428)	loss 0.141 (0.133)
Valid: [6][60/88]	BT 0.110 (0.530)	DT 0.000 (0.419)	loss 0.135 (0.134)
Valid: [6][70/88]	BT 0.109 (0.536)	DT 0.000 (0.425)	loss 0.104 (0.133)
Valid: [6][80/88]	BT 0.110 (0.534)	DT 0.000 (0.423)	loss 0.161 (0.134)
Epoch 0006: val_loss improved from 0.13410 to 0.13343, saving model
==> Saving...
Train: [7][10/589]	BT 0.399 (1.094)	DT 0.000 (0.731)	lr 0.0002	loss 0.150 (0.133)
Train: [7][20/589]	BT 0.355 (0.795)	DT 0.000 (0.434)	lr 0.0002	loss 0.138 (0.135)
Train: [7][30/589]	BT 0.358 (0.678)	DT 0.000 (0.318)	lr 0.0002	loss 0.117 (0.138)
Train: [7][40/589]	BT 0.356 (0.625)	DT 0.000 (0.264)	lr 0.0002	loss 0.155 (0.137)
Train: [7][50/589]	BT 0.360 (0.600)	DT 0.000 (0.240)	lr 0.0002	loss 0.135 (0.138)
Train: [7][60/589]	BT 0.358 (0.585)	DT 0.000 (0.225)	lr 0.0002	loss 0.157 (0.139)
Train: [7][70/589]	BT 0.367 (0.567)	DT 0.000 (0.207)	lr 0.0002	loss 0.151 (0.139)
Train: [7][80/589]	BT 0.358 (0.545)	DT 0.000 (0.185)	lr 0.0002	loss 0.117 (0.139)
Train: [7][90/589]	BT 0.358 (0.536)	DT 0.000 (0.175)	lr 0.0002	loss 0.138 (0.138)
Train: [7][100/589]	BT 0.361 (0.536)	DT 0.000 (0.176)	lr 0.0002	loss 0.136 (0.139)
Train: [7][110/589]	BT 0.362 (0.531)	DT 0.000 (0.171)	lr 0.0002	loss 0.116 (0.139)
Train: [7][120/589]	BT 0.360 (0.528)	DT 0.000 (0.168)	lr 0.0002	loss 0.142 (0.139)
Train: [7][130/589]	BT 0.395 (0.524)	DT 0.000 (0.164)	lr 0.0002	loss 0.146 (0.139)
Train: [7][140/589]	BT 0.357 (0.524)	DT 0.000 (0.164)	lr 0.0002	loss 0.127 (0.139)
Train: [7][150/589]	BT 0.387 (0.524)	DT 0.000 (0.163)	lr 0.0002	loss 0.117 (0.139)
Train: [7][160/589]	BT 0.361 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.128 (0.138)
Train: [7][170/589]	BT 0.358 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.135 (0.138)
Train: [7][180/589]	BT 0.358 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.151 (0.138)
Train: [7][190/589]	BT 0.358 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.116 (0.138)
Train: [7][200/589]	BT 0.365 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.115 (0.137)
Train: [7][210/589]	BT 0.357 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.147 (0.137)
Train: [7][220/589]	BT 0.372 (0.511)	DT 0.000 (0.150)	lr 0.0002	loss 0.125 (0.137)
Train: [7][230/589]	BT 0.359 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.153 (0.137)
Train: [7][240/589]	BT 0.381 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.149 (0.138)
Train: [7][250/589]	BT 0.369 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.119 (0.138)
Train: [7][260/589]	BT 0.359 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.115 (0.137)
Train: [7][270/589]	BT 0.358 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.147 (0.137)
Train: [7][280/589]	BT 0.359 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.154 (0.137)
Train: [7][290/589]	BT 0.357 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.128 (0.137)
Train: [7][300/589]	BT 0.360 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.136 (0.137)
Train: [7][310/589]	BT 0.359 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.126 (0.137)
Train: [7][320/589]	BT 0.359 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.158 (0.137)
Train: [7][330/589]	BT 0.396 (0.516)	DT 0.000 (0.154)	lr 0.0002	loss 0.130 (0.137)
Train: [7][340/589]	BT 0.358 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.119 (0.137)
Train: [7][350/589]	BT 0.360 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.131 (0.137)
Train: [7][360/589]	BT 0.361 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.152 (0.137)
Train: [7][370/589]	BT 0.387 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.155 (0.137)
Train: [7][380/589]	BT 0.367 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.145 (0.137)
Train: [7][390/589]	BT 0.359 (0.519)	DT 0.000 (0.157)	lr 0.0002	loss 0.120 (0.137)
Train: [7][400/589]	BT 0.358 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.156 (0.137)
Train: [7][410/589]	BT 0.359 (0.518)	DT 0.000 (0.156)	lr 0.0002	loss 0.154 (0.137)
Train: [7][420/589]	BT 0.364 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.127 (0.137)
Train: [7][430/589]	BT 0.359 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.137 (0.137)
Train: [7][440/589]	BT 0.357 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.118 (0.137)
Train: [7][450/589]	BT 0.360 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.155 (0.138)
Train: [7][460/589]	BT 0.359 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.135 (0.138)
Train: [7][470/589]	BT 0.359 (0.516)	DT 0.000 (0.154)	lr 0.0002	loss 0.150 (0.138)
Train: [7][480/589]	BT 0.358 (0.516)	DT 0.000 (0.154)	lr 0.0002	loss 0.140 (0.138)
Train: [7][490/589]	BT 0.358 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.147 (0.138)
Train: [7][500/589]	BT 0.358 (0.515)	DT 0.000 (0.153)	lr 0.0002	loss 0.134 (0.138)
Train: [7][510/589]	BT 0.358 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.135 (0.138)
Train: [7][520/589]	BT 0.360 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.126 (0.138)
Train: [7][530/589]	BT 0.358 (0.515)	DT 0.000 (0.153)	lr 0.0002	loss 0.112 (0.138)
Train: [7][540/589]	BT 0.357 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.126 (0.138)
Train: [7][550/589]	BT 0.358 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.131 (0.137)
Train: [7][560/589]	BT 0.357 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.143 (0.137)
Train: [7][570/589]	BT 0.360 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.147 (0.138)
Train: [7][580/589]	BT 0.358 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.146 (0.137)
epoch 7, total time 304.89
loss: 0.13751956340244476@Epoch: 7
learning_rate: 0.0002,7
Valid: [7][10/88]	BT 0.110 (0.764)	DT 0.000 (0.652)	loss 0.122 (0.134)
Valid: [7][20/88]	BT 0.110 (0.639)	DT 0.000 (0.527)	loss 0.134 (0.133)
Valid: [7][30/88]	BT 0.109 (0.575)	DT 0.000 (0.463)	loss 0.141 (0.135)
Valid: [7][40/88]	BT 0.110 (0.559)	DT 0.000 (0.447)	loss 0.155 (0.134)
Valid: [7][50/88]	BT 0.110 (0.561)	DT 0.000 (0.449)	loss 0.134 (0.133)
Valid: [7][60/88]	BT 0.110 (0.546)	DT 0.000 (0.434)	loss 0.151 (0.133)
Valid: [7][70/88]	BT 0.109 (0.538)	DT 0.000 (0.426)	loss 0.119 (0.134)
Valid: [7][80/88]	BT 0.110 (0.544)	DT 0.000 (0.433)	loss 0.108 (0.134)
Train: [8][10/589]	BT 0.390 (0.941)	DT 0.000 (0.574)	lr 0.0002	loss 0.117 (0.131)
Train: [8][20/589]	BT 0.361 (0.685)	DT 0.000 (0.320)	lr 0.0002	loss 0.144 (0.135)
Train: [8][30/589]	BT 0.361 (0.592)	DT 0.000 (0.229)	lr 0.0002	loss 0.149 (0.138)
Train: [8][40/589]	BT 0.363 (0.556)	DT 0.000 (0.193)	lr 0.0002	loss 0.142 (0.137)
Train: [8][50/589]	BT 0.359 (0.535)	DT 0.000 (0.172)	lr 0.0002	loss 0.124 (0.138)
Train: [8][60/589]	BT 0.359 (0.507)	DT 0.000 (0.144)	lr 0.0002	loss 0.141 (0.139)
Train: [8][70/589]	BT 0.391 (0.497)	DT 0.000 (0.134)	lr 0.0002	loss 0.151 (0.139)
Train: [8][80/589]	BT 0.359 (0.480)	DT 0.000 (0.118)	lr 0.0002	loss 0.112 (0.138)
Train: [8][90/589]	BT 0.372 (0.472)	DT 0.001 (0.109)	lr 0.0002	loss 0.110 (0.138)
Train: [8][100/589]	BT 0.362 (0.463)	DT 0.000 (0.100)	lr 0.0002	loss 0.156 (0.138)
Train: [8][110/589]	BT 0.361 (0.463)	DT 0.000 (0.100)	lr 0.0002	loss 0.137 (0.138)
Train: [8][120/589]	BT 0.357 (0.460)	DT 0.000 (0.096)	lr 0.0002	loss 0.144 (0.138)
Train: [8][130/589]	BT 0.359 (0.453)	DT 0.000 (0.090)	lr 0.0002	loss 0.137 (0.137)
Train: [8][140/589]	BT 0.359 (0.451)	DT 0.000 (0.088)	lr 0.0002	loss 0.127 (0.137)
Train: [8][150/589]	BT 0.361 (0.450)	DT 0.000 (0.088)	lr 0.0002	loss 0.138 (0.137)
Train: [8][160/589]	BT 0.359 (0.449)	DT 0.000 (0.086)	lr 0.0002	loss 0.110 (0.137)
Train: [8][170/589]	BT 0.359 (0.450)	DT 0.000 (0.087)	lr 0.0002	loss 0.142 (0.137)
Train: [8][180/589]	BT 0.361 (0.450)	DT 0.000 (0.087)	lr 0.0002	loss 0.158 (0.137)
Train: [8][190/589]	BT 0.359 (0.446)	DT 0.000 (0.084)	lr 0.0002	loss 0.164 (0.137)
Train: [8][200/589]	BT 0.360 (0.446)	DT 0.000 (0.084)	lr 0.0002	loss 0.135 (0.137)
Train: [8][210/589]	BT 0.374 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.133 (0.137)
Train: [8][220/589]	BT 0.358 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.155 (0.137)
Train: [8][230/589]	BT 0.359 (0.444)	DT 0.000 (0.082)	lr 0.0002	loss 0.130 (0.137)
Train: [8][240/589]	BT 0.358 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.140 (0.137)
Train: [8][250/589]	BT 0.360 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.161 (0.137)
Train: [8][260/589]	BT 0.360 (0.437)	DT 0.000 (0.075)	lr 0.0002	loss 0.163 (0.138)
Train: [8][270/589]	BT 0.363 (0.437)	DT 0.000 (0.075)	lr 0.0002	loss 0.139 (0.137)
Train: [8][280/589]	BT 0.359 (0.439)	DT 0.000 (0.077)	lr 0.0002	loss 0.134 (0.137)
Train: [8][290/589]	BT 0.360 (0.442)	DT 0.000 (0.080)	lr 0.0002	loss 0.129 (0.137)
Train: [8][300/589]	BT 0.364 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.131 (0.137)
Train: [8][310/589]	BT 0.358 (0.444)	DT 0.000 (0.081)	lr 0.0002	loss 0.166 (0.138)
Train: [8][320/589]	BT 0.360 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.116 (0.137)
Train: [8][330/589]	BT 0.360 (0.444)	DT 0.000 (0.082)	lr 0.0002	loss 0.148 (0.137)
Train: [8][340/589]	BT 0.359 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.146 (0.137)
Train: [8][350/589]	BT 0.358 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.131 (0.137)
Train: [8][360/589]	BT 0.361 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.142 (0.137)
Train: [8][370/589]	BT 0.358 (0.446)	DT 0.000 (0.084)	lr 0.0002	loss 0.124 (0.137)
Train: [8][380/589]	BT 0.357 (0.446)	DT 0.000 (0.084)	lr 0.0002	loss 0.148 (0.137)
Train: [8][390/589]	BT 0.358 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.142 (0.137)
Train: [8][400/589]	BT 0.360 (0.448)	DT 0.000 (0.086)	lr 0.0002	loss 0.149 (0.137)
Train: [8][410/589]	BT 0.358 (0.446)	DT 0.000 (0.084)	lr 0.0002	loss 0.124 (0.137)
Train: [8][420/589]	BT 0.359 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.124 (0.137)
Train: [8][430/589]	BT 0.359 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.138 (0.137)
Train: [8][440/589]	BT 0.359 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.116 (0.137)
Train: [8][450/589]	BT 0.364 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.143 (0.137)
Train: [8][460/589]	BT 0.365 (0.450)	DT 0.000 (0.088)	lr 0.0002	loss 0.141 (0.137)
Train: [8][470/589]	BT 0.358 (0.449)	DT 0.000 (0.087)	lr 0.0002	loss 0.113 (0.137)
Train: [8][480/589]	BT 0.374 (0.450)	DT 0.000 (0.088)	lr 0.0002	loss 0.143 (0.137)
Train: [8][490/589]	BT 0.360 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.120 (0.137)
Train: [8][500/589]	BT 0.360 (0.454)	DT 0.000 (0.092)	lr 0.0002	loss 0.130 (0.137)
Train: [8][510/589]	BT 0.358 (0.456)	DT 0.000 (0.094)	lr 0.0002	loss 0.152 (0.137)
Train: [8][520/589]	BT 0.359 (0.457)	DT 0.000 (0.095)	lr 0.0002	loss 0.115 (0.137)
Train: [8][530/589]	BT 0.358 (0.458)	DT 0.000 (0.097)	lr 0.0002	loss 0.148 (0.137)
Train: [8][540/589]	BT 0.358 (0.460)	DT 0.000 (0.098)	lr 0.0002	loss 0.143 (0.137)
Train: [8][550/589]	BT 0.379 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.130 (0.137)
Train: [8][560/589]	BT 0.358 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.151 (0.137)
Train: [8][570/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.153 (0.137)
Train: [8][580/589]	BT 0.359 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.150 (0.137)
epoch 8, total time 274.08
loss: 0.13702411450396582@Epoch: 8
learning_rate: 0.0002,8
Valid: [8][10/88]	BT 0.110 (0.913)	DT 0.000 (0.802)	loss 0.146 (0.127)
Valid: [8][20/88]	BT 0.110 (0.716)	DT 0.000 (0.606)	loss 0.110 (0.128)
Valid: [8][30/88]	BT 0.109 (0.670)	DT 0.000 (0.560)	loss 0.147 (0.131)
Valid: [8][40/88]	BT 0.109 (0.640)	DT 0.000 (0.530)	loss 0.140 (0.131)
Valid: [8][50/88]	BT 0.109 (0.616)	DT 0.000 (0.506)	loss 0.143 (0.131)
Valid: [8][60/88]	BT 0.110 (0.593)	DT 0.000 (0.482)	loss 0.133 (0.131)
Valid: [8][70/88]	BT 0.110 (0.576)	DT 0.000 (0.466)	loss 0.128 (0.133)
Valid: [8][80/88]	BT 0.110 (0.571)	DT 0.000 (0.461)	loss 0.103 (0.133)
Epoch 0008: val_loss improved from 0.13343 to 0.13249, saving model
==> Saving...
Train: [9][10/589]	BT 0.357 (0.899)	DT 0.000 (0.540)	lr 0.0002	loss 0.118 (0.128)
Train: [9][20/589]	BT 0.358 (0.667)	DT 0.000 (0.307)	lr 0.0002	loss 0.141 (0.129)
Train: [9][30/589]	BT 0.357 (0.618)	DT 0.000 (0.256)	lr 0.0002	loss 0.148 (0.133)
Train: [9][40/589]	BT 0.358 (0.580)	DT 0.000 (0.219)	lr 0.0002	loss 0.151 (0.135)
Train: [9][50/589]	BT 0.356 (0.544)	DT 0.000 (0.183)	lr 0.0002	loss 0.133 (0.135)
Train: [9][60/589]	BT 0.358 (0.526)	DT 0.000 (0.165)	lr 0.0002	loss 0.141 (0.136)
Train: [9][70/589]	BT 0.358 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.137 (0.137)
Train: [9][80/589]	BT 0.356 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.138 (0.136)
Train: [9][90/589]	BT 0.359 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.108 (0.136)
Train: [9][100/589]	BT 0.358 (0.507)	DT 0.000 (0.146)	lr 0.0002	loss 0.152 (0.136)
Train: [9][110/589]	BT 0.359 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.154 (0.137)
Train: [9][120/589]	BT 0.358 (0.512)	DT 0.000 (0.151)	lr 0.0002	loss 0.151 (0.137)
Train: [9][130/589]	BT 0.359 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.130 (0.137)
Train: [9][140/589]	BT 0.359 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.139 (0.137)
Train: [9][150/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.130 (0.137)
Train: [9][160/589]	BT 0.359 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.127 (0.137)
Train: [9][170/589]	BT 0.387 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.106 (0.137)
Train: [9][180/589]	BT 0.398 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.159 (0.137)
Train: [9][190/589]	BT 0.359 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.167 (0.137)
Train: [9][200/589]	BT 0.358 (0.511)	DT 0.000 (0.150)	lr 0.0002	loss 0.114 (0.137)
Train: [9][210/589]	BT 0.362 (0.511)	DT 0.000 (0.150)	lr 0.0002	loss 0.145 (0.137)
Train: [9][220/589]	BT 0.358 (0.508)	DT 0.000 (0.146)	lr 0.0002	loss 0.160 (0.138)
Train: [9][230/589]	BT 0.373 (0.506)	DT 0.000 (0.145)	lr 0.0002	loss 0.112 (0.137)
Train: [9][240/589]	BT 0.358 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.162 (0.137)
Train: [9][250/589]	BT 0.359 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.158 (0.138)
Train: [9][260/589]	BT 0.358 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.120 (0.138)
Train: [9][270/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.130 (0.137)
Train: [9][280/589]	BT 0.358 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.114 (0.137)
Train: [9][290/589]	BT 0.360 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.126 (0.137)
Train: [9][300/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.133 (0.137)
Train: [9][310/589]	BT 0.362 (0.502)	DT 0.000 (0.140)	lr 0.0002	loss 0.121 (0.137)
Train: [9][320/589]	BT 0.360 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.132 (0.137)
Train: [9][330/589]	BT 0.361 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.131 (0.137)
Train: [9][340/589]	BT 0.360 (0.498)	DT 0.000 (0.136)	lr 0.0002	loss 0.138 (0.137)
Train: [9][350/589]	BT 0.370 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.116 (0.137)
Train: [9][360/589]	BT 0.373 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.116 (0.137)
Train: [9][370/589]	BT 0.392 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.120 (0.137)
Train: [9][380/589]	BT 0.360 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.155 (0.137)
Train: [9][390/589]	BT 0.364 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.127 (0.137)
Train: [9][400/589]	BT 0.362 (0.486)	DT 0.000 (0.124)	lr 0.0002	loss 0.125 (0.137)
Train: [9][410/589]	BT 0.367 (0.483)	DT 0.000 (0.121)	lr 0.0002	loss 0.133 (0.137)
Train: [9][420/589]	BT 0.360 (0.480)	DT 0.000 (0.119)	lr 0.0002	loss 0.118 (0.137)
Train: [9][430/589]	BT 0.360 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.125 (0.137)
Train: [9][440/589]	BT 0.360 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.133 (0.136)
Train: [9][450/589]	BT 0.360 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.124 (0.136)
Train: [9][460/589]	BT 0.359 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.141 (0.136)
Train: [9][470/589]	BT 0.358 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.128 (0.136)
Train: [9][480/589]	BT 0.359 (0.468)	DT 0.000 (0.106)	lr 0.0002	loss 0.152 (0.136)
Train: [9][490/589]	BT 0.361 (0.466)	DT 0.000 (0.105)	lr 0.0002	loss 0.131 (0.136)
Train: [9][500/589]	BT 0.361 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.111 (0.136)
Train: [9][510/589]	BT 0.360 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.151 (0.136)
Train: [9][520/589]	BT 0.361 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.126 (0.136)
Train: [9][530/589]	BT 0.360 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.174 (0.136)
Train: [9][540/589]	BT 0.360 (0.460)	DT 0.000 (0.098)	lr 0.0002	loss 0.116 (0.136)
Train: [9][550/589]	BT 0.358 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.158 (0.136)
Train: [9][560/589]	BT 0.359 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.142 (0.136)
Train: [9][570/589]	BT 0.359 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.132 (0.136)
Train: [9][580/589]	BT 0.359 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.128 (0.136)
epoch 9, total time 272.84
loss: 0.13616242397134157@Epoch: 9
learning_rate: 0.0002,9
Valid: [9][10/88]	BT 0.110 (0.593)	DT 0.000 (0.483)	loss 0.141 (0.131)
Valid: [9][20/88]	BT 0.110 (0.549)	DT 0.000 (0.437)	loss 0.117 (0.134)
Valid: [9][30/88]	BT 0.109 (0.494)	DT 0.000 (0.383)	loss 0.129 (0.131)
Valid: [9][40/88]	BT 0.110 (0.458)	DT 0.000 (0.347)	loss 0.150 (0.132)
Valid: [9][50/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.147 (0.133)
Valid: [9][60/88]	BT 0.110 (0.425)	DT 0.000 (0.315)	loss 0.172 (0.133)
Valid: [9][70/88]	BT 0.109 (0.409)	DT 0.000 (0.299)	loss 0.153 (0.134)
Valid: [9][80/88]	BT 0.110 (0.402)	DT 0.000 (0.292)	loss 0.110 (0.133)
Train: [10][10/589]	BT 0.363 (0.838)	DT 0.000 (0.480)	lr 0.0002	loss 0.140 (0.130)
Train: [10][20/589]	BT 0.358 (0.599)	DT 0.000 (0.240)	lr 0.0002	loss 0.143 (0.132)
Train: [10][30/589]	BT 0.360 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.125 (0.134)
Train: [10][40/589]	BT 0.361 (0.489)	DT 0.000 (0.127)	lr 0.0002	loss 0.115 (0.132)
Train: [10][50/589]	BT 0.361 (0.464)	DT 0.000 (0.102)	lr 0.0002	loss 0.119 (0.132)
Train: [10][60/589]	BT 0.360 (0.447)	DT 0.000 (0.085)	lr 0.0002	loss 0.135 (0.133)
Train: [10][70/589]	BT 0.362 (0.435)	DT 0.000 (0.073)	lr 0.0002	loss 0.140 (0.134)
Train: [10][80/589]	BT 0.362 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.146 (0.134)
Train: [10][90/589]	BT 0.360 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.145 (0.135)
Train: [10][100/589]	BT 0.359 (0.414)	DT 0.000 (0.051)	lr 0.0002	loss 0.112 (0.134)
Train: [10][110/589]	BT 0.360 (0.409)	DT 0.000 (0.046)	lr 0.0002	loss 0.147 (0.134)
Train: [10][120/589]	BT 0.359 (0.405)	DT 0.000 (0.042)	lr 0.0002	loss 0.141 (0.135)
Train: [10][130/589]	BT 0.360 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.127 (0.135)
Train: [10][140/589]	BT 0.360 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.111 (0.135)
Train: [10][150/589]	BT 0.363 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.116 (0.135)
Train: [10][160/589]	BT 0.360 (0.394)	DT 0.000 (0.032)	lr 0.0002	loss 0.138 (0.135)
Train: [10][170/589]	BT 0.359 (0.392)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.135)
Train: [10][180/589]	BT 0.361 (0.390)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.135)
Train: [10][190/589]	BT 0.361 (0.389)	DT 0.000 (0.027)	lr 0.0002	loss 0.111 (0.134)
Train: [10][200/589]	BT 0.361 (0.388)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.134)
Train: [10][210/589]	BT 0.360 (0.386)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.134)
Train: [10][220/589]	BT 0.361 (0.385)	DT 0.000 (0.023)	lr 0.0002	loss 0.153 (0.135)
Train: [10][230/589]	BT 0.359 (0.384)	DT 0.000 (0.022)	lr 0.0002	loss 0.149 (0.135)
Train: [10][240/589]	BT 0.362 (0.387)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.135)
Train: [10][250/589]	BT 0.361 (0.387)	DT 0.000 (0.025)	lr 0.0002	loss 0.140 (0.135)
Train: [10][260/589]	BT 0.363 (0.386)	DT 0.000 (0.024)	lr 0.0002	loss 0.149 (0.135)
Train: [10][270/589]	BT 0.360 (0.385)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.135)
Train: [10][280/589]	BT 0.365 (0.384)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.135)
Train: [10][290/589]	BT 0.360 (0.383)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.135)
Train: [10][300/589]	BT 0.361 (0.383)	DT 0.000 (0.021)	lr 0.0002	loss 0.153 (0.135)
Train: [10][310/589]	BT 0.392 (0.382)	DT 0.000 (0.020)	lr 0.0002	loss 0.150 (0.135)
Train: [10][320/589]	BT 0.383 (0.382)	DT 0.000 (0.019)	lr 0.0002	loss 0.135 (0.135)
Train: [10][330/589]	BT 0.360 (0.381)	DT 0.000 (0.019)	lr 0.0002	loss 0.123 (0.135)
Train: [10][340/589]	BT 0.359 (0.381)	DT 0.000 (0.018)	lr 0.0002	loss 0.142 (0.135)
Train: [10][350/589]	BT 0.359 (0.381)	DT 0.000 (0.018)	lr 0.0002	loss 0.125 (0.135)
Train: [10][360/589]	BT 0.360 (0.381)	DT 0.000 (0.018)	lr 0.0002	loss 0.156 (0.135)
Train: [10][370/589]	BT 0.359 (0.383)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.135)
Train: [10][380/589]	BT 0.360 (0.382)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.135)
Train: [10][390/589]	BT 0.397 (0.385)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.135)
Train: [10][400/589]	BT 0.357 (0.387)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.135)
Train: [10][410/589]	BT 0.361 (0.388)	DT 0.000 (0.025)	lr 0.0002	loss 0.130 (0.135)
Train: [10][420/589]	BT 0.360 (0.388)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.135)
Train: [10][430/589]	BT 0.359 (0.387)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.135)
Train: [10][440/589]	BT 0.361 (0.388)	DT 0.000 (0.025)	lr 0.0002	loss 0.147 (0.135)
Train: [10][450/589]	BT 0.360 (0.388)	DT 0.000 (0.025)	lr 0.0002	loss 0.154 (0.135)
Train: [10][460/589]	BT 0.358 (0.387)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.135)
Train: [10][470/589]	BT 0.369 (0.387)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.135)
Train: [10][480/589]	BT 0.396 (0.386)	DT 0.000 (0.023)	lr 0.0002	loss 0.148 (0.135)
Train: [10][490/589]	BT 0.360 (0.386)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.135)
Train: [10][500/589]	BT 0.360 (0.385)	DT 0.000 (0.023)	lr 0.0002	loss 0.115 (0.135)
Train: [10][510/589]	BT 0.360 (0.386)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.135)
Train: [10][520/589]	BT 0.360 (0.386)	DT 0.000 (0.023)	lr 0.0002	loss 0.154 (0.135)
Train: [10][530/589]	BT 0.363 (0.386)	DT 0.000 (0.023)	lr 0.0002	loss 0.156 (0.135)
Train: [10][540/589]	BT 0.359 (0.387)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.135)
Train: [10][550/589]	BT 0.363 (0.387)	DT 0.000 (0.025)	lr 0.0002	loss 0.138 (0.135)
Train: [10][560/589]	BT 0.359 (0.389)	DT 0.000 (0.026)	lr 0.0002	loss 0.132 (0.136)
Train: [10][570/589]	BT 0.359 (0.389)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.136)
Train: [10][580/589]	BT 0.357 (0.390)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.136)
epoch 10, total time 230.09
loss: 0.1355612306476323@Epoch: 10
learning_rate: 0.0002,10
Valid: [10][10/88]	BT 0.109 (0.610)	DT 0.000 (0.496)	loss 0.138 (0.129)
Valid: [10][20/88]	BT 0.109 (0.578)	DT 0.000 (0.466)	loss 0.123 (0.133)
Valid: [10][30/88]	BT 0.110 (0.533)	DT 0.000 (0.421)	loss 0.148 (0.135)
Valid: [10][40/88]	BT 0.110 (0.497)	DT 0.000 (0.386)	loss 0.129 (0.134)
Valid: [10][50/88]	BT 0.109 (0.474)	DT 0.000 (0.363)	loss 0.124 (0.132)
Valid: [10][60/88]	BT 0.109 (0.473)	DT 0.000 (0.362)	loss 0.131 (0.132)
Valid: [10][70/88]	BT 0.110 (0.465)	DT 0.000 (0.355)	loss 0.133 (0.133)
Valid: [10][80/88]	BT 0.109 (0.456)	DT 0.000 (0.345)	loss 0.102 (0.133)
Train: [11][10/589]	BT 0.357 (0.952)	DT 0.000 (0.590)	lr 0.0002	loss 0.140 (0.132)
Train: [11][20/589]	BT 0.360 (0.666)	DT 0.000 (0.306)	lr 0.0002	loss 0.131 (0.136)
Train: [11][30/589]	BT 0.360 (0.589)	DT 0.000 (0.229)	lr 0.0002	loss 0.130 (0.135)
Train: [11][40/589]	BT 0.360 (0.552)	DT 0.000 (0.192)	lr 0.0002	loss 0.135 (0.135)
Train: [11][50/589]	BT 0.359 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.143 (0.134)
Train: [11][60/589]	BT 0.359 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.127 (0.134)
Train: [11][70/589]	BT 0.358 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.151 (0.135)
Train: [11][80/589]	BT 0.357 (0.472)	DT 0.000 (0.112)	lr 0.0002	loss 0.149 (0.136)
Train: [11][90/589]	BT 0.360 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.165 (0.136)
Train: [11][100/589]	BT 0.359 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.150 (0.136)
Train: [11][110/589]	BT 0.378 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.123 (0.136)
Train: [11][120/589]	BT 0.370 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.111 (0.136)
Train: [11][130/589]	BT 0.359 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.142 (0.136)
Train: [11][140/589]	BT 0.365 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.117 (0.136)
Train: [11][150/589]	BT 0.359 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.127 (0.135)
Train: [11][160/589]	BT 0.365 (0.434)	DT 0.000 (0.073)	lr 0.0002	loss 0.151 (0.135)
Train: [11][170/589]	BT 0.361 (0.437)	DT 0.000 (0.076)	lr 0.0002	loss 0.134 (0.135)
Train: [11][180/589]	BT 0.361 (0.433)	DT 0.000 (0.071)	lr 0.0002	loss 0.138 (0.135)
Train: [11][190/589]	BT 0.362 (0.429)	DT 0.000 (0.068)	lr 0.0002	loss 0.121 (0.135)
Train: [11][200/589]	BT 0.360 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.127 (0.135)
Train: [11][210/589]	BT 0.376 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.124 (0.135)
Train: [11][220/589]	BT 0.359 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.150 (0.135)
Train: [11][230/589]	BT 0.359 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.138 (0.135)
Train: [11][240/589]	BT 0.361 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.155 (0.135)
Train: [11][250/589]	BT 0.361 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.123 (0.135)
Train: [11][260/589]	BT 0.360 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.132 (0.136)
Train: [11][270/589]	BT 0.358 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.140 (0.135)
Train: [11][280/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.125 (0.136)
Train: [11][290/589]	BT 0.359 (0.430)	DT 0.000 (0.069)	lr 0.0002	loss 0.147 (0.135)
Train: [11][300/589]	BT 0.359 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.163 (0.136)
Train: [11][310/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.133 (0.135)
Train: [11][320/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.142 (0.135)
Train: [11][330/589]	BT 0.361 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.127 (0.135)
Train: [11][340/589]	BT 0.363 (0.428)	DT 0.000 (0.067)	lr 0.0002	loss 0.134 (0.135)
Train: [11][350/589]	BT 0.360 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.132 (0.135)
Train: [11][360/589]	BT 0.360 (0.428)	DT 0.000 (0.067)	lr 0.0002	loss 0.126 (0.135)
Train: [11][370/589]	BT 0.356 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.134 (0.135)
Train: [11][380/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.138 (0.135)
Train: [11][390/589]	BT 0.358 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.128 (0.135)
Train: [11][400/589]	BT 0.361 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.149 (0.135)
Train: [11][410/589]	BT 0.392 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.146 (0.135)
Train: [11][420/589]	BT 0.359 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.124 (0.135)
Train: [11][430/589]	BT 0.359 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.107 (0.135)
Train: [11][440/589]	BT 0.362 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.134 (0.135)
Train: [11][450/589]	BT 0.398 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.139 (0.135)
Train: [11][460/589]	BT 0.374 (0.426)	DT 0.000 (0.063)	lr 0.0002	loss 0.120 (0.135)
Train: [11][470/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.127 (0.135)
Train: [11][480/589]	BT 0.360 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.135 (0.135)
Train: [11][490/589]	BT 0.385 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.129 (0.135)
Train: [11][500/589]	BT 0.363 (0.421)	DT 0.000 (0.058)	lr 0.0002	loss 0.130 (0.135)
Train: [11][510/589]	BT 0.360 (0.420)	DT 0.000 (0.057)	lr 0.0002	loss 0.149 (0.135)
Train: [11][520/589]	BT 0.363 (0.419)	DT 0.000 (0.056)	lr 0.0002	loss 0.142 (0.135)
Train: [11][530/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.132 (0.135)
Train: [11][540/589]	BT 0.372 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.136 (0.135)
Train: [11][550/589]	BT 0.358 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.149 (0.135)
Train: [11][560/589]	BT 0.364 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.140 (0.135)
Train: [11][570/589]	BT 0.360 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.140 (0.135)
Train: [11][580/589]	BT 0.361 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.132 (0.135)
epoch 11, total time 251.69
loss: 0.13507325829518987@Epoch: 11
learning_rate: 0.0002,11
Valid: [11][10/88]	BT 0.109 (0.828)	DT 0.000 (0.717)	loss 0.148 (0.131)
Valid: [11][20/88]	BT 0.110 (0.708)	DT 0.000 (0.596)	loss 0.128 (0.127)
Valid: [11][30/88]	BT 0.109 (0.664)	DT 0.000 (0.553)	loss 0.108 (0.128)
Valid: [11][40/88]	BT 0.110 (0.624)	DT 0.000 (0.513)	loss 0.112 (0.130)
Valid: [11][50/88]	BT 0.110 (0.614)	DT 0.000 (0.504)	loss 0.135 (0.130)
Valid: [11][60/88]	BT 0.109 (0.627)	DT 0.000 (0.517)	loss 0.141 (0.131)
Valid: [11][70/88]	BT 0.110 (0.628)	DT 0.000 (0.518)	loss 0.126 (0.131)
Valid: [11][80/88]	BT 0.110 (0.614)	DT 0.000 (0.504)	loss 0.146 (0.131)
Epoch 0011: val_loss improved from 0.13249 to 0.13142, saving model
==> Saving...
Train: [12][10/589]	BT 0.359 (1.166)	DT 0.000 (0.806)	lr 0.0002	loss 0.113 (0.127)
Train: [12][20/589]	BT 0.394 (0.858)	DT 0.000 (0.495)	lr 0.0002	loss 0.118 (0.129)
Train: [12][30/589]	BT 0.360 (0.741)	DT 0.000 (0.379)	lr 0.0002	loss 0.111 (0.126)
Train: [12][40/589]	BT 0.360 (0.691)	DT 0.000 (0.329)	lr 0.0002	loss 0.126 (0.129)
Train: [12][50/589]	BT 0.359 (0.659)	DT 0.000 (0.298)	lr 0.0002	loss 0.104 (0.128)
Train: [12][60/589]	BT 0.364 (0.644)	DT 0.000 (0.283)	lr 0.0002	loss 0.147 (0.130)
Train: [12][70/589]	BT 0.376 (0.631)	DT 0.000 (0.270)	lr 0.0002	loss 0.123 (0.131)
Train: [12][80/589]	BT 0.361 (0.616)	DT 0.000 (0.254)	lr 0.0002	loss 0.139 (0.131)
Train: [12][90/589]	BT 0.365 (0.600)	DT 0.001 (0.238)	lr 0.0002	loss 0.139 (0.132)
Train: [12][100/589]	BT 0.357 (0.590)	DT 0.000 (0.227)	lr 0.0002	loss 0.122 (0.132)
Train: [12][110/589]	BT 0.359 (0.599)	DT 0.000 (0.237)	lr 0.0002	loss 0.135 (0.132)
Train: [12][120/589]	BT 0.359 (0.617)	DT 0.000 (0.255)	lr 0.0002	loss 0.133 (0.132)
Train: [12][130/589]	BT 0.357 (0.616)	DT 0.000 (0.255)	lr 0.0002	loss 0.157 (0.133)
Train: [12][140/589]	BT 0.361 (0.609)	DT 0.000 (0.248)	lr 0.0002	loss 0.135 (0.133)
Train: [12][150/589]	BT 0.359 (0.601)	DT 0.000 (0.240)	lr 0.0002	loss 0.128 (0.133)
Train: [12][160/589]	BT 0.358 (0.607)	DT 0.000 (0.246)	lr 0.0002	loss 0.130 (0.133)
Train: [12][170/589]	BT 0.359 (0.618)	DT 0.000 (0.257)	lr 0.0002	loss 0.117 (0.133)
Train: [12][180/589]	BT 0.358 (0.635)	DT 0.000 (0.274)	lr 0.0002	loss 0.135 (0.134)
Train: [12][190/589]	BT 0.357 (0.638)	DT 0.000 (0.277)	lr 0.0002	loss 0.139 (0.134)
Train: [12][200/589]	BT 0.360 (0.640)	DT 0.000 (0.279)	lr 0.0002	loss 0.128 (0.134)
Train: [12][210/589]	BT 0.360 (0.636)	DT 0.000 (0.275)	lr 0.0002	loss 0.131 (0.134)
Train: [12][220/589]	BT 0.362 (0.644)	DT 0.000 (0.282)	lr 0.0002	loss 0.153 (0.134)
Train: [12][230/589]	BT 0.357 (0.648)	DT 0.000 (0.287)	lr 0.0002	loss 0.111 (0.134)
Train: [12][240/589]	BT 0.362 (0.651)	DT 0.001 (0.290)	lr 0.0002	loss 0.139 (0.134)
Train: [12][250/589]	BT 0.358 (0.648)	DT 0.000 (0.287)	lr 0.0002	loss 0.137 (0.134)
Train: [12][260/589]	BT 0.358 (0.642)	DT 0.001 (0.281)	lr 0.0002	loss 0.132 (0.134)
Train: [12][270/589]	BT 0.358 (0.640)	DT 0.000 (0.279)	lr 0.0002	loss 0.135 (0.134)
Train: [12][280/589]	BT 0.361 (0.635)	DT 0.000 (0.274)	lr 0.0002	loss 0.148 (0.134)
Train: [12][290/589]	BT 0.359 (0.631)	DT 0.000 (0.270)	lr 0.0002	loss 0.111 (0.134)
Train: [12][300/589]	BT 0.359 (0.637)	DT 0.000 (0.275)	lr 0.0002	loss 0.138 (0.134)
Train: [12][310/589]	BT 0.358 (0.637)	DT 0.000 (0.276)	lr 0.0002	loss 0.126 (0.134)
Train: [12][320/589]	BT 0.364 (0.636)	DT 0.000 (0.274)	lr 0.0002	loss 0.136 (0.134)
Train: [12][330/589]	BT 0.358 (0.631)	DT 0.000 (0.270)	lr 0.0002	loss 0.144 (0.134)
Train: [12][340/589]	BT 0.357 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.127 (0.134)
Train: [12][350/589]	BT 0.361 (0.632)	DT 0.000 (0.270)	lr 0.0002	loss 0.127 (0.134)
Train: [12][360/589]	BT 0.359 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.132 (0.134)
Train: [12][370/589]	BT 0.360 (0.634)	DT 0.000 (0.273)	lr 0.0002	loss 0.124 (0.134)
Train: [12][380/589]	BT 0.358 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.153 (0.134)
Train: [12][390/589]	BT 0.359 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.140 (0.134)
Train: [12][400/589]	BT 0.358 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.125 (0.134)
Train: [12][410/589]	BT 0.360 (0.632)	DT 0.000 (0.271)	lr 0.0002	loss 0.133 (0.134)
Train: [12][420/589]	BT 0.357 (0.630)	DT 0.000 (0.269)	lr 0.0002	loss 0.150 (0.134)
Train: [12][430/589]	BT 0.358 (0.627)	DT 0.000 (0.266)	lr 0.0002	loss 0.134 (0.134)
Train: [12][440/589]	BT 0.358 (0.628)	DT 0.000 (0.267)	lr 0.0002	loss 0.111 (0.134)
Train: [12][450/589]	BT 0.372 (0.627)	DT 0.000 (0.266)	lr 0.0002	loss 0.146 (0.134)
Train: [12][460/589]	BT 0.359 (0.627)	DT 0.000 (0.266)	lr 0.0002	loss 0.121 (0.134)
Train: [12][470/589]	BT 0.360 (0.625)	DT 0.000 (0.264)	lr 0.0002	loss 0.158 (0.134)
Train: [12][480/589]	BT 0.359 (0.623)	DT 0.000 (0.262)	lr 0.0002	loss 0.127 (0.134)
Train: [12][490/589]	BT 0.370 (0.621)	DT 0.000 (0.260)	lr 0.0002	loss 0.148 (0.134)
Train: [12][500/589]	BT 0.361 (0.620)	DT 0.000 (0.259)	lr 0.0002	loss 0.126 (0.134)
Train: [12][510/589]	BT 0.361 (0.618)	DT 0.000 (0.257)	lr 0.0002	loss 0.142 (0.134)
Train: [12][520/589]	BT 0.361 (0.616)	DT 0.000 (0.255)	lr 0.0002	loss 0.139 (0.134)
Train: [12][530/589]	BT 0.358 (0.614)	DT 0.000 (0.253)	lr 0.0002	loss 0.122 (0.134)
Train: [12][540/589]	BT 0.359 (0.613)	DT 0.000 (0.252)	lr 0.0002	loss 0.152 (0.134)
Train: [12][550/589]	BT 0.362 (0.611)	DT 0.000 (0.250)	lr 0.0002	loss 0.158 (0.134)
Train: [12][560/589]	BT 0.360 (0.610)	DT 0.000 (0.249)	lr 0.0002	loss 0.162 (0.134)
Train: [12][570/589]	BT 0.359 (0.609)	DT 0.000 (0.248)	lr 0.0002	loss 0.131 (0.134)
Train: [12][580/589]	BT 0.360 (0.608)	DT 0.000 (0.247)	lr 0.0002	loss 0.139 (0.134)
epoch 12, total time 357.69
loss: 0.13442435515251083@Epoch: 12
learning_rate: 0.0002,12
Valid: [12][10/88]	BT 0.110 (0.622)	DT 0.000 (0.508)	loss 0.124 (0.132)
Valid: [12][20/88]	BT 0.109 (0.539)	DT 0.000 (0.428)	loss 0.141 (0.132)
Valid: [12][30/88]	BT 0.110 (0.509)	DT 0.000 (0.397)	loss 0.131 (0.133)
Valid: [12][40/88]	BT 0.110 (0.488)	DT 0.000 (0.376)	loss 0.144 (0.134)
Valid: [12][50/88]	BT 0.109 (0.490)	DT 0.000 (0.378)	loss 0.126 (0.132)
Valid: [12][60/88]	BT 0.110 (0.488)	DT 0.000 (0.377)	loss 0.142 (0.132)
Valid: [12][70/88]	BT 0.109 (0.485)	DT 0.000 (0.374)	loss 0.141 (0.132)
Valid: [12][80/88]	BT 0.109 (0.496)	DT 0.000 (0.385)	loss 0.134 (0.133)
Train: [13][10/589]	BT 0.359 (0.836)	DT 0.001 (0.470)	lr 0.0002	loss 0.165 (0.142)
Train: [13][20/589]	BT 0.364 (0.635)	DT 0.000 (0.272)	lr 0.0002	loss 0.142 (0.138)
Train: [13][30/589]	BT 0.376 (0.570)	DT 0.000 (0.208)	lr 0.0002	loss 0.147 (0.135)
Train: [13][40/589]	BT 0.358 (0.522)	DT 0.000 (0.161)	lr 0.0002	loss 0.126 (0.135)
Train: [13][50/589]	BT 0.372 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.116 (0.136)
Train: [13][60/589]	BT 0.361 (0.524)	DT 0.000 (0.163)	lr 0.0002	loss 0.152 (0.136)
Train: [13][70/589]	BT 0.397 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.134 (0.136)
Train: [13][80/589]	BT 0.359 (0.499)	DT 0.000 (0.137)	lr 0.0002	loss 0.141 (0.135)
Train: [13][90/589]	BT 0.365 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.126 (0.135)
Train: [13][100/589]	BT 0.358 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.143 (0.134)
Train: [13][110/589]	BT 0.361 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.124 (0.134)
Train: [13][120/589]	BT 0.359 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.137 (0.134)
Train: [13][130/589]	BT 0.357 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.152 (0.135)
Train: [13][140/589]	BT 0.400 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.123 (0.135)
Train: [13][150/589]	BT 0.360 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.119 (0.135)
Train: [13][160/589]	BT 0.360 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.117 (0.134)
Train: [13][170/589]	BT 0.359 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.121 (0.134)
Train: [13][180/589]	BT 0.358 (0.490)	DT 0.000 (0.128)	lr 0.0002	loss 0.129 (0.134)
Train: [13][190/589]	BT 0.360 (0.486)	DT 0.000 (0.124)	lr 0.0002	loss 0.137 (0.134)
Train: [13][200/589]	BT 0.357 (0.481)	DT 0.000 (0.119)	lr 0.0002	loss 0.148 (0.134)
Train: [13][210/589]	BT 0.358 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.150 (0.134)
Train: [13][220/589]	BT 0.358 (0.479)	DT 0.000 (0.117)	lr 0.0002	loss 0.127 (0.135)
Train: [13][230/589]	BT 0.359 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.117 (0.134)
Train: [13][240/589]	BT 0.363 (0.475)	DT 0.000 (0.113)	lr 0.0002	loss 0.150 (0.135)
Train: [13][250/589]	BT 0.359 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.149 (0.135)
Train: [13][260/589]	BT 0.371 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.134 (0.135)
Train: [13][270/589]	BT 0.358 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.142 (0.135)
Train: [13][280/589]	BT 0.391 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.131 (0.134)
Train: [13][290/589]	BT 0.363 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.117 (0.134)
Train: [13][300/589]	BT 0.363 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.136 (0.134)
Train: [13][310/589]	BT 0.357 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.145 (0.134)
Train: [13][320/589]	BT 0.387 (0.470)	DT 0.000 (0.108)	lr 0.0002	loss 0.152 (0.134)
Train: [13][330/589]	BT 0.358 (0.471)	DT 0.000 (0.110)	lr 0.0002	loss 0.162 (0.134)
Train: [13][340/589]	BT 0.398 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.139 (0.134)
Train: [13][350/589]	BT 0.363 (0.476)	DT 0.000 (0.114)	lr 0.0002	loss 0.119 (0.134)
Train: [13][360/589]	BT 0.361 (0.473)	DT 0.000 (0.112)	lr 0.0002	loss 0.139 (0.134)
Train: [13][370/589]	BT 0.357 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.123 (0.134)
Train: [13][380/589]	BT 0.358 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.130 (0.134)
Train: [13][390/589]	BT 0.386 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.145 (0.134)
Train: [13][400/589]	BT 0.357 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.137 (0.134)
Train: [13][410/589]	BT 0.395 (0.476)	DT 0.000 (0.114)	lr 0.0002	loss 0.147 (0.134)
Train: [13][420/589]	BT 0.359 (0.477)	DT 0.000 (0.114)	lr 0.0002	loss 0.128 (0.134)
Train: [13][430/589]	BT 0.358 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.117 (0.134)
Train: [13][440/589]	BT 0.395 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.150 (0.134)
Train: [13][450/589]	BT 0.360 (0.472)	DT 0.000 (0.110)	lr 0.0002	loss 0.124 (0.134)
Train: [13][460/589]	BT 0.363 (0.472)	DT 0.000 (0.110)	lr 0.0002	loss 0.109 (0.134)
Train: [13][470/589]	BT 0.361 (0.472)	DT 0.000 (0.109)	lr 0.0002	loss 0.174 (0.134)
Train: [13][480/589]	BT 0.362 (0.472)	DT 0.000 (0.110)	lr 0.0002	loss 0.137 (0.134)
Train: [13][490/589]	BT 0.391 (0.471)	DT 0.000 (0.109)	lr 0.0002	loss 0.136 (0.134)
Train: [13][500/589]	BT 0.362 (0.472)	DT 0.000 (0.110)	lr 0.0002	loss 0.129 (0.134)
Train: [13][510/589]	BT 0.360 (0.475)	DT 0.000 (0.112)	lr 0.0002	loss 0.151 (0.134)
Train: [13][520/589]	BT 0.361 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.146 (0.134)
Train: [13][530/589]	BT 0.361 (0.473)	DT 0.000 (0.110)	lr 0.0002	loss 0.134 (0.134)
Train: [13][540/589]	BT 0.379 (0.472)	DT 0.000 (0.109)	lr 0.0002	loss 0.152 (0.134)
Train: [13][550/589]	BT 0.364 (0.471)	DT 0.000 (0.108)	lr 0.0002	loss 0.131 (0.134)
Train: [13][560/589]	BT 0.361 (0.469)	DT 0.000 (0.106)	lr 0.0002	loss 0.128 (0.134)
Train: [13][570/589]	BT 0.359 (0.468)	DT 0.000 (0.106)	lr 0.0002	loss 0.137 (0.134)
Train: [13][580/589]	BT 0.358 (0.468)	DT 0.000 (0.105)	lr 0.0002	loss 0.149 (0.134)
epoch 13, total time 276.12
loss: 0.13407557483169716@Epoch: 13
learning_rate: 0.0002,13
Valid: [13][10/88]	BT 0.110 (0.645)	DT 0.000 (0.534)	loss 0.146 (0.137)
Valid: [13][20/88]	BT 0.110 (0.558)	DT 0.000 (0.447)	loss 0.107 (0.133)
Valid: [13][30/88]	BT 0.110 (0.507)	DT 0.000 (0.396)	loss 0.138 (0.133)
Valid: [13][40/88]	BT 0.109 (0.488)	DT 0.000 (0.377)	loss 0.121 (0.133)
Valid: [13][50/88]	BT 0.110 (0.501)	DT 0.000 (0.390)	loss 0.135 (0.134)
Valid: [13][60/88]	BT 0.110 (0.488)	DT 0.000 (0.377)	loss 0.142 (0.133)
Valid: [13][70/88]	BT 0.109 (0.473)	DT 0.000 (0.362)	loss 0.156 (0.133)
Valid: [13][80/88]	BT 0.110 (0.474)	DT 0.000 (0.363)	loss 0.124 (0.132)
Epoch 0013: val_loss improved from 0.13142 to 0.13083, saving model
==> Saving...
Train: [14][10/589]	BT 0.388 (0.819)	DT 0.000 (0.457)	lr 0.0002	loss 0.134 (0.130)
Train: [14][20/589]	BT 0.357 (0.591)	DT 0.000 (0.229)	lr 0.0002	loss 0.125 (0.134)
Train: [14][30/589]	BT 0.357 (0.517)	DT 0.000 (0.152)	lr 0.0002	loss 0.108 (0.132)
Train: [14][40/589]	BT 0.357 (0.479)	DT 0.000 (0.114)	lr 0.0002	loss 0.136 (0.132)
Train: [14][50/589]	BT 0.361 (0.455)	DT 0.000 (0.092)	lr 0.0002	loss 0.119 (0.132)
Train: [14][60/589]	BT 0.360 (0.439)	DT 0.000 (0.076)	lr 0.0002	loss 0.126 (0.131)
Train: [14][70/589]	BT 0.362 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.129 (0.131)
Train: [14][80/589]	BT 0.359 (0.436)	DT 0.000 (0.074)	lr 0.0002	loss 0.123 (0.130)
Train: [14][90/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.150 (0.131)
Train: [14][100/589]	BT 0.397 (0.425)	DT 0.000 (0.062)	lr 0.0002	loss 0.114 (0.131)
Train: [14][110/589]	BT 0.361 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.159 (0.132)
Train: [14][120/589]	BT 0.358 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.143 (0.132)
Train: [14][130/589]	BT 0.358 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.113 (0.132)
Train: [14][140/589]	BT 0.359 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.154 (0.132)
Train: [14][150/589]	BT 0.358 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.129 (0.132)
Train: [14][160/589]	BT 0.368 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.116 (0.132)
Train: [14][170/589]	BT 0.360 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.118 (0.132)
Train: [14][180/589]	BT 0.378 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.141 (0.132)
Train: [14][190/589]	BT 0.359 (0.411)	DT 0.000 (0.049)	lr 0.0002	loss 0.161 (0.133)
Train: [14][200/589]	BT 0.360 (0.410)	DT 0.000 (0.049)	lr 0.0002	loss 0.131 (0.132)
Train: [14][210/589]	BT 0.358 (0.412)	DT 0.000 (0.050)	lr 0.0002	loss 0.126 (0.132)
Train: [14][220/589]	BT 0.359 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.132 (0.132)
Train: [14][230/589]	BT 0.360 (0.408)	DT 0.000 (0.046)	lr 0.0002	loss 0.131 (0.132)
Train: [14][240/589]	BT 0.404 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.138 (0.132)
Train: [14][250/589]	BT 0.359 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.093 (0.132)
Train: [14][260/589]	BT 0.358 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.128 (0.132)
Train: [14][270/589]	BT 0.358 (0.409)	DT 0.000 (0.048)	lr 0.0002	loss 0.128 (0.132)
Train: [14][280/589]	BT 0.359 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.127 (0.132)
Train: [14][290/589]	BT 0.362 (0.411)	DT 0.000 (0.050)	lr 0.0002	loss 0.126 (0.132)
Train: [14][300/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.138 (0.132)
Train: [14][310/589]	BT 0.360 (0.417)	DT 0.000 (0.056)	lr 0.0002	loss 0.125 (0.132)
Train: [14][320/589]	BT 0.358 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.149 (0.132)
Train: [14][330/589]	BT 0.391 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.118 (0.132)
Train: [14][340/589]	BT 0.358 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.128 (0.132)
Train: [14][350/589]	BT 0.359 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.166 (0.133)
Train: [14][360/589]	BT 0.359 (0.420)	DT 0.000 (0.059)	lr 0.0002	loss 0.123 (0.133)
Train: [14][370/589]	BT 0.359 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.139 (0.133)
Train: [14][380/589]	BT 0.360 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.138 (0.133)
Train: [14][390/589]	BT 0.358 (0.426)	DT 0.000 (0.065)	lr 0.0002	loss 0.129 (0.133)
Train: [14][400/589]	BT 0.360 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.151 (0.133)
Train: [14][410/589]	BT 0.361 (0.427)	DT 0.000 (0.066)	lr 0.0002	loss 0.142 (0.133)
Train: [14][420/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.138 (0.133)
Train: [14][430/589]	BT 0.360 (0.431)	DT 0.000 (0.069)	lr 0.0002	loss 0.147 (0.133)
Train: [14][440/589]	BT 0.358 (0.432)	DT 0.000 (0.071)	lr 0.0002	loss 0.141 (0.133)
Train: [14][450/589]	BT 0.358 (0.433)	DT 0.000 (0.072)	lr 0.0002	loss 0.116 (0.133)
Train: [14][460/589]	BT 0.361 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.130 (0.133)
Train: [14][470/589]	BT 0.360 (0.437)	DT 0.000 (0.075)	lr 0.0002	loss 0.139 (0.133)
Train: [14][480/589]	BT 0.360 (0.441)	DT 0.000 (0.080)	lr 0.0002	loss 0.151 (0.133)
Train: [14][490/589]	BT 0.361 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.137 (0.133)
Train: [14][500/589]	BT 0.357 (0.444)	DT 0.000 (0.082)	lr 0.0002	loss 0.160 (0.133)
Train: [14][510/589]	BT 0.375 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.144 (0.133)
Train: [14][520/589]	BT 0.359 (0.447)	DT 0.000 (0.086)	lr 0.0002	loss 0.116 (0.133)
Train: [14][530/589]	BT 0.359 (0.449)	DT 0.000 (0.087)	lr 0.0002	loss 0.132 (0.134)
Train: [14][540/589]	BT 0.369 (0.449)	DT 0.000 (0.087)	lr 0.0002	loss 0.170 (0.134)
Train: [14][550/589]	BT 0.358 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.121 (0.133)
Train: [14][560/589]	BT 0.363 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.135 (0.133)
Train: [14][570/589]	BT 0.362 (0.452)	DT 0.000 (0.090)	lr 0.0002	loss 0.142 (0.133)
Train: [14][580/589]	BT 0.358 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.165 (0.133)
epoch 14, total time 268.76
loss: 0.13346785368979142@Epoch: 14
learning_rate: 0.0002,14
Valid: [14][10/88]	BT 0.110 (0.723)	DT 0.000 (0.611)	loss 0.127 (0.133)
Valid: [14][20/88]	BT 0.110 (0.630)	DT 0.000 (0.518)	loss 0.138 (0.130)
Valid: [14][30/88]	BT 0.109 (0.613)	DT 0.000 (0.501)	loss 0.131 (0.132)
Valid: [14][40/88]	BT 0.109 (0.623)	DT 0.000 (0.512)	loss 0.141 (0.132)
Valid: [14][50/88]	BT 0.110 (0.593)	DT 0.000 (0.483)	loss 0.105 (0.131)
Valid: [14][60/88]	BT 0.109 (0.577)	DT 0.000 (0.467)	loss 0.153 (0.132)
Valid: [14][70/88]	BT 0.109 (0.572)	DT 0.000 (0.462)	loss 0.139 (0.132)
Valid: [14][80/88]	BT 0.110 (0.578)	DT 0.000 (0.467)	loss 0.158 (0.133)
Train: [15][10/589]	BT 0.359 (0.927)	DT 0.000 (0.568)	lr 0.0002	loss 0.144 (0.138)
Train: [15][20/589]	BT 0.385 (0.708)	DT 0.000 (0.349)	lr 0.0002	loss 0.129 (0.131)
Train: [15][30/589]	BT 0.391 (0.628)	DT 0.000 (0.266)	lr 0.0002	loss 0.146 (0.130)
Train: [15][40/589]	BT 0.357 (0.594)	DT 0.000 (0.233)	lr 0.0002	loss 0.151 (0.132)
Train: [15][50/589]	BT 0.361 (0.568)	DT 0.000 (0.208)	lr 0.0002	loss 0.140 (0.132)
Train: [15][60/589]	BT 0.366 (0.557)	DT 0.000 (0.197)	lr 0.0002	loss 0.141 (0.134)
Train: [15][70/589]	BT 0.359 (0.546)	DT 0.000 (0.186)	lr 0.0002	loss 0.157 (0.134)
Train: [15][80/589]	BT 0.359 (0.538)	DT 0.000 (0.177)	lr 0.0002	loss 0.136 (0.135)
Train: [15][90/589]	BT 0.360 (0.541)	DT 0.000 (0.181)	lr 0.0002	loss 0.135 (0.134)
Train: [15][100/589]	BT 0.361 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.125 (0.134)
Train: [15][110/589]	BT 0.357 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.132 (0.134)
Train: [15][120/589]	BT 0.358 (0.520)	DT 0.000 (0.160)	lr 0.0002	loss 0.122 (0.133)
Train: [15][130/589]	BT 0.361 (0.516)	DT 0.000 (0.155)	lr 0.0002	loss 0.121 (0.133)
Train: [15][140/589]	BT 0.375 (0.518)	DT 0.000 (0.158)	lr 0.0002	loss 0.133 (0.133)
Train: [15][150/589]	BT 0.358 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.141 (0.133)
Train: [15][160/589]	BT 0.358 (0.506)	DT 0.000 (0.145)	lr 0.0002	loss 0.126 (0.133)
Train: [15][170/589]	BT 0.359 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.134 (0.133)
Train: [15][180/589]	BT 0.358 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.133 (0.133)
Train: [15][190/589]	BT 0.360 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.144 (0.133)
Train: [15][200/589]	BT 0.367 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.145 (0.133)
Train: [15][210/589]	BT 0.358 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.136 (0.133)
Train: [15][220/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.130 (0.133)
Train: [15][230/589]	BT 0.361 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.098 (0.133)
Train: [15][240/589]	BT 0.356 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.114 (0.133)
Train: [15][250/589]	BT 0.361 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.139 (0.133)
Train: [15][260/589]	BT 0.363 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.133 (0.133)
Train: [15][270/589]	BT 0.359 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.140 (0.133)
Train: [15][280/589]	BT 0.359 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.156 (0.133)
Train: [15][290/589]	BT 0.389 (0.487)	DT 0.000 (0.125)	lr 0.0002	loss 0.118 (0.133)
Train: [15][300/589]	BT 0.369 (0.488)	DT 0.000 (0.126)	lr 0.0002	loss 0.132 (0.133)
Train: [15][310/589]	BT 0.358 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.118 (0.133)
Train: [15][320/589]	BT 0.360 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.137 (0.133)
Train: [15][330/589]	BT 0.360 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.134 (0.133)
Train: [15][340/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.143 (0.133)
Train: [15][350/589]	BT 0.362 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.137 (0.133)
Train: [15][360/589]	BT 0.363 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.104 (0.133)
Train: [15][370/589]	BT 0.363 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.129 (0.133)
Train: [15][380/589]	BT 0.359 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.127 (0.133)
Train: [15][390/589]	BT 0.360 (0.490)	DT 0.001 (0.129)	lr 0.0002	loss 0.130 (0.133)
Train: [15][400/589]	BT 0.359 (0.492)	DT 0.000 (0.130)	lr 0.0002	loss 0.124 (0.133)
Train: [15][410/589]	BT 0.363 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.125 (0.133)
Train: [15][420/589]	BT 0.358 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.125 (0.133)
Train: [15][430/589]	BT 0.360 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.112 (0.133)
Train: [15][440/589]	BT 0.362 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.133 (0.133)
Train: [15][450/589]	BT 0.362 (0.492)	DT 0.000 (0.130)	lr 0.0002	loss 0.116 (0.133)
Train: [15][460/589]	BT 0.359 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.121 (0.133)
Train: [15][470/589]	BT 0.359 (0.500)	DT 0.000 (0.138)	lr 0.0002	loss 0.125 (0.133)
Train: [15][480/589]	BT 0.359 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.143 (0.133)
Train: [15][490/589]	BT 0.358 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.114 (0.133)
Train: [15][500/589]	BT 0.357 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.113 (0.133)
Train: [15][510/589]	BT 0.396 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.137 (0.133)
Train: [15][520/589]	BT 0.397 (0.507)	DT 0.000 (0.145)	lr 0.0002	loss 0.129 (0.133)
Train: [15][530/589]	BT 0.358 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.117 (0.133)
Train: [15][540/589]	BT 0.360 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.127 (0.133)
Train: [15][550/589]	BT 0.359 (0.511)	DT 0.000 (0.149)	lr 0.0002	loss 0.139 (0.133)
Train: [15][560/589]	BT 0.359 (0.513)	DT 0.000 (0.151)	lr 0.0002	loss 0.149 (0.133)
Train: [15][570/589]	BT 0.360 (0.513)	DT 0.000 (0.151)	lr 0.0002	loss 0.123 (0.133)
Train: [15][580/589]	BT 0.361 (0.514)	DT 0.000 (0.152)	lr 0.0002	loss 0.127 (0.133)
epoch 15, total time 303.56
loss: 0.1330496337298808@Epoch: 15
learning_rate: 0.0002,15
Valid: [15][10/88]	BT 0.110 (0.714)	DT 0.000 (0.600)	loss 0.137 (0.128)
Valid: [15][20/88]	BT 0.110 (0.614)	DT 0.000 (0.503)	loss 0.124 (0.131)
Valid: [15][30/88]	BT 0.110 (0.591)	DT 0.000 (0.480)	loss 0.145 (0.131)
Valid: [15][40/88]	BT 0.109 (0.592)	DT 0.000 (0.480)	loss 0.141 (0.131)
Valid: [15][50/88]	BT 0.110 (0.574)	DT 0.000 (0.462)	loss 0.122 (0.131)
Valid: [15][60/88]	BT 0.110 (0.580)	DT 0.000 (0.468)	loss 0.106 (0.131)
Valid: [15][70/88]	BT 0.110 (0.581)	DT 0.000 (0.469)	loss 0.140 (0.131)
Valid: [15][80/88]	BT 0.109 (0.566)	DT 0.000 (0.455)	loss 0.152 (0.131)
Train: [16][10/589]	BT 0.359 (0.872)	DT 0.000 (0.512)	lr 0.0002	loss 0.127 (0.138)
Train: [16][20/589]	BT 0.359 (0.676)	DT 0.000 (0.317)	lr 0.0002	loss 0.140 (0.135)
Train: [16][30/589]	BT 0.391 (0.613)	DT 0.000 (0.253)	lr 0.0002	loss 0.119 (0.136)
Train: [16][40/589]	BT 0.358 (0.569)	DT 0.000 (0.210)	lr 0.0002	loss 0.139 (0.135)
Train: [16][50/589]	BT 0.361 (0.544)	DT 0.000 (0.184)	lr 0.0002	loss 0.118 (0.134)
Train: [16][60/589]	BT 0.400 (0.537)	DT 0.000 (0.176)	lr 0.0002	loss 0.125 (0.134)
Train: [16][70/589]	BT 0.360 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.139 (0.134)
Train: [16][80/589]	BT 0.359 (0.528)	DT 0.000 (0.168)	lr 0.0002	loss 0.132 (0.133)
Train: [16][90/589]	BT 0.359 (0.540)	DT 0.000 (0.180)	lr 0.0002	loss 0.128 (0.132)
Train: [16][100/589]	BT 0.359 (0.550)	DT 0.000 (0.190)	lr 0.0002	loss 0.131 (0.132)
Train: [16][110/589]	BT 0.359 (0.551)	DT 0.000 (0.190)	lr 0.0002	loss 0.145 (0.133)
Train: [16][120/589]	BT 0.372 (0.551)	DT 0.000 (0.190)	lr 0.0002	loss 0.120 (0.132)
Train: [16][130/589]	BT 0.360 (0.543)	DT 0.000 (0.183)	lr 0.0002	loss 0.151 (0.132)
Train: [16][140/589]	BT 0.363 (0.547)	DT 0.000 (0.187)	lr 0.0002	loss 0.123 (0.132)
Train: [16][150/589]	BT 0.360 (0.553)	DT 0.000 (0.193)	lr 0.0002	loss 0.158 (0.132)
Train: [16][160/589]	BT 0.396 (0.555)	DT 0.000 (0.195)	lr 0.0002	loss 0.141 (0.132)
Train: [16][170/589]	BT 0.359 (0.552)	DT 0.000 (0.192)	lr 0.0002	loss 0.142 (0.132)
Train: [16][180/589]	BT 0.355 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.100 (0.132)
Train: [16][190/589]	BT 0.359 (0.550)	DT 0.000 (0.190)	lr 0.0002	loss 0.118 (0.132)
Train: [16][200/589]	BT 0.359 (0.554)	DT 0.000 (0.194)	lr 0.0002	loss 0.153 (0.132)
Train: [16][210/589]	BT 0.360 (0.555)	DT 0.000 (0.195)	lr 0.0002	loss 0.125 (0.133)
Train: [16][220/589]	BT 0.358 (0.554)	DT 0.000 (0.194)	lr 0.0002	loss 0.127 (0.133)
Train: [16][230/589]	BT 0.360 (0.554)	DT 0.000 (0.194)	lr 0.0002	loss 0.145 (0.133)
Train: [16][240/589]	BT 0.359 (0.555)	DT 0.000 (0.195)	lr 0.0002	loss 0.122 (0.133)
Train: [16][250/589]	BT 0.365 (0.556)	DT 0.000 (0.196)	lr 0.0002	loss 0.131 (0.133)
Train: [16][260/589]	BT 0.360 (0.559)	DT 0.000 (0.199)	lr 0.0002	loss 0.119 (0.133)
Train: [16][270/589]	BT 0.358 (0.560)	DT 0.000 (0.199)	lr 0.0002	loss 0.126 (0.133)
Train: [16][280/589]	BT 0.356 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.130 (0.133)
Train: [16][290/589]	BT 0.357 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.145 (0.133)
Train: [16][300/589]	BT 0.389 (0.563)	DT 0.000 (0.203)	lr 0.0002	loss 0.134 (0.133)
Train: [16][310/589]	BT 0.358 (0.571)	DT 0.000 (0.211)	lr 0.0002	loss 0.139 (0.133)
Train: [16][320/589]	BT 0.357 (0.572)	DT 0.000 (0.212)	lr 0.0002	loss 0.114 (0.133)
Train: [16][330/589]	BT 0.358 (0.575)	DT 0.000 (0.215)	lr 0.0002	loss 0.111 (0.133)
Train: [16][340/589]	BT 0.358 (0.575)	DT 0.000 (0.214)	lr 0.0002	loss 0.137 (0.133)
Train: [16][350/589]	BT 0.359 (0.575)	DT 0.000 (0.214)	lr 0.0002	loss 0.132 (0.133)
Train: [16][360/589]	BT 0.358 (0.579)	DT 0.000 (0.218)	lr 0.0002	loss 0.122 (0.133)
Train: [16][370/589]	BT 0.357 (0.583)	DT 0.000 (0.222)	lr 0.0002	loss 0.125 (0.133)
Train: [16][380/589]	BT 0.359 (0.583)	DT 0.000 (0.222)	lr 0.0002	loss 0.125 (0.133)
Train: [16][390/589]	BT 0.358 (0.584)	DT 0.000 (0.223)	lr 0.0002	loss 0.110 (0.133)
Train: [16][400/589]	BT 0.357 (0.584)	DT 0.000 (0.224)	lr 0.0002	loss 0.146 (0.133)
Train: [16][410/589]	BT 0.358 (0.585)	DT 0.000 (0.224)	lr 0.0002	loss 0.164 (0.133)
Train: [16][420/589]	BT 0.359 (0.585)	DT 0.000 (0.225)	lr 0.0002	loss 0.129 (0.133)
Train: [16][430/589]	BT 0.358 (0.586)	DT 0.000 (0.225)	lr 0.0002	loss 0.122 (0.133)
Train: [16][440/589]	BT 0.357 (0.588)	DT 0.000 (0.227)	lr 0.0002	loss 0.135 (0.133)
Train: [16][450/589]	BT 0.357 (0.589)	DT 0.000 (0.228)	lr 0.0002	loss 0.141 (0.133)
Train: [16][460/589]	BT 0.358 (0.589)	DT 0.000 (0.228)	lr 0.0002	loss 0.128 (0.133)
Train: [16][470/589]	BT 0.360 (0.589)	DT 0.000 (0.228)	lr 0.0002	loss 0.107 (0.133)
Train: [16][480/589]	BT 0.357 (0.588)	DT 0.000 (0.227)	lr 0.0002	loss 0.135 (0.133)
Train: [16][490/589]	BT 0.357 (0.588)	DT 0.000 (0.227)	lr 0.0002	loss 0.118 (0.133)
Train: [16][500/589]	BT 0.359 (0.590)	DT 0.000 (0.229)	lr 0.0002	loss 0.149 (0.133)
Train: [16][510/589]	BT 0.357 (0.592)	DT 0.000 (0.231)	lr 0.0002	loss 0.146 (0.133)
Train: [16][520/589]	BT 0.358 (0.591)	DT 0.000 (0.231)	lr 0.0002	loss 0.138 (0.133)
Train: [16][530/589]	BT 0.361 (0.591)	DT 0.000 (0.231)	lr 0.0002	loss 0.138 (0.133)
Train: [16][540/589]	BT 0.362 (0.591)	DT 0.000 (0.230)	lr 0.0002	loss 0.135 (0.133)
Train: [16][550/589]	BT 0.358 (0.590)	DT 0.000 (0.229)	lr 0.0002	loss 0.168 (0.133)
Train: [16][560/589]	BT 0.357 (0.592)	DT 0.000 (0.231)	lr 0.0002	loss 0.126 (0.133)
Train: [16][570/589]	BT 0.359 (0.592)	DT 0.000 (0.231)	lr 0.0002	loss 0.140 (0.133)
Train: [16][580/589]	BT 0.358 (0.594)	DT 0.000 (0.233)	lr 0.0002	loss 0.144 (0.133)
epoch 16, total time 352.88
loss: 0.13260467540744209@Epoch: 16
learning_rate: 0.0002,16
Valid: [16][10/88]	BT 0.110 (0.703)	DT 0.000 (0.591)	loss 0.114 (0.129)
Valid: [16][20/88]	BT 0.110 (0.635)	DT 0.000 (0.523)	loss 0.128 (0.133)
Valid: [16][30/88]	BT 0.109 (0.594)	DT 0.000 (0.482)	loss 0.123 (0.133)
Valid: [16][40/88]	BT 0.110 (0.565)	DT 0.000 (0.453)	loss 0.138 (0.132)
Valid: [16][50/88]	BT 0.134 (0.548)	DT 0.025 (0.437)	loss 0.113 (0.132)
Valid: [16][60/88]	BT 0.489 (0.533)	DT 0.380 (0.422)	loss 0.129 (0.131)
Valid: [16][70/88]	BT 0.164 (0.535)	DT 0.055 (0.424)	loss 0.132 (0.131)
Valid: [16][80/88]	BT 0.755 (0.533)	DT 0.646 (0.422)	loss 0.134 (0.130)
Epoch 0016: val_loss improved from 0.13083 to 0.13009, saving model
==> Saving...
Train: [17][10/589]	BT 0.359 (0.821)	DT 0.000 (0.459)	lr 0.0002	loss 0.125 (0.127)
Train: [17][20/589]	BT 0.357 (0.619)	DT 0.000 (0.259)	lr 0.0002	loss 0.140 (0.129)
Train: [17][30/589]	BT 0.361 (0.588)	DT 0.001 (0.227)	lr 0.0002	loss 0.132 (0.131)
Train: [17][40/589]	BT 0.379 (0.565)	DT 0.000 (0.204)	lr 0.0002	loss 0.156 (0.130)
Train: [17][50/589]	BT 0.361 (0.535)	DT 0.000 (0.175)	lr 0.0002	loss 0.135 (0.130)
Train: [17][60/589]	BT 0.392 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.146 (0.131)
Train: [17][70/589]	BT 0.359 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.111 (0.131)
Train: [17][80/589]	BT 0.370 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.150 (0.132)
Train: [17][90/589]	BT 0.360 (0.488)	DT 0.000 (0.126)	lr 0.0002	loss 0.138 (0.132)
Train: [17][100/589]	BT 0.362 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.138 (0.132)
Train: [17][110/589]	BT 0.361 (0.511)	DT 0.000 (0.150)	lr 0.0002	loss 0.118 (0.132)
Train: [17][120/589]	BT 0.361 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.137 (0.131)
Train: [17][130/589]	BT 0.361 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.129 (0.131)
Train: [17][140/589]	BT 0.359 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.121 (0.132)
Train: [17][150/589]	BT 0.359 (0.507)	DT 0.000 (0.146)	lr 0.0002	loss 0.135 (0.131)
Train: [17][160/589]	BT 0.359 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.140 (0.131)
Train: [17][170/589]	BT 0.358 (0.506)	DT 0.000 (0.145)	lr 0.0002	loss 0.136 (0.131)
Train: [17][180/589]	BT 0.395 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.142 (0.131)
Train: [17][190/589]	BT 0.361 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.126 (0.131)
Train: [17][200/589]	BT 0.362 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.153 (0.132)
Train: [17][210/589]	BT 0.385 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.138 (0.132)
Train: [17][220/589]	BT 0.361 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.147 (0.132)
Train: [17][230/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.117 (0.132)
Train: [17][240/589]	BT 0.358 (0.498)	DT 0.000 (0.136)	lr 0.0002	loss 0.143 (0.133)
Train: [17][250/589]	BT 0.359 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.117 (0.132)
Train: [17][260/589]	BT 0.360 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.108 (0.132)
Train: [17][270/589]	BT 0.359 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.139 (0.132)
Train: [17][280/589]	BT 0.367 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.124 (0.132)
Train: [17][290/589]	BT 0.362 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.131 (0.132)
Train: [17][300/589]	BT 0.378 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.119 (0.132)
Train: [17][310/589]	BT 0.357 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.133 (0.132)
Train: [17][320/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.121 (0.133)
Train: [17][330/589]	BT 0.359 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.113 (0.132)
Train: [17][340/589]	BT 0.359 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.152 (0.132)
Train: [17][350/589]	BT 0.365 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.153 (0.132)
Train: [17][360/589]	BT 0.358 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.118 (0.132)
Train: [17][370/589]	BT 0.359 (0.492)	DT 0.000 (0.130)	lr 0.0002	loss 0.128 (0.132)
Train: [17][380/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.128 (0.132)
Train: [17][390/589]	BT 0.359 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.114 (0.132)
Train: [17][400/589]	BT 0.361 (0.500)	DT 0.000 (0.138)	lr 0.0002	loss 0.135 (0.132)
Train: [17][410/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.122 (0.132)
Train: [17][420/589]	BT 0.361 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.144 (0.132)
Train: [17][430/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.106 (0.132)
Train: [17][440/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.118 (0.132)
Train: [17][450/589]	BT 0.360 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.130 (0.132)
Train: [17][460/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.137 (0.132)
Train: [17][470/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.144 (0.132)
Train: [17][480/589]	BT 0.358 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.119 (0.132)
Train: [17][490/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.133 (0.132)
Train: [17][500/589]	BT 0.359 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.145 (0.132)
Train: [17][510/589]	BT 0.393 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.132 (0.132)
Train: [17][520/589]	BT 0.358 (0.503)	DT 0.000 (0.141)	lr 0.0002	loss 0.114 (0.132)
Train: [17][530/589]	BT 0.358 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.130 (0.132)
Train: [17][540/589]	BT 0.360 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.135 (0.132)
Train: [17][550/589]	BT 0.358 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.137 (0.132)
Train: [17][560/589]	BT 0.362 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.119 (0.132)
Train: [17][570/589]	BT 0.362 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.116 (0.132)
Train: [17][580/589]	BT 0.390 (0.501)	DT 0.000 (0.139)	lr 0.0002	loss 0.117 (0.132)
epoch 17, total time 296.22
loss: 0.13205323034799704@Epoch: 17
learning_rate: 0.0002,17
Valid: [17][10/88]	BT 0.110 (0.726)	DT 0.000 (0.616)	loss 0.161 (0.139)
Valid: [17][20/88]	BT 0.110 (0.631)	DT 0.000 (0.520)	loss 0.134 (0.137)
Valid: [17][30/88]	BT 0.109 (0.600)	DT 0.000 (0.490)	loss 0.124 (0.136)
Valid: [17][40/88]	BT 0.110 (0.604)	DT 0.000 (0.493)	loss 0.116 (0.134)
Valid: [17][50/88]	BT 0.110 (0.584)	DT 0.000 (0.474)	loss 0.131 (0.134)
Valid: [17][60/88]	BT 0.110 (0.569)	DT 0.000 (0.458)	loss 0.137 (0.135)
Valid: [17][70/88]	BT 0.110 (0.568)	DT 0.000 (0.457)	loss 0.150 (0.135)
Valid: [17][80/88]	BT 0.109 (0.561)	DT 0.000 (0.451)	loss 0.126 (0.135)
Train: [18][10/589]	BT 0.358 (1.001)	DT 0.000 (0.643)	lr 0.0002	loss 0.140 (0.138)
Train: [18][20/589]	BT 0.364 (0.787)	DT 0.000 (0.429)	lr 0.0002	loss 0.118 (0.135)
Train: [18][30/589]	BT 0.358 (0.675)	DT 0.000 (0.316)	lr 0.0002	loss 0.128 (0.132)
Train: [18][40/589]	BT 0.397 (0.614)	DT 0.000 (0.253)	lr 0.0002	loss 0.128 (0.132)
Train: [18][50/589]	BT 0.356 (0.574)	DT 0.000 (0.214)	lr 0.0002	loss 0.136 (0.131)
Train: [18][60/589]	BT 0.370 (0.539)	DT 0.000 (0.178)	lr 0.0002	loss 0.124 (0.131)
Train: [18][70/589]	BT 0.358 (0.515)	DT 0.000 (0.153)	lr 0.0002	loss 0.126 (0.131)
Train: [18][80/589]	BT 0.357 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.127 (0.131)
Train: [18][90/589]	BT 0.361 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.106 (0.130)
Train: [18][100/589]	BT 0.359 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.153 (0.131)
Train: [18][110/589]	BT 0.360 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.122 (0.131)
Train: [18][120/589]	BT 0.363 (0.481)	DT 0.000 (0.120)	lr 0.0002	loss 0.131 (0.131)
Train: [18][130/589]	BT 0.358 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.138 (0.130)
Train: [18][140/589]	BT 0.358 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.123 (0.130)
Train: [18][150/589]	BT 0.360 (0.473)	DT 0.000 (0.113)	lr 0.0002	loss 0.130 (0.130)
Train: [18][160/589]	BT 0.359 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.126 (0.130)
Train: [18][170/589]	BT 0.358 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.117 (0.130)
Train: [18][180/589]	BT 0.358 (0.476)	DT 0.000 (0.116)	lr 0.0002	loss 0.137 (0.130)
Train: [18][190/589]	BT 0.359 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.124 (0.130)
Train: [18][200/589]	BT 0.358 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.139 (0.130)
Train: [18][210/589]	BT 0.359 (0.467)	DT 0.000 (0.107)	lr 0.0002	loss 0.127 (0.130)
Train: [18][220/589]	BT 0.361 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.118 (0.130)
Train: [18][230/589]	BT 0.359 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.124 (0.130)
Train: [18][240/589]	BT 0.359 (0.467)	DT 0.000 (0.106)	lr 0.0002	loss 0.113 (0.131)
Train: [18][250/589]	BT 0.357 (0.473)	DT 0.000 (0.113)	lr 0.0002	loss 0.150 (0.131)
Train: [18][260/589]	BT 0.361 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.121 (0.130)
Train: [18][270/589]	BT 0.358 (0.478)	DT 0.000 (0.118)	lr 0.0002	loss 0.141 (0.131)
Train: [18][280/589]	BT 0.359 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.130 (0.131)
Train: [18][290/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.144 (0.131)
Train: [18][300/589]	BT 0.357 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.132 (0.131)
Train: [18][310/589]	BT 0.358 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.138 (0.131)
Train: [18][320/589]	BT 0.359 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.124 (0.131)
Train: [18][330/589]	BT 0.358 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.132 (0.131)
Train: [18][340/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.116 (0.131)
Train: [18][350/589]	BT 0.361 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.135 (0.131)
Train: [18][360/589]	BT 0.357 (0.492)	DT 0.000 (0.132)	lr 0.0002	loss 0.112 (0.131)
Train: [18][370/589]	BT 0.386 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.150 (0.131)
Train: [18][380/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.138 (0.131)
Train: [18][390/589]	BT 0.357 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.125 (0.131)
Train: [18][400/589]	BT 0.357 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.123 (0.131)
Train: [18][410/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.130 (0.131)
Train: [18][420/589]	BT 0.363 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.118 (0.131)
Train: [18][430/589]	BT 0.359 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.136 (0.131)
Train: [18][440/589]	BT 0.358 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.116 (0.131)
Train: [18][450/589]	BT 0.358 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.109 (0.131)
Train: [18][460/589]	BT 0.359 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.144 (0.131)
Train: [18][470/589]	BT 0.358 (0.515)	DT 0.000 (0.155)	lr 0.0002	loss 0.137 (0.131)
Train: [18][480/589]	BT 0.358 (0.517)	DT 0.000 (0.157)	lr 0.0002	loss 0.143 (0.131)
Train: [18][490/589]	BT 0.357 (0.518)	DT 0.000 (0.158)	lr 0.0002	loss 0.147 (0.131)
Train: [18][500/589]	BT 0.360 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.115 (0.132)
Train: [18][510/589]	BT 0.359 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.140 (0.132)
Train: [18][520/589]	BT 0.359 (0.518)	DT 0.000 (0.157)	lr 0.0002	loss 0.144 (0.132)
Train: [18][530/589]	BT 0.401 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.142 (0.132)
Train: [18][540/589]	BT 0.358 (0.518)	DT 0.000 (0.158)	lr 0.0002	loss 0.122 (0.132)
Train: [18][550/589]	BT 0.358 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.114 (0.132)
Train: [18][560/589]	BT 0.358 (0.519)	DT 0.000 (0.158)	lr 0.0002	loss 0.132 (0.132)
Train: [18][570/589]	BT 0.359 (0.518)	DT 0.000 (0.158)	lr 0.0002	loss 0.110 (0.132)
Train: [18][580/589]	BT 0.359 (0.519)	DT 0.000 (0.159)	lr 0.0002	loss 0.151 (0.132)
epoch 18, total time 307.03
loss: 0.13155029793884285@Epoch: 18
learning_rate: 0.0002,18
Valid: [18][10/88]	BT 0.109 (0.760)	DT 0.000 (0.649)	loss 0.157 (0.131)
Valid: [18][20/88]	BT 0.110 (0.653)	DT 0.000 (0.543)	loss 0.151 (0.133)
Valid: [18][30/88]	BT 0.110 (0.627)	DT 0.000 (0.516)	loss 0.132 (0.133)
Valid: [18][40/88]	BT 0.110 (0.595)	DT 0.000 (0.485)	loss 0.137 (0.131)
Valid: [18][50/88]	BT 0.110 (0.588)	DT 0.000 (0.478)	loss 0.148 (0.131)
Valid: [18][60/88]	BT 0.110 (0.588)	DT 0.000 (0.478)	loss 0.143 (0.131)
Valid: [18][70/88]	BT 0.110 (0.589)	DT 0.000 (0.479)	loss 0.143 (0.132)
Valid: [18][80/88]	BT 0.110 (0.581)	DT 0.000 (0.471)	loss 0.123 (0.131)
Train: [19][10/589]	BT 0.359 (0.892)	DT 0.000 (0.534)	lr 0.0002	loss 0.162 (0.129)
Train: [19][20/589]	BT 0.358 (0.650)	DT 0.000 (0.292)	lr 0.0002	loss 0.113 (0.128)
Train: [19][30/589]	BT 0.358 (0.578)	DT 0.000 (0.219)	lr 0.0002	loss 0.119 (0.128)
Train: [19][40/589]	BT 0.358 (0.543)	DT 0.000 (0.183)	lr 0.0002	loss 0.110 (0.129)
Train: [19][50/589]	BT 0.374 (0.526)	DT 0.000 (0.166)	lr 0.0002	loss 0.120 (0.130)
Train: [19][60/589]	BT 0.357 (0.521)	DT 0.000 (0.161)	lr 0.0002	loss 0.122 (0.129)
Train: [19][70/589]	BT 0.359 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.133 (0.130)
Train: [19][80/589]	BT 0.361 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.123 (0.130)
Train: [19][90/589]	BT 0.360 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.134 (0.131)
Train: [19][100/589]	BT 0.359 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.102 (0.130)
Train: [19][110/589]	BT 0.359 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.148 (0.130)
Train: [19][120/589]	BT 0.360 (0.468)	DT 0.000 (0.108)	lr 0.0002	loss 0.141 (0.131)
Train: [19][130/589]	BT 0.358 (0.473)	DT 0.000 (0.112)	lr 0.0002	loss 0.127 (0.131)
Train: [19][140/589]	BT 0.359 (0.479)	DT 0.000 (0.119)	lr 0.0002	loss 0.121 (0.130)
Train: [19][150/589]	BT 0.357 (0.475)	DT 0.000 (0.114)	lr 0.0002	loss 0.098 (0.130)
Train: [19][160/589]	BT 0.375 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.138 (0.130)
Train: [19][170/589]	BT 0.357 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.138 (0.130)
Train: [19][180/589]	BT 0.361 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.140 (0.130)
Train: [19][190/589]	BT 0.361 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.108 (0.131)
Train: [19][200/589]	BT 0.360 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.121 (0.130)
Train: [19][210/589]	BT 0.359 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.134 (0.130)
Train: [19][220/589]	BT 0.358 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.144 (0.130)
Train: [19][230/589]	BT 0.357 (0.458)	DT 0.000 (0.097)	lr 0.0002	loss 0.143 (0.130)
Train: [19][240/589]	BT 0.361 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.157 (0.131)
Train: [19][250/589]	BT 0.359 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.149 (0.131)
Train: [19][260/589]	BT 0.360 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.182 (0.131)
Train: [19][270/589]	BT 0.359 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.105 (0.131)
Train: [19][280/589]	BT 0.357 (0.451)	DT 0.000 (0.089)	lr 0.0002	loss 0.134 (0.131)
Train: [19][290/589]	BT 0.358 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.127 (0.131)
Train: [19][300/589]	BT 0.358 (0.445)	DT 0.000 (0.084)	lr 0.0002	loss 0.137 (0.131)
Train: [19][310/589]	BT 0.358 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.123 (0.131)
Train: [19][320/589]	BT 0.388 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.133 (0.131)
Train: [19][330/589]	BT 0.362 (0.443)	DT 0.000 (0.081)	lr 0.0002	loss 0.146 (0.131)
Train: [19][340/589]	BT 0.358 (0.442)	DT 0.000 (0.081)	lr 0.0002	loss 0.152 (0.131)
Train: [19][350/589]	BT 0.359 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.140 (0.131)
Train: [19][360/589]	BT 0.362 (0.443)	DT 0.000 (0.082)	lr 0.0002	loss 0.161 (0.131)
Train: [19][370/589]	BT 0.360 (0.442)	DT 0.000 (0.081)	lr 0.0002	loss 0.130 (0.131)
Train: [19][380/589]	BT 0.390 (0.441)	DT 0.000 (0.080)	lr 0.0002	loss 0.151 (0.131)
Train: [19][390/589]	BT 0.399 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.129 (0.131)
Train: [19][400/589]	BT 0.369 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.126 (0.131)
Train: [19][410/589]	BT 0.359 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.123 (0.131)
Train: [19][420/589]	BT 0.359 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.129 (0.131)
Train: [19][430/589]	BT 0.358 (0.436)	DT 0.000 (0.074)	lr 0.0002	loss 0.115 (0.131)
Train: [19][440/589]	BT 0.361 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.128 (0.131)
Train: [19][450/589]	BT 0.360 (0.436)	DT 0.000 (0.074)	lr 0.0002	loss 0.124 (0.131)
Train: [19][460/589]	BT 0.358 (0.434)	DT 0.000 (0.073)	lr 0.0002	loss 0.122 (0.131)
Train: [19][470/589]	BT 0.359 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.128 (0.131)
Train: [19][480/589]	BT 0.398 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.131 (0.131)
Train: [19][490/589]	BT 0.358 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.129 (0.131)
Train: [19][500/589]	BT 0.359 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.131 (0.131)
Train: [19][510/589]	BT 0.361 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.133 (0.131)
Train: [19][520/589]	BT 0.360 (0.442)	DT 0.000 (0.081)	lr 0.0002	loss 0.133 (0.131)
Train: [19][530/589]	BT 0.359 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.125 (0.131)
Train: [19][540/589]	BT 0.361 (0.447)	DT 0.000 (0.085)	lr 0.0002	loss 0.144 (0.131)
Train: [19][550/589]	BT 0.358 (0.449)	DT 0.000 (0.087)	lr 0.0002	loss 0.136 (0.131)
Train: [19][560/589]	BT 0.365 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.158 (0.131)
Train: [19][570/589]	BT 0.356 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.138 (0.131)
Train: [19][580/589]	BT 0.357 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.142 (0.131)
epoch 19, total time 271.33
loss: 0.13132415251896998@Epoch: 19
learning_rate: 0.0002,19
Valid: [19][10/88]	BT 0.109 (0.858)	DT 0.000 (0.745)	loss 0.129 (0.135)
Valid: [19][20/88]	BT 0.110 (0.803)	DT 0.000 (0.690)	loss 0.119 (0.132)
Valid: [19][30/88]	BT 0.109 (0.767)	DT 0.000 (0.654)	loss 0.117 (0.130)
Valid: [19][40/88]	BT 0.109 (0.740)	DT 0.000 (0.628)	loss 0.130 (0.129)
Valid: [19][50/88]	BT 0.109 (0.714)	DT 0.000 (0.602)	loss 0.120 (0.130)
Valid: [19][60/88]	BT 0.109 (0.705)	DT 0.000 (0.594)	loss 0.160 (0.131)
Valid: [19][70/88]	BT 0.109 (0.699)	DT 0.000 (0.588)	loss 0.127 (0.130)
Valid: [19][80/88]	BT 0.110 (0.680)	DT 0.000 (0.569)	loss 0.122 (0.130)
Train: [20][10/589]	BT 0.358 (1.054)	DT 0.000 (0.697)	lr 0.0002	loss 0.139 (0.125)
Train: [20][20/589]	BT 0.357 (0.781)	DT 0.000 (0.423)	lr 0.0002	loss 0.131 (0.124)
Train: [20][30/589]	BT 0.357 (0.742)	DT 0.000 (0.384)	lr 0.0002	loss 0.134 (0.125)
Train: [20][40/589]	BT 0.361 (0.691)	DT 0.000 (0.333)	lr 0.0002	loss 0.132 (0.127)
Train: [20][50/589]	BT 0.356 (0.666)	DT 0.000 (0.307)	lr 0.0002	loss 0.112 (0.126)
Train: [20][60/589]	BT 0.358 (0.651)	DT 0.000 (0.292)	lr 0.0002	loss 0.144 (0.127)
Train: [20][70/589]	BT 0.359 (0.648)	DT 0.000 (0.290)	lr 0.0002	loss 0.132 (0.127)
Train: [20][80/589]	BT 0.356 (0.640)	DT 0.000 (0.282)	lr 0.0002	loss 0.123 (0.127)
Train: [20][90/589]	BT 0.359 (0.625)	DT 0.000 (0.266)	lr 0.0002	loss 0.134 (0.127)
Train: [20][100/589]	BT 0.359 (0.623)	DT 0.000 (0.264)	lr 0.0002	loss 0.129 (0.127)
Train: [20][110/589]	BT 0.357 (0.633)	DT 0.000 (0.274)	lr 0.0002	loss 0.129 (0.128)
Train: [20][120/589]	BT 0.361 (0.625)	DT 0.000 (0.266)	lr 0.0002	loss 0.138 (0.127)
Train: [20][130/589]	BT 0.364 (0.616)	DT 0.000 (0.257)	lr 0.0002	loss 0.130 (0.128)
Train: [20][140/589]	BT 0.359 (0.615)	DT 0.000 (0.255)	lr 0.0002	loss 0.122 (0.128)
Train: [20][150/589]	BT 0.388 (0.620)	DT 0.000 (0.260)	lr 0.0002	loss 0.136 (0.128)
Train: [20][160/589]	BT 0.358 (0.618)	DT 0.000 (0.258)	lr 0.0002	loss 0.143 (0.128)
Train: [20][170/589]	BT 0.372 (0.615)	DT 0.000 (0.255)	lr 0.0002	loss 0.150 (0.129)
Train: [20][180/589]	BT 0.399 (0.620)	DT 0.000 (0.260)	lr 0.0002	loss 0.126 (0.129)
Train: [20][190/589]	BT 0.374 (0.614)	DT 0.000 (0.253)	lr 0.0002	loss 0.126 (0.129)
Train: [20][200/589]	BT 0.358 (0.610)	DT 0.000 (0.250)	lr 0.0002	loss 0.140 (0.130)
Train: [20][210/589]	BT 0.358 (0.609)	DT 0.000 (0.249)	lr 0.0002	loss 0.119 (0.130)
Train: [20][220/589]	BT 0.397 (0.607)	DT 0.000 (0.247)	lr 0.0002	loss 0.116 (0.130)
Train: [20][230/589]	BT 0.361 (0.605)	DT 0.000 (0.245)	lr 0.0002	loss 0.132 (0.130)
Train: [20][240/589]	BT 0.362 (0.609)	DT 0.000 (0.248)	lr 0.0002	loss 0.123 (0.130)
Train: [20][250/589]	BT 0.373 (0.607)	DT 0.000 (0.247)	lr 0.0002	loss 0.115 (0.130)
Train: [20][260/589]	BT 0.362 (0.610)	DT 0.000 (0.250)	lr 0.0002	loss 0.130 (0.130)
Train: [20][270/589]	BT 0.359 (0.608)	DT 0.000 (0.248)	lr 0.0002	loss 0.158 (0.130)
Train: [20][280/589]	BT 0.358 (0.613)	DT 0.000 (0.253)	lr 0.0002	loss 0.112 (0.130)
Train: [20][290/589]	BT 0.360 (0.615)	DT 0.000 (0.254)	lr 0.0002	loss 0.105 (0.129)
Train: [20][300/589]	BT 0.357 (0.618)	DT 0.000 (0.257)	lr 0.0002	loss 0.157 (0.129)
Train: [20][310/589]	BT 0.358 (0.616)	DT 0.000 (0.256)	lr 0.0002	loss 0.137 (0.129)
Train: [20][320/589]	BT 0.394 (0.615)	DT 0.000 (0.254)	lr 0.0002	loss 0.115 (0.130)
Train: [20][330/589]	BT 0.359 (0.615)	DT 0.000 (0.254)	lr 0.0002	loss 0.141 (0.130)
Train: [20][340/589]	BT 0.358 (0.619)	DT 0.000 (0.258)	lr 0.0002	loss 0.106 (0.129)
Train: [20][350/589]	BT 0.358 (0.618)	DT 0.000 (0.257)	lr 0.0002	loss 0.109 (0.129)
Train: [20][360/589]	BT 0.358 (0.620)	DT 0.000 (0.259)	lr 0.0002	loss 0.125 (0.129)
Train: [20][370/589]	BT 0.381 (0.619)	DT 0.000 (0.259)	lr 0.0002	loss 0.142 (0.130)
Train: [20][380/589]	BT 0.360 (0.620)	DT 0.000 (0.260)	lr 0.0002	loss 0.130 (0.130)
Train: [20][390/589]	BT 0.360 (0.621)	DT 0.000 (0.261)	lr 0.0002	loss 0.135 (0.130)
Train: [20][400/589]	BT 0.359 (0.623)	DT 0.000 (0.263)	lr 0.0002	loss 0.126 (0.130)
Train: [20][410/589]	BT 0.360 (0.623)	DT 0.000 (0.262)	lr 0.0002	loss 0.119 (0.130)
Train: [20][420/589]	BT 0.359 (0.624)	DT 0.000 (0.264)	lr 0.0002	loss 0.117 (0.130)
Train: [20][430/589]	BT 0.361 (0.625)	DT 0.000 (0.265)	lr 0.0002	loss 0.123 (0.130)
Train: [20][440/589]	BT 0.359 (0.626)	DT 0.000 (0.266)	lr 0.0002	loss 0.117 (0.130)
Train: [20][450/589]	BT 0.361 (0.629)	DT 0.000 (0.268)	lr 0.0002	loss 0.146 (0.130)
Train: [20][460/589]	BT 0.359 (0.629)	DT 0.000 (0.268)	lr 0.0002	loss 0.166 (0.130)
Train: [20][470/589]	BT 0.358 (0.633)	DT 0.000 (0.272)	lr 0.0002	loss 0.117 (0.130)
Train: [20][480/589]	BT 0.359 (0.635)	DT 0.000 (0.275)	lr 0.0002	loss 0.123 (0.130)
Train: [20][490/589]	BT 0.358 (0.635)	DT 0.000 (0.275)	lr 0.0002	loss 0.134 (0.130)
Train: [20][500/589]	BT 0.359 (0.638)	DT 0.000 (0.278)	lr 0.0002	loss 0.122 (0.130)
Train: [20][510/589]	BT 0.360 (0.638)	DT 0.000 (0.278)	lr 0.0002	loss 0.124 (0.131)
Train: [20][520/589]	BT 0.373 (0.642)	DT 0.000 (0.282)	lr 0.0002	loss 0.108 (0.131)
Train: [20][530/589]	BT 0.362 (0.643)	DT 0.000 (0.283)	lr 0.0002	loss 0.126 (0.131)
Train: [20][540/589]	BT 0.361 (0.643)	DT 0.000 (0.283)	lr 0.0002	loss 0.137 (0.130)
Train: [20][550/589]	BT 0.358 (0.645)	DT 0.000 (0.285)	lr 0.0002	loss 0.115 (0.131)
Train: [20][560/589]	BT 0.359 (0.644)	DT 0.000 (0.284)	lr 0.0002	loss 0.130 (0.131)
Train: [20][570/589]	BT 0.365 (0.644)	DT 0.000 (0.284)	lr 0.0002	loss 0.117 (0.131)
Train: [20][580/589]	BT 0.358 (0.645)	DT 0.000 (0.285)	lr 0.0002	loss 0.132 (0.131)
epoch 20, total time 381.33
loss: 0.1306306089131929@Epoch: 20
learning_rate: 0.0002,20
Valid: [20][10/88]	BT 0.110 (0.706)	DT 0.000 (0.596)	loss 0.145 (0.131)
Valid: [20][20/88]	BT 0.109 (0.574)	DT 0.000 (0.464)	loss 0.129 (0.132)
Valid: [20][30/88]	BT 0.109 (0.540)	DT 0.000 (0.430)	loss 0.119 (0.130)
Valid: [20][40/88]	BT 0.110 (0.499)	DT 0.000 (0.389)	loss 0.133 (0.131)
Valid: [20][50/88]	BT 0.110 (0.479)	DT 0.000 (0.369)	loss 0.125 (0.131)
Valid: [20][60/88]	BT 0.110 (0.484)	DT 0.000 (0.374)	loss 0.143 (0.132)
Valid: [20][70/88]	BT 0.110 (0.476)	DT 0.000 (0.366)	loss 0.129 (0.132)
Valid: [20][80/88]	BT 0.110 (0.476)	DT 0.000 (0.365)	loss 0.167 (0.132)
Train: [21][10/589]	BT 0.357 (0.836)	DT 0.000 (0.478)	lr 0.0002	loss 0.127 (0.127)
Train: [21][20/589]	BT 0.360 (0.638)	DT 0.000 (0.280)	lr 0.0002	loss 0.114 (0.129)
Train: [21][30/589]	BT 0.359 (0.582)	DT 0.000 (0.222)	lr 0.0002	loss 0.140 (0.127)
Train: [21][40/589]	BT 0.364 (0.532)	DT 0.000 (0.173)	lr 0.0002	loss 0.127 (0.127)
Train: [21][50/589]	BT 0.360 (0.499)	DT 0.000 (0.140)	lr 0.0002	loss 0.137 (0.128)
Train: [21][60/589]	BT 0.360 (0.481)	DT 0.000 (0.122)	lr 0.0002	loss 0.130 (0.128)
Train: [21][70/589]	BT 0.364 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.156 (0.128)
Train: [21][80/589]	BT 0.361 (0.474)	DT 0.000 (0.115)	lr 0.0002	loss 0.134 (0.129)
Train: [21][90/589]	BT 0.360 (0.462)	DT 0.000 (0.102)	lr 0.0002	loss 0.136 (0.128)
Train: [21][100/589]	BT 0.360 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.131 (0.129)
Train: [21][110/589]	BT 0.362 (0.472)	DT 0.000 (0.112)	lr 0.0002	loss 0.143 (0.130)
Train: [21][120/589]	BT 0.359 (0.466)	DT 0.000 (0.106)	lr 0.0002	loss 0.120 (0.129)
Train: [21][130/589]	BT 0.359 (0.470)	DT 0.000 (0.110)	lr 0.0002	loss 0.137 (0.130)
Train: [21][140/589]	BT 0.358 (0.469)	DT 0.000 (0.108)	lr 0.0002	loss 0.116 (0.130)
Train: [21][150/589]	BT 0.358 (0.468)	DT 0.000 (0.107)	lr 0.0002	loss 0.136 (0.130)
Train: [21][160/589]	BT 0.358 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.126 (0.130)
Train: [21][170/589]	BT 0.359 (0.480)	DT 0.000 (0.119)	lr 0.0002	loss 0.104 (0.130)
Train: [21][180/589]	BT 0.358 (0.479)	DT 0.000 (0.118)	lr 0.0002	loss 0.107 (0.130)
Train: [21][190/589]	BT 0.358 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.126 (0.130)
Train: [21][200/589]	BT 0.357 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.125 (0.130)
Train: [21][210/589]	BT 0.373 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.143 (0.130)
Train: [21][220/589]	BT 0.357 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.151 (0.130)
Train: [21][230/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.130 (0.130)
Train: [21][240/589]	BT 0.361 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.113 (0.130)
Train: [21][250/589]	BT 0.356 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.111 (0.130)
Train: [21][260/589]	BT 0.358 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.136 (0.130)
Train: [21][270/589]	BT 0.357 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.143 (0.130)
Train: [21][280/589]	BT 0.357 (0.494)	DT 0.000 (0.134)	lr 0.0002	loss 0.148 (0.130)
Train: [21][290/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.128 (0.130)
Train: [21][300/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.145 (0.130)
Train: [21][310/589]	BT 0.356 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.128 (0.130)
Train: [21][320/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.154 (0.130)
Train: [21][330/589]	BT 0.358 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.147 (0.130)
Train: [21][340/589]	BT 0.358 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.129 (0.130)
Train: [21][350/589]	BT 0.363 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.105 (0.130)
Train: [21][360/589]	BT 0.359 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.148 (0.130)
Train: [21][370/589]	BT 0.358 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.116 (0.130)
Train: [21][380/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.127 (0.130)
Train: [21][390/589]	BT 0.358 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.107 (0.130)
Train: [21][400/589]	BT 0.358 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.116 (0.131)
Train: [21][410/589]	BT 0.358 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.137 (0.131)
Train: [21][420/589]	BT 0.358 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.142 (0.130)
Train: [21][430/589]	BT 0.359 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.119 (0.130)
Train: [21][440/589]	BT 0.357 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.126 (0.130)
Train: [21][450/589]	BT 0.359 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.166 (0.130)
Train: [21][460/589]	BT 0.358 (0.509)	DT 0.000 (0.148)	lr 0.0002	loss 0.151 (0.130)
Train: [21][470/589]	BT 0.357 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.130 (0.130)
Train: [21][480/589]	BT 0.359 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.133 (0.130)
Train: [21][490/589]	BT 0.358 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.130 (0.130)
Train: [21][500/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.121 (0.130)
Train: [21][510/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.130 (0.130)
Train: [21][520/589]	BT 0.358 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.108 (0.130)
Train: [21][530/589]	BT 0.358 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.139 (0.130)
Train: [21][540/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.133 (0.130)
Train: [21][550/589]	BT 0.357 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.115 (0.130)
Train: [21][560/589]	BT 0.364 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.156 (0.130)
Train: [21][570/589]	BT 0.361 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.136 (0.130)
Train: [21][580/589]	BT 0.358 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.151 (0.130)
epoch 21, total time 295.51
loss: 0.1303838256636521@Epoch: 21
learning_rate: 0.0002,21
Valid: [21][10/88]	BT 0.110 (0.749)	DT 0.000 (0.636)	loss 0.137 (0.131)
Valid: [21][20/88]	BT 0.110 (0.596)	DT 0.000 (0.484)	loss 0.110 (0.132)
Valid: [21][30/88]	BT 0.110 (0.552)	DT 0.000 (0.440)	loss 0.140 (0.133)
Valid: [21][40/88]	BT 0.109 (0.531)	DT 0.000 (0.420)	loss 0.137 (0.133)
Valid: [21][50/88]	BT 0.109 (0.512)	DT 0.000 (0.401)	loss 0.114 (0.133)
Valid: [21][60/88]	BT 0.110 (0.499)	DT 0.000 (0.389)	loss 0.110 (0.131)
Valid: [21][70/88]	BT 0.109 (0.500)	DT 0.000 (0.390)	loss 0.119 (0.132)
Valid: [21][80/88]	BT 0.110 (0.494)	DT 0.000 (0.384)	loss 0.125 (0.132)
Train: [22][10/589]	BT 0.358 (0.948)	DT 0.000 (0.589)	lr 0.0002	loss 0.135 (0.129)
Train: [22][20/589]	BT 0.356 (0.660)	DT 0.000 (0.299)	lr 0.0002	loss 0.116 (0.125)
Train: [22][30/589]	BT 0.358 (0.575)	DT 0.000 (0.215)	lr 0.0002	loss 0.129 (0.128)
Train: [22][40/589]	BT 0.359 (0.540)	DT 0.000 (0.181)	lr 0.0002	loss 0.106 (0.126)
Train: [22][50/589]	BT 0.379 (0.539)	DT 0.000 (0.179)	lr 0.0002	loss 0.144 (0.126)
Train: [22][60/589]	BT 0.394 (0.510)	DT 0.000 (0.149)	lr 0.0002	loss 0.120 (0.126)
Train: [22][70/589]	BT 0.410 (0.490)	DT 0.000 (0.128)	lr 0.0002	loss 0.140 (0.127)
Train: [22][80/589]	BT 0.400 (0.475)	DT 0.000 (0.112)	lr 0.0002	loss 0.119 (0.127)
Train: [22][90/589]	BT 0.359 (0.463)	DT 0.000 (0.100)	lr 0.0002	loss 0.134 (0.127)
Train: [22][100/589]	BT 0.390 (0.453)	DT 0.000 (0.090)	lr 0.0002	loss 0.141 (0.127)
Train: [22][110/589]	BT 0.360 (0.448)	DT 0.000 (0.085)	lr 0.0002	loss 0.119 (0.127)
Train: [22][120/589]	BT 0.358 (0.445)	DT 0.000 (0.083)	lr 0.0002	loss 0.131 (0.128)
Train: [22][130/589]	BT 0.380 (0.442)	DT 0.000 (0.079)	lr 0.0002	loss 0.127 (0.128)
Train: [22][140/589]	BT 0.364 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.118 (0.128)
Train: [22][150/589]	BT 0.358 (0.435)	DT 0.000 (0.073)	lr 0.0002	loss 0.122 (0.128)
Train: [22][160/589]	BT 0.361 (0.432)	DT 0.000 (0.071)	lr 0.0002	loss 0.132 (0.128)
Train: [22][170/589]	BT 0.361 (0.430)	DT 0.000 (0.069)	lr 0.0002	loss 0.125 (0.128)
Train: [22][180/589]	BT 0.361 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.131 (0.129)
Train: [22][190/589]	BT 0.358 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.167 (0.129)
Train: [22][200/589]	BT 0.370 (0.426)	DT 0.000 (0.065)	lr 0.0002	loss 0.121 (0.129)
Train: [22][210/589]	BT 0.361 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.132 (0.129)
Train: [22][220/589]	BT 0.357 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.107 (0.129)
Train: [22][230/589]	BT 0.360 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.146 (0.129)
Train: [22][240/589]	BT 0.357 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.132 (0.130)
Train: [22][250/589]	BT 0.394 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.150 (0.130)
Train: [22][260/589]	BT 0.359 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.150 (0.130)
Train: [22][270/589]	BT 0.370 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.130 (0.130)
Train: [22][280/589]	BT 0.362 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.126 (0.130)
Train: [22][290/589]	BT 0.369 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.125 (0.130)
Train: [22][300/589]	BT 0.359 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.121 (0.130)
Train: [22][310/589]	BT 0.362 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.125 (0.130)
Train: [22][320/589]	BT 0.360 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.136 (0.130)
Train: [22][330/589]	BT 0.360 (0.413)	DT 0.000 (0.051)	lr 0.0002	loss 0.142 (0.130)
Train: [22][340/589]	BT 0.360 (0.411)	DT 0.000 (0.049)	lr 0.0002	loss 0.134 (0.130)
Train: [22][350/589]	BT 0.360 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.123 (0.130)
Train: [22][360/589]	BT 0.359 (0.408)	DT 0.000 (0.046)	lr 0.0002	loss 0.129 (0.130)
Train: [22][370/589]	BT 0.358 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.133 (0.130)
Train: [22][380/589]	BT 0.359 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.133 (0.130)
Train: [22][390/589]	BT 0.359 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.146 (0.130)
Train: [22][400/589]	BT 0.361 (0.410)	DT 0.000 (0.048)	lr 0.0002	loss 0.116 (0.130)
Train: [22][410/589]	BT 0.360 (0.412)	DT 0.000 (0.051)	lr 0.0002	loss 0.150 (0.130)
Train: [22][420/589]	BT 0.360 (0.413)	DT 0.000 (0.052)	lr 0.0002	loss 0.129 (0.130)
Train: [22][430/589]	BT 0.362 (0.413)	DT 0.000 (0.052)	lr 0.0002	loss 0.141 (0.130)
Train: [22][440/589]	BT 0.359 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.103 (0.130)
Train: [22][450/589]	BT 0.361 (0.415)	DT 0.000 (0.054)	lr 0.0002	loss 0.138 (0.130)
Train: [22][460/589]	BT 0.360 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.111 (0.130)
Train: [22][470/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.130 (0.130)
Train: [22][480/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.136 (0.130)
Train: [22][490/589]	BT 0.362 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.144 (0.130)
Train: [22][500/589]	BT 0.360 (0.415)	DT 0.000 (0.054)	lr 0.0002	loss 0.116 (0.130)
Train: [22][510/589]	BT 0.360 (0.417)	DT 0.000 (0.056)	lr 0.0002	loss 0.134 (0.130)
Train: [22][520/589]	BT 0.361 (0.420)	DT 0.000 (0.059)	lr 0.0002	loss 0.130 (0.130)
Train: [22][530/589]	BT 0.358 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.141 (0.130)
Train: [22][540/589]	BT 0.359 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.115 (0.130)
Train: [22][550/589]	BT 0.358 (0.434)	DT 0.000 (0.072)	lr 0.0002	loss 0.123 (0.130)
Train: [22][560/589]	BT 0.362 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.129 (0.130)
Train: [22][570/589]	BT 0.359 (0.437)	DT 0.000 (0.076)	lr 0.0002	loss 0.136 (0.130)
Train: [22][580/589]	BT 0.359 (0.444)	DT 0.000 (0.082)	lr 0.0002	loss 0.150 (0.130)
epoch 22, total time 263.30
loss: 0.1298379677656301@Epoch: 22
learning_rate: 0.0002,22
Valid: [22][10/88]	BT 0.110 (0.775)	DT 0.000 (0.664)	loss 0.139 (0.125)
Valid: [22][20/88]	BT 0.110 (0.680)	DT 0.000 (0.571)	loss 0.116 (0.129)
Valid: [22][30/88]	BT 0.110 (0.636)	DT 0.000 (0.526)	loss 0.134 (0.131)
Valid: [22][40/88]	BT 0.109 (0.614)	DT 0.000 (0.505)	loss 0.131 (0.130)
Valid: [22][50/88]	BT 0.110 (0.603)	DT 0.000 (0.493)	loss 0.129 (0.129)
Valid: [22][60/88]	BT 0.109 (0.617)	DT 0.000 (0.507)	loss 0.125 (0.128)
Valid: [22][70/88]	BT 0.391 (0.611)	DT 0.281 (0.502)	loss 0.163 (0.129)
Valid: [22][80/88]	BT 0.247 (0.599)	DT 0.138 (0.489)	loss 0.142 (0.130)
Epoch 0022: val_loss improved from 0.13009 to 0.12980, saving model
==> Saving...
Train: [23][10/589]	BT 0.357 (1.025)	DT 0.000 (0.667)	lr 0.0002	loss 0.124 (0.135)
Train: [23][20/589]	BT 0.359 (0.731)	DT 0.000 (0.371)	lr 0.0002	loss 0.117 (0.132)
Train: [23][30/589]	BT 0.358 (0.645)	DT 0.000 (0.284)	lr 0.0002	loss 0.120 (0.128)
Train: [23][40/589]	BT 0.359 (0.603)	DT 0.000 (0.242)	lr 0.0002	loss 0.139 (0.130)
Train: [23][50/589]	BT 0.359 (0.569)	DT 0.000 (0.208)	lr 0.0002	loss 0.147 (0.130)
Train: [23][60/589]	BT 0.359 (0.560)	DT 0.000 (0.199)	lr 0.0002	loss 0.122 (0.129)
Train: [23][70/589]	BT 0.360 (0.551)	DT 0.000 (0.191)	lr 0.0002	loss 0.130 (0.129)
Train: [23][80/589]	BT 0.358 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.133 (0.129)
Train: [23][90/589]	BT 0.358 (0.544)	DT 0.000 (0.184)	lr 0.0002	loss 0.106 (0.129)
Train: [23][100/589]	BT 0.375 (0.541)	DT 0.000 (0.181)	lr 0.0002	loss 0.141 (0.129)
Train: [23][110/589]	BT 0.387 (0.540)	DT 0.000 (0.179)	lr 0.0002	loss 0.148 (0.129)
Train: [23][120/589]	BT 0.366 (0.534)	DT 0.000 (0.173)	lr 0.0002	loss 0.122 (0.129)
Train: [23][130/589]	BT 0.360 (0.525)	DT 0.000 (0.164)	lr 0.0002	loss 0.129 (0.129)
Train: [23][140/589]	BT 0.364 (0.532)	DT 0.000 (0.171)	lr 0.0002	loss 0.159 (0.129)
Train: [23][150/589]	BT 0.359 (0.526)	DT 0.000 (0.165)	lr 0.0002	loss 0.152 (0.129)
Train: [23][160/589]	BT 0.392 (0.526)	DT 0.000 (0.165)	lr 0.0002	loss 0.139 (0.129)
Train: [23][170/589]	BT 0.369 (0.519)	DT 0.003 (0.158)	lr 0.0002	loss 0.136 (0.129)
Train: [23][180/589]	BT 0.359 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.123 (0.129)
Train: [23][190/589]	BT 0.358 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.122 (0.129)
Train: [23][200/589]	BT 0.392 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.125 (0.129)
Train: [23][210/589]	BT 0.358 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.132 (0.129)
Train: [23][220/589]	BT 0.368 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.108 (0.129)
Train: [23][230/589]	BT 0.359 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.135 (0.129)
Train: [23][240/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.151 (0.130)
Train: [23][250/589]	BT 0.360 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.113 (0.130)
Train: [23][260/589]	BT 0.359 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.120 (0.130)
Train: [23][270/589]	BT 0.359 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.108 (0.130)
Train: [23][280/589]	BT 0.359 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.151 (0.130)
Train: [23][290/589]	BT 0.363 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.138 (0.130)
Train: [23][300/589]	BT 0.360 (0.494)	DT 0.000 (0.134)	lr 0.0002	loss 0.137 (0.130)
Train: [23][310/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.124 (0.130)
Train: [23][320/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.112 (0.130)
Train: [23][330/589]	BT 0.361 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.102 (0.130)
Train: [23][340/589]	BT 0.357 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.109 (0.130)
Train: [23][350/589]	BT 0.358 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.148 (0.130)
Train: [23][360/589]	BT 0.358 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.149 (0.130)
Train: [23][370/589]	BT 0.394 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.128 (0.130)
Train: [23][380/589]	BT 0.360 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.129 (0.130)
Train: [23][390/589]	BT 0.359 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.108 (0.130)
Train: [23][400/589]	BT 0.358 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.137 (0.130)
Train: [23][410/589]	BT 0.359 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.121 (0.130)
Train: [23][420/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.162 (0.130)
Train: [23][430/589]	BT 0.357 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.134 (0.130)
Train: [23][440/589]	BT 0.363 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.121 (0.130)
Train: [23][450/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.125 (0.130)
Train: [23][460/589]	BT 0.360 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.146 (0.130)
Train: [23][470/589]	BT 0.361 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.123 (0.130)
Train: [23][480/589]	BT 0.361 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.141 (0.130)
Train: [23][490/589]	BT 0.371 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.143 (0.130)
Train: [23][500/589]	BT 0.360 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.152 (0.130)
Train: [23][510/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.133 (0.130)
Train: [23][520/589]	BT 0.371 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.145 (0.130)
Train: [23][530/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.130 (0.130)
Train: [23][540/589]	BT 0.357 (0.506)	DT 0.000 (0.145)	lr 0.0002	loss 0.111 (0.130)
Train: [23][550/589]	BT 0.360 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.130 (0.130)
Train: [23][560/589]	BT 0.361 (0.512)	DT 0.000 (0.151)	lr 0.0002	loss 0.141 (0.130)
Train: [23][570/589]	BT 0.359 (0.512)	DT 0.000 (0.151)	lr 0.0002	loss 0.118 (0.130)
Train: [23][580/589]	BT 0.359 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.132 (0.130)
epoch 23, total time 303.43
loss: 0.12988762848596805@Epoch: 23
learning_rate: 0.0002,23
Valid: [23][10/88]	BT 0.110 (0.656)	DT 0.001 (0.546)	loss 0.130 (0.129)
Valid: [23][20/88]	BT 0.110 (0.545)	DT 0.000 (0.435)	loss 0.151 (0.132)
Valid: [23][30/88]	BT 0.110 (0.537)	DT 0.000 (0.427)	loss 0.113 (0.131)
Valid: [23][40/88]	BT 0.110 (0.527)	DT 0.000 (0.416)	loss 0.155 (0.132)
Valid: [23][50/88]	BT 0.109 (0.526)	DT 0.000 (0.416)	loss 0.150 (0.133)
Valid: [23][60/88]	BT 0.110 (0.507)	DT 0.000 (0.397)	loss 0.115 (0.132)
Valid: [23][70/88]	BT 0.109 (0.493)	DT 0.000 (0.382)	loss 0.114 (0.133)
Valid: [23][80/88]	BT 0.109 (0.495)	DT 0.000 (0.384)	loss 0.110 (0.132)
Train: [24][10/589]	BT 0.355 (0.866)	DT 0.000 (0.507)	lr 0.0002	loss 0.100 (0.126)
Train: [24][20/589]	BT 0.358 (0.626)	DT 0.000 (0.266)	lr 0.0002	loss 0.157 (0.128)
Train: [24][30/589]	BT 0.358 (0.559)	DT 0.000 (0.199)	lr 0.0002	loss 0.118 (0.127)
Train: [24][40/589]	BT 0.358 (0.556)	DT 0.000 (0.196)	lr 0.0002	loss 0.123 (0.126)
Train: [24][50/589]	BT 0.357 (0.543)	DT 0.000 (0.183)	lr 0.0002	loss 0.141 (0.128)
Train: [24][60/589]	BT 0.358 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.110 (0.127)
Train: [24][70/589]	BT 0.362 (0.550)	DT 0.000 (0.190)	lr 0.0002	loss 0.148 (0.128)
Train: [24][80/589]	BT 0.360 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.119 (0.129)
Train: [24][90/589]	BT 0.359 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.118 (0.129)
Train: [24][100/589]	BT 0.359 (0.512)	DT 0.000 (0.153)	lr 0.0002	loss 0.126 (0.129)
Train: [24][110/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.128 (0.129)
Train: [24][120/589]	BT 0.359 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.127 (0.129)
Train: [24][130/589]	BT 0.359 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.130 (0.129)
Train: [24][140/589]	BT 0.357 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.156 (0.129)
Train: [24][150/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.127 (0.129)
Train: [24][160/589]	BT 0.358 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.141 (0.129)
Train: [24][170/589]	BT 0.359 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.120 (0.129)
Train: [24][180/589]	BT 0.358 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.127 (0.129)
Train: [24][190/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.120 (0.129)
Train: [24][200/589]	BT 0.359 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.133 (0.129)
Train: [24][210/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.120 (0.129)
Train: [24][220/589]	BT 0.360 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.137 (0.129)
Train: [24][230/589]	BT 0.357 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.111 (0.129)
Train: [24][240/589]	BT 0.357 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.126 (0.129)
Train: [24][250/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.143 (0.129)
Train: [24][260/589]	BT 0.359 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.116 (0.129)
Train: [24][270/589]	BT 0.360 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.146 (0.129)
Train: [24][280/589]	BT 0.370 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.127 (0.129)
Train: [24][290/589]	BT 0.359 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.153 (0.129)
Train: [24][300/589]	BT 0.399 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.136 (0.129)
Train: [24][310/589]	BT 0.357 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.168 (0.129)
Train: [24][320/589]	BT 0.356 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.160 (0.129)
Train: [24][330/589]	BT 0.388 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.135 (0.129)
Train: [24][340/589]	BT 0.358 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.129 (0.129)
Train: [24][350/589]	BT 0.358 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.131 (0.129)
Train: [24][360/589]	BT 0.359 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.113 (0.129)
Train: [24][370/589]	BT 0.357 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.121 (0.129)
Train: [24][380/589]	BT 0.358 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.126 (0.129)
Train: [24][390/589]	BT 0.386 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.147 (0.129)
Train: [24][400/589]	BT 0.359 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.106 (0.129)
Train: [24][410/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.124 (0.129)
Train: [24][420/589]	BT 0.358 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.123 (0.129)
Train: [24][430/589]	BT 0.359 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.131 (0.129)
Train: [24][440/589]	BT 0.359 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.109 (0.129)
Train: [24][450/589]	BT 0.388 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.121 (0.129)
Train: [24][460/589]	BT 0.397 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.116 (0.129)
Train: [24][470/589]	BT 0.358 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.141 (0.129)
Train: [24][480/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.122 (0.129)
Train: [24][490/589]	BT 0.358 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.140 (0.129)
Train: [24][500/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.136 (0.129)
Train: [24][510/589]	BT 0.355 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.121 (0.129)
Train: [24][520/589]	BT 0.398 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.116 (0.129)
Train: [24][530/589]	BT 0.357 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.133 (0.129)
Train: [24][540/589]	BT 0.356 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.110 (0.129)
Train: [24][550/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.153 (0.129)
Train: [24][560/589]	BT 0.359 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.122 (0.129)
Train: [24][570/589]	BT 0.359 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.136 (0.129)
Train: [24][580/589]	BT 0.358 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.127 (0.129)
epoch 24, total time 288.61
loss: 0.1292246025991916@Epoch: 24
learning_rate: 0.0002,24
Valid: [24][10/88]	BT 0.110 (0.732)	DT 0.000 (0.620)	loss 0.122 (0.136)
Valid: [24][20/88]	BT 0.110 (0.598)	DT 0.000 (0.487)	loss 0.164 (0.139)
Valid: [24][30/88]	BT 0.110 (0.546)	DT 0.000 (0.436)	loss 0.124 (0.137)
Valid: [24][40/88]	BT 0.110 (0.537)	DT 0.000 (0.426)	loss 0.113 (0.135)
Valid: [24][50/88]	BT 0.110 (0.532)	DT 0.000 (0.421)	loss 0.126 (0.136)
Valid: [24][60/88]	BT 0.110 (0.533)	DT 0.000 (0.422)	loss 0.112 (0.135)
Valid: [24][70/88]	BT 0.109 (0.529)	DT 0.000 (0.418)	loss 0.129 (0.135)
Valid: [24][80/88]	BT 0.109 (0.522)	DT 0.000 (0.412)	loss 0.102 (0.134)
Train: [25][10/589]	BT 0.356 (0.779)	DT 0.000 (0.416)	lr 0.0002	loss 0.126 (0.126)
Train: [25][20/589]	BT 0.359 (0.570)	DT 0.000 (0.208)	lr 0.0002	loss 0.116 (0.126)
Train: [25][30/589]	BT 0.358 (0.501)	DT 0.000 (0.139)	lr 0.0002	loss 0.119 (0.127)
Train: [25][40/589]	BT 0.358 (0.466)	DT 0.000 (0.104)	lr 0.0002	loss 0.114 (0.127)
Train: [25][50/589]	BT 0.357 (0.446)	DT 0.000 (0.083)	lr 0.0002	loss 0.124 (0.126)
Train: [25][60/589]	BT 0.358 (0.432)	DT 0.000 (0.069)	lr 0.0002	loss 0.116 (0.127)
Train: [25][70/589]	BT 0.358 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.137 (0.126)
Train: [25][80/589]	BT 0.358 (0.415)	DT 0.000 (0.052)	lr 0.0002	loss 0.102 (0.127)
Train: [25][90/589]	BT 0.361 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.137 (0.127)
Train: [25][100/589]	BT 0.358 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.121 (0.128)
Train: [25][110/589]	BT 0.358 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.115 (0.128)
Train: [25][120/589]	BT 0.359 (0.424)	DT 0.000 (0.063)	lr 0.0002	loss 0.118 (0.127)
Train: [25][130/589]	BT 0.359 (0.420)	DT 0.000 (0.058)	lr 0.0002	loss 0.126 (0.128)
Train: [25][140/589]	BT 0.369 (0.415)	DT 0.000 (0.054)	lr 0.0002	loss 0.102 (0.127)
Train: [25][150/589]	BT 0.358 (0.412)	DT 0.000 (0.050)	lr 0.0002	loss 0.114 (0.128)
Train: [25][160/589]	BT 0.358 (0.410)	DT 0.000 (0.049)	lr 0.0002	loss 0.141 (0.128)
Train: [25][170/589]	BT 0.360 (0.407)	DT 0.000 (0.046)	lr 0.0002	loss 0.127 (0.128)
Train: [25][180/589]	BT 0.358 (0.407)	DT 0.000 (0.046)	lr 0.0002	loss 0.109 (0.128)
Train: [25][190/589]	BT 0.358 (0.411)	DT 0.000 (0.050)	lr 0.0002	loss 0.119 (0.128)
Train: [25][200/589]	BT 0.358 (0.409)	DT 0.000 (0.048)	lr 0.0002	loss 0.117 (0.128)
Train: [25][210/589]	BT 0.395 (0.408)	DT 0.000 (0.046)	lr 0.0002	loss 0.129 (0.128)
Train: [25][220/589]	BT 0.357 (0.407)	DT 0.000 (0.046)	lr 0.0002	loss 0.127 (0.128)
Train: [25][230/589]	BT 0.359 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.126 (0.127)
Train: [25][240/589]	BT 0.358 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.103 (0.127)
Train: [25][250/589]	BT 0.360 (0.404)	DT 0.000 (0.043)	lr 0.0002	loss 0.124 (0.127)
Train: [25][260/589]	BT 0.360 (0.403)	DT 0.000 (0.041)	lr 0.0002	loss 0.131 (0.127)
Train: [25][270/589]	BT 0.358 (0.404)	DT 0.000 (0.042)	lr 0.0002	loss 0.103 (0.127)
Train: [25][280/589]	BT 0.362 (0.403)	DT 0.000 (0.041)	lr 0.0002	loss 0.132 (0.127)
Train: [25][290/589]	BT 0.361 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.112 (0.127)
Train: [25][300/589]	BT 0.362 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.145 (0.128)
Train: [25][310/589]	BT 0.363 (0.400)	DT 0.000 (0.037)	lr 0.0002	loss 0.129 (0.128)
Train: [25][320/589]	BT 0.360 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.121 (0.128)
Train: [25][330/589]	BT 0.359 (0.398)	DT 0.000 (0.035)	lr 0.0002	loss 0.144 (0.128)
Train: [25][340/589]	BT 0.358 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.133 (0.128)
Train: [25][350/589]	BT 0.358 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.128)
Train: [25][360/589]	BT 0.361 (0.395)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.128)
Train: [25][370/589]	BT 0.369 (0.394)	DT 0.000 (0.032)	lr 0.0002	loss 0.150 (0.128)
Train: [25][380/589]	BT 0.358 (0.397)	DT 0.000 (0.035)	lr 0.0002	loss 0.121 (0.128)
Train: [25][390/589]	BT 0.359 (0.397)	DT 0.000 (0.034)	lr 0.0002	loss 0.117 (0.128)
Train: [25][400/589]	BT 0.375 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.125 (0.128)
Train: [25][410/589]	BT 0.358 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.130 (0.128)
Train: [25][420/589]	BT 0.357 (0.404)	DT 0.000 (0.041)	lr 0.0002	loss 0.148 (0.128)
Train: [25][430/589]	BT 0.359 (0.405)	DT 0.000 (0.043)	lr 0.0002	loss 0.141 (0.128)
Train: [25][440/589]	BT 0.359 (0.409)	DT 0.000 (0.047)	lr 0.0002	loss 0.134 (0.128)
Train: [25][450/589]	BT 0.358 (0.420)	DT 0.000 (0.058)	lr 0.0002	loss 0.154 (0.128)
Train: [25][460/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.143 (0.128)
Train: [25][470/589]	BT 0.356 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.136 (0.128)
Train: [25][480/589]	BT 0.359 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.129 (0.128)
Train: [25][490/589]	BT 0.358 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.140 (0.129)
Train: [25][500/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0002	loss 0.152 (0.129)
Train: [25][510/589]	BT 0.367 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.132 (0.129)
Train: [25][520/589]	BT 0.360 (0.432)	DT 0.000 (0.070)	lr 0.0002	loss 0.172 (0.129)
Train: [25][530/589]	BT 0.359 (0.435)	DT 0.000 (0.073)	lr 0.0002	loss 0.112 (0.129)
Train: [25][540/589]	BT 0.358 (0.438)	DT 0.000 (0.076)	lr 0.0002	loss 0.114 (0.129)
Train: [25][550/589]	BT 0.358 (0.440)	DT 0.000 (0.077)	lr 0.0002	loss 0.144 (0.129)
Train: [25][560/589]	BT 0.358 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.130 (0.129)
Train: [25][570/589]	BT 0.359 (0.440)	DT 0.000 (0.078)	lr 0.0002	loss 0.128 (0.129)
Train: [25][580/589]	BT 0.357 (0.441)	DT 0.000 (0.078)	lr 0.0002	loss 0.138 (0.129)
epoch 25, total time 260.92
loss: 0.12858059656944199@Epoch: 25
learning_rate: 0.0002,25
Valid: [25][10/88]	BT 0.110 (0.637)	DT 0.000 (0.524)	loss 0.137 (0.129)
Valid: [25][20/88]	BT 0.110 (0.619)	DT 0.000 (0.506)	loss 0.131 (0.128)
Valid: [25][30/88]	BT 0.110 (0.601)	DT 0.000 (0.489)	loss 0.136 (0.131)
Valid: [25][40/88]	BT 0.109 (0.572)	DT 0.000 (0.461)	loss 0.129 (0.130)
Valid: [25][50/88]	BT 0.110 (0.558)	DT 0.000 (0.447)	loss 0.146 (0.131)
Valid: [25][60/88]	BT 0.110 (0.541)	DT 0.000 (0.430)	loss 0.143 (0.132)
Valid: [25][70/88]	BT 0.109 (0.532)	DT 0.000 (0.421)	loss 0.131 (0.131)
Valid: [25][80/88]	BT 0.110 (0.520)	DT 0.000 (0.409)	loss 0.130 (0.131)
Train: [26][10/589]	BT 0.357 (0.851)	DT 0.000 (0.492)	lr 0.0002	loss 0.140 (0.137)
Train: [26][20/589]	BT 0.384 (0.661)	DT 0.000 (0.301)	lr 0.0002	loss 0.126 (0.134)
Train: [26][30/589]	BT 0.357 (0.575)	DT 0.000 (0.217)	lr 0.0002	loss 0.129 (0.130)
Train: [26][40/589]	BT 0.358 (0.553)	DT 0.000 (0.194)	lr 0.0002	loss 0.123 (0.131)
Train: [26][50/589]	BT 0.372 (0.525)	DT 0.000 (0.165)	lr 0.0002	loss 0.139 (0.131)
Train: [26][60/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.128 (0.130)
Train: [26][70/589]	BT 0.358 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.106 (0.130)
Train: [26][80/589]	BT 0.356 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.113 (0.130)
Train: [26][90/589]	BT 0.358 (0.472)	DT 0.000 (0.112)	lr 0.0002	loss 0.124 (0.130)
Train: [26][100/589]	BT 0.361 (0.461)	DT 0.000 (0.101)	lr 0.0002	loss 0.140 (0.130)
Train: [26][110/589]	BT 0.356 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.134 (0.129)
Train: [26][120/589]	BT 0.360 (0.448)	DT 0.000 (0.088)	lr 0.0002	loss 0.113 (0.129)
Train: [26][130/589]	BT 0.358 (0.445)	DT 0.000 (0.086)	lr 0.0002	loss 0.120 (0.129)
Train: [26][140/589]	BT 0.362 (0.447)	DT 0.000 (0.087)	lr 0.0002	loss 0.116 (0.128)
Train: [26][150/589]	BT 0.362 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.127 (0.128)
Train: [26][160/589]	BT 0.359 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.106 (0.128)
Train: [26][170/589]	BT 0.357 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.150 (0.128)
Train: [26][180/589]	BT 0.358 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.144 (0.128)
Train: [26][190/589]	BT 0.358 (0.458)	DT 0.000 (0.098)	lr 0.0002	loss 0.107 (0.128)
Train: [26][200/589]	BT 0.359 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.126 (0.128)
Train: [26][210/589]	BT 0.386 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.122 (0.128)
Train: [26][220/589]	BT 0.358 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.121 (0.128)
Train: [26][230/589]	BT 0.359 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.127 (0.129)
Train: [26][240/589]	BT 0.359 (0.449)	DT 0.000 (0.089)	lr 0.0002	loss 0.132 (0.129)
Train: [26][250/589]	BT 0.370 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.132 (0.129)
Train: [26][260/589]	BT 0.358 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.132 (0.129)
Train: [26][270/589]	BT 0.360 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.130 (0.129)
Train: [26][280/589]	BT 0.358 (0.452)	DT 0.000 (0.092)	lr 0.0002	loss 0.126 (0.128)
Train: [26][290/589]	BT 0.358 (0.452)	DT 0.000 (0.092)	lr 0.0002	loss 0.116 (0.128)
Train: [26][300/589]	BT 0.357 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.128 (0.128)
Train: [26][310/589]	BT 0.359 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.132 (0.128)
Train: [26][320/589]	BT 0.357 (0.452)	DT 0.000 (0.092)	lr 0.0002	loss 0.137 (0.129)
Train: [26][330/589]	BT 0.360 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.113 (0.129)
Train: [26][340/589]	BT 0.359 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.136 (0.129)
Train: [26][350/589]	BT 0.359 (0.450)	DT 0.000 (0.090)	lr 0.0002	loss 0.151 (0.129)
Train: [26][360/589]	BT 0.359 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.136 (0.129)
Train: [26][370/589]	BT 0.375 (0.450)	DT 0.000 (0.090)	lr 0.0002	loss 0.108 (0.129)
Train: [26][380/589]	BT 0.361 (0.448)	DT 0.000 (0.088)	lr 0.0002	loss 0.141 (0.128)
Train: [26][390/589]	BT 0.358 (0.447)	DT 0.000 (0.087)	lr 0.0002	loss 0.122 (0.129)
Train: [26][400/589]	BT 0.358 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.137 (0.129)
Train: [26][410/589]	BT 0.358 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.115 (0.129)
Train: [26][420/589]	BT 0.358 (0.449)	DT 0.000 (0.089)	lr 0.0002	loss 0.125 (0.128)
Train: [26][430/589]	BT 0.358 (0.449)	DT 0.000 (0.089)	lr 0.0002	loss 0.111 (0.128)
Train: [26][440/589]	BT 0.359 (0.452)	DT 0.000 (0.092)	lr 0.0002	loss 0.129 (0.128)
Train: [26][450/589]	BT 0.359 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.116 (0.128)
Train: [26][460/589]	BT 0.358 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.151 (0.128)
Train: [26][470/589]	BT 0.359 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.108 (0.128)
Train: [26][480/589]	BT 0.360 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.136 (0.128)
Train: [26][490/589]	BT 0.357 (0.467)	DT 0.000 (0.106)	lr 0.0002	loss 0.125 (0.128)
Train: [26][500/589]	BT 0.359 (0.469)	DT 0.000 (0.109)	lr 0.0002	loss 0.121 (0.128)
Train: [26][510/589]	BT 0.359 (0.470)	DT 0.000 (0.110)	lr 0.0002	loss 0.119 (0.128)
Train: [26][520/589]	BT 0.367 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.119 (0.128)
Train: [26][530/589]	BT 0.358 (0.473)	DT 0.000 (0.113)	lr 0.0002	loss 0.119 (0.128)
Train: [26][540/589]	BT 0.372 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.145 (0.128)
Train: [26][550/589]	BT 0.358 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.122 (0.128)
Train: [26][560/589]	BT 0.358 (0.478)	DT 0.000 (0.118)	lr 0.0002	loss 0.138 (0.128)
Train: [26][570/589]	BT 0.359 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.111 (0.128)
Train: [26][580/589]	BT 0.360 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.117 (0.128)
epoch 26, total time 287.54
loss: 0.1281647373403185@Epoch: 26
learning_rate: 0.0002,26
Valid: [26][10/88]	BT 0.110 (0.671)	DT 0.000 (0.559)	loss 0.118 (0.136)
Valid: [26][20/88]	BT 0.110 (0.739)	DT 0.000 (0.628)	loss 0.132 (0.133)
Valid: [26][30/88]	BT 0.109 (0.671)	DT 0.000 (0.561)	loss 0.124 (0.134)
Valid: [26][40/88]	BT 0.110 (0.615)	DT 0.000 (0.504)	loss 0.115 (0.132)
Valid: [26][50/88]	BT 0.110 (0.577)	DT 0.000 (0.467)	loss 0.115 (0.132)
Valid: [26][60/88]	BT 0.109 (0.560)	DT 0.000 (0.449)	loss 0.121 (0.131)
Valid: [26][70/88]	BT 0.109 (0.544)	DT 0.000 (0.434)	loss 0.146 (0.131)
Valid: [26][80/88]	BT 0.110 (0.547)	DT 0.000 (0.437)	loss 0.127 (0.131)
Train: [27][10/589]	BT 0.357 (0.902)	DT 0.000 (0.545)	lr 0.0002	loss 0.133 (0.126)
Train: [27][20/589]	BT 0.357 (0.669)	DT 0.000 (0.312)	lr 0.0002	loss 0.126 (0.125)
Train: [27][30/589]	BT 0.359 (0.592)	DT 0.000 (0.235)	lr 0.0002	loss 0.116 (0.125)
Train: [27][40/589]	BT 0.358 (0.568)	DT 0.000 (0.210)	lr 0.0002	loss 0.119 (0.125)
Train: [27][50/589]	BT 0.378 (0.536)	DT 0.000 (0.177)	lr 0.0002	loss 0.147 (0.125)
Train: [27][60/589]	BT 0.360 (0.512)	DT 0.000 (0.153)	lr 0.0002	loss 0.143 (0.125)
Train: [27][70/589]	BT 0.358 (0.495)	DT 0.000 (0.136)	lr 0.0002	loss 0.151 (0.125)
Train: [27][80/589]	BT 0.356 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.148 (0.126)
Train: [27][90/589]	BT 0.358 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.109 (0.126)
Train: [27][100/589]	BT 0.357 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.134 (0.127)
Train: [27][110/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.127 (0.128)
Train: [27][120/589]	BT 0.368 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.151 (0.128)
Train: [27][130/589]	BT 0.357 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.110 (0.128)
Train: [27][140/589]	BT 0.357 (0.497)	DT 0.000 (0.138)	lr 0.0002	loss 0.157 (0.128)
Train: [27][150/589]	BT 0.357 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.118 (0.128)
Train: [27][160/589]	BT 0.359 (0.497)	DT 0.000 (0.138)	lr 0.0002	loss 0.134 (0.128)
Train: [27][170/589]	BT 0.388 (0.495)	DT 0.000 (0.135)	lr 0.0002	loss 0.133 (0.128)
Train: [27][180/589]	BT 0.359 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.124 (0.128)
Train: [27][190/589]	BT 0.359 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.133 (0.128)
Train: [27][200/589]	BT 0.356 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.121 (0.128)
Train: [27][210/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.131 (0.128)
Train: [27][220/589]	BT 0.358 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.112 (0.128)
Train: [27][230/589]	BT 0.359 (0.479)	DT 0.000 (0.118)	lr 0.0002	loss 0.126 (0.128)
Train: [27][240/589]	BT 0.359 (0.479)	DT 0.000 (0.118)	lr 0.0002	loss 0.142 (0.127)
Train: [27][250/589]	BT 0.358 (0.481)	DT 0.000 (0.120)	lr 0.0002	loss 0.141 (0.127)
Train: [27][260/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.134 (0.128)
Train: [27][270/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.122 (0.128)
Train: [27][280/589]	BT 0.357 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.134 (0.128)
Train: [27][290/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.137 (0.128)
Train: [27][300/589]	BT 0.359 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.122 (0.127)
Train: [27][310/589]	BT 0.398 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.138 (0.128)
Train: [27][320/589]	BT 0.357 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.109 (0.127)
Train: [27][330/589]	BT 0.357 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.121 (0.128)
Train: [27][340/589]	BT 0.359 (0.514)	DT 0.000 (0.154)	lr 0.0002	loss 0.113 (0.127)
Train: [27][350/589]	BT 0.358 (0.514)	DT 0.000 (0.154)	lr 0.0002	loss 0.113 (0.127)
Train: [27][360/589]	BT 0.357 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.117 (0.127)
Train: [27][370/589]	BT 0.398 (0.519)	DT 0.000 (0.159)	lr 0.0002	loss 0.114 (0.127)
Train: [27][380/589]	BT 0.356 (0.521)	DT 0.000 (0.161)	lr 0.0002	loss 0.138 (0.127)
Train: [27][390/589]	BT 0.358 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.118 (0.127)
Train: [27][400/589]	BT 0.357 (0.525)	DT 0.000 (0.165)	lr 0.0002	loss 0.131 (0.127)
Train: [27][410/589]	BT 0.359 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.136 (0.127)
Train: [27][420/589]	BT 0.358 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.137 (0.128)
Train: [27][430/589]	BT 0.360 (0.525)	DT 0.000 (0.165)	lr 0.0002	loss 0.130 (0.128)
Train: [27][440/589]	BT 0.361 (0.526)	DT 0.000 (0.166)	lr 0.0002	loss 0.125 (0.128)
Train: [27][450/589]	BT 0.361 (0.529)	DT 0.000 (0.169)	lr 0.0002	loss 0.144 (0.128)
Train: [27][460/589]	BT 0.362 (0.529)	DT 0.000 (0.169)	lr 0.0002	loss 0.124 (0.128)
Train: [27][470/589]	BT 0.357 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.138 (0.128)
Train: [27][480/589]	BT 0.357 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.111 (0.128)
Train: [27][490/589]	BT 0.357 (0.532)	DT 0.000 (0.173)	lr 0.0002	loss 0.148 (0.128)
Train: [27][500/589]	BT 0.357 (0.535)	DT 0.000 (0.175)	lr 0.0002	loss 0.126 (0.128)
Train: [27][510/589]	BT 0.358 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.134 (0.128)
Train: [27][520/589]	BT 0.358 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.116 (0.128)
Train: [27][530/589]	BT 0.358 (0.537)	DT 0.000 (0.178)	lr 0.0002	loss 0.138 (0.128)
Train: [27][540/589]	BT 0.358 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.119 (0.128)
Train: [27][550/589]	BT 0.359 (0.537)	DT 0.000 (0.178)	lr 0.0002	loss 0.102 (0.128)
Train: [27][560/589]	BT 0.358 (0.538)	DT 0.000 (0.179)	lr 0.0002	loss 0.134 (0.128)
Train: [27][570/589]	BT 0.358 (0.540)	DT 0.000 (0.180)	lr 0.0002	loss 0.123 (0.128)
Train: [27][580/589]	BT 0.357 (0.539)	DT 0.000 (0.179)	lr 0.0002	loss 0.121 (0.128)
epoch 27, total time 318.79
loss: 0.12783231876833262@Epoch: 27
learning_rate: 0.0002,27
Valid: [27][10/88]	BT 0.110 (0.805)	DT 0.000 (0.695)	loss 0.156 (0.129)
Valid: [27][20/88]	BT 0.110 (0.747)	DT 0.000 (0.637)	loss 0.155 (0.132)
Valid: [27][30/88]	BT 0.110 (0.675)	DT 0.000 (0.565)	loss 0.137 (0.132)
Valid: [27][40/88]	BT 0.109 (0.662)	DT 0.000 (0.552)	loss 0.137 (0.136)
Valid: [27][50/88]	BT 0.109 (0.661)	DT 0.000 (0.552)	loss 0.148 (0.136)
Valid: [27][60/88]	BT 0.110 (0.644)	DT 0.000 (0.534)	loss 0.115 (0.135)
Valid: [27][70/88]	BT 0.109 (0.638)	DT 0.000 (0.528)	loss 0.115 (0.135)
Valid: [27][80/88]	BT 0.109 (0.624)	DT 0.000 (0.514)	loss 0.136 (0.135)
Train: [28][10/589]	BT 0.357 (0.942)	DT 0.000 (0.581)	lr 0.0002	loss 0.098 (0.118)
Train: [28][20/589]	BT 0.358 (0.745)	DT 0.000 (0.386)	lr 0.0002	loss 0.138 (0.122)
Train: [28][30/589]	BT 0.355 (0.636)	DT 0.000 (0.277)	lr 0.0002	loss 0.141 (0.124)
Train: [28][40/589]	BT 0.360 (0.577)	DT 0.000 (0.217)	lr 0.0002	loss 0.131 (0.125)
Train: [28][50/589]	BT 0.360 (0.534)	DT 0.000 (0.174)	lr 0.0002	loss 0.156 (0.126)
Train: [28][60/589]	BT 0.370 (0.507)	DT 0.000 (0.146)	lr 0.0002	loss 0.148 (0.126)
Train: [28][70/589]	BT 0.358 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.138 (0.127)
Train: [28][80/589]	BT 0.399 (0.485)	DT 0.000 (0.123)	lr 0.0002	loss 0.124 (0.127)
Train: [28][90/589]	BT 0.359 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.126 (0.128)
Train: [28][100/589]	BT 0.375 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.138 (0.128)
Train: [28][110/589]	BT 0.358 (0.474)	DT 0.000 (0.112)	lr 0.0002	loss 0.136 (0.129)
Train: [28][120/589]	BT 0.358 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.118 (0.129)
Train: [28][130/589]	BT 0.362 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.121 (0.129)
Train: [28][140/589]	BT 0.358 (0.471)	DT 0.000 (0.109)	lr 0.0002	loss 0.104 (0.129)
Train: [28][150/589]	BT 0.359 (0.467)	DT 0.000 (0.106)	lr 0.0002	loss 0.096 (0.129)
Train: [28][160/589]	BT 0.391 (0.471)	DT 0.000 (0.110)	lr 0.0002	loss 0.111 (0.128)
Train: [28][170/589]	BT 0.390 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.132 (0.128)
Train: [28][180/589]	BT 0.388 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.136 (0.128)
Train: [28][190/589]	BT 0.359 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.122 (0.128)
Train: [28][200/589]	BT 0.359 (0.459)	DT 0.000 (0.097)	lr 0.0002	loss 0.133 (0.128)
Train: [28][210/589]	BT 0.359 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.139 (0.128)
Train: [28][220/589]	BT 0.357 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.141 (0.128)
Train: [28][230/589]	BT 0.359 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.118 (0.128)
Train: [28][240/589]	BT 0.358 (0.455)	DT 0.000 (0.093)	lr 0.0002	loss 0.142 (0.128)
Train: [28][250/589]	BT 0.360 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.125 (0.128)
Train: [28][260/589]	BT 0.358 (0.465)	DT 0.000 (0.103)	lr 0.0002	loss 0.124 (0.128)
Train: [28][270/589]	BT 0.359 (0.468)	DT 0.000 (0.107)	lr 0.0002	loss 0.136 (0.128)
Train: [28][280/589]	BT 0.359 (0.469)	DT 0.000 (0.108)	lr 0.0002	loss 0.114 (0.128)
Train: [28][290/589]	BT 0.358 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.133 (0.128)
Train: [28][300/589]	BT 0.359 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.112 (0.128)
Train: [28][310/589]	BT 0.357 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.123 (0.128)
Train: [28][320/589]	BT 0.358 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.140 (0.128)
Train: [28][330/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.131 (0.128)
Train: [28][340/589]	BT 0.360 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.124 (0.127)
Train: [28][350/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.136 (0.127)
Train: [28][360/589]	BT 0.358 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.120 (0.127)
Train: [28][370/589]	BT 0.358 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.124 (0.127)
Train: [28][380/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.106 (0.127)
Train: [28][390/589]	BT 0.357 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.126 (0.127)
Train: [28][400/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.135 (0.127)
Train: [28][410/589]	BT 0.359 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.117 (0.127)
Train: [28][420/589]	BT 0.398 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.136 (0.127)
Train: [28][430/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.130 (0.127)
Train: [28][440/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.126 (0.127)
Train: [28][450/589]	BT 0.360 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.131 (0.127)
Train: [28][460/589]	BT 0.361 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.112 (0.127)
Train: [28][470/589]	BT 0.359 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.134 (0.127)
Train: [28][480/589]	BT 0.358 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.117 (0.127)
Train: [28][490/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.126 (0.127)
Train: [28][500/589]	BT 0.359 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.115 (0.127)
Train: [28][510/589]	BT 0.357 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.109 (0.127)
Train: [28][520/589]	BT 0.357 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.138 (0.127)
Train: [28][530/589]	BT 0.357 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.099 (0.127)
Train: [28][540/589]	BT 0.360 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.134 (0.127)
Train: [28][550/589]	BT 0.359 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.150 (0.127)
Train: [28][560/589]	BT 0.358 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.142 (0.127)
Train: [28][570/589]	BT 0.358 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.104 (0.127)
Train: [28][580/589]	BT 0.359 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.102 (0.127)
epoch 28, total time 289.72
loss: 0.12723810145790115@Epoch: 28
learning_rate: 0.0002,28
Valid: [28][10/88]	BT 0.109 (0.639)	DT 0.000 (0.526)	loss 0.140 (0.135)
Valid: [28][20/88]	BT 0.109 (0.706)	DT 0.000 (0.594)	loss 0.122 (0.133)
Valid: [28][30/88]	BT 0.110 (0.666)	DT 0.000 (0.555)	loss 0.147 (0.132)
Valid: [28][40/88]	BT 0.110 (0.612)	DT 0.000 (0.501)	loss 0.133 (0.132)
Valid: [28][50/88]	BT 0.109 (0.600)	DT 0.000 (0.489)	loss 0.127 (0.132)
Valid: [28][60/88]	BT 0.110 (0.582)	DT 0.000 (0.471)	loss 0.115 (0.132)
Valid: [28][70/88]	BT 0.110 (0.571)	DT 0.000 (0.461)	loss 0.127 (0.133)
Valid: [28][80/88]	BT 0.109 (0.551)	DT 0.000 (0.441)	loss 0.147 (0.133)
Train: [29][10/589]	BT 0.357 (0.927)	DT 0.000 (0.567)	lr 0.0002	loss 0.146 (0.141)
Train: [29][20/589]	BT 0.357 (0.677)	DT 0.000 (0.317)	lr 0.0002	loss 0.158 (0.135)
Train: [29][30/589]	BT 0.396 (0.598)	DT 0.000 (0.237)	lr 0.0002	loss 0.143 (0.132)
Train: [29][40/589]	BT 0.358 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.138 (0.129)
Train: [29][50/589]	BT 0.360 (0.566)	DT 0.000 (0.206)	lr 0.0002	loss 0.125 (0.129)
Train: [29][60/589]	BT 0.359 (0.567)	DT 0.000 (0.207)	lr 0.0002	loss 0.132 (0.129)
Train: [29][70/589]	BT 0.357 (0.557)	DT 0.000 (0.197)	lr 0.0002	loss 0.107 (0.128)
Train: [29][80/589]	BT 0.357 (0.557)	DT 0.000 (0.198)	lr 0.0002	loss 0.119 (0.127)
Train: [29][90/589]	BT 0.358 (0.564)	DT 0.000 (0.204)	lr 0.0002	loss 0.134 (0.127)
Train: [29][100/589]	BT 0.358 (0.555)	DT 0.000 (0.196)	lr 0.0002	loss 0.114 (0.127)
Train: [29][110/589]	BT 0.359 (0.553)	DT 0.000 (0.194)	lr 0.0002	loss 0.130 (0.127)
Train: [29][120/589]	BT 0.358 (0.559)	DT 0.000 (0.200)	lr 0.0002	loss 0.152 (0.127)
Train: [29][130/589]	BT 0.359 (0.554)	DT 0.000 (0.194)	lr 0.0002	loss 0.143 (0.127)
Train: [29][140/589]	BT 0.372 (0.550)	DT 0.000 (0.191)	lr 0.0002	loss 0.112 (0.127)
Train: [29][150/589]	BT 0.359 (0.547)	DT 0.000 (0.188)	lr 0.0002	loss 0.151 (0.127)
Train: [29][160/589]	BT 0.358 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.103 (0.127)
Train: [29][170/589]	BT 0.358 (0.547)	DT 0.000 (0.187)	lr 0.0002	loss 0.116 (0.127)
Train: [29][180/589]	BT 0.359 (0.545)	DT 0.000 (0.185)	lr 0.0002	loss 0.144 (0.127)
Train: [29][190/589]	BT 0.359 (0.544)	DT 0.000 (0.184)	lr 0.0002	loss 0.129 (0.127)
Train: [29][200/589]	BT 0.384 (0.546)	DT 0.000 (0.186)	lr 0.0002	loss 0.138 (0.127)
Train: [29][210/589]	BT 0.358 (0.546)	DT 0.000 (0.185)	lr 0.0002	loss 0.134 (0.127)
Train: [29][220/589]	BT 0.358 (0.542)	DT 0.000 (0.182)	lr 0.0002	loss 0.141 (0.127)
Train: [29][230/589]	BT 0.359 (0.543)	DT 0.000 (0.183)	lr 0.0002	loss 0.117 (0.126)
Train: [29][240/589]	BT 0.361 (0.542)	DT 0.000 (0.181)	lr 0.0002	loss 0.129 (0.127)
Train: [29][250/589]	BT 0.357 (0.544)	DT 0.000 (0.184)	lr 0.0002	loss 0.121 (0.127)
Train: [29][260/589]	BT 0.359 (0.544)	DT 0.000 (0.183)	lr 0.0002	loss 0.110 (0.127)
Train: [29][270/589]	BT 0.359 (0.543)	DT 0.000 (0.182)	lr 0.0002	loss 0.121 (0.127)
Train: [29][280/589]	BT 0.358 (0.546)	DT 0.000 (0.186)	lr 0.0002	loss 0.136 (0.126)
Train: [29][290/589]	BT 0.358 (0.547)	DT 0.000 (0.186)	lr 0.0002	loss 0.118 (0.126)
Train: [29][300/589]	BT 0.357 (0.550)	DT 0.000 (0.190)	lr 0.0002	loss 0.121 (0.126)
Train: [29][310/589]	BT 0.357 (0.551)	DT 0.000 (0.191)	lr 0.0002	loss 0.110 (0.126)
Train: [29][320/589]	BT 0.398 (0.553)	DT 0.000 (0.193)	lr 0.0002	loss 0.106 (0.126)
Train: [29][330/589]	BT 0.357 (0.552)	DT 0.000 (0.192)	lr 0.0002	loss 0.145 (0.126)
Train: [29][340/589]	BT 0.361 (0.550)	DT 0.000 (0.189)	lr 0.0002	loss 0.125 (0.126)
Train: [29][350/589]	BT 0.389 (0.554)	DT 0.000 (0.193)	lr 0.0002	loss 0.133 (0.126)
Train: [29][360/589]	BT 0.358 (0.552)	DT 0.000 (0.191)	lr 0.0002	loss 0.146 (0.127)
Train: [29][370/589]	BT 0.359 (0.553)	DT 0.000 (0.192)	lr 0.0002	loss 0.146 (0.127)
Train: [29][380/589]	BT 0.358 (0.552)	DT 0.000 (0.191)	lr 0.0002	loss 0.130 (0.127)
Train: [29][390/589]	BT 0.358 (0.551)	DT 0.000 (0.191)	lr 0.0002	loss 0.123 (0.127)
Train: [29][400/589]	BT 0.358 (0.553)	DT 0.000 (0.193)	lr 0.0002	loss 0.123 (0.127)
Train: [29][410/589]	BT 0.360 (0.555)	DT 0.000 (0.195)	lr 0.0002	loss 0.128 (0.127)
Train: [29][420/589]	BT 0.358 (0.556)	DT 0.000 (0.196)	lr 0.0002	loss 0.151 (0.127)
Train: [29][430/589]	BT 0.358 (0.558)	DT 0.000 (0.197)	lr 0.0002	loss 0.118 (0.127)
Train: [29][440/589]	BT 0.358 (0.557)	DT 0.000 (0.197)	lr 0.0002	loss 0.124 (0.127)
Train: [29][450/589]	BT 0.359 (0.558)	DT 0.000 (0.197)	lr 0.0002	loss 0.126 (0.127)
Train: [29][460/589]	BT 0.359 (0.559)	DT 0.000 (0.199)	lr 0.0002	loss 0.127 (0.127)
Train: [29][470/589]	BT 0.359 (0.559)	DT 0.000 (0.199)	lr 0.0002	loss 0.110 (0.127)
Train: [29][480/589]	BT 0.359 (0.558)	DT 0.000 (0.197)	lr 0.0002	loss 0.097 (0.127)
Train: [29][490/589]	BT 0.357 (0.558)	DT 0.000 (0.198)	lr 0.0002	loss 0.125 (0.127)
Train: [29][500/589]	BT 0.358 (0.558)	DT 0.000 (0.198)	lr 0.0002	loss 0.132 (0.127)
Train: [29][510/589]	BT 0.358 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.154 (0.127)
Train: [29][520/589]	BT 0.358 (0.563)	DT 0.000 (0.203)	lr 0.0002	loss 0.114 (0.127)
Train: [29][530/589]	BT 0.397 (0.563)	DT 0.000 (0.203)	lr 0.0002	loss 0.108 (0.127)
Train: [29][540/589]	BT 0.358 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.125 (0.127)
Train: [29][550/589]	BT 0.358 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.139 (0.127)
Train: [29][560/589]	BT 0.358 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.110 (0.127)
Train: [29][570/589]	BT 0.358 (0.564)	DT 0.000 (0.204)	lr 0.0002	loss 0.137 (0.127)
Train: [29][580/589]	BT 0.358 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.100 (0.127)
epoch 29, total time 332.82
loss: 0.12673868763015@Epoch: 29
learning_rate: 0.0002,29
Valid: [29][10/88]	BT 0.110 (0.734)	DT 0.000 (0.623)	loss 0.121 (0.125)
Valid: [29][20/88]	BT 0.110 (0.609)	DT 0.000 (0.499)	loss 0.098 (0.132)
Valid: [29][30/88]	BT 0.109 (0.568)	DT 0.000 (0.457)	loss 0.135 (0.133)
Valid: [29][40/88]	BT 0.109 (0.565)	DT 0.000 (0.454)	loss 0.134 (0.132)
Valid: [29][50/88]	BT 0.110 (0.551)	DT 0.000 (0.440)	loss 0.119 (0.132)
Valid: [29][60/88]	BT 0.110 (0.541)	DT 0.000 (0.430)	loss 0.144 (0.132)
Valid: [29][70/88]	BT 0.110 (0.539)	DT 0.000 (0.429)	loss 0.133 (0.132)
Valid: [29][80/88]	BT 0.109 (0.534)	DT 0.000 (0.424)	loss 0.111 (0.132)
Train: [30][10/589]	BT 0.358 (0.837)	DT 0.000 (0.477)	lr 0.0002	loss 0.145 (0.126)
Train: [30][20/589]	BT 0.359 (0.632)	DT 0.000 (0.273)	lr 0.0002	loss 0.098 (0.127)
Train: [30][30/589]	BT 0.370 (0.572)	DT 0.000 (0.214)	lr 0.0002	loss 0.126 (0.125)
Train: [30][40/589]	BT 0.359 (0.519)	DT 0.000 (0.160)	lr 0.0002	loss 0.089 (0.124)
Train: [30][50/589]	BT 0.357 (0.506)	DT 0.000 (0.148)	lr 0.0002	loss 0.113 (0.125)
Train: [30][60/589]	BT 0.359 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.116 (0.126)
Train: [30][70/589]	BT 0.400 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.111 (0.126)
Train: [30][80/589]	BT 0.358 (0.487)	DT 0.000 (0.128)	lr 0.0002	loss 0.148 (0.126)
Train: [30][90/589]	BT 0.358 (0.480)	DT 0.000 (0.121)	lr 0.0002	loss 0.131 (0.126)
Train: [30][100/589]	BT 0.397 (0.479)	DT 0.000 (0.120)	lr 0.0002	loss 0.135 (0.126)
Train: [30][110/589]	BT 0.363 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.130 (0.126)
Train: [30][120/589]	BT 0.359 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.132 (0.126)
Train: [30][130/589]	BT 0.358 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.123 (0.126)
Train: [30][140/589]	BT 0.357 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.136 (0.126)
Train: [30][150/589]	BT 0.359 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.120 (0.126)
Train: [30][160/589]	BT 0.356 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.122 (0.126)
Train: [30][170/589]	BT 0.358 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.099 (0.126)
Train: [30][180/589]	BT 0.358 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.153 (0.126)
Train: [30][190/589]	BT 0.359 (0.476)	DT 0.000 (0.116)	lr 0.0002	loss 0.114 (0.125)
Train: [30][200/589]	BT 0.358 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.126 (0.125)
Train: [30][210/589]	BT 0.357 (0.471)	DT 0.000 (0.111)	lr 0.0002	loss 0.118 (0.125)
Train: [30][220/589]	BT 0.359 (0.470)	DT 0.000 (0.110)	lr 0.0002	loss 0.125 (0.125)
Train: [30][230/589]	BT 0.358 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.129 (0.125)
Train: [30][240/589]	BT 0.358 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.136 (0.125)
Train: [30][250/589]	BT 0.390 (0.479)	DT 0.000 (0.119)	lr 0.0002	loss 0.136 (0.126)
Train: [30][260/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.125 (0.126)
Train: [30][270/589]	BT 0.356 (0.485)	DT 0.000 (0.125)	lr 0.0002	loss 0.111 (0.126)
Train: [30][280/589]	BT 0.359 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.151 (0.126)
Train: [30][290/589]	BT 0.361 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.125 (0.126)
Train: [30][300/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.110 (0.126)
Train: [30][310/589]	BT 0.359 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.117 (0.125)
Train: [30][320/589]	BT 0.358 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.106 (0.125)
Train: [30][330/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.120 (0.125)
Train: [30][340/589]	BT 0.357 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.104 (0.126)
Train: [30][350/589]	BT 0.367 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.142 (0.126)
Train: [30][360/589]	BT 0.372 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.168 (0.126)
Train: [30][370/589]	BT 0.361 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.118 (0.126)
Train: [30][380/589]	BT 0.359 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.134 (0.126)
Train: [30][390/589]	BT 0.359 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.119 (0.125)
Train: [30][400/589]	BT 0.358 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.118 (0.126)
Train: [30][410/589]	BT 0.359 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.142 (0.126)
Train: [30][420/589]	BT 0.367 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.128 (0.126)
Train: [30][430/589]	BT 0.358 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.122 (0.126)
Train: [30][440/589]	BT 0.357 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.136 (0.126)
Train: [30][450/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.116 (0.126)
Train: [30][460/589]	BT 0.358 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.124 (0.126)
Train: [30][470/589]	BT 0.358 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.127 (0.126)
Train: [30][480/589]	BT 0.383 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.109 (0.126)
Train: [30][490/589]	BT 0.359 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.132 (0.126)
Train: [30][500/589]	BT 0.454 (0.485)	DT 0.093 (0.125)	lr 0.0002	loss 0.150 (0.126)
Train: [30][510/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.131 (0.126)
Train: [30][520/589]	BT 1.084 (0.487)	DT 0.724 (0.127)	lr 0.0002	loss 0.124 (0.126)
Train: [30][530/589]	BT 0.358 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.142 (0.126)
Train: [30][540/589]	BT 0.358 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.124 (0.126)
Train: [30][550/589]	BT 0.399 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.143 (0.126)
Train: [30][560/589]	BT 0.359 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.130 (0.126)
Train: [30][570/589]	BT 0.358 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.118 (0.126)
Train: [30][580/589]	BT 0.357 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.114 (0.126)
epoch 30, total time 289.90
loss: 0.12604220870613975@Epoch: 30
learning_rate: 0.0002,30
Valid: [30][10/88]	BT 0.109 (0.620)	DT 0.000 (0.510)	loss 0.106 (0.133)
Valid: [30][20/88]	BT 0.110 (0.542)	DT 0.000 (0.431)	loss 0.107 (0.133)
Valid: [30][30/88]	BT 0.110 (0.490)	DT 0.000 (0.380)	loss 0.128 (0.132)
Valid: [30][40/88]	BT 0.109 (0.467)	DT 0.000 (0.357)	loss 0.146 (0.134)
Valid: [30][50/88]	BT 0.109 (0.465)	DT 0.000 (0.355)	loss 0.126 (0.134)
Valid: [30][60/88]	BT 0.110 (0.456)	DT 0.000 (0.346)	loss 0.139 (0.133)
Valid: [30][70/88]	BT 0.110 (0.446)	DT 0.000 (0.336)	loss 0.127 (0.134)
Valid: [30][80/88]	BT 0.110 (0.440)	DT 0.000 (0.330)	loss 0.136 (0.134)
Train: [31][10/589]	BT 0.359 (0.829)	DT 0.000 (0.468)	lr 0.0002	loss 0.113 (0.122)
Train: [31][20/589]	BT 0.375 (0.614)	DT 0.000 (0.253)	lr 0.0002	loss 0.122 (0.124)
Train: [31][30/589]	BT 0.358 (0.533)	DT 0.000 (0.170)	lr 0.0002	loss 0.099 (0.122)
Train: [31][40/589]	BT 0.359 (0.492)	DT 0.000 (0.130)	lr 0.0002	loss 0.119 (0.123)
Train: [31][50/589]	BT 0.359 (0.469)	DT 0.000 (0.108)	lr 0.0002	loss 0.140 (0.123)
Train: [31][60/589]	BT 0.359 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.127 (0.122)
Train: [31][70/589]	BT 0.359 (0.438)	DT 0.000 (0.077)	lr 0.0002	loss 0.109 (0.122)
Train: [31][80/589]	BT 0.360 (0.442)	DT 0.000 (0.082)	lr 0.0002	loss 0.137 (0.123)
Train: [31][90/589]	BT 0.358 (0.444)	DT 0.000 (0.084)	lr 0.0002	loss 0.121 (0.124)
Train: [31][100/589]	BT 0.356 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.123 (0.124)
Train: [31][110/589]	BT 0.359 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.108 (0.124)
Train: [31][120/589]	BT 0.359 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.117 (0.124)
Train: [31][130/589]	BT 0.359 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.129 (0.124)
Train: [31][140/589]	BT 0.389 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.119 (0.124)
Train: [31][150/589]	BT 0.401 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.128 (0.124)
Train: [31][160/589]	BT 0.357 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.108 (0.124)
Train: [31][170/589]	BT 0.357 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.113 (0.124)
Train: [31][180/589]	BT 0.358 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.120 (0.124)
Train: [31][190/589]	BT 0.359 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.097 (0.124)
Train: [31][200/589]	BT 0.358 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.117 (0.124)
Train: [31][210/589]	BT 0.358 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.156 (0.124)
Train: [31][220/589]	BT 0.358 (0.450)	DT 0.000 (0.090)	lr 0.0002	loss 0.114 (0.124)
Train: [31][230/589]	BT 0.358 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.147 (0.125)
Train: [31][240/589]	BT 0.359 (0.450)	DT 0.000 (0.090)	lr 0.0002	loss 0.125 (0.125)
Train: [31][250/589]	BT 0.358 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.132 (0.125)
Train: [31][260/589]	BT 0.357 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.109 (0.125)
Train: [31][270/589]	BT 0.358 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.151 (0.125)
Train: [31][280/589]	BT 0.365 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.114 (0.125)
Train: [31][290/589]	BT 0.398 (0.457)	DT 0.000 (0.097)	lr 0.0002	loss 0.135 (0.125)
Train: [31][300/589]	BT 0.369 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.113 (0.125)
Train: [31][310/589]	BT 0.399 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.146 (0.125)
Train: [31][320/589]	BT 0.358 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.115 (0.126)
Train: [31][330/589]	BT 0.358 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.150 (0.126)
Train: [31][340/589]	BT 0.359 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.108 (0.126)
Train: [31][350/589]	BT 0.373 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.132 (0.126)
Train: [31][360/589]	BT 0.386 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.139 (0.126)
Train: [31][370/589]	BT 0.359 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.114 (0.125)
Train: [31][380/589]	BT 0.360 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.142 (0.125)
Train: [31][390/589]	BT 0.359 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.134 (0.126)
Train: [31][400/589]	BT 0.359 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.116 (0.125)
Train: [31][410/589]	BT 0.359 (0.447)	DT 0.000 (0.086)	lr 0.0002	loss 0.119 (0.125)
Train: [31][420/589]	BT 0.358 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.146 (0.126)
Train: [31][430/589]	BT 0.359 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.127 (0.126)
Train: [31][440/589]	BT 0.360 (0.447)	DT 0.000 (0.086)	lr 0.0002	loss 0.129 (0.126)
Train: [31][450/589]	BT 0.360 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.153 (0.126)
Train: [31][460/589]	BT 0.357 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.131 (0.126)
Train: [31][470/589]	BT 0.358 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.130 (0.126)
Train: [31][480/589]	BT 0.358 (0.449)	DT 0.000 (0.088)	lr 0.0002	loss 0.110 (0.126)
Train: [31][490/589]	BT 0.358 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.130 (0.126)
Train: [31][500/589]	BT 0.358 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.098 (0.126)
Train: [31][510/589]	BT 0.358 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.116 (0.126)
Train: [31][520/589]	BT 0.358 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.140 (0.125)
Train: [31][530/589]	BT 0.360 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.117 (0.125)
Train: [31][540/589]	BT 0.359 (0.455)	DT 0.000 (0.094)	lr 0.0002	loss 0.151 (0.125)
Train: [31][550/589]	BT 0.360 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.137 (0.126)
Train: [31][560/589]	BT 0.359 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.131 (0.126)
Train: [31][570/589]	BT 0.358 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.141 (0.126)
Train: [31][580/589]	BT 0.357 (0.466)	DT 0.000 (0.106)	lr 0.0002	loss 0.124 (0.126)
epoch 31, total time 275.69
loss: 0.12570106199662953@Epoch: 31
learning_rate: 0.0002,31
Valid: [31][10/88]	BT 0.109 (0.663)	DT 0.000 (0.554)	loss 0.143 (0.134)
Valid: [31][20/88]	BT 0.110 (0.692)	DT 0.000 (0.582)	loss 0.135 (0.135)
Valid: [31][30/88]	BT 0.110 (0.737)	DT 0.000 (0.627)	loss 0.133 (0.136)
Valid: [31][40/88]	BT 0.110 (0.819)	DT 0.000 (0.709)	loss 0.136 (0.135)
Valid: [31][50/88]	BT 0.110 (0.800)	DT 0.000 (0.690)	loss 0.147 (0.134)
Valid: [31][60/88]	BT 0.109 (0.759)	DT 0.000 (0.649)	loss 0.144 (0.136)
Valid: [31][70/88]	BT 0.110 (0.730)	DT 0.000 (0.620)	loss 0.127 (0.136)
Valid: [31][80/88]	BT 0.109 (0.714)	DT 0.000 (0.604)	loss 0.128 (0.136)
Train: [32][10/589]	BT 0.357 (0.921)	DT 0.000 (0.559)	lr 0.0002	loss 0.124 (0.126)
Train: [32][20/589]	BT 0.357 (0.691)	DT 0.000 (0.332)	lr 0.0002	loss 0.144 (0.129)
Train: [32][30/589]	BT 0.372 (0.632)	DT 0.000 (0.273)	lr 0.0002	loss 0.130 (0.127)
Train: [32][40/589]	BT 0.358 (0.601)	DT 0.000 (0.242)	lr 0.0002	loss 0.119 (0.127)
Train: [32][50/589]	BT 0.358 (0.592)	DT 0.000 (0.233)	lr 0.0002	loss 0.112 (0.127)
Train: [32][60/589]	BT 0.357 (0.577)	DT 0.000 (0.218)	lr 0.0002	loss 0.111 (0.126)
Train: [32][70/589]	BT 0.358 (0.571)	DT 0.000 (0.211)	lr 0.0002	loss 0.139 (0.126)
Train: [32][80/589]	BT 0.359 (0.552)	DT 0.000 (0.192)	lr 0.0002	loss 0.130 (0.126)
Train: [32][90/589]	BT 0.357 (0.538)	DT 0.000 (0.178)	lr 0.0002	loss 0.110 (0.126)
Train: [32][100/589]	BT 0.357 (0.534)	DT 0.000 (0.175)	lr 0.0002	loss 0.117 (0.126)
Train: [32][110/589]	BT 0.358 (0.532)	DT 0.000 (0.172)	lr 0.0002	loss 0.159 (0.126)
Train: [32][120/589]	BT 0.358 (0.524)	DT 0.000 (0.164)	lr 0.0002	loss 0.122 (0.126)
Train: [32][130/589]	BT 0.397 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.122 (0.126)
Train: [32][140/589]	BT 0.358 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.128 (0.126)
Train: [32][150/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.125 (0.125)
Train: [32][160/589]	BT 0.359 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.112 (0.126)
Train: [32][170/589]	BT 0.360 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.115 (0.126)
Train: [32][180/589]	BT 0.359 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.136 (0.126)
Train: [32][190/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.135 (0.126)
Train: [32][200/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.114 (0.126)
Train: [32][210/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.130 (0.126)
Train: [32][220/589]	BT 0.360 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.135 (0.126)
Train: [32][230/589]	BT 0.362 (0.501)	DT 0.000 (0.142)	lr 0.0002	loss 0.102 (0.126)
Train: [32][240/589]	BT 0.358 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.137 (0.126)
Train: [32][250/589]	BT 0.359 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.138 (0.126)
Train: [32][260/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0002	loss 0.123 (0.126)
Train: [32][270/589]	BT 0.358 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.101 (0.126)
Train: [32][280/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.131 (0.126)
Train: [32][290/589]	BT 0.360 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.124 (0.126)
Train: [32][300/589]	BT 0.358 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.109 (0.126)
Train: [32][310/589]	BT 0.359 (0.495)	DT 0.000 (0.136)	lr 0.0002	loss 0.127 (0.126)
Train: [32][320/589]	BT 0.360 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.110 (0.126)
Train: [32][330/589]	BT 0.357 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.154 (0.126)
Train: [32][340/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.127 (0.126)
Train: [32][350/589]	BT 0.390 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.105 (0.126)
Train: [32][360/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.114 (0.126)
Train: [32][370/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.117 (0.126)
Train: [32][380/589]	BT 0.358 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.148 (0.126)
Train: [32][390/589]	BT 0.359 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.120 (0.126)
Train: [32][400/589]	BT 0.358 (0.495)	DT 0.000 (0.135)	lr 0.0002	loss 0.132 (0.126)
Train: [32][410/589]	BT 0.359 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.107 (0.126)
Train: [32][420/589]	BT 0.357 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.126 (0.126)
Train: [32][430/589]	BT 0.359 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.119 (0.126)
Train: [32][440/589]	BT 0.381 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.143 (0.126)
Train: [32][450/589]	BT 0.393 (0.492)	DT 0.000 (0.131)	lr 0.0002	loss 0.112 (0.126)
Train: [32][460/589]	BT 0.380 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.128 (0.126)
Train: [32][470/589]	BT 0.359 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.127 (0.126)
Train: [32][480/589]	BT 0.359 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.134 (0.126)
Train: [32][490/589]	BT 0.360 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.121 (0.125)
Train: [32][500/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.109 (0.126)
Train: [32][510/589]	BT 0.361 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.112 (0.125)
Train: [32][520/589]	BT 0.358 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.110 (0.125)
Train: [32][530/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.110 (0.125)
Train: [32][540/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.122 (0.125)
Train: [32][550/589]	BT 0.541 (0.487)	DT 0.180 (0.127)	lr 0.0002	loss 0.131 (0.125)
Train: [32][560/589]	BT 2.218 (0.490)	DT 1.859 (0.129)	lr 0.0002	loss 0.122 (0.125)
Train: [32][570/589]	BT 1.123 (0.489)	DT 0.761 (0.128)	lr 0.0002	loss 0.115 (0.125)
Train: [32][580/589]	BT 1.774 (0.490)	DT 1.413 (0.129)	lr 0.0002	loss 0.109 (0.125)
epoch 32, total time 287.93
loss: 0.12515406754079178@Epoch: 32
learning_rate: 0.0002,32
Valid: [32][10/88]	BT 0.109 (0.614)	DT 0.000 (0.501)	loss 0.117 (0.134)
Valid: [32][20/88]	BT 0.110 (0.523)	DT 0.000 (0.411)	loss 0.145 (0.136)
Valid: [32][30/88]	BT 0.109 (0.489)	DT 0.000 (0.378)	loss 0.143 (0.135)
Valid: [32][40/88]	BT 0.109 (0.492)	DT 0.000 (0.382)	loss 0.132 (0.134)
Valid: [32][50/88]	BT 0.110 (0.475)	DT 0.000 (0.365)	loss 0.139 (0.134)
Valid: [32][60/88]	BT 0.110 (0.475)	DT 0.000 (0.365)	loss 0.109 (0.133)
Valid: [32][70/88]	BT 0.109 (0.484)	DT 0.000 (0.374)	loss 0.173 (0.133)
Valid: [32][80/88]	BT 0.110 (0.487)	DT 0.000 (0.377)	loss 0.139 (0.134)
Train: [33][10/589]	BT 0.363 (1.042)	DT 0.000 (0.683)	lr 0.0002	loss 0.111 (0.126)
Train: [33][20/589]	BT 0.359 (0.735)	DT 0.000 (0.377)	lr 0.0002	loss 0.122 (0.126)
Train: [33][30/589]	BT 0.372 (0.642)	DT 0.000 (0.284)	lr 0.0002	loss 0.129 (0.127)
Train: [33][40/589]	BT 0.364 (0.600)	DT 0.000 (0.241)	lr 0.0002	loss 0.118 (0.128)
Train: [33][50/589]	BT 0.390 (0.572)	DT 0.000 (0.213)	lr 0.0002	loss 0.166 (0.128)
Train: [33][60/589]	BT 0.358 (0.548)	DT 0.000 (0.189)	lr 0.0002	loss 0.116 (0.128)
Train: [33][70/589]	BT 0.357 (0.542)	DT 0.000 (0.183)	lr 0.0002	loss 0.122 (0.126)
Train: [33][80/589]	BT 0.378 (0.536)	DT 0.000 (0.176)	lr 0.0002	loss 0.128 (0.125)
Train: [33][90/589]	BT 0.371 (0.536)	DT 0.000 (0.176)	lr 0.0002	loss 0.118 (0.125)
Train: [33][100/589]	BT 0.360 (0.527)	DT 0.000 (0.168)	lr 0.0002	loss 0.120 (0.124)
Train: [33][110/589]	BT 0.357 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.131 (0.125)
Train: [33][120/589]	BT 0.356 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.135 (0.124)
Train: [33][130/589]	BT 0.356 (0.518)	DT 0.000 (0.159)	lr 0.0002	loss 0.144 (0.125)
Train: [33][140/589]	BT 0.359 (0.519)	DT 0.000 (0.160)	lr 0.0002	loss 0.123 (0.124)
Train: [33][150/589]	BT 0.358 (0.519)	DT 0.000 (0.160)	lr 0.0002	loss 0.131 (0.124)
Train: [33][160/589]	BT 0.359 (0.518)	DT 0.000 (0.159)	lr 0.0002	loss 0.120 (0.124)
Train: [33][170/589]	BT 0.359 (0.515)	DT 0.000 (0.156)	lr 0.0002	loss 0.123 (0.124)
Train: [33][180/589]	BT 0.359 (0.514)	DT 0.000 (0.155)	lr 0.0002	loss 0.117 (0.123)
Train: [33][190/589]	BT 0.359 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.131 (0.124)
Train: [33][200/589]	BT 0.361 (0.515)	DT 0.000 (0.155)	lr 0.0002	loss 0.121 (0.124)
Train: [33][210/589]	BT 0.358 (0.514)	DT 0.000 (0.154)	lr 0.0002	loss 0.138 (0.124)
Train: [33][220/589]	BT 0.361 (0.511)	DT 0.000 (0.152)	lr 0.0002	loss 0.112 (0.124)
Train: [33][230/589]	BT 0.359 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.130 (0.124)
Train: [33][240/589]	BT 0.357 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.129 (0.124)
Train: [33][250/589]	BT 0.357 (0.506)	DT 0.000 (0.147)	lr 0.0002	loss 0.114 (0.124)
Train: [33][260/589]	BT 0.360 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.122 (0.124)
Train: [33][270/589]	BT 0.357 (0.503)	DT 0.000 (0.144)	lr 0.0002	loss 0.123 (0.124)
Train: [33][280/589]	BT 0.358 (0.502)	DT 0.000 (0.143)	lr 0.0002	loss 0.125 (0.124)
Train: [33][290/589]	BT 0.359 (0.500)	DT 0.000 (0.141)	lr 0.0002	loss 0.137 (0.125)
Train: [33][300/589]	BT 0.359 (0.498)	DT 0.000 (0.139)	lr 0.0002	loss 0.115 (0.125)
Train: [33][310/589]	BT 0.359 (0.498)	DT 0.000 (0.139)	lr 0.0002	loss 0.119 (0.125)
Train: [33][320/589]	BT 0.359 (0.495)	DT 0.000 (0.136)	lr 0.0002	loss 0.139 (0.125)
Train: [33][330/589]	BT 0.357 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.116 (0.125)
Train: [33][340/589]	BT 0.359 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.119 (0.125)
Train: [33][350/589]	BT 0.359 (0.492)	DT 0.000 (0.132)	lr 0.0002	loss 0.142 (0.125)
Train: [33][360/589]	BT 0.358 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.112 (0.125)
Train: [33][370/589]	BT 0.379 (0.492)	DT 0.000 (0.132)	lr 0.0002	loss 0.139 (0.125)
Train: [33][380/589]	BT 0.357 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.117 (0.125)
Train: [33][390/589]	BT 0.358 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.142 (0.125)
Train: [33][400/589]	BT 0.361 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.121 (0.125)
Train: [33][410/589]	BT 0.358 (0.492)	DT 0.000 (0.133)	lr 0.0002	loss 0.146 (0.125)
Train: [33][420/589]	BT 0.371 (0.495)	DT 0.000 (0.135)	lr 0.0002	loss 0.103 (0.125)
Train: [33][430/589]	BT 0.359 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.109 (0.125)
Train: [33][440/589]	BT 0.358 (0.497)	DT 0.000 (0.138)	lr 0.0002	loss 0.124 (0.125)
Train: [33][450/589]	BT 0.359 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.112 (0.125)
Train: [33][460/589]	BT 0.358 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.134 (0.125)
Train: [33][470/589]	BT 0.359 (0.498)	DT 0.000 (0.139)	lr 0.0002	loss 0.137 (0.125)
Train: [33][480/589]	BT 0.357 (0.499)	DT 0.000 (0.140)	lr 0.0002	loss 0.117 (0.125)
Train: [33][490/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.124 (0.125)
Train: [33][500/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.108 (0.125)
Train: [33][510/589]	BT 0.360 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.135 (0.125)
Train: [33][520/589]	BT 0.357 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.119 (0.125)
Train: [33][530/589]	BT 0.361 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.135 (0.125)
Train: [33][540/589]	BT 0.356 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.132 (0.125)
Train: [33][550/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.137 (0.125)
Train: [33][560/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.118 (0.125)
Train: [33][570/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.125 (0.125)
Train: [33][580/589]	BT 0.359 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.108 (0.125)
epoch 33, total time 299.21
loss: 0.12477033186109551@Epoch: 33
learning_rate: 0.0002,33
Valid: [33][10/88]	BT 0.109 (0.747)	DT 0.000 (0.637)	loss 0.103 (0.137)
Valid: [33][20/88]	BT 0.109 (0.616)	DT 0.000 (0.506)	loss 0.145 (0.134)
Valid: [33][30/88]	BT 0.110 (0.565)	DT 0.000 (0.455)	loss 0.126 (0.136)
Valid: [33][40/88]	BT 0.110 (0.546)	DT 0.000 (0.436)	loss 0.129 (0.136)
Valid: [33][50/88]	BT 0.110 (0.564)	DT 0.000 (0.454)	loss 0.125 (0.135)
Valid: [33][60/88]	BT 0.109 (0.564)	DT 0.000 (0.454)	loss 0.142 (0.134)
Valid: [33][70/88]	BT 0.109 (0.560)	DT 0.000 (0.451)	loss 0.134 (0.135)
Valid: [33][80/88]	BT 0.109 (0.555)	DT 0.000 (0.445)	loss 0.137 (0.135)
Train: [34][10/589]	BT 0.357 (0.913)	DT 0.000 (0.556)	lr 0.0002	loss 0.128 (0.127)
Train: [34][20/589]	BT 0.362 (0.684)	DT 0.000 (0.327)	lr 0.0002	loss 0.130 (0.125)
Train: [34][30/589]	BT 0.359 (0.582)	DT 0.000 (0.225)	lr 0.0002	loss 0.113 (0.123)
Train: [34][40/589]	BT 0.358 (0.540)	DT 0.000 (0.182)	lr 0.0002	loss 0.125 (0.124)
Train: [34][50/589]	BT 0.389 (0.566)	DT 0.000 (0.208)	lr 0.0002	loss 0.141 (0.124)
Train: [34][60/589]	BT 0.395 (0.550)	DT 0.000 (0.191)	lr 0.0002	loss 0.129 (0.124)
Train: [34][70/589]	BT 0.386 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.118 (0.124)
Train: [34][80/589]	BT 0.388 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.103 (0.123)
Train: [34][90/589]	BT 0.359 (0.521)	DT 0.000 (0.160)	lr 0.0002	loss 0.123 (0.123)
Train: [34][100/589]	BT 0.358 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.117 (0.123)
Train: [34][110/589]	BT 0.358 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.130 (0.122)
Train: [34][120/589]	BT 0.378 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.119 (0.122)
Train: [34][130/589]	BT 0.357 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.134 (0.122)
Train: [34][140/589]	BT 0.358 (0.512)	DT 0.000 (0.151)	lr 0.0002	loss 0.153 (0.122)
Train: [34][150/589]	BT 0.398 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.118 (0.123)
Train: [34][160/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.133 (0.123)
Train: [34][170/589]	BT 0.359 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.110 (0.122)
Train: [34][180/589]	BT 0.358 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.114 (0.123)
Train: [34][190/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.141 (0.123)
Train: [34][200/589]	BT 0.359 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.114 (0.123)
Train: [34][210/589]	BT 0.398 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.122 (0.123)
Train: [34][220/589]	BT 0.357 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.122 (0.123)
Train: [34][230/589]	BT 0.358 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.129 (0.123)
Train: [34][240/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.126 (0.123)
Train: [34][250/589]	BT 0.358 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.111 (0.123)
Train: [34][260/589]	BT 0.359 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.136 (0.123)
Train: [34][270/589]	BT 0.359 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.129 (0.123)
Train: [34][280/589]	BT 0.357 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.135 (0.123)
Train: [34][290/589]	BT 0.519 (0.500)	DT 0.163 (0.140)	lr 0.0002	loss 0.122 (0.123)
Train: [34][300/589]	BT 0.429 (0.502)	DT 0.073 (0.142)	lr 0.0002	loss 0.124 (0.123)
Train: [34][310/589]	BT 0.357 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.130 (0.123)
Train: [34][320/589]	BT 0.718 (0.512)	DT 0.356 (0.152)	lr 0.0002	loss 0.132 (0.123)
Train: [34][330/589]	BT 0.357 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.115 (0.123)
Train: [34][340/589]	BT 0.820 (0.510)	DT 0.450 (0.150)	lr 0.0002	loss 0.137 (0.123)
Train: [34][350/589]	BT 1.340 (0.509)	DT 0.962 (0.149)	lr 0.0002	loss 0.133 (0.123)
Train: [34][360/589]	BT 3.598 (0.516)	DT 3.239 (0.156)	lr 0.0002	loss 0.139 (0.123)
Train: [34][370/589]	BT 2.200 (0.519)	DT 1.841 (0.159)	lr 0.0002	loss 0.125 (0.123)
Train: [34][380/589]	BT 3.246 (0.522)	DT 2.871 (0.162)	lr 0.0002	loss 0.123 (0.123)
Train: [34][390/589]	BT 3.204 (0.525)	DT 2.844 (0.165)	lr 0.0002	loss 0.143 (0.123)
Train: [34][400/589]	BT 3.486 (0.529)	DT 3.127 (0.169)	lr 0.0002	loss 0.152 (0.124)
Train: [34][410/589]	BT 3.615 (0.533)	DT 3.255 (0.173)	lr 0.0002	loss 0.136 (0.124)
Train: [34][420/589]	BT 1.829 (0.532)	DT 1.470 (0.172)	lr 0.0002	loss 0.122 (0.124)
Train: [34][430/589]	BT 0.358 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.118 (0.124)
Train: [34][440/589]	BT 0.358 (0.530)	DT 0.000 (0.170)	lr 0.0002	loss 0.096 (0.124)
Train: [34][450/589]	BT 2.684 (0.533)	DT 2.325 (0.173)	lr 0.0002	loss 0.135 (0.124)
Train: [34][460/589]	BT 1.525 (0.535)	DT 1.167 (0.175)	lr 0.0002	loss 0.123 (0.124)
Train: [34][470/589]	BT 0.582 (0.534)	DT 0.224 (0.174)	lr 0.0002	loss 0.129 (0.124)
Train: [34][480/589]	BT 0.465 (0.532)	DT 0.107 (0.172)	lr 0.0002	loss 0.120 (0.124)
Train: [34][490/589]	BT 0.359 (0.532)	DT 0.000 (0.172)	lr 0.0002	loss 0.115 (0.124)
Train: [34][500/589]	BT 1.231 (0.533)	DT 0.872 (0.173)	lr 0.0002	loss 0.122 (0.124)
Train: [34][510/589]	BT 1.255 (0.532)	DT 0.879 (0.172)	lr 0.0002	loss 0.133 (0.124)
Train: [34][520/589]	BT 1.436 (0.531)	DT 1.077 (0.171)	lr 0.0002	loss 0.120 (0.124)
Train: [34][530/589]	BT 1.283 (0.530)	DT 0.925 (0.170)	lr 0.0002	loss 0.105 (0.124)
Train: [34][540/589]	BT 1.772 (0.529)	DT 1.413 (0.169)	lr 0.0002	loss 0.124 (0.124)
Train: [34][550/589]	BT 1.126 (0.527)	DT 0.765 (0.167)	lr 0.0002	loss 0.115 (0.124)
Train: [34][560/589]	BT 1.498 (0.526)	DT 1.139 (0.166)	lr 0.0002	loss 0.135 (0.124)
Train: [34][570/589]	BT 1.573 (0.526)	DT 1.211 (0.166)	lr 0.0002	loss 0.147 (0.124)
Train: [34][580/589]	BT 0.866 (0.524)	DT 0.507 (0.164)	lr 0.0002	loss 0.135 (0.124)
epoch 34, total time 306.84
loss: 0.12426614666696767@Epoch: 34
learning_rate: 0.0002,34
Valid: [34][10/88]	BT 0.110 (0.591)	DT 0.000 (0.481)	loss 0.137 (0.132)
Valid: [34][20/88]	BT 0.109 (0.485)	DT 0.000 (0.374)	loss 0.142 (0.139)
Valid: [34][30/88]	BT 0.110 (0.481)	DT 0.000 (0.370)	loss 0.140 (0.136)
Valid: [34][40/88]	BT 0.109 (0.505)	DT 0.000 (0.394)	loss 0.141 (0.135)
Valid: [34][50/88]	BT 0.110 (0.494)	DT 0.000 (0.383)	loss 0.107 (0.134)
Valid: [34][60/88]	BT 0.109 (0.485)	DT 0.000 (0.374)	loss 0.164 (0.135)
Valid: [34][70/88]	BT 0.109 (0.480)	DT 0.000 (0.369)	loss 0.108 (0.133)
Valid: [34][80/88]	BT 0.110 (0.478)	DT 0.000 (0.367)	loss 0.124 (0.133)
Train: [35][10/589]	BT 0.359 (0.826)	DT 0.000 (0.463)	lr 0.0002	loss 0.126 (0.127)
Train: [35][20/589]	BT 0.358 (0.663)	DT 0.000 (0.303)	lr 0.0002	loss 0.133 (0.126)
Train: [35][30/589]	BT 0.358 (0.598)	DT 0.000 (0.239)	lr 0.0002	loss 0.126 (0.126)
Train: [35][40/589]	BT 0.357 (0.550)	DT 0.000 (0.191)	lr 0.0002	loss 0.113 (0.123)
Train: [35][50/589]	BT 0.357 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.126 (0.122)
Train: [35][60/589]	BT 0.359 (0.507)	DT 0.000 (0.148)	lr 0.0002	loss 0.132 (0.123)
Train: [35][70/589]	BT 0.359 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.106 (0.123)
Train: [35][80/589]	BT 0.359 (0.475)	DT 0.000 (0.116)	lr 0.0002	loss 0.130 (0.123)
Train: [35][90/589]	BT 0.359 (0.472)	DT 0.000 (0.113)	lr 0.0002	loss 0.112 (0.123)
Train: [35][100/589]	BT 0.359 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.108 (0.123)
Train: [35][110/589]	BT 0.359 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.145 (0.123)
Train: [35][120/589]	BT 0.360 (0.448)	DT 0.000 (0.088)	lr 0.0002	loss 0.135 (0.123)
Train: [35][130/589]	BT 0.368 (0.442)	DT 0.000 (0.081)	lr 0.0002	loss 0.138 (0.124)
Train: [35][140/589]	BT 0.360 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.095 (0.123)
Train: [35][150/589]	BT 0.358 (0.431)	DT 0.000 (0.071)	lr 0.0002	loss 0.114 (0.123)
Train: [35][160/589]	BT 0.358 (0.432)	DT 0.000 (0.071)	lr 0.0002	loss 0.127 (0.123)
Train: [35][170/589]	BT 0.357 (0.430)	DT 0.000 (0.070)	lr 0.0002	loss 0.124 (0.123)
Train: [35][180/589]	BT 0.359 (0.433)	DT 0.000 (0.072)	lr 0.0002	loss 0.097 (0.123)
Train: [35][190/589]	BT 0.358 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.131 (0.123)
Train: [35][200/589]	BT 0.359 (0.437)	DT 0.000 (0.076)	lr 0.0002	loss 0.134 (0.123)
Train: [35][210/589]	BT 0.362 (0.439)	DT 0.000 (0.079)	lr 0.0002	loss 0.130 (0.123)
Train: [35][220/589]	BT 0.358 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.101 (0.123)
Train: [35][230/589]	BT 0.378 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.119 (0.123)
Train: [35][240/589]	BT 0.358 (0.433)	DT 0.000 (0.073)	lr 0.0002	loss 0.126 (0.123)
Train: [35][250/589]	BT 0.358 (0.438)	DT 0.000 (0.077)	lr 0.0002	loss 0.160 (0.123)
Train: [35][260/589]	BT 0.358 (0.441)	DT 0.000 (0.080)	lr 0.0002	loss 0.127 (0.123)
Train: [35][270/589]	BT 0.359 (0.445)	DT 0.000 (0.084)	lr 0.0002	loss 0.116 (0.123)
Train: [35][280/589]	BT 0.357 (0.447)	DT 0.000 (0.087)	lr 0.0002	loss 0.115 (0.123)
Train: [35][290/589]	BT 0.358 (0.448)	DT 0.000 (0.087)	lr 0.0002	loss 0.132 (0.123)
Train: [35][300/589]	BT 0.359 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.114 (0.123)
Train: [35][310/589]	BT 0.363 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.115 (0.123)
Train: [35][320/589]	BT 0.360 (0.452)	DT 0.001 (0.091)	lr 0.0002	loss 0.104 (0.123)
Train: [35][330/589]	BT 0.357 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.107 (0.123)
Train: [35][340/589]	BT 0.359 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.121 (0.123)
Train: [35][350/589]	BT 0.358 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.119 (0.123)
Train: [35][360/589]	BT 0.358 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.126 (0.124)
Train: [35][370/589]	BT 0.358 (0.458)	DT 0.000 (0.098)	lr 0.0002	loss 0.138 (0.124)
Train: [35][380/589]	BT 0.357 (0.458)	DT 0.000 (0.098)	lr 0.0002	loss 0.103 (0.124)
Train: [35][390/589]	BT 0.359 (0.458)	DT 0.000 (0.098)	lr 0.0002	loss 0.120 (0.124)
Train: [35][400/589]	BT 0.397 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.126 (0.124)
Train: [35][410/589]	BT 0.357 (0.464)	DT 0.000 (0.104)	lr 0.0002	loss 0.117 (0.124)
Train: [35][420/589]	BT 0.381 (0.465)	DT 0.000 (0.104)	lr 0.0002	loss 0.115 (0.124)
Train: [35][430/589]	BT 0.358 (0.466)	DT 0.000 (0.106)	lr 0.0002	loss 0.110 (0.124)
Train: [35][440/589]	BT 0.357 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.131 (0.124)
Train: [35][450/589]	BT 0.356 (0.465)	DT 0.000 (0.104)	lr 0.0002	loss 0.134 (0.124)
Train: [35][460/589]	BT 0.358 (0.466)	DT 0.000 (0.106)	lr 0.0002	loss 0.118 (0.124)
Train: [35][470/589]	BT 0.512 (0.466)	DT 0.151 (0.106)	lr 0.0002	loss 0.088 (0.123)
Train: [35][480/589]	BT 0.731 (0.467)	DT 0.370 (0.106)	lr 0.0002	loss 0.119 (0.124)
Train: [35][490/589]	BT 1.030 (0.467)	DT 0.669 (0.107)	lr 0.0002	loss 0.114 (0.124)
Train: [35][500/589]	BT 1.009 (0.472)	DT 0.648 (0.111)	lr 0.0002	loss 0.107 (0.124)
Train: [35][510/589]	BT 0.881 (0.472)	DT 0.520 (0.111)	lr 0.0002	loss 0.112 (0.123)
Train: [35][520/589]	BT 0.977 (0.472)	DT 0.616 (0.112)	lr 0.0002	loss 0.138 (0.124)
Train: [35][530/589]	BT 1.168 (0.472)	DT 0.809 (0.111)	lr 0.0002	loss 0.137 (0.124)
Train: [35][540/589]	BT 1.251 (0.472)	DT 0.891 (0.111)	lr 0.0002	loss 0.133 (0.124)
Train: [35][550/589]	BT 1.265 (0.472)	DT 0.906 (0.111)	lr 0.0002	loss 0.097 (0.124)
Train: [35][560/589]	BT 1.124 (0.472)	DT 0.765 (0.111)	lr 0.0002	loss 0.127 (0.124)
Train: [35][570/589]	BT 1.456 (0.472)	DT 1.101 (0.112)	lr 0.0002	loss 0.129 (0.124)
Train: [35][580/589]	BT 0.849 (0.472)	DT 0.490 (0.112)	lr 0.0002	loss 0.126 (0.124)
epoch 35, total time 277.09
loss: 0.12364387853790905@Epoch: 35
learning_rate: 0.0002,35
Valid: [35][10/88]	BT 0.109 (0.880)	DT 0.000 (0.769)	loss 0.142 (0.131)
Valid: [35][20/88]	BT 0.109 (0.666)	DT 0.000 (0.556)	loss 0.146 (0.134)
Valid: [35][30/88]	BT 0.109 (0.618)	DT 0.000 (0.508)	loss 0.133 (0.136)
Valid: [35][40/88]	BT 0.109 (0.581)	DT 0.000 (0.471)	loss 0.156 (0.137)
Valid: [35][50/88]	BT 0.109 (0.584)	DT 0.000 (0.474)	loss 0.134 (0.136)
Valid: [35][60/88]	BT 0.110 (0.573)	DT 0.000 (0.464)	loss 0.115 (0.136)
Valid: [35][70/88]	BT 0.109 (0.592)	DT 0.000 (0.482)	loss 0.142 (0.135)
Valid: [35][80/88]	BT 0.110 (0.589)	DT 0.000 (0.479)	loss 0.126 (0.134)
Train: [36][10/589]	BT 0.386 (0.917)	DT 0.000 (0.556)	lr 0.0002	loss 0.118 (0.120)
Train: [36][20/589]	BT 0.358 (0.696)	DT 0.000 (0.337)	lr 0.0002	loss 0.113 (0.124)
Train: [36][30/589]	BT 0.358 (0.583)	DT 0.000 (0.225)	lr 0.0002	loss 0.131 (0.123)
Train: [36][40/589]	BT 0.357 (0.534)	DT 0.000 (0.175)	lr 0.0002	loss 0.126 (0.123)
Train: [36][50/589]	BT 0.363 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.122 (0.124)
Train: [36][60/589]	BT 0.357 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.129 (0.125)
Train: [36][70/589]	BT 0.364 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.115 (0.124)
Train: [36][80/589]	BT 0.355 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.146 (0.124)
Train: [36][90/589]	BT 0.357 (0.483)	DT 0.000 (0.124)	lr 0.0002	loss 0.126 (0.124)
Train: [36][100/589]	BT 0.358 (0.486)	DT 0.000 (0.127)	lr 0.0002	loss 0.135 (0.124)
Train: [36][110/589]	BT 0.358 (0.488)	DT 0.000 (0.129)	lr 0.0002	loss 0.113 (0.124)
Train: [36][120/589]	BT 0.358 (0.486)	DT 0.000 (0.128)	lr 0.0002	loss 0.112 (0.123)
Train: [36][130/589]	BT 0.361 (0.489)	DT 0.000 (0.131)	lr 0.0002	loss 0.131 (0.123)
Train: [36][140/589]	BT 0.359 (0.495)	DT 0.000 (0.136)	lr 0.0002	loss 0.117 (0.123)
Train: [36][150/589]	BT 0.380 (0.493)	DT 0.000 (0.134)	lr 0.0002	loss 0.134 (0.123)
Train: [36][160/589]	BT 0.360 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.115 (0.123)
Train: [36][170/589]	BT 0.359 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.137 (0.123)
Train: [36][180/589]	BT 0.358 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.125 (0.123)
Train: [36][190/589]	BT 0.357 (0.495)	DT 0.000 (0.136)	lr 0.0002	loss 0.131 (0.123)
Train: [36][200/589]	BT 0.357 (0.493)	DT 0.000 (0.134)	lr 0.0002	loss 0.113 (0.123)
Train: [36][210/589]	BT 0.358 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.126 (0.124)
Train: [36][220/589]	BT 0.358 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.097 (0.123)
Train: [36][230/589]	BT 0.359 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.149 (0.123)
Train: [36][240/589]	BT 0.359 (0.484)	DT 0.000 (0.125)	lr 0.0002	loss 0.126 (0.123)
Train: [36][250/589]	BT 0.358 (0.483)	DT 0.000 (0.124)	lr 0.0002	loss 0.116 (0.123)
Train: [36][260/589]	BT 0.359 (0.486)	DT 0.000 (0.127)	lr 0.0002	loss 0.121 (0.123)
Train: [36][270/589]	BT 0.358 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.133 (0.123)
Train: [36][280/589]	BT 0.359 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.148 (0.123)
Train: [36][290/589]	BT 0.358 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.117 (0.123)
Train: [36][300/589]	BT 0.357 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.121 (0.123)
Train: [36][310/589]	BT 0.356 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.131 (0.123)
Train: [36][320/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.147 (0.123)
Train: [36][330/589]	BT 0.360 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.142 (0.123)
Train: [36][340/589]	BT 0.358 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.123 (0.123)
Train: [36][350/589]	BT 0.358 (0.492)	DT 0.000 (0.133)	lr 0.0002	loss 0.147 (0.123)
Train: [36][360/589]	BT 0.360 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.102 (0.123)
Train: [36][370/589]	BT 0.371 (0.491)	DT 0.000 (0.131)	lr 0.0002	loss 0.126 (0.123)
Train: [36][380/589]	BT 0.383 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.119 (0.123)
Train: [36][390/589]	BT 0.359 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.126 (0.123)
Train: [36][400/589]	BT 0.359 (0.487)	DT 0.000 (0.127)	lr 0.0002	loss 0.117 (0.123)
Train: [36][410/589]	BT 0.359 (0.486)	DT 0.000 (0.127)	lr 0.0002	loss 0.116 (0.123)
Train: [36][420/589]	BT 0.359 (0.486)	DT 0.000 (0.127)	lr 0.0002	loss 0.125 (0.123)
Train: [36][430/589]	BT 0.360 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.137 (0.123)
Train: [36][440/589]	BT 0.358 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.151 (0.123)
Train: [36][450/589]	BT 0.358 (0.484)	DT 0.000 (0.125)	lr 0.0002	loss 0.136 (0.123)
Train: [36][460/589]	BT 0.358 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.127 (0.123)
Train: [36][470/589]	BT 0.359 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.128 (0.123)
Train: [36][480/589]	BT 0.360 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.122 (0.123)
Train: [36][490/589]	BT 0.357 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.125 (0.123)
Train: [36][500/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.105 (0.123)
Train: [36][510/589]	BT 0.361 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.116 (0.123)
Train: [36][520/589]	BT 0.357 (0.489)	DT 0.000 (0.130)	lr 0.0002	loss 0.107 (0.123)
Train: [36][530/589]	BT 0.359 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.128 (0.123)
Train: [36][540/589]	BT 0.356 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.119 (0.123)
Train: [36][550/589]	BT 0.359 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.116 (0.123)
Train: [36][560/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.148 (0.123)
Train: [36][570/589]	BT 0.360 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.116 (0.123)
Train: [36][580/589]	BT 0.357 (0.490)	DT 0.000 (0.130)	lr 0.0002	loss 0.142 (0.123)
epoch 36, total time 288.84
loss: 0.12313637995171603@Epoch: 36
learning_rate: 0.0002,36
Valid: [36][10/88]	BT 0.109 (0.597)	DT 0.000 (0.485)	loss 0.132 (0.131)
Valid: [36][20/88]	BT 0.109 (0.505)	DT 0.000 (0.395)	loss 0.153 (0.133)
Valid: [36][30/88]	BT 0.110 (0.539)	DT 0.000 (0.428)	loss 0.138 (0.132)
Valid: [36][40/88]	BT 0.109 (0.517)	DT 0.000 (0.406)	loss 0.148 (0.133)
Valid: [36][50/88]	BT 0.110 (0.496)	DT 0.000 (0.385)	loss 0.126 (0.133)
Valid: [36][60/88]	BT 0.110 (0.491)	DT 0.000 (0.380)	loss 0.178 (0.133)
Valid: [36][70/88]	BT 0.110 (0.482)	DT 0.000 (0.371)	loss 0.136 (0.134)
Valid: [36][80/88]	BT 0.110 (0.471)	DT 0.000 (0.360)	loss 0.152 (0.134)
Train: [37][10/589]	BT 0.369 (0.810)	DT 0.000 (0.452)	lr 0.0002	loss 0.135 (0.130)
Train: [37][20/589]	BT 0.359 (0.585)	DT 0.000 (0.226)	lr 0.0002	loss 0.105 (0.125)
Train: [37][30/589]	BT 0.387 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.130 (0.123)
Train: [37][40/589]	BT 0.358 (0.473)	DT 0.000 (0.113)	lr 0.0002	loss 0.120 (0.124)
Train: [37][50/589]	BT 0.359 (0.450)	DT 0.000 (0.090)	lr 0.0002	loss 0.116 (0.123)
Train: [37][60/589]	BT 0.357 (0.447)	DT 0.000 (0.088)	lr 0.0002	loss 0.120 (0.121)
Train: [37][70/589]	BT 0.369 (0.435)	DT 0.000 (0.075)	lr 0.0002	loss 0.114 (0.122)
Train: [37][80/589]	BT 0.388 (0.426)	DT 0.000 (0.066)	lr 0.0002	loss 0.109 (0.122)
Train: [37][90/589]	BT 0.374 (0.419)	DT 0.000 (0.059)	lr 0.0002	loss 0.117 (0.122)
Train: [37][100/589]	BT 0.357 (0.413)	DT 0.000 (0.053)	lr 0.0002	loss 0.112 (0.122)
Train: [37][110/589]	BT 0.358 (0.419)	DT 0.000 (0.059)	lr 0.0002	loss 0.129 (0.122)
Train: [37][120/589]	BT 0.358 (0.417)	DT 0.000 (0.056)	lr 0.0002	loss 0.105 (0.122)
Train: [37][130/589]	BT 0.362 (0.418)	DT 0.000 (0.058)	lr 0.0002	loss 0.133 (0.123)
Train: [37][140/589]	BT 0.388 (0.415)	DT 0.000 (0.054)	lr 0.0002	loss 0.132 (0.122)
Train: [37][150/589]	BT 0.389 (0.411)	DT 0.000 (0.051)	lr 0.0002	loss 0.121 (0.123)
Train: [37][160/589]	BT 0.391 (0.409)	DT 0.000 (0.047)	lr 0.0002	loss 0.118 (0.123)
Train: [37][170/589]	BT 0.372 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.131 (0.123)
Train: [37][180/589]	BT 0.379 (0.403)	DT 0.000 (0.042)	lr 0.0002	loss 0.112 (0.123)
Train: [37][190/589]	BT 0.360 (0.401)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.123)
Train: [37][200/589]	BT 0.360 (0.401)	DT 0.000 (0.040)	lr 0.0002	loss 0.104 (0.123)
Train: [37][210/589]	BT 0.358 (0.402)	DT 0.000 (0.041)	lr 0.0002	loss 0.126 (0.123)
Train: [37][220/589]	BT 0.355 (0.400)	DT 0.000 (0.039)	lr 0.0002	loss 0.118 (0.122)
Train: [37][230/589]	BT 0.360 (0.399)	DT 0.000 (0.038)	lr 0.0002	loss 0.091 (0.123)
Train: [37][240/589]	BT 0.362 (0.397)	DT 0.000 (0.036)	lr 0.0002	loss 0.135 (0.122)
Train: [37][250/589]	BT 0.357 (0.396)	DT 0.000 (0.035)	lr 0.0002	loss 0.141 (0.122)
Train: [37][260/589]	BT 0.359 (0.395)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.122)
Train: [37][270/589]	BT 0.359 (0.395)	DT 0.000 (0.034)	lr 0.0002	loss 0.119 (0.122)
Train: [37][280/589]	BT 0.358 (0.394)	DT 0.000 (0.032)	lr 0.0002	loss 0.117 (0.122)
Train: [37][290/589]	BT 0.373 (0.393)	DT 0.000 (0.031)	lr 0.0002	loss 0.148 (0.122)
Train: [37][300/589]	BT 0.358 (0.392)	DT 0.000 (0.030)	lr 0.0002	loss 0.135 (0.122)
Train: [37][310/589]	BT 0.359 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.119 (0.122)
Train: [37][320/589]	BT 0.360 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.119 (0.122)
Train: [37][330/589]	BT 0.361 (0.395)	DT 0.000 (0.033)	lr 0.0002	loss 0.112 (0.122)
Train: [37][340/589]	BT 0.361 (0.394)	DT 0.000 (0.032)	lr 0.0002	loss 0.134 (0.122)
Train: [37][350/589]	BT 0.359 (0.393)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.122)
Train: [37][360/589]	BT 0.357 (0.394)	DT 0.000 (0.032)	lr 0.0002	loss 0.107 (0.122)
Train: [37][370/589]	BT 0.358 (0.393)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.122)
Train: [37][380/589]	BT 0.360 (0.393)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.122)
Train: [37][390/589]	BT 0.391 (0.393)	DT 0.000 (0.031)	lr 0.0002	loss 0.108 (0.123)
Train: [37][400/589]	BT 0.358 (0.393)	DT 0.000 (0.031)	lr 0.0002	loss 0.109 (0.122)
Train: [37][410/589]	BT 0.360 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.096 (0.122)
Train: [37][420/589]	BT 0.360 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.122)
Train: [37][430/589]	BT 0.357 (0.396)	DT 0.000 (0.035)	lr 0.0002	loss 0.122 (0.123)
Train: [37][440/589]	BT 0.359 (0.397)	DT 0.000 (0.036)	lr 0.0002	loss 0.134 (0.122)
Train: [37][450/589]	BT 0.358 (0.398)	DT 0.000 (0.037)	lr 0.0002	loss 0.099 (0.122)
Train: [37][460/589]	BT 0.359 (0.401)	DT 0.000 (0.040)	lr 0.0002	loss 0.130 (0.122)
Train: [37][470/589]	BT 0.373 (0.400)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.123)
Train: [37][480/589]	BT 0.360 (0.399)	DT 0.000 (0.038)	lr 0.0002	loss 0.121 (0.123)
Train: [37][490/589]	BT 0.395 (0.399)	DT 0.000 (0.037)	lr 0.0002	loss 0.134 (0.123)
Train: [37][500/589]	BT 0.386 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.117 (0.123)
Train: [37][510/589]	BT 0.363 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.126 (0.123)
Train: [37][520/589]	BT 0.359 (0.397)	DT 0.000 (0.035)	lr 0.0002	loss 0.121 (0.123)
Train: [37][530/589]	BT 0.361 (0.397)	DT 0.000 (0.034)	lr 0.0002	loss 0.119 (0.123)
Train: [37][540/589]	BT 0.359 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.134 (0.123)
Train: [37][550/589]	BT 0.360 (0.397)	DT 0.000 (0.034)	lr 0.0002	loss 0.132 (0.123)
Train: [37][560/589]	BT 0.360 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.123)
Train: [37][570/589]	BT 0.359 (0.395)	DT 0.000 (0.033)	lr 0.0002	loss 0.141 (0.123)
Train: [37][580/589]	BT 0.358 (0.396)	DT 0.000 (0.034)	lr 0.0002	loss 0.099 (0.123)
epoch 37, total time 234.34
loss: 0.1226715440611589@Epoch: 37
learning_rate: 0.0002,37
Valid: [37][10/88]	BT 0.109 (0.598)	DT 0.000 (0.486)	loss 0.136 (0.141)
Valid: [37][20/88]	BT 0.110 (0.493)	DT 0.000 (0.383)	loss 0.130 (0.137)
Valid: [37][30/88]	BT 0.109 (0.455)	DT 0.000 (0.345)	loss 0.129 (0.138)
Valid: [37][40/88]	BT 0.110 (0.436)	DT 0.000 (0.326)	loss 0.124 (0.138)
Valid: [37][50/88]	BT 0.109 (0.423)	DT 0.000 (0.312)	loss 0.144 (0.137)
Valid: [37][60/88]	BT 0.127 (0.417)	DT 0.017 (0.306)	loss 0.145 (0.139)
Valid: [37][70/88]	BT 0.109 (0.408)	DT 0.000 (0.297)	loss 0.144 (0.139)
Valid: [37][80/88]	BT 0.109 (0.408)	DT 0.000 (0.297)	loss 0.125 (0.137)
Train: [38][10/589]	BT 0.380 (0.889)	DT 0.000 (0.528)	lr 0.0002	loss 0.114 (0.115)
Train: [38][20/589]	BT 0.371 (0.735)	DT 0.000 (0.373)	lr 0.0002	loss 0.131 (0.117)
Train: [38][30/589]	BT 0.356 (0.609)	DT 0.000 (0.249)	lr 0.0002	loss 0.133 (0.119)
Train: [38][40/589]	BT 0.358 (0.547)	DT 0.000 (0.186)	lr 0.0002	loss 0.115 (0.120)
Train: [38][50/589]	BT 0.359 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.112 (0.120)
Train: [38][60/589]	BT 0.379 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.109 (0.120)
Train: [38][70/589]	BT 0.360 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.109 (0.120)
Train: [38][80/589]	BT 0.370 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.124 (0.120)
Train: [38][90/589]	BT 0.358 (0.450)	DT 0.000 (0.089)	lr 0.0002	loss 0.117 (0.120)
Train: [38][100/589]	BT 0.359 (0.442)	DT 0.000 (0.081)	lr 0.0002	loss 0.116 (0.120)
Train: [38][110/589]	BT 0.364 (0.435)	DT 0.000 (0.073)	lr 0.0002	loss 0.142 (0.120)
Train: [38][120/589]	BT 0.359 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.132 (0.121)
Train: [38][130/589]	BT 0.393 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.130 (0.121)
Train: [38][140/589]	BT 0.360 (0.424)	DT 0.000 (0.062)	lr 0.0002	loss 0.117 (0.121)
Train: [38][150/589]	BT 0.363 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.128 (0.121)
Train: [38][160/589]	BT 0.358 (0.431)	DT 0.000 (0.069)	lr 0.0002	loss 0.132 (0.121)
Train: [38][170/589]	BT 0.360 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.134 (0.121)
Train: [38][180/589]	BT 0.356 (0.429)	DT 0.000 (0.067)	lr 0.0002	loss 0.134 (0.122)
Train: [38][190/589]	BT 0.360 (0.427)	DT 0.000 (0.065)	lr 0.0002	loss 0.132 (0.121)
Train: [38][200/589]	BT 0.359 (0.425)	DT 0.000 (0.064)	lr 0.0002	loss 0.113 (0.122)
Train: [38][210/589]	BT 0.357 (0.426)	DT 0.001 (0.065)	lr 0.0002	loss 0.119 (0.122)
Train: [38][220/589]	BT 0.358 (0.429)	DT 0.000 (0.068)	lr 0.0002	loss 0.119 (0.122)
Train: [38][230/589]	BT 0.360 (0.427)	DT 0.000 (0.066)	lr 0.0002	loss 0.121 (0.122)
Train: [38][240/589]	BT 0.360 (0.427)	DT 0.000 (0.066)	lr 0.0002	loss 0.130 (0.122)
Train: [38][250/589]	BT 0.368 (0.426)	DT 0.000 (0.064)	lr 0.0002	loss 0.124 (0.122)
Train: [38][260/589]	BT 0.357 (0.423)	DT 0.000 (0.062)	lr 0.0002	loss 0.137 (0.123)
Train: [38][270/589]	BT 0.358 (0.421)	DT 0.000 (0.059)	lr 0.0002	loss 0.133 (0.123)
Train: [38][280/589]	BT 0.358 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.148 (0.123)
Train: [38][290/589]	BT 0.386 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.106 (0.123)
Train: [38][300/589]	BT 0.359 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.119 (0.123)
Train: [38][310/589]	BT 0.360 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.118 (0.123)
Train: [38][320/589]	BT 0.359 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.136 (0.123)
Train: [38][330/589]	BT 0.360 (0.414)	DT 0.000 (0.053)	lr 0.0002	loss 0.123 (0.123)
Train: [38][340/589]	BT 0.362 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.132 (0.123)
Train: [38][350/589]	BT 0.359 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.109 (0.123)
Train: [38][360/589]	BT 0.359 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.131 (0.123)
Train: [38][370/589]	BT 0.359 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.114 (0.123)
Train: [38][380/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.123 (0.123)
Train: [38][390/589]	BT 0.360 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.143 (0.123)
Train: [38][400/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.106 (0.123)
Train: [38][410/589]	BT 0.358 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.140 (0.123)
Train: [38][420/589]	BT 0.358 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.125 (0.123)
Train: [38][430/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.129 (0.123)
Train: [38][440/589]	BT 0.359 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.104 (0.123)
Train: [38][450/589]	BT 0.358 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.115 (0.123)
Train: [38][460/589]	BT 0.358 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.128 (0.123)
Train: [38][470/589]	BT 0.388 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.132 (0.123)
Train: [38][480/589]	BT 0.377 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.118 (0.123)
Train: [38][490/589]	BT 0.359 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.114 (0.123)
Train: [38][500/589]	BT 0.358 (0.413)	DT 0.000 (0.051)	lr 0.0002	loss 0.100 (0.122)
Train: [38][510/589]	BT 0.358 (0.413)	DT 0.000 (0.051)	lr 0.0002	loss 0.121 (0.122)
Train: [38][520/589]	BT 0.359 (0.413)	DT 0.000 (0.051)	lr 0.0002	loss 0.131 (0.122)
Train: [38][530/589]	BT 0.358 (0.414)	DT 0.000 (0.052)	lr 0.0002	loss 0.130 (0.122)
Train: [38][540/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.118 (0.122)
Train: [38][550/589]	BT 0.359 (0.416)	DT 0.000 (0.054)	lr 0.0002	loss 0.139 (0.122)
Train: [38][560/589]	BT 0.358 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.109 (0.122)
Train: [38][570/589]	BT 0.360 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.110 (0.122)
Train: [38][580/589]	BT 0.359 (0.417)	DT 0.000 (0.055)	lr 0.0002	loss 0.126 (0.123)
epoch 38, total time 246.23
loss: 0.12258631568413923@Epoch: 38
learning_rate: 0.0002,38
Valid: [38][10/88]	BT 0.109 (0.706)	DT 0.000 (0.595)	loss 0.158 (0.127)
Valid: [38][20/88]	BT 0.109 (0.681)	DT 0.000 (0.571)	loss 0.154 (0.132)
Valid: [38][30/88]	BT 0.109 (0.646)	DT 0.000 (0.536)	loss 0.116 (0.134)
Valid: [38][40/88]	BT 0.109 (0.633)	DT 0.000 (0.523)	loss 0.162 (0.135)
Valid: [38][50/88]	BT 0.110 (0.646)	DT 0.000 (0.536)	loss 0.120 (0.135)
Valid: [38][60/88]	BT 0.109 (0.627)	DT 0.000 (0.517)	loss 0.148 (0.134)
Valid: [38][70/88]	BT 0.110 (0.631)	DT 0.000 (0.521)	loss 0.116 (0.134)
Valid: [38][80/88]	BT 0.110 (0.620)	DT 0.000 (0.510)	loss 0.145 (0.134)
Train: [39][10/589]	BT 0.356 (0.997)	DT 0.000 (0.638)	lr 0.0002	loss 0.150 (0.121)
Train: [39][20/589]	BT 0.360 (0.741)	DT 0.000 (0.383)	lr 0.0002	loss 0.115 (0.118)
Train: [39][30/589]	BT 0.361 (0.668)	DT 0.000 (0.309)	lr 0.0002	loss 0.149 (0.121)
Train: [39][40/589]	BT 0.356 (0.602)	DT 0.000 (0.244)	lr 0.0002	loss 0.117 (0.122)
Train: [39][50/589]	BT 0.360 (0.562)	DT 0.000 (0.204)	lr 0.0002	loss 0.122 (0.123)
Train: [39][60/589]	BT 0.368 (0.540)	DT 0.000 (0.182)	lr 0.0002	loss 0.127 (0.122)
Train: [39][70/589]	BT 0.382 (0.541)	DT 0.000 (0.182)	lr 0.0002	loss 0.115 (0.123)
Train: [39][80/589]	BT 0.358 (0.547)	DT 0.000 (0.187)	lr 0.0002	loss 0.106 (0.122)
Train: [39][90/589]	BT 0.374 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.153 (0.122)
Train: [39][100/589]	BT 0.356 (0.532)	DT 0.000 (0.173)	lr 0.0002	loss 0.128 (0.122)
Train: [39][110/589]	BT 0.357 (0.527)	DT 0.000 (0.168)	lr 0.0002	loss 0.113 (0.122)
Train: [39][120/589]	BT 0.391 (0.517)	DT 0.000 (0.157)	lr 0.0002	loss 0.121 (0.122)
Train: [39][130/589]	BT 0.357 (0.520)	DT 0.000 (0.160)	lr 0.0002	loss 0.115 (0.122)
Train: [39][140/589]	BT 0.387 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.124 (0.122)
Train: [39][150/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.116 (0.122)
Train: [39][160/589]	BT 0.359 (0.509)	DT 0.000 (0.149)	lr 0.0002	loss 0.118 (0.122)
Train: [39][170/589]	BT 0.378 (0.512)	DT 0.000 (0.152)	lr 0.0002	loss 0.135 (0.122)
Train: [39][180/589]	BT 0.358 (0.514)	DT 0.000 (0.155)	lr 0.0002	loss 0.136 (0.122)
Train: [39][190/589]	BT 0.393 (0.514)	DT 0.000 (0.155)	lr 0.0002	loss 0.117 (0.122)
Train: [39][200/589]	BT 0.374 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.119 (0.122)
Train: [39][210/589]	BT 0.359 (0.514)	DT 0.000 (0.154)	lr 0.0002	loss 0.131 (0.122)
Train: [39][220/589]	BT 0.358 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.107 (0.122)
Train: [39][230/589]	BT 0.358 (0.518)	DT 0.000 (0.158)	lr 0.0002	loss 0.133 (0.122)
Train: [39][240/589]	BT 0.359 (0.518)	DT 0.000 (0.159)	lr 0.0002	loss 0.138 (0.122)
Train: [39][250/589]	BT 0.359 (0.522)	DT 0.000 (0.162)	lr 0.0002	loss 0.120 (0.122)
Train: [39][260/589]	BT 0.359 (0.522)	DT 0.000 (0.162)	lr 0.0002	loss 0.118 (0.122)
Train: [39][270/589]	BT 0.358 (0.522)	DT 0.000 (0.162)	lr 0.0002	loss 0.124 (0.122)
Train: [39][280/589]	BT 0.357 (0.522)	DT 0.000 (0.162)	lr 0.0002	loss 0.120 (0.122)
Train: [39][290/589]	BT 0.358 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.123 (0.122)
Train: [39][300/589]	BT 0.361 (0.531)	DT 0.000 (0.172)	lr 0.0002	loss 0.123 (0.122)
Train: [39][310/589]	BT 0.358 (0.532)	DT 0.000 (0.173)	lr 0.0002	loss 0.116 (0.122)
Train: [39][320/589]	BT 0.357 (0.533)	DT 0.000 (0.173)	lr 0.0002	loss 0.113 (0.122)
Train: [39][330/589]	BT 0.359 (0.533)	DT 0.000 (0.174)	lr 0.0002	loss 0.126 (0.122)
Train: [39][340/589]	BT 0.358 (0.535)	DT 0.000 (0.176)	lr 0.0002	loss 0.107 (0.122)
Train: [39][350/589]	BT 0.358 (0.537)	DT 0.000 (0.178)	lr 0.0002	loss 0.125 (0.122)
Train: [39][360/589]	BT 0.358 (0.537)	DT 0.000 (0.177)	lr 0.0002	loss 0.116 (0.122)
Train: [39][370/589]	BT 0.357 (0.542)	DT 0.000 (0.182)	lr 0.0002	loss 0.138 (0.122)
Train: [39][380/589]	BT 0.391 (0.543)	DT 0.000 (0.183)	lr 0.0002	loss 0.114 (0.122)
Train: [39][390/589]	BT 0.359 (0.545)	DT 0.000 (0.186)	lr 0.0002	loss 0.120 (0.122)
Train: [39][400/589]	BT 0.360 (0.544)	DT 0.000 (0.185)	lr 0.0002	loss 0.152 (0.122)
Train: [39][410/589]	BT 0.360 (0.545)	DT 0.000 (0.185)	lr 0.0002	loss 0.114 (0.122)
Train: [39][420/589]	BT 0.357 (0.545)	DT 0.000 (0.186)	lr 0.0002	loss 0.116 (0.122)
Train: [39][430/589]	BT 0.361 (0.546)	DT 0.000 (0.186)	lr 0.0002	loss 0.136 (0.122)
Train: [39][440/589]	BT 0.357 (0.547)	DT 0.000 (0.187)	lr 0.0002	loss 0.131 (0.122)
Train: [39][450/589]	BT 0.358 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.131 (0.122)
Train: [39][460/589]	BT 0.357 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.117 (0.122)
Train: [39][470/589]	BT 0.393 (0.548)	DT 0.000 (0.188)	lr 0.0002	loss 0.134 (0.122)
Train: [39][480/589]	BT 0.359 (0.546)	DT 0.000 (0.186)	lr 0.0002	loss 0.120 (0.121)
Train: [39][490/589]	BT 0.358 (0.549)	DT 0.000 (0.189)	lr 0.0002	loss 0.124 (0.122)
Train: [39][500/589]	BT 0.358 (0.548)	DT 0.000 (0.188)	lr 0.0002	loss 0.100 (0.122)
Train: [39][510/589]	BT 0.359 (0.548)	DT 0.000 (0.188)	lr 0.0002	loss 0.132 (0.122)
Train: [39][520/589]	BT 0.358 (0.548)	DT 0.000 (0.188)	lr 0.0002	loss 0.129 (0.122)
Train: [39][530/589]	BT 0.370 (0.553)	DT 0.000 (0.193)	lr 0.0002	loss 0.115 (0.122)
Train: [39][540/589]	BT 0.357 (0.554)	DT 0.000 (0.195)	lr 0.0002	loss 0.126 (0.122)
Train: [39][550/589]	BT 0.357 (0.557)	DT 0.000 (0.197)	lr 0.0002	loss 0.140 (0.122)
Train: [39][560/589]	BT 0.358 (0.558)	DT 0.000 (0.198)	lr 0.0002	loss 0.124 (0.122)
Train: [39][570/589]	BT 0.359 (0.563)	DT 0.000 (0.203)	lr 0.0002	loss 0.137 (0.122)
Train: [39][580/589]	BT 0.463 (0.565)	DT 0.104 (0.205)	lr 0.0002	loss 0.129 (0.122)
epoch 39, total time 336.92
loss: 0.12173556675728855@Epoch: 39
learning_rate: 0.0002,39
Valid: [39][10/88]	BT 0.109 (0.847)	DT 0.000 (0.735)	loss 0.179 (0.138)
Valid: [39][20/88]	BT 0.109 (0.703)	DT 0.000 (0.593)	loss 0.120 (0.141)
Valid: [39][30/88]	BT 0.109 (0.752)	DT 0.000 (0.641)	loss 0.161 (0.141)
Valid: [39][40/88]	BT 0.109 (0.714)	DT 0.000 (0.604)	loss 0.140 (0.140)
Valid: [39][50/88]	BT 0.110 (0.685)	DT 0.000 (0.574)	loss 0.147 (0.139)
Valid: [39][60/88]	BT 0.110 (0.685)	DT 0.000 (0.575)	loss 0.115 (0.139)
Valid: [39][70/88]	BT 0.110 (0.679)	DT 0.000 (0.569)	loss 0.127 (0.138)
Valid: [39][80/88]	BT 0.109 (0.680)	DT 0.000 (0.570)	loss 0.177 (0.138)
Train: [40][10/589]	BT 0.358 (0.879)	DT 0.000 (0.521)	lr 0.0002	loss 0.107 (0.119)
Train: [40][20/589]	BT 0.356 (0.668)	DT 0.000 (0.310)	lr 0.0002	loss 0.100 (0.120)
Train: [40][30/589]	BT 0.358 (0.585)	DT 0.000 (0.227)	lr 0.0002	loss 0.121 (0.118)
Train: [40][40/589]	BT 0.357 (0.561)	DT 0.000 (0.203)	lr 0.0002	loss 0.147 (0.118)
Train: [40][50/589]	BT 0.359 (0.533)	DT 0.000 (0.175)	lr 0.0002	loss 0.124 (0.119)
Train: [40][60/589]	BT 0.359 (0.555)	DT 0.000 (0.197)	lr 0.0002	loss 0.113 (0.119)
Train: [40][70/589]	BT 0.357 (0.550)	DT 0.000 (0.191)	lr 0.0002	loss 0.121 (0.119)
Train: [40][80/589]	BT 0.358 (0.541)	DT 0.000 (0.183)	lr 0.0002	loss 0.121 (0.120)
Train: [40][90/589]	BT 0.358 (0.527)	DT 0.000 (0.169)	lr 0.0002	loss 0.159 (0.120)
Train: [40][100/589]	BT 0.358 (0.528)	DT 0.000 (0.169)	lr 0.0002	loss 0.111 (0.121)
Train: [40][110/589]	BT 0.357 (0.529)	DT 0.000 (0.171)	lr 0.0002	loss 0.130 (0.121)
Train: [40][120/589]	BT 0.393 (0.525)	DT 0.000 (0.166)	lr 0.0002	loss 0.112 (0.121)
Train: [40][130/589]	BT 0.358 (0.516)	DT 0.000 (0.157)	lr 0.0002	loss 0.112 (0.120)
Train: [40][140/589]	BT 0.372 (0.514)	DT 0.000 (0.155)	lr 0.0002	loss 0.108 (0.120)
Train: [40][150/589]	BT 0.357 (0.510)	DT 0.000 (0.151)	lr 0.0002	loss 0.111 (0.120)
Train: [40][160/589]	BT 0.360 (0.511)	DT 0.000 (0.152)	lr 0.0002	loss 0.136 (0.121)
Train: [40][170/589]	BT 0.358 (0.516)	DT 0.000 (0.157)	lr 0.0002	loss 0.124 (0.121)
Train: [40][180/589]	BT 0.359 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.135 (0.121)
Train: [40][190/589]	BT 0.358 (0.516)	DT 0.000 (0.157)	lr 0.0002	loss 0.108 (0.121)
Train: [40][200/589]	BT 0.357 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.113 (0.121)
Train: [40][210/589]	BT 0.358 (0.510)	DT 0.000 (0.151)	lr 0.0002	loss 0.141 (0.122)
Train: [40][220/589]	BT 0.360 (0.508)	DT 0.000 (0.149)	lr 0.0002	loss 0.123 (0.122)
Train: [40][230/589]	BT 0.400 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.113 (0.121)
Train: [40][240/589]	BT 0.394 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.131 (0.121)
Train: [40][250/589]	BT 0.356 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.125 (0.122)
Train: [40][260/589]	BT 0.359 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.101 (0.121)
Train: [40][270/589]	BT 0.358 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.124 (0.121)
Train: [40][280/589]	BT 0.360 (0.507)	DT 0.000 (0.147)	lr 0.0002	loss 0.106 (0.121)
Train: [40][290/589]	BT 0.358 (0.507)	DT 0.000 (0.146)	lr 0.0002	loss 0.145 (0.121)
Train: [40][300/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0002	loss 0.139 (0.121)
Train: [40][310/589]	BT 0.359 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.108 (0.121)
Train: [40][320/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.111 (0.121)
Train: [40][330/589]	BT 0.358 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.106 (0.121)
Train: [40][340/589]	BT 0.358 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.121 (0.121)
Train: [40][350/589]	BT 0.395 (0.494)	DT 0.000 (0.134)	lr 0.0002	loss 0.098 (0.121)
Train: [40][360/589]	BT 0.359 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.133 (0.121)
Train: [40][370/589]	BT 0.359 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.123 (0.121)
Train: [40][380/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.100 (0.121)
Train: [40][390/589]	BT 0.360 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.111 (0.121)
Train: [40][400/589]	BT 0.359 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.104 (0.121)
Train: [40][410/589]	BT 0.359 (0.484)	DT 0.000 (0.123)	lr 0.0002	loss 0.122 (0.121)
Train: [40][420/589]	BT 0.358 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.114 (0.121)
Train: [40][430/589]	BT 0.358 (0.486)	DT 0.000 (0.125)	lr 0.0002	loss 0.122 (0.121)
Train: [40][440/589]	BT 0.359 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.124 (0.121)
Train: [40][450/589]	BT 0.359 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.137 (0.121)
Train: [40][460/589]	BT 0.361 (0.492)	DT 0.000 (0.132)	lr 0.0002	loss 0.116 (0.121)
Train: [40][470/589]	BT 0.357 (0.493)	DT 0.000 (0.133)	lr 0.0002	loss 0.120 (0.121)
Train: [40][480/589]	BT 0.357 (0.495)	DT 0.000 (0.135)	lr 0.0002	loss 0.127 (0.121)
Train: [40][490/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.136 (0.121)
Train: [40][500/589]	BT 0.396 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.109 (0.121)
Train: [40][510/589]	BT 0.398 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.101 (0.121)
Train: [40][520/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.122 (0.121)
Train: [40][530/589]	BT 0.360 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.099 (0.121)
Train: [40][540/589]	BT 0.359 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.122 (0.121)
Train: [40][550/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.115 (0.121)
Train: [40][560/589]	BT 0.372 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.132 (0.121)
Train: [40][570/589]	BT 0.368 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.117 (0.121)
Train: [40][580/589]	BT 0.358 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.132 (0.121)
epoch 40, total time 298.20
loss: 0.12101063915491357@Epoch: 40
learning_rate: 0.0002,40
Valid: [40][10/88]	BT 0.110 (0.742)	DT 0.000 (0.630)	loss 0.167 (0.137)
Valid: [40][20/88]	BT 0.109 (0.651)	DT 0.000 (0.539)	loss 0.130 (0.137)
Valid: [40][30/88]	BT 0.109 (0.604)	DT 0.000 (0.493)	loss 0.139 (0.135)
Valid: [40][40/88]	BT 0.110 (0.571)	DT 0.000 (0.460)	loss 0.139 (0.134)
Valid: [40][50/88]	BT 0.109 (0.570)	DT 0.000 (0.460)	loss 0.134 (0.136)
Valid: [40][60/88]	BT 0.112 (0.566)	DT 0.000 (0.455)	loss 0.128 (0.137)
Valid: [40][70/88]	BT 0.109 (0.550)	DT 0.000 (0.439)	loss 0.131 (0.137)
Valid: [40][80/88]	BT 0.110 (0.566)	DT 0.000 (0.455)	loss 0.139 (0.136)
Train: [41][10/589]	BT 0.357 (0.938)	DT 0.000 (0.576)	lr 0.0002	loss 0.109 (0.118)
Train: [41][20/589]	BT 0.363 (0.800)	DT 0.000 (0.440)	lr 0.0002	loss 0.115 (0.119)
Train: [41][30/589]	BT 0.380 (0.689)	DT 0.000 (0.328)	lr 0.0002	loss 0.109 (0.116)
Train: [41][40/589]	BT 0.359 (0.626)	DT 0.000 (0.265)	lr 0.0002	loss 0.118 (0.116)
Train: [41][50/589]	BT 0.359 (0.583)	DT 0.000 (0.223)	lr 0.0002	loss 0.121 (0.116)
Train: [41][60/589]	BT 0.359 (0.575)	DT 0.000 (0.214)	lr 0.0002	loss 0.122 (0.118)
Train: [41][70/589]	BT 0.362 (0.557)	DT 0.000 (0.196)	lr 0.0002	loss 0.119 (0.118)
Train: [41][80/589]	BT 0.362 (0.538)	DT 0.000 (0.178)	lr 0.0002	loss 0.101 (0.118)
Train: [41][90/589]	BT 0.358 (0.531)	DT 0.000 (0.171)	lr 0.0002	loss 0.119 (0.118)
Train: [41][100/589]	BT 0.359 (0.527)	DT 0.000 (0.167)	lr 0.0002	loss 0.105 (0.118)
Train: [41][110/589]	BT 0.360 (0.519)	DT 0.000 (0.159)	lr 0.0002	loss 0.127 (0.119)
Train: [41][120/589]	BT 0.358 (0.517)	DT 0.000 (0.157)	lr 0.0002	loss 0.122 (0.119)
Train: [41][130/589]	BT 0.384 (0.511)	DT 0.000 (0.150)	lr 0.0002	loss 0.109 (0.119)
Train: [41][140/589]	BT 0.358 (0.508)	DT 0.000 (0.147)	lr 0.0002	loss 0.127 (0.120)
Train: [41][150/589]	BT 0.358 (0.517)	DT 0.000 (0.156)	lr 0.0002	loss 0.102 (0.119)
Train: [41][160/589]	BT 0.359 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.127 (0.119)
Train: [41][170/589]	BT 0.359 (0.504)	DT 0.000 (0.143)	lr 0.0002	loss 0.118 (0.119)
Train: [41][180/589]	BT 0.361 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.126 (0.120)
Train: [41][190/589]	BT 0.382 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.123 (0.120)
Train: [41][200/589]	BT 0.359 (0.493)	DT 0.000 (0.131)	lr 0.0002	loss 0.144 (0.120)
Train: [41][210/589]	BT 0.361 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.133 (0.120)
Train: [41][220/589]	BT 0.393 (0.491)	DT 0.000 (0.130)	lr 0.0002	loss 0.128 (0.120)
Train: [41][230/589]	BT 0.390 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.142 (0.120)
Train: [41][240/589]	BT 0.358 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.112 (0.121)
Train: [41][250/589]	BT 0.358 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.125 (0.121)
Train: [41][260/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.106 (0.121)
Train: [41][270/589]	BT 0.359 (0.494)	DT 0.000 (0.133)	lr 0.0002	loss 0.101 (0.121)
Train: [41][280/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.133 (0.121)
Train: [41][290/589]	BT 0.358 (0.499)	DT 0.000 (0.138)	lr 0.0002	loss 0.119 (0.121)
Train: [41][300/589]	BT 0.362 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.135 (0.121)
Train: [41][310/589]	BT 0.359 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.096 (0.121)
Train: [41][320/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.121 (0.121)
Train: [41][330/589]	BT 0.393 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.109 (0.121)
Train: [41][340/589]	BT 0.370 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.120 (0.121)
Train: [41][350/589]	BT 0.359 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.135 (0.121)
Train: [41][360/589]	BT 0.356 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.112 (0.121)
Train: [41][370/589]	BT 0.358 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.112 (0.121)
Train: [41][380/589]	BT 0.359 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.132 (0.121)
Train: [41][390/589]	BT 0.358 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.101 (0.121)
Train: [41][400/589]	BT 0.357 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.117 (0.121)
Train: [41][410/589]	BT 0.360 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.128 (0.121)
Train: [41][420/589]	BT 0.363 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.132 (0.121)
Train: [41][430/589]	BT 0.398 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.141 (0.121)
Train: [41][440/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0002	loss 0.111 (0.120)
Train: [41][450/589]	BT 0.359 (0.499)	DT 0.000 (0.139)	lr 0.0002	loss 0.114 (0.120)
Train: [41][460/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.122 (0.120)
Train: [41][470/589]	BT 0.358 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.121 (0.120)
Train: [41][480/589]	BT 0.358 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.112 (0.120)
Train: [41][490/589]	BT 0.375 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.120 (0.120)
Train: [41][500/589]	BT 0.356 (0.498)	DT 0.000 (0.137)	lr 0.0002	loss 0.108 (0.120)
Train: [41][510/589]	BT 0.397 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.130 (0.120)
Train: [41][520/589]	BT 0.360 (0.497)	DT 0.000 (0.137)	lr 0.0002	loss 0.130 (0.120)
Train: [41][530/589]	BT 0.359 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.120 (0.120)
Train: [41][540/589]	BT 0.359 (0.494)	DT 0.000 (0.134)	lr 0.0002	loss 0.138 (0.120)
Train: [41][550/589]	BT 0.400 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.113 (0.120)
Train: [41][560/589]	BT 0.384 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.113 (0.120)
Train: [41][570/589]	BT 0.357 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.119 (0.120)
Train: [41][580/589]	BT 0.357 (0.496)	DT 0.000 (0.135)	lr 0.0002	loss 0.140 (0.120)
epoch 41, total time 292.92
loss: 0.12050143120735599@Epoch: 41
learning_rate: 0.0002,41
Valid: [41][10/88]	BT 0.110 (0.672)	DT 0.000 (0.561)	loss 0.126 (0.132)
Valid: [41][20/88]	BT 0.109 (0.554)	DT 0.000 (0.444)	loss 0.135 (0.135)
Valid: [41][30/88]	BT 0.109 (0.495)	DT 0.000 (0.384)	loss 0.130 (0.138)
Valid: [41][40/88]	BT 0.110 (0.483)	DT 0.000 (0.372)	loss 0.146 (0.138)
Valid: [41][50/88]	BT 0.110 (0.502)	DT 0.000 (0.392)	loss 0.129 (0.136)
Valid: [41][60/88]	BT 0.126 (0.584)	DT 0.000 (0.473)	loss 0.137 (0.137)
Valid: [41][70/88]	BT 0.109 (0.563)	DT 0.000 (0.453)	loss 0.166 (0.138)
Valid: [41][80/88]	BT 0.109 (0.555)	DT 0.000 (0.445)	loss 0.119 (0.137)
Train: [42][10/589]	BT 0.357 (0.855)	DT 0.000 (0.496)	lr 0.0002	loss 0.111 (0.117)
Train: [42][20/589]	BT 0.357 (1.029)	DT 0.000 (0.670)	lr 0.0002	loss 0.103 (0.119)
Train: [42][30/589]	BT 0.374 (0.861)	DT 0.000 (0.502)	lr 0.0002	loss 0.114 (0.118)
Train: [42][40/589]	BT 0.357 (0.760)	DT 0.000 (0.401)	lr 0.0002	loss 0.106 (0.117)
Train: [42][50/589]	BT 0.373 (0.696)	DT 0.000 (0.337)	lr 0.0002	loss 0.107 (0.118)
Train: [42][60/589]	BT 0.357 (0.659)	DT 0.000 (0.300)	lr 0.0002	loss 0.133 (0.119)
Train: [42][70/589]	BT 0.359 (0.658)	DT 0.000 (0.298)	lr 0.0002	loss 0.150 (0.119)
Train: [42][80/589]	BT 0.358 (0.622)	DT 0.000 (0.263)	lr 0.0002	loss 0.131 (0.121)
Train: [42][90/589]	BT 0.362 (0.603)	DT 0.000 (0.242)	lr 0.0002	loss 0.103 (0.121)
Train: [42][100/589]	BT 0.359 (0.588)	DT 0.000 (0.227)	lr 0.0002	loss 0.127 (0.121)
Train: [42][110/589]	BT 0.355 (0.594)	DT 0.000 (0.234)	lr 0.0002	loss 0.094 (0.121)
Train: [42][120/589]	BT 0.358 (0.605)	DT 0.000 (0.245)	lr 0.0002	loss 0.108 (0.121)
Train: [42][130/589]	BT 0.360 (0.602)	DT 0.000 (0.242)	lr 0.0002	loss 0.129 (0.121)
Train: [42][140/589]	BT 0.358 (0.594)	DT 0.000 (0.233)	lr 0.0002	loss 0.127 (0.121)
Train: [42][150/589]	BT 0.359 (0.590)	DT 0.000 (0.229)	lr 0.0002	loss 0.129 (0.121)
Train: [42][160/589]	BT 0.401 (0.582)	DT 0.000 (0.222)	lr 0.0002	loss 0.137 (0.121)
Train: [42][170/589]	BT 0.357 (0.590)	DT 0.000 (0.230)	lr 0.0002	loss 0.142 (0.121)
Train: [42][180/589]	BT 0.409 (0.587)	DT 0.000 (0.226)	lr 0.0002	loss 0.103 (0.121)
Train: [42][190/589]	BT 0.357 (0.595)	DT 0.000 (0.234)	lr 0.0002	loss 0.118 (0.121)
Train: [42][200/589]	BT 0.357 (0.588)	DT 0.000 (0.227)	lr 0.0002	loss 0.111 (0.121)
Train: [42][210/589]	BT 0.358 (0.581)	DT 0.000 (0.220)	lr 0.0002	loss 0.102 (0.120)
Train: [42][220/589]	BT 0.358 (0.580)	DT 0.000 (0.220)	lr 0.0002	loss 0.117 (0.120)
Train: [42][230/589]	BT 0.359 (0.576)	DT 0.000 (0.215)	lr 0.0002	loss 0.122 (0.120)
Train: [42][240/589]	BT 0.358 (0.576)	DT 0.000 (0.215)	lr 0.0002	loss 0.130 (0.120)
Train: [42][250/589]	BT 0.357 (0.572)	DT 0.000 (0.212)	lr 0.0002	loss 0.118 (0.120)
Train: [42][260/589]	BT 0.358 (0.569)	DT 0.000 (0.209)	lr 0.0002	loss 0.102 (0.120)
Train: [42][270/589]	BT 0.357 (0.566)	DT 0.000 (0.205)	lr 0.0002	loss 0.110 (0.120)
Train: [42][280/589]	BT 0.358 (0.564)	DT 0.000 (0.204)	lr 0.0002	loss 0.121 (0.120)
Train: [42][290/589]	BT 0.359 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.138 (0.120)
Train: [42][300/589]	BT 0.397 (0.569)	DT 0.000 (0.209)	lr 0.0002	loss 0.114 (0.120)
Train: [42][310/589]	BT 0.359 (0.570)	DT 0.000 (0.210)	lr 0.0002	loss 0.131 (0.119)
Train: [42][320/589]	BT 0.357 (0.572)	DT 0.000 (0.211)	lr 0.0002	loss 0.112 (0.120)
Train: [42][330/589]	BT 0.358 (0.575)	DT 0.000 (0.214)	lr 0.0002	loss 0.120 (0.120)
Train: [42][340/589]	BT 0.358 (0.574)	DT 0.000 (0.213)	lr 0.0002	loss 0.124 (0.120)
Train: [42][350/589]	BT 0.359 (0.571)	DT 0.000 (0.211)	lr 0.0002	loss 0.118 (0.120)
Train: [42][360/589]	BT 0.358 (0.571)	DT 0.000 (0.210)	lr 0.0002	loss 0.111 (0.120)
Train: [42][370/589]	BT 0.357 (0.569)	DT 0.000 (0.209)	lr 0.0002	loss 0.129 (0.120)
Train: [42][380/589]	BT 0.359 (0.567)	DT 0.000 (0.207)	lr 0.0002	loss 0.123 (0.120)
Train: [42][390/589]	BT 0.358 (0.567)	DT 0.000 (0.206)	lr 0.0002	loss 0.127 (0.120)
Train: [42][400/589]	BT 0.358 (0.565)	DT 0.000 (0.205)	lr 0.0002	loss 0.136 (0.120)
Train: [42][410/589]	BT 0.388 (0.564)	DT 0.000 (0.203)	lr 0.0002	loss 0.141 (0.120)
Train: [42][420/589]	BT 0.358 (0.562)	DT 0.000 (0.201)	lr 0.0002	loss 0.124 (0.120)
Train: [42][430/589]	BT 0.359 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.105 (0.120)
Train: [42][440/589]	BT 0.359 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.130 (0.120)
Train: [42][450/589]	BT 0.357 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.100 (0.120)
Train: [42][460/589]	BT 0.357 (0.560)	DT 0.000 (0.200)	lr 0.0002	loss 0.122 (0.120)
Train: [42][470/589]	BT 0.359 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.105 (0.120)
Train: [42][480/589]	BT 0.359 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.122 (0.120)
Train: [42][490/589]	BT 0.357 (0.561)	DT 0.000 (0.201)	lr 0.0002	loss 0.120 (0.120)
Train: [42][500/589]	BT 0.357 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.106 (0.120)
Train: [42][510/589]	BT 0.359 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.127 (0.120)
Train: [42][520/589]	BT 0.367 (0.565)	DT 0.000 (0.204)	lr 0.0002	loss 0.130 (0.120)
Train: [42][530/589]	BT 0.357 (0.565)	DT 0.000 (0.204)	lr 0.0002	loss 0.125 (0.120)
Train: [42][540/589]	BT 0.359 (0.564)	DT 0.000 (0.204)	lr 0.0002	loss 0.128 (0.120)
Train: [42][550/589]	BT 0.361 (0.564)	DT 0.000 (0.204)	lr 0.0002	loss 0.113 (0.120)
Train: [42][560/589]	BT 0.357 (0.565)	DT 0.000 (0.205)	lr 0.0002	loss 0.097 (0.120)
Train: [42][570/589]	BT 0.359 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.112 (0.120)
Train: [42][580/589]	BT 0.359 (0.563)	DT 0.000 (0.202)	lr 0.0002	loss 0.098 (0.120)
epoch 42, total time 332.80
loss: 0.11970615741526318@Epoch: 42
learning_rate: 0.0002,42
Valid: [42][10/88]	BT 0.110 (0.691)	DT 0.000 (0.581)	loss 0.155 (0.141)
Valid: [42][20/88]	BT 0.110 (0.600)	DT 0.000 (0.490)	loss 0.149 (0.143)
Valid: [42][30/88]	BT 0.109 (0.552)	DT 0.000 (0.442)	loss 0.160 (0.141)
Valid: [42][40/88]	BT 0.109 (0.557)	DT 0.000 (0.448)	loss 0.132 (0.141)
Valid: [42][50/88]	BT 0.109 (0.556)	DT 0.000 (0.447)	loss 0.148 (0.140)
Valid: [42][60/88]	BT 0.110 (0.560)	DT 0.000 (0.451)	loss 0.152 (0.139)
Valid: [42][70/88]	BT 0.110 (0.542)	DT 0.000 (0.433)	loss 0.146 (0.139)
Valid: [42][80/88]	BT 0.110 (0.540)	DT 0.000 (0.430)	loss 0.117 (0.138)
Train: [43][10/589]	BT 0.358 (0.882)	DT 0.000 (0.524)	lr 0.0002	loss 0.109 (0.125)
Train: [43][20/589]	BT 0.362 (0.708)	DT 0.000 (0.351)	lr 0.0002	loss 0.114 (0.122)
Train: [43][30/589]	BT 0.358 (0.642)	DT 0.000 (0.285)	lr 0.0002	loss 0.115 (0.122)
Train: [43][40/589]	BT 0.358 (0.603)	DT 0.000 (0.245)	lr 0.0002	loss 0.136 (0.122)
Train: [43][50/589]	BT 0.358 (0.566)	DT 0.000 (0.208)	lr 0.0002	loss 0.118 (0.121)
Train: [43][60/589]	BT 0.357 (0.542)	DT 0.000 (0.183)	lr 0.0002	loss 0.130 (0.120)
Train: [43][70/589]	BT 0.398 (0.524)	DT 0.000 (0.165)	lr 0.0002	loss 0.112 (0.119)
Train: [43][80/589]	BT 0.357 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.128 (0.119)
Train: [43][90/589]	BT 0.357 (0.506)	DT 0.000 (0.147)	lr 0.0002	loss 0.129 (0.118)
Train: [43][100/589]	BT 0.357 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.139 (0.118)
Train: [43][110/589]	BT 0.358 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.106 (0.119)
Train: [43][120/589]	BT 0.357 (0.525)	DT 0.000 (0.165)	lr 0.0002	loss 0.139 (0.119)
Train: [43][130/589]	BT 0.359 (0.516)	DT 0.000 (0.156)	lr 0.0002	loss 0.124 (0.119)
Train: [43][140/589]	BT 0.358 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.125 (0.119)
Train: [43][150/589]	BT 0.357 (0.513)	DT 0.000 (0.154)	lr 0.0002	loss 0.121 (0.119)
Train: [43][160/589]	BT 0.358 (0.513)	DT 0.000 (0.153)	lr 0.0002	loss 0.114 (0.119)
Train: [43][170/589]	BT 0.358 (0.507)	DT 0.000 (0.148)	lr 0.0002	loss 0.122 (0.119)
Train: [43][180/589]	BT 0.358 (0.505)	DT 0.000 (0.146)	lr 0.0002	loss 0.115 (0.119)
Train: [43][190/589]	BT 0.358 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.143 (0.119)
Train: [43][200/589]	BT 0.388 (0.511)	DT 0.000 (0.151)	lr 0.0002	loss 0.119 (0.119)
Train: [43][210/589]	BT 0.359 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.133 (0.119)
Train: [43][220/589]	BT 0.407 (0.502)	DT 0.000 (0.142)	lr 0.0002	loss 0.117 (0.119)
Train: [43][230/589]	BT 0.359 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.098 (0.119)
Train: [43][240/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.128 (0.119)
Train: [43][250/589]	BT 0.360 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.139 (0.119)
Train: [43][260/589]	BT 0.357 (0.494)	DT 0.000 (0.134)	lr 0.0002	loss 0.117 (0.119)
Train: [43][270/589]	BT 0.406 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.120 (0.119)
Train: [43][280/589]	BT 0.359 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.128 (0.119)
Train: [43][290/589]	BT 0.360 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.128 (0.119)
Train: [43][300/589]	BT 0.364 (0.488)	DT 0.000 (0.127)	lr 0.0002	loss 0.097 (0.119)
Train: [43][310/589]	BT 0.359 (0.489)	DT 0.000 (0.128)	lr 0.0002	loss 0.108 (0.119)
Train: [43][320/589]	BT 0.358 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.121 (0.119)
Train: [43][330/589]	BT 0.359 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.100 (0.119)
Train: [43][340/589]	BT 0.359 (0.487)	DT 0.000 (0.127)	lr 0.0002	loss 0.100 (0.119)
Train: [43][350/589]	BT 0.358 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.131 (0.119)
Train: [43][360/589]	BT 0.398 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.100 (0.119)
Train: [43][370/589]	BT 0.359 (0.480)	DT 0.000 (0.119)	lr 0.0002	loss 0.109 (0.119)
Train: [43][380/589]	BT 0.359 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.117 (0.119)
Train: [43][390/589]	BT 0.358 (0.476)	DT 0.000 (0.114)	lr 0.0002	loss 0.109 (0.119)
Train: [43][400/589]	BT 0.360 (0.473)	DT 0.000 (0.111)	lr 0.0002	loss 0.120 (0.119)
Train: [43][410/589]	BT 0.359 (0.477)	DT 0.000 (0.115)	lr 0.0002	loss 0.126 (0.119)
Train: [43][420/589]	BT 0.358 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.119 (0.119)
Train: [43][430/589]	BT 0.360 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.132 (0.119)
Train: [43][440/589]	BT 0.358 (0.470)	DT 0.000 (0.109)	lr 0.0002	loss 0.112 (0.119)
Train: [43][450/589]	BT 0.357 (0.468)	DT 0.000 (0.106)	lr 0.0002	loss 0.102 (0.119)
Train: [43][460/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0002	loss 0.109 (0.119)
Train: [43][470/589]	BT 0.358 (0.465)	DT 0.000 (0.104)	lr 0.0002	loss 0.120 (0.119)
Train: [43][480/589]	BT 0.359 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.124 (0.119)
Train: [43][490/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0002	loss 0.106 (0.119)
Train: [43][500/589]	BT 0.401 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.123 (0.119)
Train: [43][510/589]	BT 0.375 (0.463)	DT 0.000 (0.101)	lr 0.0002	loss 0.132 (0.119)
Train: [43][520/589]	BT 0.357 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.126 (0.119)
Train: [43][530/589]	BT 0.361 (0.463)	DT 0.000 (0.101)	lr 0.0002	loss 0.103 (0.119)
Train: [43][540/589]	BT 0.358 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.119 (0.119)
Train: [43][550/589]	BT 0.357 (0.460)	DT 0.000 (0.099)	lr 0.0002	loss 0.137 (0.119)
Train: [43][560/589]	BT 0.358 (0.459)	DT 0.000 (0.097)	lr 0.0002	loss 0.131 (0.119)
Train: [43][570/589]	BT 0.358 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.131 (0.119)
Train: [43][580/589]	BT 0.358 (0.461)	DT 0.000 (0.100)	lr 0.0002	loss 0.126 (0.119)
epoch 43, total time 271.94
loss: 0.11921977663948097@Epoch: 43
learning_rate: 0.0002,43
Valid: [43][10/88]	BT 0.109 (0.607)	DT 0.000 (0.496)	loss 0.128 (0.140)
Valid: [43][20/88]	BT 0.109 (0.557)	DT 0.000 (0.447)	loss 0.137 (0.137)
Valid: [43][30/88]	BT 0.110 (0.525)	DT 0.000 (0.414)	loss 0.144 (0.135)
Valid: [43][40/88]	BT 0.110 (0.524)	DT 0.000 (0.414)	loss 0.167 (0.137)
Valid: [43][50/88]	BT 0.109 (0.498)	DT 0.000 (0.388)	loss 0.143 (0.135)
Valid: [43][60/88]	BT 0.110 (0.503)	DT 0.000 (0.392)	loss 0.146 (0.134)
Valid: [43][70/88]	BT 0.109 (0.482)	DT 0.000 (0.371)	loss 0.148 (0.135)
Valid: [43][80/88]	BT 0.110 (0.467)	DT 0.000 (0.357)	loss 0.123 (0.135)
Train: [44][10/589]	BT 0.357 (0.807)	DT 0.000 (0.450)	lr 0.0002	loss 0.120 (0.124)
Train: [44][20/589]	BT 0.358 (0.599)	DT 0.000 (0.242)	lr 0.0002	loss 0.107 (0.121)
Train: [44][30/589]	BT 0.359 (0.553)	DT 0.000 (0.195)	lr 0.0002	loss 0.125 (0.120)
Train: [44][40/589]	BT 0.372 (0.535)	DT 0.000 (0.176)	lr 0.0002	loss 0.127 (0.119)
Train: [44][50/589]	BT 0.357 (0.510)	DT 0.000 (0.151)	lr 0.0002	loss 0.135 (0.118)
Train: [44][60/589]	BT 0.357 (0.492)	DT 0.000 (0.133)	lr 0.0002	loss 0.122 (0.117)
Train: [44][70/589]	BT 0.358 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.114 (0.117)
Train: [44][80/589]	BT 0.370 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.165 (0.118)
Train: [44][90/589]	BT 0.357 (0.449)	DT 0.000 (0.089)	lr 0.0002	loss 0.129 (0.117)
Train: [44][100/589]	BT 0.358 (0.440)	DT 0.000 (0.080)	lr 0.0002	loss 0.089 (0.117)
Train: [44][110/589]	BT 0.356 (0.433)	DT 0.000 (0.073)	lr 0.0002	loss 0.097 (0.117)
Train: [44][120/589]	BT 0.400 (0.427)	DT 0.000 (0.067)	lr 0.0002	loss 0.120 (0.117)
Train: [44][130/589]	BT 0.358 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.142 (0.117)
Train: [44][140/589]	BT 0.360 (0.418)	DT 0.000 (0.057)	lr 0.0002	loss 0.127 (0.117)
Train: [44][150/589]	BT 0.358 (0.415)	DT 0.000 (0.053)	lr 0.0002	loss 0.116 (0.117)
Train: [44][160/589]	BT 0.359 (0.411)	DT 0.000 (0.050)	lr 0.0002	loss 0.140 (0.117)
Train: [44][170/589]	BT 0.359 (0.408)	DT 0.000 (0.047)	lr 0.0002	loss 0.113 (0.117)
Train: [44][180/589]	BT 0.358 (0.405)	DT 0.000 (0.044)	lr 0.0002	loss 0.104 (0.117)
Train: [44][190/589]	BT 0.359 (0.406)	DT 0.000 (0.045)	lr 0.0002	loss 0.100 (0.117)
Train: [44][200/589]	BT 0.359 (0.411)	DT 0.000 (0.050)	lr 0.0002	loss 0.124 (0.118)
Train: [44][210/589]	BT 0.389 (0.409)	DT 0.000 (0.047)	lr 0.0002	loss 0.115 (0.117)
Train: [44][220/589]	BT 0.359 (0.407)	DT 0.000 (0.045)	lr 0.0002	loss 0.109 (0.117)
Train: [44][230/589]	BT 0.358 (0.405)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.118)
Train: [44][240/589]	BT 0.389 (0.403)	DT 0.000 (0.041)	lr 0.0002	loss 0.119 (0.118)
Train: [44][250/589]	BT 0.383 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.117 (0.118)
Train: [44][260/589]	BT 0.358 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.133 (0.118)
Train: [44][270/589]	BT 0.359 (0.404)	DT 0.000 (0.042)	lr 0.0002	loss 0.106 (0.118)
Train: [44][280/589]	BT 0.359 (0.403)	DT 0.000 (0.041)	lr 0.0002	loss 0.110 (0.118)
Train: [44][290/589]	BT 0.357 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.133 (0.119)
Train: [44][300/589]	BT 0.358 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.140 (0.118)
Train: [44][310/589]	BT 0.358 (0.399)	DT 0.000 (0.037)	lr 0.0002	loss 0.109 (0.118)
Train: [44][320/589]	BT 0.359 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.114 (0.118)
Train: [44][330/589]	BT 0.359 (0.399)	DT 0.000 (0.037)	lr 0.0002	loss 0.127 (0.118)
Train: [44][340/589]	BT 0.360 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.125 (0.118)
Train: [44][350/589]	BT 0.361 (0.398)	DT 0.000 (0.036)	lr 0.0002	loss 0.100 (0.118)
Train: [44][360/589]	BT 0.399 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.127 (0.118)
Train: [44][370/589]	BT 0.360 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.130 (0.118)
Train: [44][380/589]	BT 0.358 (0.402)	DT 0.000 (0.039)	lr 0.0002	loss 0.117 (0.118)
Train: [44][390/589]	BT 0.358 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.111 (0.118)
Train: [44][400/589]	BT 0.359 (0.402)	DT 0.000 (0.039)	lr 0.0002	loss 0.124 (0.118)
Train: [44][410/589]	BT 0.468 (0.402)	DT 0.092 (0.039)	lr 0.0002	loss 0.164 (0.118)
Train: [44][420/589]	BT 0.359 (0.402)	DT 0.000 (0.039)	lr 0.0002	loss 0.107 (0.118)
Train: [44][430/589]	BT 0.359 (0.402)	DT 0.000 (0.040)	lr 0.0002	loss 0.111 (0.118)
Train: [44][440/589]	BT 0.359 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.117 (0.118)
Train: [44][450/589]	BT 0.359 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.134 (0.118)
Train: [44][460/589]	BT 0.570 (0.400)	DT 0.211 (0.038)	lr 0.0002	loss 0.137 (0.118)
Train: [44][470/589]	BT 0.359 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.136 (0.118)
Train: [44][480/589]	BT 0.383 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.103 (0.118)
Train: [44][490/589]	BT 0.358 (0.400)	DT 0.000 (0.038)	lr 0.0002	loss 0.105 (0.118)
Train: [44][500/589]	BT 0.360 (0.401)	DT 0.000 (0.039)	lr 0.0002	loss 0.114 (0.118)
Train: [44][510/589]	BT 1.533 (0.402)	DT 1.173 (0.040)	lr 0.0002	loss 0.104 (0.118)
Train: [44][520/589]	BT 0.385 (0.404)	DT 0.000 (0.042)	lr 0.0002	loss 0.139 (0.118)
Train: [44][530/589]	BT 0.360 (0.404)	DT 0.000 (0.042)	lr 0.0002	loss 0.135 (0.118)
Train: [44][540/589]	BT 0.358 (0.404)	DT 0.000 (0.041)	lr 0.0002	loss 0.113 (0.118)
Train: [44][550/589]	BT 0.359 (0.403)	DT 0.000 (0.041)	lr 0.0002	loss 0.116 (0.118)
Train: [44][560/589]	BT 0.358 (0.404)	DT 0.000 (0.041)	lr 0.0002	loss 0.150 (0.118)
Train: [44][570/589]	BT 0.360 (0.405)	DT 0.000 (0.042)	lr 0.0002	loss 0.121 (0.118)
Train: [44][580/589]	BT 0.359 (0.406)	DT 0.000 (0.044)	lr 0.0002	loss 0.125 (0.118)
epoch 44, total time 238.99
loss: 0.11839386220409634@Epoch: 44
learning_rate: 0.0002,44
Valid: [44][10/88]	BT 0.110 (0.687)	DT 0.000 (0.576)	loss 0.123 (0.138)
Valid: [44][20/88]	BT 0.109 (0.561)	DT 0.000 (0.451)	loss 0.122 (0.138)
Valid: [44][30/88]	BT 0.109 (0.516)	DT 0.000 (0.406)	loss 0.146 (0.139)
Valid: [44][40/88]	BT 0.110 (0.485)	DT 0.000 (0.374)	loss 0.126 (0.137)
Valid: [44][50/88]	BT 0.109 (0.472)	DT 0.000 (0.362)	loss 0.116 (0.136)
Valid: [44][60/88]	BT 0.110 (0.479)	DT 0.000 (0.369)	loss 0.152 (0.139)
Valid: [44][70/88]	BT 0.109 (0.477)	DT 0.000 (0.367)	loss 0.147 (0.139)
Valid: [44][80/88]	BT 0.110 (0.488)	DT 0.000 (0.378)	loss 0.130 (0.139)
Train: [45][10/589]	BT 0.386 (0.912)	DT 0.000 (0.550)	lr 0.0002	loss 0.098 (0.111)
Train: [45][20/589]	BT 0.359 (0.681)	DT 0.000 (0.322)	lr 0.0002	loss 0.101 (0.113)
Train: [45][30/589]	BT 0.388 (0.614)	DT 0.000 (0.254)	lr 0.0002	loss 0.116 (0.113)
Train: [45][40/589]	BT 0.395 (0.561)	DT 0.000 (0.200)	lr 0.0002	loss 0.121 (0.116)
Train: [45][50/589]	BT 0.358 (0.531)	DT 0.000 (0.171)	lr 0.0002	loss 0.122 (0.115)
Train: [45][60/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0002	loss 0.105 (0.115)
Train: [45][70/589]	BT 0.357 (0.484)	DT 0.000 (0.122)	lr 0.0002	loss 0.114 (0.115)
Train: [45][80/589]	BT 0.359 (0.472)	DT 0.000 (0.110)	lr 0.0002	loss 0.128 (0.115)
Train: [45][90/589]	BT 0.358 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.113 (0.115)
Train: [45][100/589]	BT 0.358 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.125 (0.116)
Train: [45][110/589]	BT 0.358 (0.460)	DT 0.000 (0.100)	lr 0.0002	loss 0.097 (0.116)
Train: [45][120/589]	BT 0.361 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.117 (0.116)
Train: [45][130/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.131 (0.117)
Train: [45][140/589]	BT 0.364 (0.464)	DT 0.000 (0.104)	lr 0.0002	loss 0.120 (0.117)
Train: [45][150/589]	BT 0.358 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.108 (0.117)
Train: [45][160/589]	BT 0.359 (0.455)	DT 0.000 (0.095)	lr 0.0002	loss 0.117 (0.118)
Train: [45][170/589]	BT 0.357 (0.454)	DT 0.000 (0.093)	lr 0.0002	loss 0.095 (0.118)
Train: [45][180/589]	BT 0.358 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.103 (0.117)
Train: [45][190/589]	BT 0.359 (0.446)	DT 0.000 (0.086)	lr 0.0002	loss 0.130 (0.117)
Train: [45][200/589]	BT 0.359 (0.442)	DT 0.000 (0.082)	lr 0.0002	loss 0.118 (0.117)
Train: [45][210/589]	BT 0.359 (0.438)	DT 0.000 (0.078)	lr 0.0002	loss 0.108 (0.118)
Train: [45][220/589]	BT 0.358 (0.435)	DT 0.000 (0.074)	lr 0.0002	loss 0.120 (0.118)
Train: [45][230/589]	BT 0.359 (0.432)	DT 0.000 (0.071)	lr 0.0002	loss 0.123 (0.118)
Train: [45][240/589]	BT 0.358 (0.441)	DT 0.000 (0.080)	lr 0.0002	loss 0.127 (0.118)
Train: [45][250/589]	BT 0.358 (0.443)	DT 0.000 (0.082)	lr 0.0002	loss 0.126 (0.118)
Train: [45][260/589]	BT 0.358 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.105 (0.118)
Train: [45][270/589]	BT 0.359 (0.445)	DT 0.000 (0.084)	lr 0.0002	loss 0.109 (0.118)
Train: [45][280/589]	BT 0.398 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.116 (0.118)
Train: [45][290/589]	BT 0.357 (0.443)	DT 0.000 (0.082)	lr 0.0002	loss 0.113 (0.118)
Train: [45][300/589]	BT 0.359 (0.444)	DT 0.000 (0.084)	lr 0.0002	loss 0.096 (0.118)
Train: [45][310/589]	BT 0.360 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.108 (0.118)
Train: [45][320/589]	BT 0.358 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.144 (0.118)
Train: [45][330/589]	BT 0.358 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.118 (0.118)
Train: [45][340/589]	BT 0.359 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.129 (0.118)
Train: [45][350/589]	BT 0.359 (0.453)	DT 0.000 (0.092)	lr 0.0002	loss 0.115 (0.118)
Train: [45][360/589]	BT 0.359 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.115 (0.118)
Train: [45][370/589]	BT 0.357 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.120 (0.118)
Train: [45][380/589]	BT 0.359 (0.452)	DT 0.000 (0.091)	lr 0.0002	loss 0.111 (0.118)
Train: [45][390/589]	BT 0.358 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.125 (0.118)
Train: [45][400/589]	BT 0.359 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.111 (0.118)
Train: [45][410/589]	BT 0.358 (0.458)	DT 0.000 (0.097)	lr 0.0002	loss 0.095 (0.118)
Train: [45][420/589]	BT 0.358 (0.462)	DT 0.000 (0.101)	lr 0.0002	loss 0.144 (0.118)
Train: [45][430/589]	BT 0.395 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.114 (0.118)
Train: [45][440/589]	BT 0.356 (0.469)	DT 0.000 (0.108)	lr 0.0002	loss 0.105 (0.118)
Train: [45][450/589]	BT 0.358 (0.473)	DT 0.000 (0.112)	lr 0.0002	loss 0.112 (0.118)
Train: [45][460/589]	BT 0.358 (0.475)	DT 0.000 (0.114)	lr 0.0002	loss 0.083 (0.118)
Train: [45][470/589]	BT 0.358 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.107 (0.118)
Train: [45][480/589]	BT 0.358 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.098 (0.118)
Train: [45][490/589]	BT 0.357 (0.488)	DT 0.000 (0.128)	lr 0.0002	loss 0.119 (0.118)
Train: [45][500/589]	BT 0.357 (0.495)	DT 0.000 (0.134)	lr 0.0002	loss 0.143 (0.118)
Train: [45][510/589]	BT 0.358 (0.495)	DT 0.000 (0.135)	lr 0.0002	loss 0.122 (0.118)
Train: [45][520/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0002	loss 0.126 (0.118)
Train: [45][530/589]	BT 0.398 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.112 (0.118)
Train: [45][540/589]	BT 0.362 (0.502)	DT 0.000 (0.141)	lr 0.0002	loss 0.105 (0.118)
Train: [45][550/589]	BT 0.357 (0.508)	DT 0.000 (0.148)	lr 0.0002	loss 0.105 (0.118)
Train: [45][560/589]	BT 0.355 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.106 (0.118)
Train: [45][570/589]	BT 0.358 (0.512)	DT 0.000 (0.151)	lr 0.0002	loss 0.120 (0.118)
Train: [45][580/589]	BT 0.357 (0.515)	DT 0.000 (0.154)	lr 0.0002	loss 0.126 (0.118)
epoch 45, total time 305.01
loss: 0.11782007849479852@Epoch: 45
learning_rate: 0.0002,45
Valid: [45][10/88]	BT 0.109 (0.753)	DT 0.000 (0.641)	loss 0.138 (0.147)
Valid: [45][20/88]	BT 0.109 (0.665)	DT 0.000 (0.553)	loss 0.148 (0.145)
Valid: [45][30/88]	BT 0.110 (0.642)	DT 0.000 (0.531)	loss 0.138 (0.142)
Valid: [45][40/88]	BT 0.110 (0.610)	DT 0.000 (0.499)	loss 0.131 (0.141)
Valid: [45][50/88]	BT 0.110 (0.597)	DT 0.000 (0.486)	loss 0.137 (0.141)
Valid: [45][60/88]	BT 0.110 (0.626)	DT 0.000 (0.515)	loss 0.142 (0.140)
Valid: [45][70/88]	BT 0.110 (0.612)	DT 0.000 (0.502)	loss 0.162 (0.140)
Valid: [45][80/88]	BT 0.109 (0.600)	DT 0.000 (0.489)	loss 0.124 (0.140)
Train: [46][10/589]	BT 0.357 (0.859)	DT 0.000 (0.500)	lr 0.0002	loss 0.115 (0.116)
Train: [46][20/589]	BT 0.357 (0.636)	DT 0.000 (0.278)	lr 0.0002	loss 0.124 (0.117)
Train: [46][30/589]	BT 0.357 (0.559)	DT 0.000 (0.201)	lr 0.0002	loss 0.106 (0.115)
Train: [46][40/589]	BT 0.357 (0.540)	DT 0.000 (0.182)	lr 0.0002	loss 0.118 (0.114)
Train: [46][50/589]	BT 0.363 (0.519)	DT 0.000 (0.161)	lr 0.0002	loss 0.110 (0.114)
Train: [46][60/589]	BT 0.359 (0.497)	DT 0.000 (0.138)	lr 0.0002	loss 0.090 (0.113)
Train: [46][70/589]	BT 0.358 (0.480)	DT 0.000 (0.122)	lr 0.0002	loss 0.139 (0.113)
Train: [46][80/589]	BT 0.358 (0.470)	DT 0.000 (0.111)	lr 0.0002	loss 0.122 (0.113)
Train: [46][90/589]	BT 0.358 (0.469)	DT 0.000 (0.110)	lr 0.0002	loss 0.113 (0.113)
Train: [46][100/589]	BT 0.359 (0.459)	DT 0.000 (0.100)	lr 0.0002	loss 0.122 (0.114)
Train: [46][110/589]	BT 0.358 (0.482)	DT 0.000 (0.123)	lr 0.0002	loss 0.101 (0.114)
Train: [46][120/589]	BT 0.358 (0.482)	DT 0.000 (0.123)	lr 0.0002	loss 0.105 (0.115)
Train: [46][130/589]	BT 0.357 (0.481)	DT 0.000 (0.122)	lr 0.0002	loss 0.111 (0.115)
Train: [46][140/589]	BT 0.358 (0.484)	DT 0.000 (0.125)	lr 0.0002	loss 0.096 (0.114)
Train: [46][150/589]	BT 0.358 (0.491)	DT 0.000 (0.132)	lr 0.0002	loss 0.120 (0.115)
Train: [46][160/589]	BT 0.359 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.117 (0.115)
Train: [46][170/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.103 (0.115)
Train: [46][180/589]	BT 0.387 (0.489)	DT 0.000 (0.129)	lr 0.0002	loss 0.094 (0.115)
Train: [46][190/589]	BT 0.381 (0.486)	DT 0.000 (0.126)	lr 0.0002	loss 0.107 (0.115)
Train: [46][200/589]	BT 0.371 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.120 (0.115)
Train: [46][210/589]	BT 0.358 (0.478)	DT 0.000 (0.118)	lr 0.0002	loss 0.135 (0.115)
Train: [46][220/589]	BT 0.357 (0.479)	DT 0.000 (0.120)	lr 0.0002	loss 0.124 (0.116)
Train: [46][230/589]	BT 0.383 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.109 (0.115)
Train: [46][240/589]	BT 0.397 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.122 (0.116)
Train: [46][250/589]	BT 0.355 (0.478)	DT 0.000 (0.118)	lr 0.0002	loss 0.133 (0.116)
Train: [46][260/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.122 (0.116)
Train: [46][270/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.129 (0.117)
Train: [46][280/589]	BT 0.358 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.122 (0.117)
Train: [46][290/589]	BT 0.359 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.119 (0.117)
Train: [46][300/589]	BT 0.373 (0.479)	DT 0.000 (0.119)	lr 0.0002	loss 0.112 (0.117)
Train: [46][310/589]	BT 0.361 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.124 (0.117)
Train: [46][320/589]	BT 0.358 (0.484)	DT 0.000 (0.124)	lr 0.0002	loss 0.118 (0.117)
Train: [46][330/589]	BT 0.361 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.122 (0.117)
Train: [46][340/589]	BT 0.359 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.127 (0.117)
Train: [46][350/589]	BT 0.357 (0.477)	DT 0.000 (0.117)	lr 0.0002	loss 0.098 (0.117)
Train: [46][360/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.122 (0.117)
Train: [46][370/589]	BT 0.359 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.100 (0.117)
Train: [46][380/589]	BT 0.357 (0.483)	DT 0.000 (0.122)	lr 0.0002	loss 0.124 (0.117)
Train: [46][390/589]	BT 0.397 (0.481)	DT 0.000 (0.121)	lr 0.0002	loss 0.128 (0.117)
Train: [46][400/589]	BT 0.358 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.118 (0.117)
Train: [46][410/589]	BT 0.398 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.108 (0.117)
Train: [46][420/589]	BT 0.359 (0.478)	DT 0.000 (0.118)	lr 0.0002	loss 0.129 (0.117)
Train: [46][430/589]	BT 0.359 (0.482)	DT 0.000 (0.121)	lr 0.0002	loss 0.113 (0.117)
Train: [46][440/589]	BT 0.386 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.126 (0.117)
Train: [46][450/589]	BT 0.369 (0.479)	DT 0.000 (0.118)	lr 0.0002	loss 0.085 (0.117)
Train: [46][460/589]	BT 0.356 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.134 (0.117)
Train: [46][470/589]	BT 0.358 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.127 (0.117)
Train: [46][480/589]	BT 0.359 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.113 (0.117)
Train: [46][490/589]	BT 0.359 (0.473)	DT 0.000 (0.112)	lr 0.0002	loss 0.139 (0.117)
Train: [46][500/589]	BT 0.356 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.104 (0.117)
Train: [46][510/589]	BT 0.359 (0.472)	DT 0.000 (0.112)	lr 0.0002	loss 0.125 (0.117)
Train: [46][520/589]	BT 0.358 (0.473)	DT 0.000 (0.112)	lr 0.0002	loss 0.107 (0.117)
Train: [46][530/589]	BT 0.357 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.102 (0.117)
Train: [46][540/589]	BT 0.357 (0.471)	DT 0.000 (0.111)	lr 0.0002	loss 0.122 (0.117)
Train: [46][550/589]	BT 0.358 (0.472)	DT 0.000 (0.111)	lr 0.0002	loss 0.114 (0.117)
Train: [46][560/589]	BT 0.358 (0.474)	DT 0.000 (0.113)	lr 0.0002	loss 0.136 (0.117)
Train: [46][570/589]	BT 0.358 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.124 (0.117)
Train: [46][580/589]	BT 0.357 (0.475)	DT 0.000 (0.114)	lr 0.0002	loss 0.101 (0.117)
epoch 46, total time 280.47
loss: 0.11697802553200687@Epoch: 46
learning_rate: 0.0002,46
Valid: [46][10/88]	BT 0.109 (0.675)	DT 0.000 (0.564)	loss 0.158 (0.145)
Valid: [46][20/88]	BT 0.110 (0.584)	DT 0.000 (0.474)	loss 0.177 (0.144)
Valid: [46][30/88]	BT 0.109 (0.555)	DT 0.000 (0.444)	loss 0.171 (0.144)
Valid: [46][40/88]	BT 0.110 (0.527)	DT 0.000 (0.417)	loss 0.129 (0.142)
Valid: [46][50/88]	BT 0.109 (0.517)	DT 0.000 (0.407)	loss 0.135 (0.142)
Valid: [46][60/88]	BT 0.110 (0.503)	DT 0.000 (0.393)	loss 0.137 (0.142)
Valid: [46][70/88]	BT 0.109 (0.495)	DT 0.000 (0.385)	loss 0.151 (0.141)
Valid: [46][80/88]	BT 0.110 (0.500)	DT 0.000 (0.390)	loss 0.134 (0.141)
Train: [47][10/589]	BT 0.358 (0.968)	DT 0.000 (0.607)	lr 0.0002	loss 0.120 (0.117)
Train: [47][20/589]	BT 0.358 (0.762)	DT 0.000 (0.404)	lr 0.0002	loss 0.116 (0.114)
Train: [47][30/589]	BT 0.387 (0.658)	DT 0.000 (0.298)	lr 0.0002	loss 0.116 (0.116)
Train: [47][40/589]	BT 0.358 (0.586)	DT 0.000 (0.227)	lr 0.0002	loss 0.118 (0.117)
Train: [47][50/589]	BT 0.389 (0.544)	DT 0.000 (0.183)	lr 0.0002	loss 0.109 (0.118)
Train: [47][60/589]	BT 0.358 (0.514)	DT 0.000 (0.153)	lr 0.0002	loss 0.125 (0.118)
Train: [47][70/589]	BT 0.358 (0.505)	DT 0.000 (0.144)	lr 0.0002	loss 0.109 (0.117)
Train: [47][80/589]	BT 0.360 (0.497)	DT 0.000 (0.136)	lr 0.0002	loss 0.124 (0.117)
Train: [47][90/589]	BT 0.373 (0.487)	DT 0.000 (0.126)	lr 0.0002	loss 0.137 (0.117)
Train: [47][100/589]	BT 0.357 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.126 (0.117)
Train: [47][110/589]	BT 0.358 (0.470)	DT 0.000 (0.108)	lr 0.0002	loss 0.108 (0.117)
Train: [47][120/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.108 (0.117)
Train: [47][130/589]	BT 0.359 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.120 (0.117)
Train: [47][140/589]	BT 0.357 (0.468)	DT 0.000 (0.107)	lr 0.0002	loss 0.122 (0.117)
Train: [47][150/589]	BT 0.358 (0.462)	DT 0.000 (0.101)	lr 0.0002	loss 0.113 (0.116)
Train: [47][160/589]	BT 0.359 (0.456)	DT 0.000 (0.095)	lr 0.0002	loss 0.115 (0.117)
Train: [47][170/589]	BT 0.358 (0.451)	DT 0.000 (0.090)	lr 0.0002	loss 0.114 (0.116)
Train: [47][180/589]	BT 0.358 (0.446)	DT 0.000 (0.085)	lr 0.0002	loss 0.105 (0.117)
Train: [47][190/589]	BT 0.358 (0.444)	DT 0.000 (0.083)	lr 0.0002	loss 0.122 (0.117)
Train: [47][200/589]	BT 0.359 (0.441)	DT 0.000 (0.080)	lr 0.0002	loss 0.108 (0.117)
Train: [47][210/589]	BT 0.358 (0.439)	DT 0.000 (0.078)	lr 0.0002	loss 0.114 (0.117)
Train: [47][220/589]	BT 0.364 (0.436)	DT 0.000 (0.075)	lr 0.0002	loss 0.101 (0.117)
Train: [47][230/589]	BT 0.357 (0.433)	DT 0.000 (0.071)	lr 0.0002	loss 0.136 (0.117)
Train: [47][240/589]	BT 0.359 (0.430)	DT 0.000 (0.068)	lr 0.0002	loss 0.106 (0.117)
Train: [47][250/589]	BT 0.359 (0.427)	DT 0.000 (0.066)	lr 0.0002	loss 0.105 (0.117)
Train: [47][260/589]	BT 0.359 (0.425)	DT 0.000 (0.063)	lr 0.0002	loss 0.108 (0.117)
Train: [47][270/589]	BT 0.358 (0.428)	DT 0.000 (0.067)	lr 0.0002	loss 0.112 (0.117)
Train: [47][280/589]	BT 0.359 (0.427)	DT 0.000 (0.066)	lr 0.0002	loss 0.115 (0.117)
Train: [47][290/589]	BT 0.359 (0.425)	DT 0.000 (0.064)	lr 0.0002	loss 0.099 (0.117)
Train: [47][300/589]	BT 0.359 (0.423)	DT 0.000 (0.062)	lr 0.0002	loss 0.112 (0.117)
Train: [47][310/589]	BT 0.358 (0.421)	DT 0.000 (0.060)	lr 0.0002	loss 0.105 (0.117)
Train: [47][320/589]	BT 0.358 (0.420)	DT 0.000 (0.058)	lr 0.0002	loss 0.105 (0.116)
Train: [47][330/589]	BT 0.360 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.121 (0.116)
Train: [47][340/589]	BT 0.360 (0.418)	DT 0.000 (0.057)	lr 0.0002	loss 0.113 (0.116)
Train: [47][350/589]	BT 0.359 (0.419)	DT 0.000 (0.057)	lr 0.0002	loss 0.120 (0.116)
Train: [47][360/589]	BT 0.359 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.115 (0.116)
Train: [47][370/589]	BT 0.360 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.138 (0.116)
Train: [47][380/589]	BT 0.359 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.122 (0.116)
Train: [47][390/589]	BT 0.360 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.112 (0.116)
Train: [47][400/589]	BT 0.367 (0.418)	DT 0.000 (0.056)	lr 0.0002	loss 0.109 (0.116)
Train: [47][410/589]	BT 0.370 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.114 (0.116)
Train: [47][420/589]	BT 0.358 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.111 (0.116)
Train: [47][430/589]	BT 0.358 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.128 (0.116)
Train: [47][440/589]	BT 0.359 (0.416)	DT 0.000 (0.055)	lr 0.0002	loss 0.108 (0.116)
Train: [47][450/589]	BT 0.358 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.129 (0.116)
Train: [47][460/589]	BT 0.360 (0.420)	DT 0.000 (0.058)	lr 0.0002	loss 0.134 (0.116)
Train: [47][470/589]	BT 0.392 (0.419)	DT 0.000 (0.058)	lr 0.0002	loss 0.107 (0.117)
Train: [47][480/589]	BT 0.358 (0.422)	DT 0.000 (0.060)	lr 0.0002	loss 0.103 (0.117)
Train: [47][490/589]	BT 0.359 (0.421)	DT 0.000 (0.060)	lr 0.0002	loss 0.131 (0.117)
Train: [47][500/589]	BT 0.391 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.146 (0.117)
Train: [47][510/589]	BT 0.358 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.099 (0.117)
Train: [47][520/589]	BT 0.361 (0.423)	DT 0.000 (0.062)	lr 0.0002	loss 0.116 (0.117)
Train: [47][530/589]	BT 0.357 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.110 (0.117)
Train: [47][540/589]	BT 0.358 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.133 (0.117)
Train: [47][550/589]	BT 0.358 (0.422)	DT 0.000 (0.061)	lr 0.0002	loss 0.112 (0.117)
Train: [47][560/589]	BT 0.364 (0.423)	DT 0.000 (0.061)	lr 0.0002	loss 0.132 (0.117)
Train: [47][570/589]	BT 0.361 (0.423)	DT 0.000 (0.062)	lr 0.0002	loss 0.141 (0.117)
Train: [47][580/589]	BT 0.358 (0.425)	DT 0.000 (0.064)	lr 0.0002	loss 0.113 (0.117)
epoch 47, total time 253.18
loss: 0.1168739710573763@Epoch: 47
learning_rate: 0.0002,47
Valid: [47][10/88]	BT 0.110 (0.646)	DT 0.000 (0.535)	loss 0.127 (0.147)
Valid: [47][20/88]	BT 0.110 (0.532)	DT 0.000 (0.422)	loss 0.154 (0.141)
Valid: [47][30/88]	BT 0.110 (0.489)	DT 0.000 (0.379)	loss 0.130 (0.142)
Valid: [47][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.188 (0.143)
Valid: [47][50/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.148 (0.142)
Valid: [47][60/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.123 (0.141)
Valid: [47][70/88]	BT 0.110 (0.451)	DT 0.000 (0.341)	loss 0.142 (0.140)
Valid: [47][80/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.137 (0.140)
Train: [48][10/589]	BT 0.384 (0.892)	DT 0.000 (0.531)	lr 0.0002	loss 0.119 (0.116)
Train: [48][20/589]	BT 0.357 (0.642)	DT 0.000 (0.283)	lr 0.0002	loss 0.104 (0.116)
Train: [48][30/589]	BT 0.388 (0.555)	DT 0.000 (0.195)	lr 0.0002	loss 0.122 (0.118)
Train: [48][40/589]	BT 0.358 (0.523)	DT 0.000 (0.163)	lr 0.0002	loss 0.103 (0.116)
Train: [48][50/589]	BT 0.358 (0.490)	DT 0.000 (0.131)	lr 0.0002	loss 0.120 (0.115)
Train: [48][60/589]	BT 0.359 (0.483)	DT 0.000 (0.123)	lr 0.0002	loss 0.101 (0.114)
Train: [48][70/589]	BT 0.361 (0.476)	DT 0.000 (0.117)	lr 0.0002	loss 0.108 (0.115)
Train: [48][80/589]	BT 0.359 (0.469)	DT 0.000 (0.109)	lr 0.0002	loss 0.108 (0.114)
Train: [48][90/589]	BT 0.357 (0.457)	DT 0.000 (0.097)	lr 0.0002	loss 0.098 (0.114)
Train: [48][100/589]	BT 0.360 (0.459)	DT 0.000 (0.099)	lr 0.0002	loss 0.111 (0.115)
Train: [48][110/589]	BT 0.359 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.121 (0.115)
Train: [48][120/589]	BT 0.359 (0.459)	DT 0.000 (0.099)	lr 0.0002	loss 0.149 (0.116)
Train: [48][130/589]	BT 0.359 (0.461)	DT 0.000 (0.101)	lr 0.0002	loss 0.119 (0.115)
Train: [48][140/589]	BT 0.366 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.131 (0.116)
Train: [48][150/589]	BT 0.359 (0.451)	DT 0.000 (0.091)	lr 0.0002	loss 0.109 (0.116)
Train: [48][160/589]	BT 0.359 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.122 (0.116)
Train: [48][170/589]	BT 0.358 (0.462)	DT 0.000 (0.102)	lr 0.0002	loss 0.124 (0.117)
Train: [48][180/589]	BT 0.363 (0.466)	DT 0.000 (0.106)	lr 0.0002	loss 0.109 (0.116)
Train: [48][190/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.113 (0.116)
Train: [48][200/589]	BT 0.359 (0.461)	DT 0.000 (0.101)	lr 0.0002	loss 0.123 (0.116)
Train: [48][210/589]	BT 0.360 (0.459)	DT 0.000 (0.098)	lr 0.0002	loss 0.106 (0.116)
Train: [48][220/589]	BT 0.359 (0.457)	DT 0.000 (0.096)	lr 0.0002	loss 0.126 (0.116)
Train: [48][230/589]	BT 0.357 (0.456)	DT 0.000 (0.096)	lr 0.0002	loss 0.125 (0.117)
Train: [48][240/589]	BT 0.358 (0.462)	DT 0.000 (0.101)	lr 0.0002	loss 0.121 (0.117)
Train: [48][250/589]	BT 0.357 (0.462)	DT 0.000 (0.102)	lr 0.0002	loss 0.110 (0.117)
Train: [48][260/589]	BT 0.359 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.103 (0.117)
Train: [48][270/589]	BT 0.359 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.139 (0.117)
Train: [48][280/589]	BT 0.359 (0.462)	DT 0.000 (0.102)	lr 0.0002	loss 0.114 (0.117)
Train: [48][290/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.118 (0.117)
Train: [48][300/589]	BT 0.368 (0.462)	DT 0.000 (0.101)	lr 0.0002	loss 0.113 (0.116)
Train: [48][310/589]	BT 0.360 (0.464)	DT 0.000 (0.103)	lr 0.0002	loss 0.136 (0.117)
Train: [48][320/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0002	loss 0.111 (0.117)
Train: [48][330/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0002	loss 0.113 (0.116)
Train: [48][340/589]	BT 0.357 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.084 (0.116)
Train: [48][350/589]	BT 0.358 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.122 (0.116)
Train: [48][360/589]	BT 0.358 (0.467)	DT 0.000 (0.106)	lr 0.0002	loss 0.112 (0.116)
Train: [48][370/589]	BT 0.359 (0.466)	DT 0.000 (0.105)	lr 0.0002	loss 0.095 (0.116)
Train: [48][380/589]	BT 0.587 (0.469)	DT 0.232 (0.108)	lr 0.0002	loss 0.124 (0.116)
Train: [48][390/589]	BT 0.361 (0.473)	DT 0.000 (0.113)	lr 0.0002	loss 0.111 (0.116)
Train: [48][400/589]	BT 0.358 (0.475)	DT 0.000 (0.114)	lr 0.0002	loss 0.125 (0.116)
Train: [48][410/589]	BT 0.356 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.116 (0.116)
Train: [48][420/589]	BT 0.358 (0.476)	DT 0.000 (0.115)	lr 0.0002	loss 0.129 (0.116)
Train: [48][430/589]	BT 0.358 (0.477)	DT 0.000 (0.116)	lr 0.0002	loss 0.113 (0.116)
Train: [48][440/589]	BT 0.358 (0.475)	DT 0.000 (0.115)	lr 0.0002	loss 0.115 (0.116)
Train: [48][450/589]	BT 0.358 (0.476)	DT 0.000 (0.116)	lr 0.0002	loss 0.106 (0.116)
Train: [48][460/589]	BT 0.358 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.111 (0.116)
Train: [48][470/589]	BT 0.360 (0.478)	DT 0.000 (0.117)	lr 0.0002	loss 0.109 (0.116)
Train: [48][480/589]	BT 0.358 (0.480)	DT 0.000 (0.120)	lr 0.0002	loss 0.100 (0.116)
Train: [48][490/589]	BT 0.358 (0.485)	DT 0.000 (0.124)	lr 0.0002	loss 0.105 (0.116)
Train: [48][500/589]	BT 0.359 (0.490)	DT 0.000 (0.129)	lr 0.0002	loss 0.123 (0.116)
Train: [48][510/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0002	loss 0.111 (0.116)
Train: [48][520/589]	BT 0.401 (0.496)	DT 0.000 (0.136)	lr 0.0002	loss 0.102 (0.116)
Train: [48][530/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0002	loss 0.121 (0.116)
Train: [48][540/589]	BT 0.358 (0.501)	DT 0.000 (0.140)	lr 0.0002	loss 0.114 (0.116)
Train: [48][550/589]	BT 0.357 (0.504)	DT 0.000 (0.144)	lr 0.0002	loss 0.107 (0.116)
Train: [48][560/589]	BT 0.358 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.133 (0.116)
Train: [48][570/589]	BT 0.873 (0.509)	DT 0.514 (0.149)	lr 0.0002	loss 0.143 (0.116)
Train: [48][580/589]	BT 0.357 (0.513)	DT 0.000 (0.152)	lr 0.0002	loss 0.109 (0.116)
epoch 48, total time 303.01
loss: 0.11595165498106753@Epoch: 48
learning_rate: 0.0002,48
Valid: [48][10/88]	BT 0.109 (0.882)	DT 0.000 (0.771)	loss 0.170 (0.143)
Valid: [48][20/88]	BT 0.110 (0.727)	DT 0.000 (0.617)	loss 0.151 (0.146)
Valid: [48][30/88]	BT 0.109 (0.741)	DT 0.000 (0.630)	loss 0.162 (0.148)
Valid: [48][40/88]	BT 0.109 (0.844)	DT 0.000 (0.734)	loss 0.116 (0.146)
Valid: [48][50/88]	BT 0.110 (0.816)	DT 0.000 (0.706)	loss 0.135 (0.146)
Valid: [48][60/88]	BT 0.110 (0.782)	DT 0.000 (0.672)	loss 0.114 (0.146)
Valid: [48][70/88]	BT 0.110 (0.775)	DT 0.000 (0.664)	loss 0.118 (0.145)
Valid: [48][80/88]	BT 0.110 (0.757)	DT 0.000 (0.647)	loss 0.128 (0.143)
Epoch    48: reducing learning rate of group 0 to 1.0000e-04.
Train: [49][10/589]	BT 0.356 (0.954)	DT 0.000 (0.597)	lr 0.0001	loss 0.120 (0.113)
Train: [49][20/589]	BT 0.359 (0.953)	DT 0.000 (0.594)	lr 0.0001	loss 0.098 (0.108)
Train: [49][30/589]	BT 0.357 (0.830)	DT 0.000 (0.472)	lr 0.0001	loss 0.102 (0.108)
Train: [49][40/589]	BT 0.357 (0.779)	DT 0.000 (0.421)	lr 0.0001	loss 0.105 (0.110)
Train: [49][50/589]	BT 0.357 (0.766)	DT 0.000 (0.408)	lr 0.0001	loss 0.128 (0.111)
Train: [49][60/589]	BT 0.357 (0.731)	DT 0.000 (0.372)	lr 0.0001	loss 0.110 (0.111)
Train: [49][70/589]	BT 0.357 (0.711)	DT 0.000 (0.352)	lr 0.0001	loss 0.130 (0.112)
Train: [49][80/589]	BT 0.399 (0.699)	DT 0.000 (0.340)	lr 0.0001	loss 0.109 (0.112)
Train: [49][90/589]	BT 0.357 (0.704)	DT 0.000 (0.344)	lr 0.0001	loss 0.114 (0.112)
Train: [49][100/589]	BT 0.358 (0.678)	DT 0.000 (0.318)	lr 0.0001	loss 0.124 (0.112)
Train: [49][110/589]	BT 0.356 (0.663)	DT 0.000 (0.303)	lr 0.0001	loss 0.122 (0.112)
Train: [49][120/589]	BT 0.358 (0.664)	DT 0.000 (0.305)	lr 0.0001	loss 0.132 (0.112)
Train: [49][130/589]	BT 0.358 (0.649)	DT 0.000 (0.289)	lr 0.0001	loss 0.140 (0.112)
Train: [49][140/589]	BT 0.359 (0.641)	DT 0.000 (0.281)	lr 0.0001	loss 0.108 (0.112)
Train: [49][150/589]	BT 0.359 (0.629)	DT 0.000 (0.269)	lr 0.0001	loss 0.139 (0.112)
Train: [49][160/589]	BT 0.358 (0.620)	DT 0.000 (0.260)	lr 0.0001	loss 0.141 (0.112)
Train: [49][170/589]	BT 0.394 (0.612)	DT 0.000 (0.253)	lr 0.0001	loss 0.116 (0.112)
Train: [49][180/589]	BT 0.359 (0.604)	DT 0.000 (0.244)	lr 0.0001	loss 0.114 (0.112)
Train: [49][190/589]	BT 0.359 (0.598)	DT 0.000 (0.239)	lr 0.0001	loss 0.118 (0.112)
Train: [49][200/589]	BT 0.361 (0.599)	DT 0.000 (0.239)	lr 0.0001	loss 0.092 (0.111)
Train: [49][210/589]	BT 0.358 (0.600)	DT 0.000 (0.240)	lr 0.0001	loss 0.130 (0.111)
Train: [49][220/589]	BT 0.358 (0.593)	DT 0.000 (0.233)	lr 0.0001	loss 0.113 (0.111)
Train: [49][230/589]	BT 0.359 (0.596)	DT 0.000 (0.236)	lr 0.0001	loss 0.115 (0.111)
Train: [49][240/589]	BT 0.361 (0.595)	DT 0.000 (0.235)	lr 0.0001	loss 0.125 (0.111)
Train: [49][250/589]	BT 0.358 (0.588)	DT 0.000 (0.228)	lr 0.0001	loss 0.122 (0.111)
Train: [49][260/589]	BT 0.358 (0.583)	DT 0.000 (0.224)	lr 0.0001	loss 0.123 (0.111)
Train: [49][270/589]	BT 0.357 (0.581)	DT 0.000 (0.221)	lr 0.0001	loss 0.105 (0.111)
Train: [49][280/589]	BT 0.358 (0.579)	DT 0.000 (0.219)	lr 0.0001	loss 0.121 (0.111)
Train: [49][290/589]	BT 0.389 (0.578)	DT 0.000 (0.219)	lr 0.0001	loss 0.129 (0.111)
Train: [49][300/589]	BT 0.356 (0.575)	DT 0.000 (0.215)	lr 0.0001	loss 0.137 (0.111)
Train: [49][310/589]	BT 0.361 (0.571)	DT 0.000 (0.212)	lr 0.0001	loss 0.103 (0.111)
Train: [49][320/589]	BT 0.357 (0.571)	DT 0.000 (0.211)	lr 0.0001	loss 0.124 (0.111)
Train: [49][330/589]	BT 0.359 (0.570)	DT 0.000 (0.210)	lr 0.0001	loss 0.102 (0.112)
Train: [49][340/589]	BT 0.358 (0.567)	DT 0.000 (0.207)	lr 0.0001	loss 0.117 (0.112)
Train: [49][350/589]	BT 0.360 (0.567)	DT 0.000 (0.207)	lr 0.0001	loss 0.096 (0.112)
Train: [49][360/589]	BT 0.358 (0.573)	DT 0.000 (0.213)	lr 0.0001	loss 0.102 (0.111)
Train: [49][370/589]	BT 0.357 (0.573)	DT 0.000 (0.213)	lr 0.0001	loss 0.101 (0.111)
Train: [49][380/589]	BT 0.359 (0.574)	DT 0.000 (0.214)	lr 0.0001	loss 0.100 (0.111)
Train: [49][390/589]	BT 0.357 (0.575)	DT 0.000 (0.215)	lr 0.0001	loss 0.107 (0.111)
Train: [49][400/589]	BT 0.359 (0.573)	DT 0.000 (0.213)	lr 0.0001	loss 0.114 (0.111)
Train: [49][410/589]	BT 0.360 (0.572)	DT 0.000 (0.212)	lr 0.0001	loss 0.107 (0.111)
Train: [49][420/589]	BT 0.358 (0.570)	DT 0.000 (0.210)	lr 0.0001	loss 0.120 (0.111)
Train: [49][430/589]	BT 0.379 (0.567)	DT 0.000 (0.207)	lr 0.0001	loss 0.103 (0.112)
Train: [49][440/589]	BT 0.358 (0.564)	DT 0.000 (0.205)	lr 0.0001	loss 0.107 (0.112)
Train: [49][450/589]	BT 0.360 (0.566)	DT 0.000 (0.207)	lr 0.0001	loss 0.124 (0.111)
Train: [49][460/589]	BT 0.357 (0.581)	DT 0.000 (0.221)	lr 0.0001	loss 0.095 (0.111)
Train: [49][470/589]	BT 0.358 (0.579)	DT 0.000 (0.219)	lr 0.0001	loss 0.127 (0.112)
Train: [49][480/589]	BT 0.358 (0.576)	DT 0.000 (0.216)	lr 0.0001	loss 0.109 (0.112)
Train: [49][490/589]	BT 0.359 (0.575)	DT 0.000 (0.215)	lr 0.0001	loss 0.114 (0.112)
Train: [49][500/589]	BT 0.359 (0.573)	DT 0.000 (0.214)	lr 0.0001	loss 0.115 (0.111)
Train: [49][510/589]	BT 0.357 (0.574)	DT 0.000 (0.214)	lr 0.0001	loss 0.114 (0.111)
Train: [49][520/589]	BT 0.358 (0.572)	DT 0.000 (0.212)	lr 0.0001	loss 0.109 (0.111)
Train: [49][530/589]	BT 0.357 (0.571)	DT 0.000 (0.211)	lr 0.0001	loss 0.111 (0.111)
Train: [49][540/589]	BT 0.356 (0.572)	DT 0.000 (0.212)	lr 0.0001	loss 0.098 (0.111)
Train: [49][550/589]	BT 0.357 (0.571)	DT 0.000 (0.211)	lr 0.0001	loss 0.101 (0.111)
Train: [49][560/589]	BT 0.358 (0.574)	DT 0.000 (0.214)	lr 0.0001	loss 0.098 (0.111)
Train: [49][570/589]	BT 0.357 (0.575)	DT 0.000 (0.215)	lr 0.0001	loss 0.106 (0.111)
Train: [49][580/589]	BT 0.357 (0.577)	DT 0.000 (0.217)	lr 0.0001	loss 0.108 (0.111)
epoch 49, total time 340.54
loss: 0.11110229103560658@Epoch: 49
learning_rate: 0.0001,49
Valid: [49][10/88]	BT 0.110 (0.795)	DT 0.000 (0.686)	loss 0.129 (0.139)
Valid: [49][20/88]	BT 0.109 (0.608)	DT 0.000 (0.499)	loss 0.162 (0.147)
Valid: [49][30/88]	BT 0.110 (0.531)	DT 0.000 (0.422)	loss 0.159 (0.147)
Valid: [49][40/88]	BT 0.125 (0.550)	DT 0.000 (0.440)	loss 0.171 (0.145)
Valid: [49][50/88]	BT 0.110 (0.505)	DT 0.000 (0.395)	loss 0.162 (0.144)
Valid: [49][60/88]	BT 0.133 (0.502)	DT 0.000 (0.391)	loss 0.136 (0.145)
Valid: [49][70/88]	BT 0.110 (0.483)	DT 0.000 (0.372)	loss 0.133 (0.146)
Valid: [49][80/88]	BT 0.111 (0.472)	DT 0.000 (0.362)	loss 0.115 (0.146)
Train: [50][10/589]	BT 0.362 (0.742)	DT 0.004 (0.384)	lr 0.0001	loss 0.117 (0.114)
Train: [50][20/589]	BT 0.397 (0.642)	DT 0.000 (0.282)	lr 0.0001	loss 0.102 (0.112)
Train: [50][30/589]	BT 0.359 (0.547)	DT 0.000 (0.188)	lr 0.0001	loss 0.113 (0.109)
Train: [50][40/589]	BT 0.389 (0.502)	DT 0.000 (0.141)	lr 0.0001	loss 0.108 (0.107)
Train: [50][50/589]	BT 0.358 (0.475)	DT 0.000 (0.113)	lr 0.0001	loss 0.115 (0.108)
Train: [50][60/589]	BT 0.357 (0.457)	DT 0.000 (0.094)	lr 0.0001	loss 0.100 (0.108)
Train: [50][70/589]	BT 0.357 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.113 (0.109)
Train: [50][80/589]	BT 0.358 (0.433)	DT 0.000 (0.071)	lr 0.0001	loss 0.086 (0.109)
Train: [50][90/589]	BT 0.359 (0.425)	DT 0.000 (0.063)	lr 0.0001	loss 0.096 (0.108)
Train: [50][100/589]	BT 0.357 (0.418)	DT 0.000 (0.057)	lr 0.0001	loss 0.108 (0.108)
Train: [50][110/589]	BT 0.359 (0.415)	DT 0.000 (0.053)	lr 0.0001	loss 0.113 (0.108)
Train: [50][120/589]	BT 0.371 (0.411)	DT 0.000 (0.049)	lr 0.0001	loss 0.093 (0.108)
Train: [50][130/589]	BT 0.360 (0.411)	DT 0.000 (0.049)	lr 0.0001	loss 0.100 (0.108)
Train: [50][140/589]	BT 0.358 (0.408)	DT 0.000 (0.046)	lr 0.0001	loss 0.106 (0.108)
Train: [50][150/589]	BT 0.545 (0.406)	DT 0.184 (0.044)	lr 0.0001	loss 0.132 (0.109)
Train: [50][160/589]	BT 0.358 (0.407)	DT 0.000 (0.046)	lr 0.0001	loss 0.105 (0.109)
Train: [50][170/589]	BT 0.370 (0.405)	DT 0.000 (0.043)	lr 0.0001	loss 0.103 (0.108)
Train: [50][180/589]	BT 0.360 (0.402)	DT 0.000 (0.041)	lr 0.0001	loss 0.125 (0.109)
Train: [50][190/589]	BT 1.208 (0.405)	DT 0.848 (0.043)	lr 0.0001	loss 0.113 (0.108)
Train: [50][200/589]	BT 0.359 (0.405)	DT 0.000 (0.043)	lr 0.0001	loss 0.106 (0.108)
Train: [50][210/589]	BT 0.360 (0.403)	DT 0.000 (0.042)	lr 0.0001	loss 0.134 (0.108)
Train: [50][220/589]	BT 0.360 (0.401)	DT 0.000 (0.040)	lr 0.0001	loss 0.103 (0.109)
Train: [50][230/589]	BT 0.359 (0.400)	DT 0.000 (0.038)	lr 0.0001	loss 0.105 (0.109)
Train: [50][240/589]	BT 0.360 (0.402)	DT 0.000 (0.041)	lr 0.0001	loss 0.119 (0.108)
Train: [50][250/589]	BT 0.358 (0.404)	DT 0.000 (0.042)	lr 0.0001	loss 0.120 (0.108)
Train: [50][260/589]	BT 0.366 (0.402)	DT 0.000 (0.040)	lr 0.0001	loss 0.113 (0.108)
Train: [50][270/589]	BT 0.359 (0.404)	DT 0.000 (0.042)	lr 0.0001	loss 0.107 (0.108)
Train: [50][280/589]	BT 0.358 (0.417)	DT 0.000 (0.055)	lr 0.0001	loss 0.104 (0.109)
Train: [50][290/589]	BT 0.360 (0.417)	DT 0.000 (0.055)	lr 0.0001	loss 0.096 (0.109)
Train: [50][300/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0001	loss 0.127 (0.109)
Train: [50][310/589]	BT 0.400 (0.414)	DT 0.000 (0.052)	lr 0.0001	loss 0.106 (0.109)
Train: [50][320/589]	BT 0.359 (0.412)	DT 0.000 (0.051)	lr 0.0001	loss 0.117 (0.109)
Train: [50][330/589]	BT 0.388 (0.412)	DT 0.000 (0.050)	lr 0.0001	loss 0.103 (0.109)
Train: [50][340/589]	BT 0.359 (0.414)	DT 0.000 (0.052)	lr 0.0001	loss 0.126 (0.109)
Train: [50][350/589]	BT 0.358 (0.414)	DT 0.000 (0.052)	lr 0.0001	loss 0.115 (0.109)
Train: [50][360/589]	BT 0.357 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.104 (0.109)
Train: [50][370/589]	BT 0.400 (0.425)	DT 0.000 (0.063)	lr 0.0001	loss 0.116 (0.109)
Train: [50][380/589]	BT 0.360 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.108 (0.109)
Train: [50][390/589]	BT 0.365 (0.422)	DT 0.000 (0.060)	lr 0.0001	loss 0.106 (0.109)
Train: [50][400/589]	BT 0.389 (0.421)	DT 0.000 (0.059)	lr 0.0001	loss 0.130 (0.109)
Train: [50][410/589]	BT 0.359 (0.420)	DT 0.000 (0.058)	lr 0.0001	loss 0.132 (0.109)
Train: [50][420/589]	BT 0.359 (0.418)	DT 0.000 (0.056)	lr 0.0001	loss 0.117 (0.109)
Train: [50][430/589]	BT 0.393 (0.417)	DT 0.000 (0.055)	lr 0.0001	loss 0.108 (0.109)
Train: [50][440/589]	BT 0.362 (0.416)	DT 0.000 (0.054)	lr 0.0001	loss 0.105 (0.109)
Train: [50][450/589]	BT 0.359 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.113 (0.109)
Train: [50][460/589]	BT 0.359 (0.425)	DT 0.000 (0.063)	lr 0.0001	loss 0.105 (0.109)
Train: [50][470/589]	BT 0.358 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.085 (0.109)
Train: [50][480/589]	BT 0.366 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.118 (0.109)
Train: [50][490/589]	BT 0.359 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.121 (0.109)
Train: [50][500/589]	BT 0.358 (0.425)	DT 0.000 (0.063)	lr 0.0001	loss 0.121 (0.109)
Train: [50][510/589]	BT 0.361 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.120 (0.109)
Train: [50][520/589]	BT 0.360 (0.423)	DT 0.000 (0.060)	lr 0.0001	loss 0.105 (0.109)
Train: [50][530/589]	BT 0.358 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.116 (0.109)
Train: [50][540/589]	BT 0.360 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.125 (0.110)
Train: [50][550/589]	BT 0.358 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.121 (0.109)
Train: [50][560/589]	BT 0.359 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.105 (0.109)
Train: [50][570/589]	BT 0.357 (0.426)	DT 0.000 (0.063)	lr 0.0001	loss 0.154 (0.110)
Train: [50][580/589]	BT 0.360 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.108 (0.110)
epoch 50, total time 251.31
loss: 0.10969343348713927@Epoch: 50
learning_rate: 0.0001,50
Valid: [50][10/88]	BT 0.110 (0.626)	DT 0.000 (0.510)	loss 0.119 (0.144)
Valid: [50][20/88]	BT 0.110 (0.591)	DT 0.000 (0.477)	loss 0.140 (0.143)
Valid: [50][30/88]	BT 0.109 (0.576)	DT 0.000 (0.463)	loss 0.138 (0.144)
Valid: [50][40/88]	BT 0.109 (0.573)	DT 0.000 (0.461)	loss 0.141 (0.146)
Valid: [50][50/88]	BT 0.110 (0.544)	DT 0.000 (0.432)	loss 0.111 (0.146)
Valid: [50][60/88]	BT 0.110 (0.523)	DT 0.000 (0.411)	loss 0.137 (0.144)
Valid: [50][70/88]	BT 0.109 (0.519)	DT 0.000 (0.408)	loss 0.152 (0.145)
Valid: [50][80/88]	BT 0.109 (0.511)	DT 0.000 (0.400)	loss 0.151 (0.146)
Train: [51][10/589]	BT 0.358 (0.861)	DT 0.000 (0.502)	lr 0.0001	loss 0.092 (0.109)
Train: [51][20/589]	BT 0.357 (0.679)	DT 0.000 (0.321)	lr 0.0001	loss 0.098 (0.108)
Train: [51][30/589]	BT 0.391 (0.693)	DT 0.000 (0.334)	lr 0.0001	loss 0.119 (0.107)
Train: [51][40/589]	BT 0.357 (0.647)	DT 0.000 (0.287)	lr 0.0001	loss 0.103 (0.109)
Train: [51][50/589]	BT 0.358 (0.598)	DT 0.000 (0.239)	lr 0.0001	loss 0.107 (0.109)
Train: [51][60/589]	BT 0.358 (0.558)	DT 0.000 (0.199)	lr 0.0001	loss 0.088 (0.108)
Train: [51][70/589]	BT 0.358 (0.532)	DT 0.000 (0.173)	lr 0.0001	loss 0.118 (0.109)
Train: [51][80/589]	BT 0.359 (0.517)	DT 0.000 (0.158)	lr 0.0001	loss 0.081 (0.108)
Train: [51][90/589]	BT 0.359 (0.508)	DT 0.000 (0.149)	lr 0.0001	loss 0.105 (0.108)
Train: [51][100/589]	BT 0.357 (0.500)	DT 0.000 (0.141)	lr 0.0001	loss 0.097 (0.107)
Train: [51][110/589]	BT 0.358 (0.544)	DT 0.000 (0.185)	lr 0.0001	loss 0.126 (0.107)
Train: [51][120/589]	BT 0.359 (0.572)	DT 0.000 (0.213)	lr 0.0001	loss 0.138 (0.108)
Train: [51][130/589]	BT 0.358 (0.560)	DT 0.000 (0.200)	lr 0.0001	loss 0.120 (0.108)
Train: [51][140/589]	BT 0.394 (0.553)	DT 0.000 (0.193)	lr 0.0001	loss 0.087 (0.107)
Train: [51][150/589]	BT 0.358 (0.543)	DT 0.000 (0.183)	lr 0.0001	loss 0.108 (0.107)
Train: [51][160/589]	BT 0.361 (0.537)	DT 0.000 (0.178)	lr 0.0001	loss 0.099 (0.107)
Train: [51][170/589]	BT 0.396 (0.554)	DT 0.000 (0.194)	lr 0.0001	loss 0.097 (0.107)
Train: [51][180/589]	BT 0.392 (0.558)	DT 0.000 (0.199)	lr 0.0001	loss 0.129 (0.107)
Train: [51][190/589]	BT 0.357 (0.580)	DT 0.000 (0.221)	lr 0.0001	loss 0.111 (0.107)
Train: [51][200/589]	BT 0.355 (0.580)	DT 0.000 (0.220)	lr 0.0001	loss 0.113 (0.107)
Train: [51][210/589]	BT 0.359 (0.576)	DT 0.000 (0.217)	lr 0.0001	loss 0.099 (0.107)
Train: [51][220/589]	BT 0.357 (0.589)	DT 0.000 (0.229)	lr 0.0001	loss 0.123 (0.107)
Train: [51][230/589]	BT 0.358 (0.587)	DT 0.000 (0.227)	lr 0.0001	loss 0.110 (0.107)
Train: [51][240/589]	BT 0.366 (0.598)	DT 0.000 (0.238)	lr 0.0001	loss 0.098 (0.107)
Train: [51][250/589]	BT 0.356 (0.597)	DT 0.000 (0.237)	lr 0.0001	loss 0.109 (0.107)
Train: [51][260/589]	BT 0.357 (0.595)	DT 0.000 (0.235)	lr 0.0001	loss 0.098 (0.107)
Train: [51][270/589]	BT 0.357 (0.597)	DT 0.000 (0.237)	lr 0.0001	loss 0.119 (0.107)
Train: [51][280/589]	BT 0.372 (0.601)	DT 0.000 (0.241)	lr 0.0001	loss 0.102 (0.107)
Train: [51][290/589]	BT 0.357 (0.602)	DT 0.000 (0.242)	lr 0.0001	loss 0.104 (0.108)
Train: [51][300/589]	BT 0.357 (0.609)	DT 0.000 (0.249)	lr 0.0001	loss 0.109 (0.108)
Train: [51][310/589]	BT 0.358 (0.610)	DT 0.000 (0.250)	lr 0.0001	loss 0.110 (0.108)
Train: [51][320/589]	BT 0.358 (0.608)	DT 0.000 (0.248)	lr 0.0001	loss 0.096 (0.108)
Train: [51][330/589]	BT 0.384 (0.610)	DT 0.000 (0.250)	lr 0.0001	loss 0.086 (0.108)
Train: [51][340/589]	BT 0.356 (0.616)	DT 0.000 (0.256)	lr 0.0001	loss 0.100 (0.108)
Train: [51][350/589]	BT 0.377 (0.620)	DT 0.000 (0.260)	lr 0.0001	loss 0.122 (0.108)
Train: [51][360/589]	BT 0.358 (0.621)	DT 0.000 (0.261)	lr 0.0001	loss 0.116 (0.108)
Train: [51][370/589]	BT 0.357 (0.622)	DT 0.000 (0.262)	lr 0.0001	loss 0.105 (0.108)
Train: [51][380/589]	BT 0.357 (0.628)	DT 0.000 (0.268)	lr 0.0001	loss 0.094 (0.108)
Train: [51][390/589]	BT 0.358 (0.633)	DT 0.000 (0.274)	lr 0.0001	loss 0.100 (0.108)
Train: [51][400/589]	BT 0.396 (0.638)	DT 0.000 (0.278)	lr 0.0001	loss 0.102 (0.108)
Train: [51][410/589]	BT 0.357 (0.639)	DT 0.000 (0.279)	lr 0.0001	loss 0.097 (0.108)
Train: [51][420/589]	BT 0.359 (0.639)	DT 0.000 (0.279)	lr 0.0001	loss 0.123 (0.108)
Train: [51][430/589]	BT 0.357 (0.644)	DT 0.000 (0.285)	lr 0.0001	loss 0.102 (0.108)
Train: [51][440/589]	BT 0.387 (0.651)	DT 0.000 (0.291)	lr 0.0001	loss 0.091 (0.108)
Train: [51][450/589]	BT 0.356 (0.650)	DT 0.000 (0.290)	lr 0.0001	loss 0.110 (0.108)
Train: [51][460/589]	BT 0.357 (0.650)	DT 0.000 (0.291)	lr 0.0001	loss 0.116 (0.108)
Train: [51][470/589]	BT 0.358 (0.650)	DT 0.000 (0.290)	lr 0.0001	loss 0.104 (0.108)
Train: [51][480/589]	BT 0.358 (0.656)	DT 0.000 (0.296)	lr 0.0001	loss 0.102 (0.108)
Train: [51][490/589]	BT 0.650 (0.660)	DT 0.292 (0.301)	lr 0.0001	loss 0.093 (0.108)
Train: [51][500/589]	BT 0.443 (0.661)	DT 0.068 (0.301)	lr 0.0001	loss 0.116 (0.108)
Train: [51][510/589]	BT 0.359 (0.662)	DT 0.000 (0.302)	lr 0.0001	loss 0.112 (0.108)
Train: [51][520/589]	BT 0.358 (0.664)	DT 0.000 (0.304)	lr 0.0001	loss 0.127 (0.108)
Train: [51][530/589]	BT 1.159 (0.667)	DT 0.805 (0.308)	lr 0.0001	loss 0.095 (0.108)
Train: [51][540/589]	BT 1.087 (0.672)	DT 0.729 (0.313)	lr 0.0001	loss 0.111 (0.108)
Train: [51][550/589]	BT 3.188 (0.675)	DT 2.827 (0.316)	lr 0.0001	loss 0.119 (0.108)
Train: [51][560/589]	BT 2.438 (0.675)	DT 2.079 (0.316)	lr 0.0001	loss 0.116 (0.108)
Train: [51][570/589]	BT 2.933 (0.677)	DT 2.574 (0.318)	lr 0.0001	loss 0.111 (0.108)
Train: [51][580/589]	BT 0.683 (0.677)	DT 0.327 (0.317)	lr 0.0001	loss 0.118 (0.108)
epoch 51, total time 400.49
loss: 0.10825186452466463@Epoch: 51
learning_rate: 0.0001,51
Valid: [51][10/88]	BT 0.110 (0.894)	DT 0.000 (0.785)	loss 0.163 (0.154)
Valid: [51][20/88]	BT 0.109 (0.847)	DT 0.000 (0.737)	loss 0.143 (0.151)
Valid: [51][30/88]	BT 0.109 (0.909)	DT 0.000 (0.799)	loss 0.131 (0.153)
Valid: [51][40/88]	BT 0.109 (0.947)	DT 0.000 (0.836)	loss 0.138 (0.149)
Valid: [51][50/88]	BT 0.109 (0.929)	DT 0.000 (0.819)	loss 0.162 (0.148)
Valid: [51][60/88]	BT 0.110 (0.913)	DT 0.000 (0.803)	loss 0.163 (0.150)
Valid: [51][70/88]	BT 0.109 (0.920)	DT 0.000 (0.809)	loss 0.193 (0.151)
Valid: [51][80/88]	BT 0.110 (0.904)	DT 0.000 (0.793)	loss 0.150 (0.151)
Train: [52][10/589]	BT 0.358 (1.216)	DT 0.000 (0.859)	lr 0.0001	loss 0.106 (0.102)
Train: [52][20/589]	BT 0.357 (0.854)	DT 0.000 (0.497)	lr 0.0001	loss 0.108 (0.105)
Train: [52][30/589]	BT 0.360 (0.871)	DT 0.000 (0.514)	lr 0.0001	loss 0.093 (0.106)
Train: [52][40/589]	BT 0.395 (0.780)	DT 0.000 (0.422)	lr 0.0001	loss 0.099 (0.105)
Train: [52][50/589]	BT 0.362 (0.716)	DT 0.000 (0.358)	lr 0.0001	loss 0.115 (0.106)
Train: [52][60/589]	BT 0.356 (0.694)	DT 0.000 (0.336)	lr 0.0001	loss 0.102 (0.105)
Train: [52][70/589]	BT 0.358 (0.713)	DT 0.000 (0.354)	lr 0.0001	loss 0.106 (0.105)
Train: [52][80/589]	BT 0.358 (0.688)	DT 0.000 (0.330)	lr 0.0001	loss 0.096 (0.105)
Train: [52][90/589]	BT 0.357 (0.677)	DT 0.000 (0.318)	lr 0.0001	loss 0.124 (0.105)
Train: [52][100/589]	BT 0.358 (0.687)	DT 0.000 (0.329)	lr 0.0001	loss 0.119 (0.105)
Train: [52][110/589]	BT 0.358 (0.667)	DT 0.000 (0.308)	lr 0.0001	loss 0.111 (0.105)
Train: [52][120/589]	BT 0.374 (0.648)	DT 0.000 (0.290)	lr 0.0001	loss 0.105 (0.105)
Train: [52][130/589]	BT 0.360 (0.642)	DT 0.000 (0.283)	lr 0.0001	loss 0.130 (0.105)
Train: [52][140/589]	BT 0.358 (0.664)	DT 0.000 (0.306)	lr 0.0001	loss 0.104 (0.105)
Train: [52][150/589]	BT 0.356 (0.655)	DT 0.000 (0.295)	lr 0.0001	loss 0.099 (0.106)
Train: [52][160/589]	BT 0.358 (0.644)	DT 0.000 (0.284)	lr 0.0001	loss 0.091 (0.106)
Train: [52][170/589]	BT 0.357 (0.658)	DT 0.000 (0.299)	lr 0.0001	loss 0.107 (0.106)
Train: [52][180/589]	BT 0.359 (0.644)	DT 0.000 (0.285)	lr 0.0001	loss 0.098 (0.106)
Train: [52][190/589]	BT 0.359 (0.645)	DT 0.000 (0.286)	lr 0.0001	loss 0.092 (0.107)
Train: [52][200/589]	BT 0.390 (0.637)	DT 0.000 (0.277)	lr 0.0001	loss 0.133 (0.107)
Train: [52][210/589]	BT 0.362 (0.630)	DT 0.000 (0.271)	lr 0.0001	loss 0.111 (0.107)
Train: [52][220/589]	BT 0.358 (0.623)	DT 0.000 (0.264)	lr 0.0001	loss 0.109 (0.107)
Train: [52][230/589]	BT 0.357 (0.620)	DT 0.000 (0.261)	lr 0.0001	loss 0.111 (0.107)
Train: [52][240/589]	BT 0.357 (0.610)	DT 0.000 (0.251)	lr 0.0001	loss 0.109 (0.107)
Train: [52][250/589]	BT 0.359 (0.602)	DT 0.000 (0.243)	lr 0.0001	loss 0.118 (0.107)
Train: [52][260/589]	BT 0.358 (0.598)	DT 0.000 (0.239)	lr 0.0001	loss 0.126 (0.107)
Train: [52][270/589]	BT 0.358 (0.593)	DT 0.000 (0.233)	lr 0.0001	loss 0.096 (0.107)
Train: [52][280/589]	BT 0.359 (0.586)	DT 0.000 (0.227)	lr 0.0001	loss 0.103 (0.107)
Train: [52][290/589]	BT 0.360 (0.581)	DT 0.000 (0.221)	lr 0.0001	loss 0.100 (0.107)
Train: [52][300/589]	BT 0.360 (0.579)	DT 0.000 (0.219)	lr 0.0001	loss 0.111 (0.107)
Train: [52][310/589]	BT 0.358 (0.576)	DT 0.000 (0.216)	lr 0.0001	loss 0.116 (0.107)
Train: [52][320/589]	BT 0.358 (0.570)	DT 0.000 (0.210)	lr 0.0001	loss 0.098 (0.107)
Train: [52][330/589]	BT 0.358 (0.566)	DT 0.000 (0.206)	lr 0.0001	loss 0.103 (0.107)
Train: [52][340/589]	BT 0.358 (0.566)	DT 0.000 (0.206)	lr 0.0001	loss 0.114 (0.107)
Train: [52][350/589]	BT 0.356 (0.564)	DT 0.000 (0.204)	lr 0.0001	loss 0.098 (0.107)
Train: [52][360/589]	BT 0.374 (0.563)	DT 0.000 (0.202)	lr 0.0001	loss 0.095 (0.107)
Train: [52][370/589]	BT 0.370 (0.557)	DT 0.000 (0.197)	lr 0.0001	loss 0.105 (0.107)
Train: [52][380/589]	BT 0.359 (0.555)	DT 0.000 (0.194)	lr 0.0001	loss 0.132 (0.107)
Train: [52][390/589]	BT 0.359 (0.551)	DT 0.000 (0.191)	lr 0.0001	loss 0.099 (0.107)
Train: [52][400/589]	BT 0.356 (0.549)	DT 0.000 (0.188)	lr 0.0001	loss 0.117 (0.107)
Train: [52][410/589]	BT 0.362 (0.547)	DT 0.000 (0.186)	lr 0.0001	loss 0.104 (0.107)
Train: [52][420/589]	BT 0.358 (0.545)	DT 0.000 (0.184)	lr 0.0001	loss 0.089 (0.107)
Train: [52][430/589]	BT 0.358 (0.542)	DT 0.000 (0.182)	lr 0.0001	loss 0.119 (0.107)
Train: [52][440/589]	BT 0.359 (0.542)	DT 0.000 (0.182)	lr 0.0001	loss 0.124 (0.107)
Train: [52][450/589]	BT 0.359 (0.541)	DT 0.000 (0.181)	lr 0.0001	loss 0.107 (0.107)
Train: [52][460/589]	BT 0.358 (0.538)	DT 0.000 (0.178)	lr 0.0001	loss 0.130 (0.107)
Train: [52][470/589]	BT 0.357 (0.537)	DT 0.000 (0.177)	lr 0.0001	loss 0.100 (0.107)
Train: [52][480/589]	BT 0.358 (0.535)	DT 0.000 (0.175)	lr 0.0001	loss 0.107 (0.107)
Train: [52][490/589]	BT 0.359 (0.533)	DT 0.000 (0.173)	lr 0.0001	loss 0.116 (0.107)
Train: [52][500/589]	BT 0.363 (0.532)	DT 0.000 (0.171)	lr 0.0001	loss 0.112 (0.107)
Train: [52][510/589]	BT 0.359 (0.529)	DT 0.000 (0.169)	lr 0.0001	loss 0.126 (0.107)
Train: [52][520/589]	BT 0.369 (0.527)	DT 0.000 (0.167)	lr 0.0001	loss 0.113 (0.107)
Train: [52][530/589]	BT 0.360 (0.525)	DT 0.000 (0.165)	lr 0.0001	loss 0.122 (0.107)
Train: [52][540/589]	BT 0.358 (0.523)	DT 0.000 (0.163)	lr 0.0001	loss 0.105 (0.107)
Train: [52][550/589]	BT 0.361 (0.523)	DT 0.000 (0.163)	lr 0.0001	loss 0.101 (0.108)
Train: [52][560/589]	BT 0.358 (0.522)	DT 0.000 (0.162)	lr 0.0001	loss 0.107 (0.107)
Train: [52][570/589]	BT 0.383 (0.521)	DT 0.000 (0.161)	lr 0.0001	loss 0.133 (0.107)
Train: [52][580/589]	BT 0.359 (0.519)	DT 0.000 (0.159)	lr 0.0001	loss 0.116 (0.107)
epoch 52, total time 305.88
loss: 0.10748108618384034@Epoch: 52
learning_rate: 0.0001,52
Valid: [52][10/88]	BT 0.110 (0.608)	DT 0.000 (0.497)	loss 0.161 (0.152)
Valid: [52][20/88]	BT 0.110 (0.526)	DT 0.000 (0.415)	loss 0.137 (0.150)
Valid: [52][30/88]	BT 0.110 (0.471)	DT 0.000 (0.359)	loss 0.150 (0.148)
Valid: [52][40/88]	BT 0.109 (0.458)	DT 0.000 (0.347)	loss 0.152 (0.147)
Valid: [52][50/88]	BT 0.109 (0.459)	DT 0.000 (0.348)	loss 0.147 (0.148)
Valid: [52][60/88]	BT 0.111 (0.459)	DT 0.000 (0.348)	loss 0.137 (0.148)
Valid: [52][70/88]	BT 0.110 (0.450)	DT 0.000 (0.340)	loss 0.166 (0.148)
Valid: [52][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.142 (0.147)
Train: [53][10/589]	BT 0.376 (0.791)	DT 0.000 (0.430)	lr 0.0001	loss 0.119 (0.103)
Train: [53][20/589]	BT 0.391 (0.589)	DT 0.000 (0.228)	lr 0.0001	loss 0.099 (0.103)
Train: [53][30/589]	BT 0.358 (0.512)	DT 0.000 (0.152)	lr 0.0001	loss 0.087 (0.102)
Train: [53][40/589]	BT 0.357 (0.475)	DT 0.000 (0.114)	lr 0.0001	loss 0.134 (0.103)
Train: [53][50/589]	BT 0.358 (0.452)	DT 0.000 (0.091)	lr 0.0001	loss 0.118 (0.105)
Train: [53][60/589]	BT 0.357 (0.437)	DT 0.000 (0.076)	lr 0.0001	loss 0.091 (0.104)
Train: [53][70/589]	BT 0.358 (0.426)	DT 0.000 (0.065)	lr 0.0001	loss 0.121 (0.105)
Train: [53][80/589]	BT 0.358 (0.418)	DT 0.000 (0.057)	lr 0.0001	loss 0.134 (0.106)
Train: [53][90/589]	BT 0.365 (0.411)	DT 0.000 (0.051)	lr 0.0001	loss 0.112 (0.106)
Train: [53][100/589]	BT 0.397 (0.407)	DT 0.000 (0.046)	lr 0.0001	loss 0.092 (0.105)
Train: [53][110/589]	BT 0.359 (0.408)	DT 0.000 (0.047)	lr 0.0001	loss 0.096 (0.106)
Train: [53][120/589]	BT 0.359 (0.407)	DT 0.000 (0.046)	lr 0.0001	loss 0.100 (0.106)
Train: [53][130/589]	BT 0.358 (0.404)	DT 0.000 (0.042)	lr 0.0001	loss 0.116 (0.106)
Train: [53][140/589]	BT 0.359 (0.402)	DT 0.000 (0.040)	lr 0.0001	loss 0.097 (0.105)
Train: [53][150/589]	BT 0.360 (0.399)	DT 0.000 (0.037)	lr 0.0001	loss 0.102 (0.106)
Train: [53][160/589]	BT 0.358 (0.397)	DT 0.000 (0.035)	lr 0.0001	loss 0.113 (0.106)
Train: [53][170/589]	BT 0.359 (0.395)	DT 0.000 (0.033)	lr 0.0001	loss 0.102 (0.106)
Train: [53][180/589]	BT 0.385 (0.394)	DT 0.000 (0.031)	lr 0.0001	loss 0.111 (0.106)
Train: [53][190/589]	BT 0.362 (0.392)	DT 0.000 (0.029)	lr 0.0001	loss 0.130 (0.106)
Train: [53][200/589]	BT 0.360 (0.390)	DT 0.000 (0.028)	lr 0.0001	loss 0.101 (0.106)
Train: [53][210/589]	BT 0.358 (0.389)	DT 0.000 (0.027)	lr 0.0001	loss 0.098 (0.105)
Train: [53][220/589]	BT 0.358 (0.388)	DT 0.000 (0.025)	lr 0.0001	loss 0.103 (0.105)
Train: [53][230/589]	BT 0.363 (0.387)	DT 0.000 (0.025)	lr 0.0001	loss 0.093 (0.106)
Train: [53][240/589]	BT 0.357 (0.386)	DT 0.000 (0.024)	lr 0.0001	loss 0.100 (0.106)
Train: [53][250/589]	BT 0.359 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.120 (0.106)
Train: [53][260/589]	BT 0.364 (0.384)	DT 0.000 (0.022)	lr 0.0001	loss 0.132 (0.106)
Train: [53][270/589]	BT 0.355 (0.384)	DT 0.000 (0.021)	lr 0.0001	loss 0.118 (0.107)
Train: [53][280/589]	BT 0.359 (0.383)	DT 0.000 (0.020)	lr 0.0001	loss 0.117 (0.106)
Train: [53][290/589]	BT 0.398 (0.382)	DT 0.000 (0.020)	lr 0.0001	loss 0.109 (0.107)
Train: [53][300/589]	BT 0.359 (0.382)	DT 0.000 (0.019)	lr 0.0001	loss 0.106 (0.106)
Train: [53][310/589]	BT 0.358 (0.381)	DT 0.000 (0.018)	lr 0.0001	loss 0.097 (0.106)
Train: [53][320/589]	BT 0.360 (0.380)	DT 0.000 (0.018)	lr 0.0001	loss 0.111 (0.106)
Train: [53][330/589]	BT 0.398 (0.380)	DT 0.000 (0.017)	lr 0.0001	loss 0.134 (0.107)
Train: [53][340/589]	BT 0.360 (0.380)	DT 0.000 (0.017)	lr 0.0001	loss 0.103 (0.106)
Train: [53][350/589]	BT 0.359 (0.379)	DT 0.000 (0.016)	lr 0.0001	loss 0.108 (0.106)
Train: [53][360/589]	BT 0.360 (0.379)	DT 0.000 (0.016)	lr 0.0001	loss 0.107 (0.106)
Train: [53][370/589]	BT 0.360 (0.378)	DT 0.000 (0.015)	lr 0.0001	loss 0.111 (0.106)
Train: [53][380/589]	BT 0.358 (0.378)	DT 0.000 (0.015)	lr 0.0001	loss 0.085 (0.106)
Train: [53][390/589]	BT 0.358 (0.377)	DT 0.000 (0.015)	lr 0.0001	loss 0.122 (0.106)
Train: [53][400/589]	BT 0.359 (0.377)	DT 0.000 (0.014)	lr 0.0001	loss 0.092 (0.106)
Train: [53][410/589]	BT 0.388 (0.377)	DT 0.000 (0.014)	lr 0.0001	loss 0.097 (0.106)
Train: [53][420/589]	BT 0.390 (0.376)	DT 0.000 (0.014)	lr 0.0001	loss 0.099 (0.106)
Train: [53][430/589]	BT 0.360 (0.376)	DT 0.000 (0.013)	lr 0.0001	loss 0.101 (0.106)
Train: [53][440/589]	BT 0.359 (0.376)	DT 0.000 (0.013)	lr 0.0001	loss 0.082 (0.106)
Train: [53][450/589]	BT 0.395 (0.376)	DT 0.000 (0.013)	lr 0.0001	loss 0.103 (0.106)
Train: [53][460/589]	BT 0.360 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.101 (0.106)
Train: [53][470/589]	BT 0.358 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.104 (0.106)
Train: [53][480/589]	BT 0.389 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.130 (0.106)
Train: [53][490/589]	BT 0.360 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.112 (0.106)
Train: [53][500/589]	BT 0.360 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.133 (0.106)
Train: [53][510/589]	BT 0.359 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.101 (0.107)
Train: [53][520/589]	BT 0.355 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.104 (0.107)
Train: [53][530/589]	BT 0.358 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.112 (0.107)
Train: [53][540/589]	BT 0.399 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.126 (0.107)
Train: [53][550/589]	BT 0.390 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.110 (0.107)
Train: [53][560/589]	BT 0.358 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.114 (0.107)
Train: [53][570/589]	BT 0.359 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.114 (0.106)
Train: [53][580/589]	BT 0.359 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.100 (0.106)
epoch 53, total time 219.49
loss: 0.10640184846569177@Epoch: 53
learning_rate: 0.0001,53
Valid: [53][10/88]	BT 0.110 (0.519)	DT 0.000 (0.408)	loss 0.170 (0.161)
Valid: [53][20/88]	BT 0.110 (0.405)	DT 0.000 (0.293)	loss 0.154 (0.153)
Valid: [53][30/88]	BT 0.110 (0.360)	DT 0.000 (0.249)	loss 0.136 (0.151)
Valid: [53][40/88]	BT 0.109 (0.341)	DT 0.000 (0.229)	loss 0.147 (0.152)
Valid: [53][50/88]	BT 0.110 (0.331)	DT 0.000 (0.220)	loss 0.165 (0.151)
Valid: [53][60/88]	BT 0.110 (0.322)	DT 0.000 (0.211)	loss 0.172 (0.151)
Valid: [53][70/88]	BT 0.109 (0.330)	DT 0.000 (0.219)	loss 0.127 (0.150)
Valid: [53][80/88]	BT 0.125 (0.325)	DT 0.000 (0.213)	loss 0.153 (0.151)
Train: [54][10/589]	BT 0.356 (0.743)	DT 0.000 (0.385)	lr 0.0001	loss 0.108 (0.109)
Train: [54][20/589]	BT 0.397 (0.555)	DT 0.000 (0.193)	lr 0.0001	loss 0.101 (0.104)
Train: [54][30/589]	BT 0.361 (0.491)	DT 0.000 (0.128)	lr 0.0001	loss 0.094 (0.103)
Train: [54][40/589]	BT 0.359 (0.459)	DT 0.000 (0.096)	lr 0.0001	loss 0.115 (0.103)
Train: [54][50/589]	BT 0.358 (0.440)	DT 0.000 (0.077)	lr 0.0001	loss 0.115 (0.103)
Train: [54][60/589]	BT 0.355 (0.427)	DT 0.000 (0.064)	lr 0.0001	loss 0.089 (0.103)
Train: [54][70/589]	BT 0.361 (0.417)	DT 0.000 (0.055)	lr 0.0001	loss 0.103 (0.103)
Train: [54][80/589]	BT 0.361 (0.410)	DT 0.000 (0.048)	lr 0.0001	loss 0.103 (0.104)
Train: [54][90/589]	BT 0.358 (0.404)	DT 0.000 (0.043)	lr 0.0001	loss 0.100 (0.104)
Train: [54][100/589]	BT 0.358 (0.400)	DT 0.000 (0.039)	lr 0.0001	loss 0.109 (0.104)
Train: [54][110/589]	BT 0.359 (0.397)	DT 0.000 (0.035)	lr 0.0001	loss 0.114 (0.104)
Train: [54][120/589]	BT 0.399 (0.394)	DT 0.000 (0.032)	lr 0.0001	loss 0.106 (0.104)
Train: [54][130/589]	BT 0.359 (0.391)	DT 0.000 (0.030)	lr 0.0001	loss 0.103 (0.104)
Train: [54][140/589]	BT 0.359 (0.389)	DT 0.000 (0.028)	lr 0.0001	loss 0.100 (0.104)
Train: [54][150/589]	BT 0.359 (0.387)	DT 0.000 (0.026)	lr 0.0001	loss 0.114 (0.104)
Train: [54][160/589]	BT 0.358 (0.386)	DT 0.000 (0.024)	lr 0.0001	loss 0.095 (0.104)
Train: [54][170/589]	BT 0.358 (0.391)	DT 0.000 (0.029)	lr 0.0001	loss 0.103 (0.104)
Train: [54][180/589]	BT 0.358 (0.392)	DT 0.000 (0.030)	lr 0.0001	loss 0.106 (0.105)
Train: [54][190/589]	BT 0.357 (0.393)	DT 0.000 (0.032)	lr 0.0001	loss 0.096 (0.105)
Train: [54][200/589]	BT 0.396 (0.392)	DT 0.000 (0.030)	lr 0.0001	loss 0.117 (0.105)
Train: [54][210/589]	BT 0.388 (0.390)	DT 0.000 (0.029)	lr 0.0001	loss 0.095 (0.105)
Train: [54][220/589]	BT 0.358 (0.389)	DT 0.000 (0.027)	lr 0.0001	loss 0.135 (0.105)
Train: [54][230/589]	BT 0.359 (0.388)	DT 0.000 (0.026)	lr 0.0001	loss 0.104 (0.105)
Train: [54][240/589]	BT 0.360 (0.387)	DT 0.000 (0.025)	lr 0.0001	loss 0.123 (0.105)
Train: [54][250/589]	BT 0.361 (0.386)	DT 0.000 (0.024)	lr 0.0001	loss 0.114 (0.105)
Train: [54][260/589]	BT 0.359 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.093 (0.105)
Train: [54][270/589]	BT 0.359 (0.384)	DT 0.000 (0.022)	lr 0.0001	loss 0.098 (0.105)
Train: [54][280/589]	BT 0.360 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.116 (0.105)
Train: [54][290/589]	BT 0.377 (0.384)	DT 0.000 (0.022)	lr 0.0001	loss 0.117 (0.105)
Train: [54][300/589]	BT 0.363 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.106 (0.105)
Train: [54][310/589]	BT 0.357 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.107 (0.105)
Train: [54][320/589]	BT 0.360 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.093 (0.105)
Train: [54][330/589]	BT 0.361 (0.384)	DT 0.001 (0.022)	lr 0.0001	loss 0.102 (0.105)
Train: [54][340/589]	BT 0.359 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.108 (0.105)
Train: [54][350/589]	BT 0.361 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.118 (0.105)
Train: [54][360/589]	BT 0.359 (0.384)	DT 0.000 (0.022)	lr 0.0001	loss 0.111 (0.105)
Train: [54][370/589]	BT 0.359 (0.384)	DT 0.000 (0.021)	lr 0.0001	loss 0.089 (0.105)
Train: [54][380/589]	BT 0.360 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.110 (0.105)
Train: [54][390/589]	BT 0.370 (0.382)	DT 0.000 (0.020)	lr 0.0001	loss 0.114 (0.105)
Train: [54][400/589]	BT 0.360 (0.382)	DT 0.000 (0.020)	lr 0.0001	loss 0.090 (0.105)
Train: [54][410/589]	BT 0.358 (0.381)	DT 0.000 (0.019)	lr 0.0001	loss 0.104 (0.105)
Train: [54][420/589]	BT 0.381 (0.381)	DT 0.000 (0.019)	lr 0.0001	loss 0.094 (0.105)
Train: [54][430/589]	BT 0.363 (0.381)	DT 0.000 (0.018)	lr 0.0001	loss 0.101 (0.105)
Train: [54][440/589]	BT 0.358 (0.380)	DT 0.000 (0.018)	lr 0.0001	loss 0.097 (0.105)
Train: [54][450/589]	BT 0.363 (0.380)	DT 0.000 (0.018)	lr 0.0001	loss 0.124 (0.105)
Train: [54][460/589]	BT 0.401 (0.380)	DT 0.000 (0.017)	lr 0.0001	loss 0.109 (0.105)
Train: [54][470/589]	BT 0.361 (0.379)	DT 0.000 (0.017)	lr 0.0001	loss 0.101 (0.105)
Train: [54][480/589]	BT 0.359 (0.379)	DT 0.000 (0.017)	lr 0.0001	loss 0.082 (0.105)
Train: [54][490/589]	BT 0.359 (0.379)	DT 0.000 (0.016)	lr 0.0001	loss 0.122 (0.105)
Train: [54][500/589]	BT 0.359 (0.378)	DT 0.000 (0.016)	lr 0.0001	loss 0.118 (0.105)
Train: [54][510/589]	BT 0.378 (0.378)	DT 0.000 (0.016)	lr 0.0001	loss 0.090 (0.106)
Train: [54][520/589]	BT 0.357 (0.378)	DT 0.000 (0.015)	lr 0.0001	loss 0.109 (0.106)
Train: [54][530/589]	BT 0.358 (0.377)	DT 0.000 (0.015)	lr 0.0001	loss 0.116 (0.106)
Train: [54][540/589]	BT 0.359 (0.379)	DT 0.000 (0.017)	lr 0.0001	loss 0.121 (0.106)
Train: [54][550/589]	BT 0.360 (0.382)	DT 0.000 (0.020)	lr 0.0001	loss 0.119 (0.106)
Train: [54][560/589]	BT 0.401 (0.384)	DT 0.000 (0.021)	lr 0.0001	loss 0.102 (0.106)
Train: [54][570/589]	BT 0.358 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.099 (0.106)
Train: [54][580/589]	BT 0.359 (0.390)	DT 0.000 (0.028)	lr 0.0001	loss 0.098 (0.106)
epoch 54, total time 232.47
loss: 0.10563686474863324@Epoch: 54
learning_rate: 0.0001,54
Valid: [54][10/88]	BT 0.110 (0.683)	DT 0.000 (0.574)	loss 0.157 (0.160)
Valid: [54][20/88]	BT 0.110 (0.561)	DT 0.000 (0.452)	loss 0.155 (0.156)
Valid: [54][30/88]	BT 0.109 (0.590)	DT 0.000 (0.480)	loss 0.154 (0.154)
Valid: [54][40/88]	BT 0.110 (0.564)	DT 0.000 (0.454)	loss 0.151 (0.154)
Valid: [54][50/88]	BT 0.109 (0.561)	DT 0.000 (0.451)	loss 0.162 (0.154)
Valid: [54][60/88]	BT 0.109 (0.555)	DT 0.000 (0.445)	loss 0.148 (0.151)
Valid: [54][70/88]	BT 0.109 (0.541)	DT 0.000 (0.431)	loss 0.155 (0.152)
Valid: [54][80/88]	BT 0.109 (0.533)	DT 0.000 (0.423)	loss 0.189 (0.154)
Train: [55][10/589]	BT 0.357 (0.912)	DT 0.000 (0.553)	lr 0.0001	loss 0.111 (0.108)
Train: [55][20/589]	BT 0.357 (0.681)	DT 0.000 (0.323)	lr 0.0001	loss 0.102 (0.106)
Train: [55][30/589]	BT 0.358 (0.590)	DT 0.000 (0.232)	lr 0.0001	loss 0.124 (0.108)
Train: [55][40/589]	BT 0.356 (0.551)	DT 0.000 (0.193)	lr 0.0001	loss 0.127 (0.107)
Train: [55][50/589]	BT 0.359 (0.542)	DT 0.000 (0.183)	lr 0.0001	loss 0.114 (0.106)
Train: [55][60/589]	BT 0.359 (0.525)	DT 0.000 (0.166)	lr 0.0001	loss 0.108 (0.106)
Train: [55][70/589]	BT 0.359 (0.525)	DT 0.000 (0.165)	lr 0.0001	loss 0.102 (0.105)
Train: [55][80/589]	BT 0.358 (0.516)	DT 0.000 (0.157)	lr 0.0001	loss 0.083 (0.105)
Train: [55][90/589]	BT 0.358 (0.507)	DT 0.000 (0.147)	lr 0.0001	loss 0.095 (0.105)
Train: [55][100/589]	BT 1.639 (0.510)	DT 1.279 (0.151)	lr 0.0001	loss 0.108 (0.104)
Train: [55][110/589]	BT 1.141 (0.504)	DT 0.779 (0.144)	lr 0.0001	loss 0.126 (0.105)
Train: [55][120/589]	BT 1.020 (0.498)	DT 0.642 (0.137)	lr 0.0001	loss 0.123 (0.105)
Train: [55][130/589]	BT 1.257 (0.494)	DT 0.895 (0.134)	lr 0.0001	loss 0.108 (0.105)
Train: [55][140/589]	BT 1.719 (0.494)	DT 1.356 (0.134)	lr 0.0001	loss 0.093 (0.105)
Train: [55][150/589]	BT 1.399 (0.492)	DT 1.038 (0.132)	lr 0.0001	loss 0.097 (0.105)
Train: [55][160/589]	BT 0.359 (0.484)	DT 0.000 (0.124)	lr 0.0001	loss 0.081 (0.105)
Train: [55][170/589]	BT 1.294 (0.483)	DT 0.933 (0.122)	lr 0.0001	loss 0.102 (0.105)
Train: [55][180/589]	BT 1.678 (0.486)	DT 1.318 (0.125)	lr 0.0001	loss 0.112 (0.105)
Train: [55][190/589]	BT 0.572 (0.485)	DT 0.211 (0.124)	lr 0.0001	loss 0.117 (0.104)
Train: [55][200/589]	BT 0.811 (0.491)	DT 0.448 (0.130)	lr 0.0001	loss 0.104 (0.104)
Train: [55][210/589]	BT 0.398 (0.495)	DT 0.042 (0.135)	lr 0.0001	loss 0.100 (0.104)
Train: [55][220/589]	BT 0.366 (0.493)	DT 0.000 (0.132)	lr 0.0001	loss 0.099 (0.104)
Train: [55][230/589]	BT 0.360 (0.492)	DT 0.001 (0.131)	lr 0.0001	loss 0.079 (0.104)
Train: [55][240/589]	BT 0.357 (0.488)	DT 0.000 (0.127)	lr 0.0001	loss 0.091 (0.104)
Train: [55][250/589]	BT 0.357 (0.488)	DT 0.000 (0.127)	lr 0.0001	loss 0.102 (0.104)
Train: [55][260/589]	BT 0.378 (0.490)	DT 0.000 (0.128)	lr 0.0001	loss 0.095 (0.104)
Train: [55][270/589]	BT 0.357 (0.485)	DT 0.000 (0.124)	lr 0.0001	loss 0.119 (0.104)
Train: [55][280/589]	BT 1.714 (0.486)	DT 1.355 (0.125)	lr 0.0001	loss 0.087 (0.104)
Train: [55][290/589]	BT 0.482 (0.489)	DT 0.125 (0.127)	lr 0.0001	loss 0.100 (0.104)
Train: [55][300/589]	BT 0.359 (0.487)	DT 0.000 (0.126)	lr 0.0001	loss 0.094 (0.104)
Train: [55][310/589]	BT 0.834 (0.487)	DT 0.474 (0.126)	lr 0.0001	loss 0.114 (0.104)
Train: [55][320/589]	BT 0.472 (0.485)	DT 0.112 (0.124)	lr 0.0001	loss 0.110 (0.104)
Train: [55][330/589]	BT 0.848 (0.484)	DT 0.476 (0.123)	lr 0.0001	loss 0.089 (0.104)
Train: [55][340/589]	BT 1.069 (0.483)	DT 0.712 (0.122)	lr 0.0001	loss 0.106 (0.104)
Train: [55][350/589]	BT 1.233 (0.482)	DT 0.873 (0.121)	lr 0.0001	loss 0.101 (0.104)
Train: [55][360/589]	BT 0.359 (0.478)	DT 0.000 (0.117)	lr 0.0001	loss 0.138 (0.104)
Train: [55][370/589]	BT 0.842 (0.480)	DT 0.483 (0.119)	lr 0.0001	loss 0.113 (0.104)
Train: [55][380/589]	BT 0.507 (0.478)	DT 0.147 (0.117)	lr 0.0001	loss 0.107 (0.104)
Train: [55][390/589]	BT 0.500 (0.476)	DT 0.141 (0.115)	lr 0.0001	loss 0.107 (0.104)
Train: [55][400/589]	BT 0.596 (0.473)	DT 0.234 (0.112)	lr 0.0001	loss 0.107 (0.104)
Train: [55][410/589]	BT 0.872 (0.472)	DT 0.514 (0.111)	lr 0.0001	loss 0.120 (0.104)
Train: [55][420/589]	BT 0.429 (0.469)	DT 0.069 (0.108)	lr 0.0001	loss 0.090 (0.104)
Train: [55][430/589]	BT 0.868 (0.468)	DT 0.508 (0.107)	lr 0.0001	loss 0.117 (0.104)
Train: [55][440/589]	BT 1.088 (0.468)	DT 0.729 (0.107)	lr 0.0001	loss 0.089 (0.104)
Train: [55][450/589]	BT 2.382 (0.470)	DT 2.005 (0.109)	lr 0.0001	loss 0.109 (0.104)
Train: [55][460/589]	BT 1.182 (0.469)	DT 0.822 (0.108)	lr 0.0001	loss 0.099 (0.104)
Train: [55][470/589]	BT 0.738 (0.468)	DT 0.377 (0.107)	lr 0.0001	loss 0.106 (0.104)
Train: [55][480/589]	BT 0.662 (0.466)	DT 0.303 (0.105)	lr 0.0001	loss 0.120 (0.104)
Train: [55][490/589]	BT 1.161 (0.466)	DT 0.801 (0.105)	lr 0.0001	loss 0.109 (0.104)
Train: [55][500/589]	BT 0.360 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.110 (0.104)
Train: [55][510/589]	BT 0.737 (0.463)	DT 0.375 (0.101)	lr 0.0001	loss 0.095 (0.104)
Train: [55][520/589]	BT 0.790 (0.461)	DT 0.429 (0.100)	lr 0.0001	loss 0.105 (0.104)
Train: [55][530/589]	BT 0.844 (0.460)	DT 0.487 (0.099)	lr 0.0001	loss 0.114 (0.104)
Train: [55][540/589]	BT 0.512 (0.459)	DT 0.151 (0.098)	lr 0.0001	loss 0.093 (0.104)
Train: [55][550/589]	BT 0.473 (0.458)	DT 0.113 (0.097)	lr 0.0001	loss 0.098 (0.104)
Train: [55][560/589]	BT 0.672 (0.457)	DT 0.313 (0.096)	lr 0.0001	loss 0.095 (0.104)
Train: [55][570/589]	BT 0.415 (0.456)	DT 0.059 (0.095)	lr 0.0001	loss 0.104 (0.104)
Train: [55][580/589]	BT 0.737 (0.456)	DT 0.377 (0.094)	lr 0.0001	loss 0.096 (0.104)
epoch 55, total time 268.28
loss: 0.10440136116478431@Epoch: 55
learning_rate: 0.0001,55
Valid: [55][10/88]	BT 0.110 (0.610)	DT 0.000 (0.499)	loss 0.149 (0.148)
Valid: [55][20/88]	BT 0.109 (0.488)	DT 0.000 (0.378)	loss 0.141 (0.156)
Valid: [55][30/88]	BT 0.110 (0.452)	DT 0.000 (0.342)	loss 0.137 (0.157)
Valid: [55][40/88]	BT 0.110 (0.446)	DT 0.000 (0.336)	loss 0.168 (0.160)
Valid: [55][50/88]	BT 0.110 (0.427)	DT 0.000 (0.317)	loss 0.160 (0.160)
Valid: [55][60/88]	BT 0.110 (0.409)	DT 0.000 (0.299)	loss 0.163 (0.160)
Valid: [55][70/88]	BT 0.110 (0.399)	DT 0.000 (0.290)	loss 0.178 (0.161)
Valid: [55][80/88]	BT 0.109 (0.396)	DT 0.000 (0.286)	loss 0.168 (0.161)
Train: [56][10/589]	BT 0.384 (0.723)	DT 0.000 (0.360)	lr 0.0001	loss 0.107 (0.101)
Train: [56][20/589]	BT 0.358 (0.545)	DT 0.000 (0.180)	lr 0.0001	loss 0.098 (0.100)
Train: [56][30/589]	BT 0.358 (0.486)	DT 0.000 (0.120)	lr 0.0001	loss 0.107 (0.101)
Train: [56][40/589]	BT 0.358 (0.457)	DT 0.000 (0.090)	lr 0.0001	loss 0.103 (0.101)
Train: [56][50/589]	BT 0.398 (0.438)	DT 0.000 (0.072)	lr 0.0001	loss 0.104 (0.101)
Train: [56][60/589]	BT 0.358 (0.425)	DT 0.000 (0.060)	lr 0.0001	loss 0.094 (0.102)
Train: [56][70/589]	BT 0.357 (0.415)	DT 0.000 (0.052)	lr 0.0001	loss 0.103 (0.101)
Train: [56][80/589]	BT 0.357 (0.409)	DT 0.000 (0.045)	lr 0.0001	loss 0.085 (0.101)
Train: [56][90/589]	BT 0.359 (0.404)	DT 0.000 (0.040)	lr 0.0001	loss 0.127 (0.102)
Train: [56][100/589]	BT 0.358 (0.400)	DT 0.000 (0.036)	lr 0.0001	loss 0.106 (0.102)
Train: [56][110/589]	BT 0.374 (0.397)	DT 0.000 (0.033)	lr 0.0001	loss 0.107 (0.102)
Train: [56][120/589]	BT 0.357 (0.394)	DT 0.000 (0.030)	lr 0.0001	loss 0.108 (0.102)
Train: [56][130/589]	BT 0.359 (0.392)	DT 0.000 (0.028)	lr 0.0001	loss 0.090 (0.103)
Train: [56][140/589]	BT 0.361 (0.390)	DT 0.000 (0.026)	lr 0.0001	loss 0.080 (0.103)
Train: [56][150/589]	BT 0.360 (0.388)	DT 0.000 (0.024)	lr 0.0001	loss 0.113 (0.103)
Train: [56][160/589]	BT 0.359 (0.386)	DT 0.000 (0.023)	lr 0.0001	loss 0.103 (0.103)
Train: [56][170/589]	BT 0.359 (0.385)	DT 0.000 (0.021)	lr 0.0001	loss 0.120 (0.103)
Train: [56][180/589]	BT 0.358 (0.384)	DT 0.000 (0.020)	lr 0.0001	loss 0.096 (0.103)
Train: [56][190/589]	BT 0.360 (0.383)	DT 0.000 (0.019)	lr 0.0001	loss 0.107 (0.103)
Train: [56][200/589]	BT 0.360 (0.382)	DT 0.000 (0.018)	lr 0.0001	loss 0.104 (0.103)
Train: [56][210/589]	BT 0.358 (0.381)	DT 0.000 (0.017)	lr 0.0001	loss 0.092 (0.103)
Train: [56][220/589]	BT 0.359 (0.380)	DT 0.000 (0.017)	lr 0.0001	loss 0.118 (0.103)
Train: [56][230/589]	BT 0.360 (0.379)	DT 0.000 (0.016)	lr 0.0001	loss 0.108 (0.103)
Train: [56][240/589]	BT 0.359 (0.378)	DT 0.000 (0.015)	lr 0.0001	loss 0.105 (0.104)
Train: [56][250/589]	BT 0.358 (0.378)	DT 0.000 (0.015)	lr 0.0001	loss 0.082 (0.103)
Train: [56][260/589]	BT 0.359 (0.377)	DT 0.000 (0.014)	lr 0.0001	loss 0.114 (0.103)
Train: [56][270/589]	BT 0.359 (0.377)	DT 0.000 (0.014)	lr 0.0001	loss 0.140 (0.103)
Train: [56][280/589]	BT 0.360 (0.376)	DT 0.000 (0.013)	lr 0.0001	loss 0.105 (0.103)
Train: [56][290/589]	BT 0.360 (0.375)	DT 0.000 (0.013)	lr 0.0001	loss 0.120 (0.103)
Train: [56][300/589]	BT 0.359 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.104 (0.103)
Train: [56][310/589]	BT 0.367 (0.375)	DT 0.000 (0.012)	lr 0.0001	loss 0.094 (0.103)
Train: [56][320/589]	BT 0.373 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.081 (0.104)
Train: [56][330/589]	BT 0.359 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.122 (0.104)
Train: [56][340/589]	BT 0.360 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.098 (0.104)
Train: [56][350/589]	BT 0.359 (0.374)	DT 0.000 (0.010)	lr 0.0001	loss 0.103 (0.103)
Train: [56][360/589]	BT 0.362 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.111 (0.103)
Train: [56][370/589]	BT 0.360 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.112 (0.103)
Train: [56][380/589]	BT 0.361 (0.373)	DT 0.000 (0.010)	lr 0.0001	loss 0.082 (0.103)
Train: [56][390/589]	BT 0.376 (0.372)	DT 0.000 (0.009)	lr 0.0001	loss 0.104 (0.103)
Train: [56][400/589]	BT 0.360 (0.372)	DT 0.000 (0.009)	lr 0.0001	loss 0.098 (0.103)
Train: [56][410/589]	BT 1.054 (0.377)	DT 0.694 (0.014)	lr 0.0001	loss 0.115 (0.103)
Train: [56][420/589]	BT 0.358 (0.377)	DT 0.000 (0.014)	lr 0.0001	loss 0.131 (0.103)
Train: [56][430/589]	BT 0.492 (0.378)	DT 0.108 (0.015)	lr 0.0001	loss 0.133 (0.103)
Train: [56][440/589]	BT 0.514 (0.380)	DT 0.155 (0.018)	lr 0.0001	loss 0.120 (0.103)
Train: [56][450/589]	BT 0.358 (0.380)	DT 0.000 (0.017)	lr 0.0001	loss 0.095 (0.103)
Train: [56][460/589]	BT 1.151 (0.382)	DT 0.784 (0.019)	lr 0.0001	loss 0.095 (0.103)
Train: [56][470/589]	BT 1.599 (0.384)	DT 1.239 (0.021)	lr 0.0001	loss 0.126 (0.103)
Train: [56][480/589]	BT 1.648 (0.386)	DT 1.288 (0.023)	lr 0.0001	loss 0.078 (0.103)
Train: [56][490/589]	BT 1.137 (0.387)	DT 0.775 (0.024)	lr 0.0001	loss 0.093 (0.103)
Train: [56][500/589]	BT 0.991 (0.388)	DT 0.631 (0.025)	lr 0.0001	loss 0.087 (0.103)
Train: [56][510/589]	BT 2.355 (0.391)	DT 1.994 (0.029)	lr 0.0001	loss 0.106 (0.103)
Train: [56][520/589]	BT 1.107 (0.392)	DT 0.750 (0.030)	lr 0.0001	loss 0.090 (0.103)
Train: [56][530/589]	BT 1.532 (0.394)	DT 1.167 (0.031)	lr 0.0001	loss 0.099 (0.103)
Train: [56][540/589]	BT 1.194 (0.395)	DT 0.833 (0.033)	lr 0.0001	loss 0.104 (0.103)
Train: [56][550/589]	BT 1.110 (0.397)	DT 0.750 (0.034)	lr 0.0001	loss 0.105 (0.103)
Train: [56][560/589]	BT 0.886 (0.397)	DT 0.524 (0.035)	lr 0.0001	loss 0.130 (0.103)
Train: [56][570/589]	BT 0.483 (0.397)	DT 0.123 (0.034)	lr 0.0001	loss 0.111 (0.103)
Train: [56][580/589]	BT 1.000 (0.397)	DT 0.640 (0.035)	lr 0.0001	loss 0.096 (0.103)
epoch 56, total time 233.73
loss: 0.10350969064025482@Epoch: 56
learning_rate: 0.0001,56
Valid: [56][10/88]	BT 0.109 (0.608)	DT 0.000 (0.496)	loss 0.175 (0.161)
Valid: [56][20/88]	BT 0.110 (0.491)	DT 0.000 (0.381)	loss 0.182 (0.156)
Valid: [56][30/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.179 (0.157)
Valid: [56][40/88]	BT 0.110 (0.424)	DT 0.000 (0.313)	loss 0.159 (0.156)
Valid: [56][50/88]	BT 0.110 (0.414)	DT 0.000 (0.302)	loss 0.158 (0.157)
Valid: [56][60/88]	BT 0.109 (0.403)	DT 0.000 (0.291)	loss 0.142 (0.156)
Valid: [56][70/88]	BT 0.110 (0.397)	DT 0.000 (0.285)	loss 0.173 (0.156)
Valid: [56][80/88]	BT 0.109 (0.389)	DT 0.000 (0.278)	loss 0.200 (0.156)
Train: [57][10/589]	BT 0.357 (0.800)	DT 0.000 (0.440)	lr 0.0001	loss 0.105 (0.097)
Train: [57][20/589]	BT 0.357 (0.580)	DT 0.000 (0.220)	lr 0.0001	loss 0.117 (0.099)
Train: [57][30/589]	BT 0.357 (0.506)	DT 0.000 (0.147)	lr 0.0001	loss 0.111 (0.099)
Train: [57][40/589]	BT 0.355 (0.470)	DT 0.000 (0.110)	lr 0.0001	loss 0.114 (0.102)
Train: [57][50/589]	BT 0.359 (0.448)	DT 0.000 (0.088)	lr 0.0001	loss 0.112 (0.102)
Train: [57][60/589]	BT 0.356 (0.433)	DT 0.000 (0.073)	lr 0.0001	loss 0.121 (0.103)
Train: [57][70/589]	BT 0.360 (0.425)	DT 0.000 (0.065)	lr 0.0001	loss 0.104 (0.103)
Train: [57][80/589]	BT 0.378 (0.424)	DT 0.000 (0.063)	lr 0.0001	loss 0.108 (0.103)
Train: [57][90/589]	BT 0.358 (0.424)	DT 0.000 (0.064)	lr 0.0001	loss 0.105 (0.103)
Train: [57][100/589]	BT 0.359 (0.418)	DT 0.000 (0.057)	lr 0.0001	loss 0.119 (0.103)
Train: [57][110/589]	BT 0.359 (0.413)	DT 0.000 (0.052)	lr 0.0001	loss 0.094 (0.103)
Train: [57][120/589]	BT 0.358 (0.411)	DT 0.000 (0.049)	lr 0.0001	loss 0.114 (0.103)
Train: [57][130/589]	BT 0.359 (0.412)	DT 0.000 (0.051)	lr 0.0001	loss 0.121 (0.103)
Train: [57][140/589]	BT 0.358 (0.409)	DT 0.000 (0.048)	lr 0.0001	loss 0.098 (0.103)
Train: [57][150/589]	BT 0.359 (0.413)	DT 0.000 (0.052)	lr 0.0001	loss 0.117 (0.103)
Train: [57][160/589]	BT 0.359 (0.415)	DT 0.000 (0.054)	lr 0.0001	loss 0.098 (0.103)
Train: [57][170/589]	BT 0.360 (0.419)	DT 0.000 (0.057)	lr 0.0001	loss 0.108 (0.103)
Train: [57][180/589]	BT 0.363 (0.420)	DT 0.000 (0.059)	lr 0.0001	loss 0.098 (0.103)
Train: [57][190/589]	BT 0.359 (0.419)	DT 0.000 (0.058)	lr 0.0001	loss 0.095 (0.103)
Train: [57][200/589]	BT 0.359 (0.418)	DT 0.000 (0.057)	lr 0.0001	loss 0.087 (0.102)
Train: [57][210/589]	BT 0.358 (0.417)	DT 0.000 (0.056)	lr 0.0001	loss 0.089 (0.102)
Train: [57][220/589]	BT 0.359 (0.419)	DT 0.000 (0.058)	lr 0.0001	loss 0.111 (0.102)
Train: [57][230/589]	BT 0.359 (0.431)	DT 0.000 (0.070)	lr 0.0001	loss 0.097 (0.102)
Train: [57][240/589]	BT 0.359 (0.433)	DT 0.000 (0.073)	lr 0.0001	loss 0.084 (0.102)
Train: [57][250/589]	BT 0.358 (0.437)	DT 0.000 (0.077)	lr 0.0001	loss 0.101 (0.102)
Train: [57][260/589]	BT 0.358 (0.438)	DT 0.000 (0.078)	lr 0.0001	loss 0.097 (0.102)
Train: [57][270/589]	BT 0.359 (0.437)	DT 0.000 (0.076)	lr 0.0001	loss 0.124 (0.102)
Train: [57][280/589]	BT 0.359 (0.436)	DT 0.000 (0.076)	lr 0.0001	loss 0.085 (0.102)
Train: [57][290/589]	BT 0.359 (0.435)	DT 0.000 (0.074)	lr 0.0001	loss 0.112 (0.102)
Train: [57][300/589]	BT 0.357 (0.433)	DT 0.000 (0.072)	lr 0.0001	loss 0.101 (0.102)
Train: [57][310/589]	BT 0.356 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.110 (0.102)
Train: [57][320/589]	BT 0.358 (0.441)	DT 0.000 (0.080)	lr 0.0001	loss 0.124 (0.102)
Train: [57][330/589]	BT 0.359 (0.441)	DT 0.000 (0.080)	lr 0.0001	loss 0.087 (0.102)
Train: [57][340/589]	BT 0.357 (0.445)	DT 0.000 (0.085)	lr 0.0001	loss 0.088 (0.102)
Train: [57][350/589]	BT 0.358 (0.447)	DT 0.000 (0.087)	lr 0.0001	loss 0.097 (0.102)
Train: [57][360/589]	BT 0.360 (0.449)	DT 0.000 (0.088)	lr 0.0001	loss 0.093 (0.102)
Train: [57][370/589]	BT 0.358 (0.454)	DT 0.000 (0.093)	lr 0.0001	loss 0.102 (0.102)
Train: [57][380/589]	BT 0.360 (0.454)	DT 0.000 (0.094)	lr 0.0001	loss 0.105 (0.102)
Train: [57][390/589]	BT 0.359 (0.456)	DT 0.000 (0.095)	lr 0.0001	loss 0.112 (0.102)
Train: [57][400/589]	BT 0.359 (0.457)	DT 0.000 (0.097)	lr 0.0001	loss 0.108 (0.102)
Train: [57][410/589]	BT 0.357 (0.458)	DT 0.000 (0.098)	lr 0.0001	loss 0.100 (0.102)
Train: [57][420/589]	BT 0.356 (0.458)	DT 0.000 (0.098)	lr 0.0001	loss 0.097 (0.102)
Train: [57][430/589]	BT 0.358 (0.460)	DT 0.000 (0.100)	lr 0.0001	loss 0.098 (0.102)
Train: [57][440/589]	BT 0.358 (0.461)	DT 0.000 (0.101)	lr 0.0001	loss 0.109 (0.103)
Train: [57][450/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0001	loss 0.110 (0.103)
Train: [57][460/589]	BT 0.358 (0.464)	DT 0.000 (0.104)	lr 0.0001	loss 0.099 (0.103)
Train: [57][470/589]	BT 0.359 (0.465)	DT 0.000 (0.105)	lr 0.0001	loss 0.112 (0.103)
Train: [57][480/589]	BT 0.357 (0.466)	DT 0.000 (0.106)	lr 0.0001	loss 0.115 (0.103)
Train: [57][490/589]	BT 0.372 (0.467)	DT 0.000 (0.107)	lr 0.0001	loss 0.107 (0.103)
Train: [57][500/589]	BT 0.363 (0.466)	DT 0.000 (0.106)	lr 0.0001	loss 0.085 (0.103)
Train: [57][510/589]	BT 0.398 (0.467)	DT 0.000 (0.107)	lr 0.0001	loss 0.104 (0.103)
Train: [57][520/589]	BT 0.358 (0.469)	DT 0.000 (0.109)	lr 0.0001	loss 0.100 (0.103)
Train: [57][530/589]	BT 0.358 (0.468)	DT 0.000 (0.108)	lr 0.0001	loss 0.122 (0.103)
Train: [57][540/589]	BT 0.359 (0.469)	DT 0.000 (0.109)	lr 0.0001	loss 0.108 (0.103)
Train: [57][550/589]	BT 0.359 (0.469)	DT 0.000 (0.109)	lr 0.0001	loss 0.090 (0.103)
Train: [57][560/589]	BT 0.358 (0.470)	DT 0.000 (0.110)	lr 0.0001	loss 0.099 (0.103)
Train: [57][570/589]	BT 0.358 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.104 (0.103)
Train: [57][580/589]	BT 0.357 (0.473)	DT 0.000 (0.113)	lr 0.0001	loss 0.115 (0.103)
epoch 57, total time 280.76
loss: 0.10272510960422708@Epoch: 57
learning_rate: 0.0001,57
Valid: [57][10/88]	BT 0.109 (0.729)	DT 0.000 (0.618)	loss 0.166 (0.157)
Valid: [57][20/88]	BT 0.109 (0.709)	DT 0.000 (0.597)	loss 0.137 (0.156)
Valid: [57][30/88]	BT 0.110 (0.674)	DT 0.000 (0.564)	loss 0.167 (0.156)
Valid: [57][40/88]	BT 0.109 (0.675)	DT 0.000 (0.565)	loss 0.169 (0.155)
Valid: [57][50/88]	BT 0.110 (0.664)	DT 0.000 (0.553)	loss 0.169 (0.156)
Valid: [57][60/88]	BT 0.109 (0.633)	DT 0.000 (0.523)	loss 0.183 (0.156)
Valid: [57][70/88]	BT 0.109 (0.606)	DT 0.000 (0.496)	loss 0.150 (0.158)
Valid: [57][80/88]	BT 0.110 (0.597)	DT 0.000 (0.487)	loss 0.145 (0.157)
Train: [58][10/589]	BT 0.357 (0.890)	DT 0.000 (0.532)	lr 0.0001	loss 0.095 (0.103)
Train: [58][20/589]	BT 0.358 (0.702)	DT 0.000 (0.344)	lr 0.0001	loss 0.122 (0.103)
Train: [58][30/589]	BT 0.358 (0.657)	DT 0.000 (0.299)	lr 0.0001	loss 0.132 (0.104)
Train: [58][40/589]	BT 0.401 (0.618)	DT 0.000 (0.257)	lr 0.0001	loss 0.113 (0.104)
Train: [58][50/589]	BT 0.358 (0.574)	DT 0.000 (0.214)	lr 0.0001	loss 0.104 (0.103)
Train: [58][60/589]	BT 0.358 (0.562)	DT 0.000 (0.202)	lr 0.0001	loss 0.111 (0.104)
Train: [58][70/589]	BT 0.358 (0.561)	DT 0.000 (0.202)	lr 0.0001	loss 0.073 (0.103)
Train: [58][80/589]	BT 0.398 (0.555)	DT 0.000 (0.194)	lr 0.0001	loss 0.096 (0.103)
Train: [58][90/589]	BT 0.404 (0.545)	DT 0.000 (0.184)	lr 0.0001	loss 0.105 (0.103)
Train: [58][100/589]	BT 0.358 (0.536)	DT 0.000 (0.175)	lr 0.0001	loss 0.099 (0.103)
Train: [58][110/589]	BT 0.391 (0.534)	DT 0.000 (0.174)	lr 0.0001	loss 0.108 (0.102)
Train: [58][120/589]	BT 0.359 (0.522)	DT 0.000 (0.161)	lr 0.0001	loss 0.112 (0.103)
Train: [58][130/589]	BT 0.373 (0.513)	DT 0.000 (0.152)	lr 0.0001	loss 0.091 (0.102)
Train: [58][140/589]	BT 0.359 (0.511)	DT 0.000 (0.150)	lr 0.0001	loss 0.101 (0.102)
Train: [58][150/589]	BT 0.376 (0.503)	DT 0.000 (0.143)	lr 0.0001	loss 0.106 (0.102)
Train: [58][160/589]	BT 0.359 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.102 (0.102)
Train: [58][170/589]	BT 0.368 (0.487)	DT 0.000 (0.126)	lr 0.0001	loss 0.098 (0.102)
Train: [58][180/589]	BT 0.366 (0.480)	DT 0.000 (0.119)	lr 0.0001	loss 0.100 (0.102)
Train: [58][190/589]	BT 0.386 (0.474)	DT 0.000 (0.114)	lr 0.0001	loss 0.111 (0.102)
Train: [58][200/589]	BT 0.359 (0.469)	DT 0.000 (0.108)	lr 0.0001	loss 0.103 (0.102)
Train: [58][210/589]	BT 0.360 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.112 (0.102)
Train: [58][220/589]	BT 0.356 (0.459)	DT 0.000 (0.099)	lr 0.0001	loss 0.098 (0.102)
Train: [58][230/589]	BT 0.388 (0.455)	DT 0.000 (0.094)	lr 0.0001	loss 0.089 (0.102)
Train: [58][240/589]	BT 0.356 (0.451)	DT 0.000 (0.090)	lr 0.0001	loss 0.103 (0.102)
Train: [58][250/589]	BT 0.358 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.115 (0.102)
Train: [58][260/589]	BT 0.356 (0.444)	DT 0.000 (0.083)	lr 0.0001	loss 0.118 (0.102)
Train: [58][270/589]	BT 0.358 (0.443)	DT 0.000 (0.082)	lr 0.0001	loss 0.108 (0.102)
Train: [58][280/589]	BT 0.358 (0.445)	DT 0.000 (0.084)	lr 0.0001	loss 0.102 (0.102)
Train: [58][290/589]	BT 0.363 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.096 (0.102)
Train: [58][300/589]	BT 0.358 (0.453)	DT 0.000 (0.092)	lr 0.0001	loss 0.090 (0.102)
Train: [58][310/589]	BT 0.360 (0.454)	DT 0.000 (0.093)	lr 0.0001	loss 0.107 (0.102)
Train: [58][320/589]	BT 0.359 (0.454)	DT 0.000 (0.093)	lr 0.0001	loss 0.100 (0.102)
Train: [58][330/589]	BT 0.357 (0.457)	DT 0.000 (0.096)	lr 0.0001	loss 0.102 (0.102)
Train: [58][340/589]	BT 0.383 (0.457)	DT 0.000 (0.096)	lr 0.0001	loss 0.105 (0.102)
Train: [58][350/589]	BT 0.403 (0.460)	DT 0.043 (0.099)	lr 0.0001	loss 0.096 (0.102)
Train: [58][360/589]	BT 0.358 (0.462)	DT 0.000 (0.101)	lr 0.0001	loss 0.120 (0.102)
Train: [58][370/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.100 (0.102)
Train: [58][380/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.108 (0.102)
Train: [58][390/589]	BT 0.358 (0.466)	DT 0.000 (0.105)	lr 0.0001	loss 0.106 (0.102)
Train: [58][400/589]	BT 0.358 (0.466)	DT 0.000 (0.105)	lr 0.0001	loss 0.107 (0.102)
Train: [58][410/589]	BT 0.359 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.105 (0.102)
Train: [58][420/589]	BT 0.821 (0.479)	DT 0.462 (0.118)	lr 0.0001	loss 0.099 (0.102)
Train: [58][430/589]	BT 0.464 (0.482)	DT 0.109 (0.121)	lr 0.0001	loss 0.115 (0.102)
Train: [58][440/589]	BT 0.358 (0.485)	DT 0.000 (0.124)	lr 0.0001	loss 0.103 (0.102)
Train: [58][450/589]	BT 0.898 (0.486)	DT 0.538 (0.125)	lr 0.0001	loss 0.111 (0.102)
Train: [58][460/589]	BT 0.832 (0.488)	DT 0.474 (0.128)	lr 0.0001	loss 0.089 (0.102)
Train: [58][470/589]	BT 0.891 (0.493)	DT 0.532 (0.132)	lr 0.0001	loss 0.119 (0.102)
Train: [58][480/589]	BT 0.357 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.089 (0.102)
Train: [58][490/589]	BT 0.358 (0.496)	DT 0.000 (0.136)	lr 0.0001	loss 0.096 (0.102)
Train: [58][500/589]	BT 0.357 (0.496)	DT 0.000 (0.136)	lr 0.0001	loss 0.105 (0.102)
Train: [58][510/589]	BT 0.998 (0.498)	DT 0.639 (0.138)	lr 0.0001	loss 0.094 (0.102)
Train: [58][520/589]	BT 0.843 (0.502)	DT 0.483 (0.142)	lr 0.0001	loss 0.087 (0.102)
Train: [58][530/589]	BT 0.357 (0.503)	DT 0.000 (0.142)	lr 0.0001	loss 0.103 (0.102)
Train: [58][540/589]	BT 0.936 (0.506)	DT 0.575 (0.145)	lr 0.0001	loss 0.093 (0.102)
Train: [58][550/589]	BT 1.183 (0.506)	DT 0.824 (0.146)	lr 0.0001	loss 0.102 (0.102)
Train: [58][560/589]	BT 1.387 (0.508)	DT 1.027 (0.147)	lr 0.0001	loss 0.107 (0.102)
Train: [58][570/589]	BT 1.499 (0.507)	DT 1.138 (0.147)	lr 0.0001	loss 0.099 (0.102)
Train: [58][580/589]	BT 1.289 (0.506)	DT 0.928 (0.146)	lr 0.0001	loss 0.091 (0.102)
epoch 58, total time 296.82
loss: 0.10194549422742@Epoch: 58
learning_rate: 0.0001,58
Valid: [58][10/88]	BT 0.110 (0.622)	DT 0.000 (0.511)	loss 0.140 (0.160)
Valid: [58][20/88]	BT 0.110 (0.583)	DT 0.000 (0.472)	loss 0.142 (0.158)
Valid: [58][30/88]	BT 0.110 (0.550)	DT 0.000 (0.440)	loss 0.151 (0.161)
Valid: [58][40/88]	BT 0.109 (0.527)	DT 0.000 (0.417)	loss 0.154 (0.162)
Valid: [58][50/88]	BT 0.110 (0.525)	DT 0.000 (0.415)	loss 0.176 (0.163)
Valid: [58][60/88]	BT 0.109 (0.515)	DT 0.000 (0.405)	loss 0.139 (0.162)
Valid: [58][70/88]	BT 0.109 (0.512)	DT 0.000 (0.402)	loss 0.170 (0.162)
Valid: [58][80/88]	BT 0.110 (0.507)	DT 0.000 (0.398)	loss 0.146 (0.161)
Train: [59][10/589]	BT 0.358 (0.785)	DT 0.000 (0.425)	lr 0.0001	loss 0.108 (0.104)
Train: [59][20/589]	BT 0.385 (0.588)	DT 0.000 (0.228)	lr 0.0001	loss 0.102 (0.102)
Train: [59][30/589]	BT 0.381 (0.514)	DT 0.000 (0.152)	lr 0.0001	loss 0.098 (0.100)
Train: [59][40/589]	BT 0.355 (0.476)	DT 0.000 (0.114)	lr 0.0001	loss 0.110 (0.101)
Train: [59][50/589]	BT 0.401 (0.454)	DT 0.000 (0.091)	lr 0.0001	loss 0.093 (0.101)
Train: [59][60/589]	BT 0.359 (0.438)	DT 0.000 (0.076)	lr 0.0001	loss 0.103 (0.101)
Train: [59][70/589]	BT 0.360 (0.453)	DT 0.000 (0.091)	lr 0.0001	loss 0.100 (0.101)
Train: [59][80/589]	BT 0.360 (0.442)	DT 0.000 (0.079)	lr 0.0001	loss 0.098 (0.100)
Train: [59][90/589]	BT 0.357 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.096 (0.100)
Train: [59][100/589]	BT 0.357 (0.444)	DT 0.000 (0.082)	lr 0.0001	loss 0.110 (0.100)
Train: [59][110/589]	BT 0.359 (0.437)	DT 0.000 (0.075)	lr 0.0001	loss 0.103 (0.100)
Train: [59][120/589]	BT 0.358 (0.438)	DT 0.000 (0.075)	lr 0.0001	loss 0.116 (0.100)
Train: [59][130/589]	BT 0.358 (0.432)	DT 0.000 (0.070)	lr 0.0001	loss 0.086 (0.100)
Train: [59][140/589]	BT 0.430 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.102 (0.099)
Train: [59][150/589]	BT 0.358 (0.427)	DT 0.000 (0.064)	lr 0.0001	loss 0.090 (0.100)
Train: [59][160/589]	BT 0.359 (0.423)	DT 0.000 (0.060)	lr 0.0001	loss 0.085 (0.100)
Train: [59][170/589]	BT 0.359 (0.419)	DT 0.000 (0.057)	lr 0.0001	loss 0.103 (0.100)
Train: [59][180/589]	BT 0.359 (0.416)	DT 0.000 (0.054)	lr 0.0001	loss 0.081 (0.100)
Train: [59][190/589]	BT 0.361 (0.414)	DT 0.000 (0.051)	lr 0.0001	loss 0.102 (0.100)
Train: [59][200/589]	BT 0.364 (0.411)	DT 0.000 (0.048)	lr 0.0001	loss 0.100 (0.100)
Train: [59][210/589]	BT 0.359 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.101 (0.100)
Train: [59][220/589]	BT 0.372 (0.426)	DT 0.000 (0.063)	lr 0.0001	loss 0.104 (0.100)
Train: [59][230/589]	BT 0.392 (0.427)	DT 0.000 (0.064)	lr 0.0001	loss 0.098 (0.100)
Train: [59][240/589]	BT 0.356 (0.426)	DT 0.000 (0.063)	lr 0.0001	loss 0.098 (0.100)
Train: [59][250/589]	BT 0.359 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.100 (0.100)
Train: [59][260/589]	BT 0.396 (0.424)	DT 0.000 (0.061)	lr 0.0001	loss 0.099 (0.100)
Train: [59][270/589]	BT 0.361 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.087 (0.100)
Train: [59][280/589]	BT 0.393 (0.426)	DT 0.000 (0.063)	lr 0.0001	loss 0.107 (0.101)
Train: [59][290/589]	BT 0.359 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.107 (0.101)
Train: [59][300/589]	BT 0.362 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.088 (0.101)
Train: [59][310/589]	BT 0.357 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.093 (0.101)
Train: [59][320/589]	BT 0.359 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.103 (0.101)
Train: [59][330/589]	BT 0.360 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.118 (0.101)
Train: [59][340/589]	BT 0.389 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.136 (0.101)
Train: [59][350/589]	BT 0.360 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.105 (0.101)
Train: [59][360/589]	BT 0.358 (0.426)	DT 0.000 (0.063)	lr 0.0001	loss 0.085 (0.101)
Train: [59][370/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.115 (0.101)
Train: [59][380/589]	BT 0.358 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.102 (0.101)
Train: [59][390/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.092 (0.101)
Train: [59][400/589]	BT 0.357 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.112 (0.101)
Train: [59][410/589]	BT 0.359 (0.422)	DT 0.000 (0.060)	lr 0.0001	loss 0.110 (0.101)
Train: [59][420/589]	BT 0.359 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.116 (0.101)
Train: [59][430/589]	BT 0.396 (0.424)	DT 0.000 (0.062)	lr 0.0001	loss 0.088 (0.101)
Train: [59][440/589]	BT 0.357 (0.423)	DT 0.000 (0.061)	lr 0.0001	loss 0.109 (0.101)
Train: [59][450/589]	BT 0.358 (0.423)	DT 0.000 (0.060)	lr 0.0001	loss 0.095 (0.101)
Train: [59][460/589]	BT 0.514 (0.426)	DT 0.154 (0.063)	lr 0.0001	loss 0.107 (0.101)
Train: [59][470/589]	BT 0.358 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.125 (0.101)
Train: [59][480/589]	BT 0.365 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.106 (0.101)
Train: [59][490/589]	BT 0.356 (0.432)	DT 0.000 (0.069)	lr 0.0001	loss 0.096 (0.101)
Train: [59][500/589]	BT 0.358 (0.432)	DT 0.000 (0.069)	lr 0.0001	loss 0.102 (0.101)
Train: [59][510/589]	BT 0.358 (0.432)	DT 0.000 (0.069)	lr 0.0001	loss 0.095 (0.101)
Train: [59][520/589]	BT 0.359 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.091 (0.101)
Train: [59][530/589]	BT 0.356 (0.432)	DT 0.000 (0.070)	lr 0.0001	loss 0.102 (0.101)
Train: [59][540/589]	BT 0.360 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.115 (0.101)
Train: [59][550/589]	BT 0.359 (0.430)	DT 0.000 (0.068)	lr 0.0001	loss 0.092 (0.101)
Train: [59][560/589]	BT 0.876 (0.431)	DT 0.515 (0.069)	lr 0.0001	loss 0.095 (0.101)
Train: [59][570/589]	BT 0.359 (0.431)	DT 0.000 (0.068)	lr 0.0001	loss 0.098 (0.101)
Train: [59][580/589]	BT 1.321 (0.431)	DT 0.961 (0.069)	lr 0.0001	loss 0.096 (0.101)
epoch 59, total time 253.28
loss: 0.10118877152323293@Epoch: 59
learning_rate: 0.0001,59
Valid: [59][10/88]	BT 0.110 (0.592)	DT 0.000 (0.478)	loss 0.176 (0.168)
Valid: [59][20/88]	BT 0.110 (0.538)	DT 0.000 (0.426)	loss 0.167 (0.166)
Valid: [59][30/88]	BT 0.110 (0.506)	DT 0.000 (0.395)	loss 0.187 (0.163)
Valid: [59][40/88]	BT 0.110 (0.496)	DT 0.000 (0.385)	loss 0.156 (0.163)
Valid: [59][50/88]	BT 0.110 (0.502)	DT 0.000 (0.391)	loss 0.183 (0.164)
Valid: [59][60/88]	BT 0.110 (0.485)	DT 0.000 (0.375)	loss 0.148 (0.162)
Valid: [59][70/88]	BT 0.110 (0.468)	DT 0.000 (0.357)	loss 0.143 (0.162)
Valid: [59][80/88]	BT 0.110 (0.463)	DT 0.000 (0.353)	loss 0.176 (0.162)
Train: [60][10/589]	BT 0.358 (0.824)	DT 0.000 (0.466)	lr 0.0001	loss 0.097 (0.094)
Train: [60][20/589]	BT 0.366 (0.634)	DT 0.000 (0.274)	lr 0.0001	loss 0.098 (0.098)
Train: [60][30/589]	BT 0.380 (0.565)	DT 0.000 (0.203)	lr 0.0001	loss 0.118 (0.100)
Train: [60][40/589]	BT 0.358 (0.513)	DT 0.000 (0.153)	lr 0.0001	loss 0.101 (0.099)
Train: [60][50/589]	BT 0.365 (0.483)	DT 0.000 (0.122)	lr 0.0001	loss 0.087 (0.099)
Train: [60][60/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.093 (0.099)
Train: [60][70/589]	BT 0.358 (0.458)	DT 0.000 (0.097)	lr 0.0001	loss 0.114 (0.100)
Train: [60][80/589]	BT 0.378 (0.463)	DT 0.000 (0.103)	lr 0.0001	loss 0.107 (0.100)
Train: [60][90/589]	BT 0.357 (0.460)	DT 0.000 (0.100)	lr 0.0001	loss 0.093 (0.099)
Train: [60][100/589]	BT 0.358 (0.463)	DT 0.000 (0.103)	lr 0.0001	loss 0.087 (0.099)
Train: [60][110/589]	BT 0.360 (0.458)	DT 0.000 (0.098)	lr 0.0001	loss 0.107 (0.099)
Train: [60][120/589]	BT 0.358 (0.455)	DT 0.000 (0.095)	lr 0.0001	loss 0.118 (0.100)
Train: [60][130/589]	BT 0.357 (0.450)	DT 0.000 (0.090)	lr 0.0001	loss 0.118 (0.100)
Train: [60][140/589]	BT 0.360 (0.452)	DT 0.000 (0.092)	lr 0.0001	loss 0.101 (0.100)
Train: [60][150/589]	BT 0.367 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.101 (0.099)
Train: [60][160/589]	BT 0.359 (0.443)	DT 0.000 (0.083)	lr 0.0001	loss 0.122 (0.099)
Train: [60][170/589]	BT 0.359 (0.444)	DT 0.000 (0.084)	lr 0.0001	loss 0.107 (0.099)
Train: [60][180/589]	BT 0.358 (0.443)	DT 0.000 (0.083)	lr 0.0001	loss 0.093 (0.099)
Train: [60][190/589]	BT 0.389 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.092 (0.099)
Train: [60][200/589]	BT 0.358 (0.437)	DT 0.000 (0.076)	lr 0.0001	loss 0.096 (0.099)
Train: [60][210/589]	BT 0.413 (0.434)	DT 0.000 (0.072)	lr 0.0001	loss 0.092 (0.099)
Train: [60][220/589]	BT 0.397 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.088 (0.099)
Train: [60][230/589]	BT 0.359 (0.434)	DT 0.000 (0.072)	lr 0.0001	loss 0.088 (0.099)
Train: [60][240/589]	BT 0.358 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.104 (0.099)
Train: [60][250/589]	BT 0.358 (0.439)	DT 0.000 (0.077)	lr 0.0001	loss 0.092 (0.099)
Train: [60][260/589]	BT 0.401 (0.436)	DT 0.000 (0.074)	lr 0.0001	loss 0.122 (0.099)
Train: [60][270/589]	BT 0.357 (0.433)	DT 0.000 (0.072)	lr 0.0001	loss 0.095 (0.099)
Train: [60][280/589]	BT 0.358 (0.431)	DT 0.000 (0.069)	lr 0.0001	loss 0.105 (0.100)
Train: [60][290/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.113 (0.100)
Train: [60][300/589]	BT 0.360 (0.427)	DT 0.000 (0.064)	lr 0.0001	loss 0.093 (0.100)
Train: [60][310/589]	BT 0.359 (0.425)	DT 0.000 (0.062)	lr 0.0001	loss 0.084 (0.100)
Train: [60][320/589]	BT 0.359 (0.423)	DT 0.000 (0.060)	lr 0.0001	loss 0.114 (0.100)
Train: [60][330/589]	BT 0.371 (0.421)	DT 0.000 (0.059)	lr 0.0001	loss 0.090 (0.099)
Train: [60][340/589]	BT 0.360 (0.419)	DT 0.000 (0.057)	lr 0.0001	loss 0.088 (0.099)
Train: [60][350/589]	BT 0.360 (0.418)	DT 0.000 (0.055)	lr 0.0001	loss 0.112 (0.100)
Train: [60][360/589]	BT 0.360 (0.416)	DT 0.000 (0.054)	lr 0.0001	loss 0.090 (0.100)
Train: [60][370/589]	BT 0.358 (0.415)	DT 0.000 (0.052)	lr 0.0001	loss 0.105 (0.100)
Train: [60][380/589]	BT 0.358 (0.413)	DT 0.000 (0.051)	lr 0.0001	loss 0.103 (0.100)
Train: [60][390/589]	BT 0.362 (0.412)	DT 0.000 (0.050)	lr 0.0001	loss 0.095 (0.100)
Train: [60][400/589]	BT 0.359 (0.411)	DT 0.000 (0.048)	lr 0.0001	loss 0.110 (0.100)
Train: [60][410/589]	BT 0.360 (0.410)	DT 0.000 (0.047)	lr 0.0001	loss 0.116 (0.100)
Train: [60][420/589]	BT 0.489 (0.409)	DT 0.118 (0.046)	lr 0.0001	loss 0.088 (0.100)
Train: [60][430/589]	BT 1.706 (0.412)	DT 1.347 (0.050)	lr 0.0001	loss 0.097 (0.100)
Train: [60][440/589]	BT 1.698 (0.414)	DT 1.337 (0.052)	lr 0.0001	loss 0.085 (0.100)
Train: [60][450/589]	BT 1.715 (0.418)	DT 1.355 (0.056)	lr 0.0001	loss 0.109 (0.100)
Train: [60][460/589]	BT 1.654 (0.420)	DT 1.294 (0.058)	lr 0.0001	loss 0.106 (0.100)
Train: [60][470/589]	BT 1.627 (0.423)	DT 1.268 (0.060)	lr 0.0001	loss 0.111 (0.100)
Train: [60][480/589]	BT 2.570 (0.428)	DT 2.210 (0.065)	lr 0.0001	loss 0.093 (0.100)
Train: [60][490/589]	BT 1.847 (0.429)	DT 1.485 (0.067)	lr 0.0001	loss 0.112 (0.100)
Train: [60][500/589]	BT 1.678 (0.432)	DT 1.319 (0.070)	lr 0.0001	loss 0.086 (0.100)
Train: [60][510/589]	BT 0.915 (0.434)	DT 0.556 (0.072)	lr 0.0001	loss 0.107 (0.100)
Train: [60][520/589]	BT 1.366 (0.437)	DT 0.985 (0.075)	lr 0.0001	loss 0.072 (0.100)
Train: [60][530/589]	BT 1.426 (0.439)	DT 1.069 (0.077)	lr 0.0001	loss 0.103 (0.100)
Train: [60][540/589]	BT 3.318 (0.444)	DT 2.947 (0.082)	lr 0.0001	loss 0.116 (0.100)
Train: [60][550/589]	BT 3.636 (0.450)	DT 3.277 (0.088)	lr 0.0001	loss 0.088 (0.100)
Train: [60][560/589]	BT 2.391 (0.454)	DT 2.033 (0.092)	lr 0.0001	loss 0.094 (0.100)
Train: [60][570/589]	BT 2.620 (0.458)	DT 2.261 (0.096)	lr 0.0001	loss 0.092 (0.100)
Train: [60][580/589]	BT 2.410 (0.461)	DT 2.049 (0.099)	lr 0.0001	loss 0.106 (0.100)
epoch 60, total time 272.07
loss: 0.1001796182241059@Epoch: 60
learning_rate: 0.0001,60
Valid: [60][10/88]	BT 0.109 (1.049)	DT 0.000 (0.937)	loss 0.128 (0.165)
Valid: [60][20/88]	BT 0.109 (0.912)	DT 0.000 (0.800)	loss 0.176 (0.170)
Valid: [60][30/88]	BT 0.109 (0.858)	DT 0.000 (0.747)	loss 0.186 (0.167)
Valid: [60][40/88]	BT 0.110 (0.827)	DT 0.000 (0.715)	loss 0.158 (0.169)
Valid: [60][50/88]	BT 0.110 (0.811)	DT 0.000 (0.699)	loss 0.171 (0.169)
Valid: [60][60/88]	BT 0.110 (0.821)	DT 0.000 (0.710)	loss 0.188 (0.168)
Valid: [60][70/88]	BT 0.110 (0.801)	DT 0.000 (0.690)	loss 0.198 (0.168)
Valid: [60][80/88]	BT 0.109 (0.784)	DT 0.000 (0.673)	loss 0.168 (0.168)
Train: [61][10/589]	BT 0.358 (0.996)	DT 0.000 (0.638)	lr 0.0001	loss 0.115 (0.099)
Train: [61][20/589]	BT 0.358 (0.714)	DT 0.000 (0.357)	lr 0.0001	loss 0.098 (0.099)
Train: [61][30/589]	BT 0.356 (0.617)	DT 0.000 (0.258)	lr 0.0001	loss 0.095 (0.100)
Train: [61][40/589]	BT 0.357 (0.560)	DT 0.000 (0.202)	lr 0.0001	loss 0.089 (0.099)
Train: [61][50/589]	BT 0.357 (0.536)	DT 0.000 (0.178)	lr 0.0001	loss 0.082 (0.098)
Train: [61][60/589]	BT 0.357 (0.530)	DT 0.000 (0.171)	lr 0.0001	loss 0.130 (0.099)
Train: [61][70/589]	BT 0.358 (0.532)	DT 0.000 (0.174)	lr 0.0001	loss 0.097 (0.099)
Train: [61][80/589]	BT 0.358 (0.534)	DT 0.000 (0.176)	lr 0.0001	loss 0.106 (0.099)
Train: [61][90/589]	BT 0.356 (0.526)	DT 0.000 (0.167)	lr 0.0001	loss 0.107 (0.099)
Train: [61][100/589]	BT 0.362 (0.549)	DT 0.000 (0.191)	lr 0.0001	loss 0.122 (0.100)
Train: [61][110/589]	BT 0.359 (0.545)	DT 0.000 (0.186)	lr 0.0001	loss 0.087 (0.099)
Train: [61][120/589]	BT 0.358 (0.536)	DT 0.000 (0.177)	lr 0.0001	loss 0.094 (0.099)
Train: [61][130/589]	BT 0.397 (0.530)	DT 0.000 (0.171)	lr 0.0001	loss 0.080 (0.099)
Train: [61][140/589]	BT 0.358 (0.527)	DT 0.000 (0.168)	lr 0.0001	loss 0.104 (0.100)
Train: [61][150/589]	BT 0.358 (0.525)	DT 0.000 (0.166)	lr 0.0001	loss 0.092 (0.099)
Train: [61][160/589]	BT 0.358 (0.521)	DT 0.000 (0.162)	lr 0.0001	loss 0.106 (0.099)
Train: [61][170/589]	BT 0.360 (0.519)	DT 0.000 (0.160)	lr 0.0001	loss 0.082 (0.099)
Train: [61][180/589]	BT 0.360 (0.520)	DT 0.000 (0.162)	lr 0.0001	loss 0.094 (0.099)
Train: [61][190/589]	BT 0.360 (0.515)	DT 0.000 (0.156)	lr 0.0001	loss 0.102 (0.099)
Train: [61][200/589]	BT 0.359 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.085 (0.099)
Train: [61][210/589]	BT 0.359 (0.508)	DT 0.000 (0.150)	lr 0.0001	loss 0.095 (0.099)
Train: [61][220/589]	BT 0.376 (0.505)	DT 0.000 (0.146)	lr 0.0001	loss 0.104 (0.099)
Train: [61][230/589]	BT 0.358 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.089 (0.099)
Train: [61][240/589]	BT 0.362 (0.500)	DT 0.000 (0.141)	lr 0.0001	loss 0.090 (0.099)
Train: [61][250/589]	BT 0.360 (0.500)	DT 0.000 (0.141)	lr 0.0001	loss 0.100 (0.099)
Train: [61][260/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.127 (0.099)
Train: [61][270/589]	BT 0.360 (0.496)	DT 0.000 (0.137)	lr 0.0001	loss 0.120 (0.099)
Train: [61][280/589]	BT 0.357 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.112 (0.099)
Train: [61][290/589]	BT 0.359 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.087 (0.099)
Train: [61][300/589]	BT 0.357 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.099 (0.099)
Train: [61][310/589]	BT 0.358 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.106 (0.100)
Train: [61][320/589]	BT 0.358 (0.506)	DT 0.000 (0.147)	lr 0.0001	loss 0.107 (0.099)
Train: [61][330/589]	BT 0.357 (0.510)	DT 0.000 (0.150)	lr 0.0001	loss 0.090 (0.099)
Train: [61][340/589]	BT 0.357 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.086 (0.099)
Train: [61][350/589]	BT 0.370 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.107 (0.099)
Train: [61][360/589]	BT 0.357 (0.513)	DT 0.000 (0.154)	lr 0.0001	loss 0.110 (0.099)
Train: [61][370/589]	BT 0.390 (0.515)	DT 0.000 (0.156)	lr 0.0001	loss 0.098 (0.099)
Train: [61][380/589]	BT 0.359 (0.517)	DT 0.000 (0.157)	lr 0.0001	loss 0.099 (0.099)
Train: [61][390/589]	BT 0.357 (0.514)	DT 0.000 (0.155)	lr 0.0001	loss 0.091 (0.099)
Train: [61][400/589]	BT 0.360 (0.514)	DT 0.000 (0.155)	lr 0.0001	loss 0.093 (0.099)
Train: [61][410/589]	BT 0.360 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.103 (0.099)
Train: [61][420/589]	BT 0.357 (0.511)	DT 0.000 (0.151)	lr 0.0001	loss 0.084 (0.099)
Train: [61][430/589]	BT 0.358 (0.508)	DT 0.000 (0.149)	lr 0.0001	loss 0.101 (0.099)
Train: [61][440/589]	BT 0.358 (0.510)	DT 0.000 (0.150)	lr 0.0001	loss 0.097 (0.099)
Train: [61][450/589]	BT 0.358 (0.511)	DT 0.000 (0.152)	lr 0.0001	loss 0.088 (0.099)
Train: [61][460/589]	BT 0.365 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.108 (0.100)
Train: [61][470/589]	BT 0.357 (0.513)	DT 0.000 (0.154)	lr 0.0001	loss 0.100 (0.099)
Train: [61][480/589]	BT 0.358 (0.513)	DT 0.000 (0.154)	lr 0.0001	loss 0.108 (0.099)
Train: [61][490/589]	BT 0.358 (0.514)	DT 0.000 (0.155)	lr 0.0001	loss 0.087 (0.099)
Train: [61][500/589]	BT 0.358 (0.516)	DT 0.000 (0.157)	lr 0.0001	loss 0.099 (0.099)
Train: [61][510/589]	BT 0.359 (0.516)	DT 0.000 (0.157)	lr 0.0001	loss 0.107 (0.099)
Train: [61][520/589]	BT 0.358 (0.518)	DT 0.000 (0.159)	lr 0.0001	loss 0.115 (0.099)
Train: [61][530/589]	BT 0.359 (0.521)	DT 0.000 (0.161)	lr 0.0001	loss 0.087 (0.099)
Train: [61][540/589]	BT 0.359 (0.520)	DT 0.000 (0.161)	lr 0.0001	loss 0.105 (0.099)
Train: [61][550/589]	BT 0.398 (0.520)	DT 0.000 (0.160)	lr 0.0001	loss 0.109 (0.099)
Train: [61][560/589]	BT 0.356 (0.521)	DT 0.000 (0.161)	lr 0.0001	loss 0.100 (0.099)
Train: [61][570/589]	BT 0.358 (0.523)	DT 0.000 (0.163)	lr 0.0001	loss 0.116 (0.099)
Train: [61][580/589]	BT 0.395 (0.528)	DT 0.000 (0.168)	lr 0.0001	loss 0.108 (0.099)
epoch 61, total time 315.53
loss: 0.09935760915608625@Epoch: 61
learning_rate: 0.0001,61
Valid: [61][10/88]	BT 0.110 (0.783)	DT 0.000 (0.673)	loss 0.183 (0.167)
Valid: [61][20/88]	BT 0.110 (0.680)	DT 0.000 (0.570)	loss 0.171 (0.169)
Valid: [61][30/88]	BT 0.109 (0.633)	DT 0.000 (0.523)	loss 0.159 (0.165)
Valid: [61][40/88]	BT 0.110 (0.600)	DT 0.000 (0.490)	loss 0.159 (0.164)
Valid: [61][50/88]	BT 0.110 (0.589)	DT 0.000 (0.479)	loss 0.185 (0.165)
Valid: [61][60/88]	BT 0.109 (0.577)	DT 0.000 (0.467)	loss 0.159 (0.166)
Valid: [61][70/88]	BT 0.110 (0.560)	DT 0.000 (0.450)	loss 0.156 (0.165)
Valid: [61][80/88]	BT 0.109 (0.562)	DT 0.000 (0.452)	loss 0.144 (0.165)
Train: [62][10/589]	BT 0.357 (1.165)	DT 0.000 (0.807)	lr 0.0001	loss 0.102 (0.100)
Train: [62][20/589]	BT 0.357 (0.850)	DT 0.000 (0.491)	lr 0.0001	loss 0.103 (0.101)
Train: [62][30/589]	BT 0.357 (0.755)	DT 0.000 (0.397)	lr 0.0001	loss 0.080 (0.099)
Train: [62][40/589]	BT 0.357 (0.683)	DT 0.000 (0.325)	lr 0.0001	loss 0.067 (0.098)
Train: [62][50/589]	BT 0.360 (0.686)	DT 0.000 (0.328)	lr 0.0001	loss 0.116 (0.098)
Train: [62][60/589]	BT 0.357 (0.669)	DT 0.000 (0.311)	lr 0.0001	loss 0.102 (0.097)
Train: [62][70/589]	BT 0.358 (0.642)	DT 0.000 (0.283)	lr 0.0001	loss 0.098 (0.097)
Train: [62][80/589]	BT 0.357 (0.635)	DT 0.000 (0.277)	lr 0.0001	loss 0.083 (0.096)
Train: [62][90/589]	BT 0.358 (0.615)	DT 0.000 (0.257)	lr 0.0001	loss 0.093 (0.096)
Train: [62][100/589]	BT 0.394 (0.611)	DT 0.000 (0.252)	lr 0.0001	loss 0.104 (0.096)
Train: [62][110/589]	BT 0.357 (0.616)	DT 0.000 (0.256)	lr 0.0001	loss 0.108 (0.096)
Train: [62][120/589]	BT 0.358 (0.608)	DT 0.000 (0.247)	lr 0.0001	loss 0.109 (0.096)
Train: [62][130/589]	BT 0.357 (0.591)	DT 0.000 (0.231)	lr 0.0001	loss 0.086 (0.096)
Train: [62][140/589]	BT 0.363 (0.594)	DT 0.000 (0.234)	lr 0.0001	loss 0.085 (0.096)
Train: [62][150/589]	BT 0.356 (0.598)	DT 0.000 (0.238)	lr 0.0001	loss 0.085 (0.096)
Train: [62][160/589]	BT 0.359 (0.591)	DT 0.000 (0.231)	lr 0.0001	loss 0.125 (0.097)
Train: [62][170/589]	BT 0.361 (0.591)	DT 0.000 (0.232)	lr 0.0001	loss 0.119 (0.097)
Train: [62][180/589]	BT 0.383 (0.594)	DT 0.000 (0.234)	lr 0.0001	loss 0.101 (0.097)
Train: [62][190/589]	BT 0.358 (0.583)	DT 0.000 (0.223)	lr 0.0001	loss 0.127 (0.097)
Train: [62][200/589]	BT 0.358 (0.575)	DT 0.000 (0.215)	lr 0.0001	loss 0.135 (0.097)
Train: [62][210/589]	BT 0.374 (0.570)	DT 0.000 (0.209)	lr 0.0001	loss 0.091 (0.097)
Train: [62][220/589]	BT 0.358 (0.563)	DT 0.000 (0.203)	lr 0.0001	loss 0.097 (0.097)
Train: [62][230/589]	BT 0.358 (0.559)	DT 0.000 (0.199)	lr 0.0001	loss 0.103 (0.097)
Train: [62][240/589]	BT 0.357 (0.557)	DT 0.000 (0.197)	lr 0.0001	loss 0.097 (0.097)
Train: [62][250/589]	BT 0.358 (0.557)	DT 0.000 (0.197)	lr 0.0001	loss 0.104 (0.097)
Train: [62][260/589]	BT 0.358 (0.560)	DT 0.000 (0.200)	lr 0.0001	loss 0.106 (0.097)
Train: [62][270/589]	BT 0.359 (0.564)	DT 0.000 (0.203)	lr 0.0001	loss 0.090 (0.097)
Train: [62][280/589]	BT 0.361 (0.564)	DT 0.000 (0.204)	lr 0.0001	loss 0.092 (0.097)
Train: [62][290/589]	BT 0.355 (0.563)	DT 0.000 (0.203)	lr 0.0001	loss 0.099 (0.098)
Train: [62][300/589]	BT 0.369 (0.559)	DT 0.000 (0.199)	lr 0.0001	loss 0.108 (0.098)
Train: [62][310/589]	BT 0.359 (0.555)	DT 0.000 (0.195)	lr 0.0001	loss 0.081 (0.098)
Train: [62][320/589]	BT 0.358 (0.556)	DT 0.000 (0.196)	lr 0.0001	loss 0.108 (0.098)
Train: [62][330/589]	BT 0.358 (0.559)	DT 0.000 (0.199)	lr 0.0001	loss 0.095 (0.098)
Train: [62][340/589]	BT 0.359 (0.559)	DT 0.000 (0.199)	lr 0.0001	loss 0.112 (0.098)
Train: [62][350/589]	BT 0.356 (0.559)	DT 0.000 (0.200)	lr 0.0001	loss 0.099 (0.098)
Train: [62][360/589]	BT 0.358 (0.557)	DT 0.000 (0.198)	lr 0.0001	loss 0.093 (0.098)
Train: [62][370/589]	BT 0.358 (0.553)	DT 0.000 (0.194)	lr 0.0001	loss 0.097 (0.098)
Train: [62][380/589]	BT 0.358 (0.552)	DT 0.000 (0.192)	lr 0.0001	loss 0.106 (0.098)
Train: [62][390/589]	BT 0.358 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.112 (0.098)
Train: [62][400/589]	BT 0.357 (0.554)	DT 0.000 (0.194)	lr 0.0001	loss 0.110 (0.098)
Train: [62][410/589]	BT 0.359 (0.554)	DT 0.000 (0.194)	lr 0.0001	loss 0.104 (0.098)
Train: [62][420/589]	BT 0.361 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.090 (0.098)
Train: [62][430/589]	BT 0.357 (0.547)	DT 0.000 (0.186)	lr 0.0001	loss 0.104 (0.098)
Train: [62][440/589]	BT 0.357 (0.544)	DT 0.000 (0.184)	lr 0.0001	loss 0.113 (0.098)
Train: [62][450/589]	BT 0.358 (0.541)	DT 0.000 (0.181)	lr 0.0001	loss 0.086 (0.098)
Train: [62][460/589]	BT 0.359 (0.538)	DT 0.000 (0.178)	lr 0.0001	loss 0.079 (0.098)
Train: [62][470/589]	BT 0.357 (0.537)	DT 0.000 (0.177)	lr 0.0001	loss 0.089 (0.098)
Train: [62][480/589]	BT 0.360 (0.535)	DT 0.000 (0.175)	lr 0.0001	loss 0.093 (0.098)
Train: [62][490/589]	BT 0.357 (0.533)	DT 0.000 (0.173)	lr 0.0001	loss 0.100 (0.098)
Train: [62][500/589]	BT 0.360 (0.531)	DT 0.000 (0.171)	lr 0.0001	loss 0.079 (0.099)
Train: [62][510/589]	BT 0.360 (0.530)	DT 0.000 (0.169)	lr 0.0001	loss 0.099 (0.099)
Train: [62][520/589]	BT 0.357 (0.527)	DT 0.000 (0.167)	lr 0.0001	loss 0.088 (0.099)
Train: [62][530/589]	BT 0.370 (0.526)	DT 0.000 (0.165)	lr 0.0001	loss 0.091 (0.099)
Train: [62][540/589]	BT 0.358 (0.527)	DT 0.000 (0.167)	lr 0.0001	loss 0.102 (0.099)
Train: [62][550/589]	BT 0.359 (0.525)	DT 0.000 (0.165)	lr 0.0001	loss 0.110 (0.099)
Train: [62][560/589]	BT 0.356 (0.524)	DT 0.000 (0.164)	lr 0.0001	loss 0.084 (0.099)
Train: [62][570/589]	BT 0.357 (0.523)	DT 0.000 (0.163)	lr 0.0001	loss 0.101 (0.099)
Train: [62][580/589]	BT 0.359 (0.523)	DT 0.000 (0.162)	lr 0.0001	loss 0.090 (0.099)
epoch 62, total time 310.90
loss: 0.09866279852739787@Epoch: 62
learning_rate: 0.0001,62
Valid: [62][10/88]	BT 0.110 (0.740)	DT 0.000 (0.630)	loss 0.142 (0.165)
Valid: [62][20/88]	BT 0.110 (0.621)	DT 0.000 (0.511)	loss 0.182 (0.165)
Valid: [62][30/88]	BT 0.109 (0.594)	DT 0.000 (0.485)	loss 0.175 (0.164)
Valid: [62][40/88]	BT 0.110 (0.618)	DT 0.000 (0.508)	loss 0.184 (0.167)
Valid: [62][50/88]	BT 0.109 (0.623)	DT 0.000 (0.514)	loss 0.153 (0.167)
Valid: [62][60/88]	BT 0.109 (0.615)	DT 0.000 (0.505)	loss 0.196 (0.168)
Valid: [62][70/88]	BT 0.110 (0.599)	DT 0.000 (0.489)	loss 0.184 (0.169)
Valid: [62][80/88]	BT 0.110 (0.589)	DT 0.000 (0.479)	loss 0.127 (0.167)
Train: [63][10/589]	BT 0.357 (1.065)	DT 0.000 (0.708)	lr 0.0001	loss 0.090 (0.103)
Train: [63][20/589]	BT 0.356 (0.819)	DT 0.000 (0.462)	lr 0.0001	loss 0.090 (0.102)
Train: [63][30/589]	BT 0.356 (0.702)	DT 0.000 (0.345)	lr 0.0001	loss 0.103 (0.100)
Train: [63][40/589]	BT 0.356 (0.663)	DT 0.000 (0.305)	lr 0.0001	loss 0.100 (0.099)
Train: [63][50/589]	BT 0.357 (0.618)	DT 0.000 (0.260)	lr 0.0001	loss 0.100 (0.097)
Train: [63][60/589]	BT 0.357 (0.598)	DT 0.000 (0.240)	lr 0.0001	loss 0.091 (0.097)
Train: [63][70/589]	BT 0.358 (0.579)	DT 0.000 (0.221)	lr 0.0001	loss 0.083 (0.096)
Train: [63][80/589]	BT 0.358 (0.577)	DT 0.000 (0.218)	lr 0.0001	loss 0.083 (0.097)
Train: [63][90/589]	BT 0.388 (0.564)	DT 0.000 (0.205)	lr 0.0001	loss 0.081 (0.098)
Train: [63][100/589]	BT 0.358 (0.554)	DT 0.000 (0.195)	lr 0.0001	loss 0.092 (0.097)
Train: [63][110/589]	BT 0.358 (0.556)	DT 0.000 (0.197)	lr 0.0001	loss 0.092 (0.097)
Train: [63][120/589]	BT 0.391 (0.552)	DT 0.000 (0.193)	lr 0.0001	loss 0.122 (0.097)
Train: [63][130/589]	BT 0.358 (0.549)	DT 0.000 (0.190)	lr 0.0001	loss 0.095 (0.097)
Train: [63][140/589]	BT 0.358 (0.551)	DT 0.000 (0.192)	lr 0.0001	loss 0.106 (0.097)
Train: [63][150/589]	BT 0.357 (0.550)	DT 0.000 (0.191)	lr 0.0001	loss 0.091 (0.097)
Train: [63][160/589]	BT 0.357 (0.552)	DT 0.000 (0.193)	lr 0.0001	loss 0.106 (0.097)
Train: [63][170/589]	BT 0.357 (0.552)	DT 0.000 (0.193)	lr 0.0001	loss 0.087 (0.097)
Train: [63][180/589]	BT 0.357 (0.552)	DT 0.000 (0.193)	lr 0.0001	loss 0.091 (0.097)
Train: [63][190/589]	BT 0.357 (0.548)	DT 0.000 (0.189)	lr 0.0001	loss 0.089 (0.097)
Train: [63][200/589]	BT 0.359 (0.546)	DT 0.000 (0.187)	lr 0.0001	loss 0.093 (0.097)
Train: [63][210/589]	BT 0.388 (0.547)	DT 0.000 (0.188)	lr 0.0001	loss 0.098 (0.097)
Train: [63][220/589]	BT 0.360 (0.544)	DT 0.000 (0.184)	lr 0.0001	loss 0.114 (0.097)
Train: [63][230/589]	BT 0.409 (0.542)	DT 0.000 (0.182)	lr 0.0001	loss 0.103 (0.097)
Train: [63][240/589]	BT 0.359 (0.542)	DT 0.000 (0.182)	lr 0.0001	loss 0.094 (0.097)
Train: [63][250/589]	BT 0.358 (0.548)	DT 0.000 (0.188)	lr 0.0001	loss 0.102 (0.097)
Train: [63][260/589]	BT 0.359 (0.552)	DT 0.000 (0.192)	lr 0.0001	loss 0.082 (0.097)
Train: [63][270/589]	BT 0.358 (0.552)	DT 0.000 (0.192)	lr 0.0001	loss 0.082 (0.097)
Train: [63][280/589]	BT 0.359 (0.555)	DT 0.000 (0.194)	lr 0.0001	loss 0.106 (0.097)
Train: [63][290/589]	BT 0.360 (0.553)	DT 0.000 (0.192)	lr 0.0001	loss 0.099 (0.097)
Train: [63][300/589]	BT 0.358 (0.553)	DT 0.000 (0.193)	lr 0.0001	loss 0.084 (0.097)
Train: [63][310/589]	BT 0.357 (0.552)	DT 0.000 (0.191)	lr 0.0001	loss 0.107 (0.097)
Train: [63][320/589]	BT 0.356 (0.550)	DT 0.000 (0.189)	lr 0.0001	loss 0.098 (0.097)
Train: [63][330/589]	BT 0.357 (0.548)	DT 0.000 (0.187)	lr 0.0001	loss 0.116 (0.097)
Train: [63][340/589]	BT 0.359 (0.546)	DT 0.000 (0.185)	lr 0.0001	loss 0.088 (0.097)
Train: [63][350/589]	BT 0.358 (0.547)	DT 0.000 (0.186)	lr 0.0001	loss 0.098 (0.097)
Train: [63][360/589]	BT 0.359 (0.550)	DT 0.000 (0.189)	lr 0.0001	loss 0.093 (0.097)
Train: [63][370/589]	BT 0.359 (0.548)	DT 0.000 (0.187)	lr 0.0001	loss 0.093 (0.097)
Train: [63][380/589]	BT 0.358 (0.551)	DT 0.000 (0.191)	lr 0.0001	loss 0.104 (0.097)
Train: [63][390/589]	BT 0.356 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.074 (0.097)
Train: [63][400/589]	BT 0.357 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.087 (0.097)
Train: [63][410/589]	BT 0.358 (0.548)	DT 0.000 (0.188)	lr 0.0001	loss 0.092 (0.097)
Train: [63][420/589]	BT 0.358 (0.549)	DT 0.000 (0.188)	lr 0.0001	loss 0.088 (0.097)
Train: [63][430/589]	BT 0.359 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.117 (0.097)
Train: [63][440/589]	BT 0.357 (0.551)	DT 0.000 (0.190)	lr 0.0001	loss 0.102 (0.097)
Train: [63][450/589]	BT 0.395 (0.552)	DT 0.000 (0.192)	lr 0.0001	loss 0.104 (0.097)
Train: [63][460/589]	BT 0.359 (0.552)	DT 0.000 (0.192)	lr 0.0001	loss 0.092 (0.097)
Train: [63][470/589]	BT 0.388 (0.551)	DT 0.000 (0.190)	lr 0.0001	loss 0.099 (0.097)
Train: [63][480/589]	BT 0.359 (0.550)	DT 0.000 (0.189)	lr 0.0001	loss 0.089 (0.097)
Train: [63][490/589]	BT 0.361 (0.550)	DT 0.000 (0.190)	lr 0.0001	loss 0.098 (0.097)
Train: [63][500/589]	BT 0.375 (0.551)	DT 0.000 (0.191)	lr 0.0001	loss 0.084 (0.097)
Train: [63][510/589]	BT 0.358 (0.550)	DT 0.000 (0.189)	lr 0.0001	loss 0.075 (0.097)
Train: [63][520/589]	BT 0.388 (0.548)	DT 0.000 (0.187)	lr 0.0001	loss 0.121 (0.097)
Train: [63][530/589]	BT 0.361 (0.547)	DT 0.000 (0.186)	lr 0.0001	loss 0.093 (0.097)
Train: [63][540/589]	BT 0.359 (0.545)	DT 0.000 (0.185)	lr 0.0001	loss 0.092 (0.097)
Train: [63][550/589]	BT 0.359 (0.544)	DT 0.000 (0.183)	lr 0.0001	loss 0.086 (0.097)
Train: [63][560/589]	BT 0.357 (0.543)	DT 0.000 (0.182)	lr 0.0001	loss 0.116 (0.097)
Train: [63][570/589]	BT 0.357 (0.542)	DT 0.000 (0.182)	lr 0.0001	loss 0.108 (0.097)
Train: [63][580/589]	BT 0.358 (0.543)	DT 0.000 (0.183)	lr 0.0001	loss 0.100 (0.097)
epoch 63, total time 321.03
loss: 0.09745613583237953@Epoch: 63
learning_rate: 0.0001,63
Valid: [63][10/88]	BT 0.109 (0.648)	DT 0.000 (0.535)	loss 0.194 (0.182)
Valid: [63][20/88]	BT 0.110 (0.558)	DT 0.000 (0.444)	loss 0.159 (0.172)
Valid: [63][30/88]	BT 0.110 (0.540)	DT 0.000 (0.428)	loss 0.180 (0.171)
Valid: [63][40/88]	BT 0.110 (0.513)	DT 0.000 (0.402)	loss 0.181 (0.172)
Valid: [63][50/88]	BT 0.110 (0.493)	DT 0.000 (0.381)	loss 0.179 (0.172)
Valid: [63][60/88]	BT 0.110 (0.479)	DT 0.000 (0.368)	loss 0.136 (0.172)
Valid: [63][70/88]	BT 0.109 (0.477)	DT 0.000 (0.365)	loss 0.185 (0.170)
Valid: [63][80/88]	BT 0.109 (0.474)	DT 0.000 (0.363)	loss 0.167 (0.172)
Train: [64][10/589]	BT 0.370 (0.750)	DT 0.000 (0.387)	lr 0.0001	loss 0.095 (0.096)
Train: [64][20/589]	BT 0.359 (0.555)	DT 0.000 (0.194)	lr 0.0001	loss 0.088 (0.097)
Train: [64][30/589]	BT 0.360 (0.490)	DT 0.000 (0.129)	lr 0.0001	loss 0.094 (0.099)
Train: [64][40/589]	BT 0.370 (0.457)	DT 0.000 (0.097)	lr 0.0001	loss 0.101 (0.098)
Train: [64][50/589]	BT 0.356 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.095 (0.097)
Train: [64][60/589]	BT 0.400 (0.426)	DT 0.000 (0.065)	lr 0.0001	loss 0.088 (0.097)
Train: [64][70/589]	BT 0.359 (0.417)	DT 0.000 (0.056)	lr 0.0001	loss 0.098 (0.097)
Train: [64][80/589]	BT 0.358 (0.411)	DT 0.000 (0.049)	lr 0.0001	loss 0.091 (0.096)
Train: [64][90/589]	BT 0.359 (0.406)	DT 0.000 (0.043)	lr 0.0001	loss 0.105 (0.096)
Train: [64][100/589]	BT 0.360 (0.401)	DT 0.000 (0.039)	lr 0.0001	loss 0.095 (0.096)
Train: [64][110/589]	BT 0.362 (0.398)	DT 0.000 (0.035)	lr 0.0001	loss 0.094 (0.096)
Train: [64][120/589]	BT 0.361 (0.395)	DT 0.000 (0.032)	lr 0.0001	loss 0.107 (0.097)
Train: [64][130/589]	BT 0.357 (0.392)	DT 0.000 (0.030)	lr 0.0001	loss 0.100 (0.097)
Train: [64][140/589]	BT 0.359 (0.390)	DT 0.000 (0.028)	lr 0.0001	loss 0.115 (0.097)
Train: [64][150/589]	BT 0.360 (0.389)	DT 0.000 (0.026)	lr 0.0001	loss 0.074 (0.097)
Train: [64][160/589]	BT 0.359 (0.387)	DT 0.000 (0.024)	lr 0.0001	loss 0.108 (0.096)
Train: [64][170/589]	BT 0.360 (0.385)	DT 0.000 (0.023)	lr 0.0001	loss 0.087 (0.096)
Train: [64][180/589]	BT 0.359 (0.384)	DT 0.000 (0.022)	lr 0.0001	loss 0.104 (0.097)
Train: [64][190/589]	BT 0.358 (0.383)	DT 0.000 (0.021)	lr 0.0001	loss 0.076 (0.096)
Train: [64][200/589]	BT 0.360 (0.382)	DT 0.000 (0.020)	lr 0.0001	loss 0.102 (0.096)
Train: [64][210/589]	BT 0.359 (0.381)	DT 0.000 (0.019)	lr 0.0001	loss 0.111 (0.097)
Train: [64][220/589]	BT 0.360 (0.380)	DT 0.000 (0.018)	lr 0.0001	loss 0.107 (0.097)
Train: [64][230/589]	BT 0.359 (0.379)	DT 0.000 (0.017)	lr 0.0001	loss 0.104 (0.097)
Train: [64][240/589]	BT 0.359 (0.378)	DT 0.000 (0.016)	lr 0.0001	loss 0.094 (0.097)
Train: [64][250/589]	BT 0.360 (0.378)	DT 0.000 (0.016)	lr 0.0001	loss 0.117 (0.097)
Train: [64][260/589]	BT 0.360 (0.377)	DT 0.000 (0.015)	lr 0.0001	loss 0.101 (0.097)
Train: [64][270/589]	BT 0.359 (0.377)	DT 0.000 (0.015)	lr 0.0001	loss 0.093 (0.097)
Train: [64][280/589]	BT 0.360 (0.376)	DT 0.000 (0.014)	lr 0.0001	loss 0.094 (0.097)
Train: [64][290/589]	BT 0.360 (0.376)	DT 0.000 (0.014)	lr 0.0001	loss 0.093 (0.097)
Train: [64][300/589]	BT 0.358 (0.375)	DT 0.000 (0.013)	lr 0.0001	loss 0.087 (0.097)
Train: [64][310/589]	BT 0.368 (0.375)	DT 0.000 (0.013)	lr 0.0001	loss 0.092 (0.097)
Train: [64][320/589]	BT 0.358 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.104 (0.097)
Train: [64][330/589]	BT 0.359 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.091 (0.097)
Train: [64][340/589]	BT 0.360 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.083 (0.097)
Train: [64][350/589]	BT 0.358 (0.373)	DT 0.000 (0.011)	lr 0.0001	loss 0.109 (0.097)
Train: [64][360/589]	BT 0.358 (0.373)	DT 0.000 (0.011)	lr 0.0001	loss 0.105 (0.097)
Train: [64][370/589]	BT 0.361 (0.373)	DT 0.000 (0.011)	lr 0.0001	loss 0.096 (0.097)
Train: [64][380/589]	BT 0.360 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.109 (0.097)
Train: [64][390/589]	BT 0.359 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.092 (0.097)
Train: [64][400/589]	BT 0.360 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.094 (0.097)
Train: [64][410/589]	BT 0.358 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.103 (0.097)
Train: [64][420/589]	BT 0.360 (0.372)	DT 0.000 (0.009)	lr 0.0001	loss 0.085 (0.097)
Train: [64][430/589]	BT 0.360 (0.372)	DT 0.000 (0.009)	lr 0.0001	loss 0.113 (0.097)
Train: [64][440/589]	BT 0.358 (0.371)	DT 0.000 (0.009)	lr 0.0001	loss 0.091 (0.097)
Train: [64][450/589]	BT 0.358 (0.371)	DT 0.000 (0.009)	lr 0.0001	loss 0.109 (0.097)
Train: [64][460/589]	BT 0.360 (0.371)	DT 0.000 (0.009)	lr 0.0001	loss 0.099 (0.097)
Train: [64][470/589]	BT 0.360 (0.371)	DT 0.000 (0.008)	lr 0.0001	loss 0.100 (0.097)
Train: [64][480/589]	BT 0.360 (0.371)	DT 0.000 (0.008)	lr 0.0001	loss 0.118 (0.097)
Train: [64][490/589]	BT 0.424 (0.371)	DT 0.066 (0.008)	lr 0.0001	loss 0.093 (0.097)
Train: [64][500/589]	BT 0.359 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.094 (0.097)
Train: [64][510/589]	BT 0.360 (0.372)	DT 0.000 (0.010)	lr 0.0001	loss 0.104 (0.097)
Train: [64][520/589]	BT 0.370 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.096 (0.097)
Train: [64][530/589]	BT 0.362 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.090 (0.097)
Train: [64][540/589]	BT 0.387 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.066 (0.097)
Train: [64][550/589]	BT 0.362 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.099 (0.097)
Train: [64][560/589]	BT 0.358 (0.374)	DT 0.000 (0.012)	lr 0.0001	loss 0.095 (0.097)
Train: [64][570/589]	BT 0.359 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.107 (0.097)
Train: [64][580/589]	BT 0.358 (0.374)	DT 0.000 (0.011)	lr 0.0001	loss 0.077 (0.097)
epoch 64, total time 219.87
loss: 0.09702329841741766@Epoch: 64
learning_rate: 0.0001,64
Valid: [64][10/88]	BT 0.110 (0.650)	DT 0.000 (0.538)	loss 0.144 (0.173)
Valid: [64][20/88]	BT 0.110 (0.490)	DT 0.000 (0.378)	loss 0.206 (0.176)
Valid: [64][30/88]	BT 0.109 (0.448)	DT 0.000 (0.336)	loss 0.176 (0.176)
Valid: [64][40/88]	BT 0.109 (0.441)	DT 0.000 (0.329)	loss 0.113 (0.170)
Valid: [64][50/88]	BT 0.110 (0.446)	DT 0.000 (0.334)	loss 0.192 (0.171)
Valid: [64][60/88]	BT 0.109 (0.451)	DT 0.000 (0.339)	loss 0.169 (0.170)
Valid: [64][70/88]	BT 0.109 (0.461)	DT 0.000 (0.349)	loss 0.192 (0.169)
Valid: [64][80/88]	BT 0.109 (0.459)	DT 0.000 (0.348)	loss 0.151 (0.171)
Train: [65][10/589]	BT 0.360 (0.819)	DT 0.000 (0.457)	lr 0.0001	loss 0.094 (0.098)
Train: [65][20/589]	BT 0.358 (0.597)	DT 0.000 (0.235)	lr 0.0001	loss 0.093 (0.095)
Train: [65][30/589]	BT 0.358 (0.533)	DT 0.000 (0.173)	lr 0.0001	loss 0.078 (0.094)
Train: [65][40/589]	BT 0.358 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.075 (0.093)
Train: [65][50/589]	BT 0.358 (0.470)	DT 0.000 (0.111)	lr 0.0001	loss 0.108 (0.094)
Train: [65][60/589]	BT 0.358 (0.452)	DT 0.000 (0.092)	lr 0.0001	loss 0.110 (0.095)
Train: [65][70/589]	BT 0.368 (0.447)	DT 0.000 (0.087)	lr 0.0001	loss 0.100 (0.095)
Train: [65][80/589]	BT 0.379 (0.454)	DT 0.000 (0.094)	lr 0.0001	loss 0.107 (0.095)
Train: [65][90/589]	BT 0.356 (0.452)	DT 0.000 (0.092)	lr 0.0001	loss 0.094 (0.095)
Train: [65][100/589]	BT 0.360 (0.451)	DT 0.000 (0.091)	lr 0.0001	loss 0.113 (0.095)
Train: [65][110/589]	BT 0.358 (0.450)	DT 0.000 (0.090)	lr 0.0001	loss 0.109 (0.096)
Train: [65][120/589]	BT 0.357 (0.444)	DT 0.000 (0.083)	lr 0.0001	loss 0.103 (0.096)
Train: [65][130/589]	BT 0.387 (0.438)	DT 0.000 (0.077)	lr 0.0001	loss 0.111 (0.096)
Train: [65][140/589]	BT 0.358 (0.433)	DT 0.000 (0.073)	lr 0.0001	loss 0.098 (0.096)
Train: [65][150/589]	BT 0.368 (0.433)	DT 0.000 (0.072)	lr 0.0001	loss 0.095 (0.096)
Train: [65][160/589]	BT 0.360 (0.428)	DT 0.000 (0.068)	lr 0.0001	loss 0.113 (0.096)
Train: [65][170/589]	BT 0.357 (0.426)	DT 0.000 (0.065)	lr 0.0001	loss 0.100 (0.096)
Train: [65][180/589]	BT 0.360 (0.434)	DT 0.000 (0.073)	lr 0.0001	loss 0.095 (0.096)
Train: [65][190/589]	BT 0.395 (0.436)	DT 0.000 (0.075)	lr 0.0001	loss 0.077 (0.095)
Train: [65][200/589]	BT 0.358 (0.435)	DT 0.000 (0.074)	lr 0.0001	loss 0.094 (0.095)
Train: [65][210/589]	BT 0.389 (0.436)	DT 0.000 (0.075)	lr 0.0001	loss 0.108 (0.095)
Train: [65][220/589]	BT 0.357 (0.438)	DT 0.000 (0.077)	lr 0.0001	loss 0.070 (0.095)
Train: [65][230/589]	BT 0.388 (0.445)	DT 0.000 (0.084)	lr 0.0001	loss 0.093 (0.095)
Train: [65][240/589]	BT 0.361 (0.449)	DT 0.000 (0.088)	lr 0.0001	loss 0.095 (0.095)
Train: [65][250/589]	BT 0.359 (0.451)	DT 0.000 (0.090)	lr 0.0001	loss 0.105 (0.095)
Train: [65][260/589]	BT 0.359 (0.457)	DT 0.000 (0.096)	lr 0.0001	loss 0.091 (0.095)
Train: [65][270/589]	BT 0.359 (0.458)	DT 0.000 (0.097)	lr 0.0001	loss 0.086 (0.095)
Train: [65][280/589]	BT 0.359 (0.460)	DT 0.000 (0.100)	lr 0.0001	loss 0.097 (0.095)
Train: [65][290/589]	BT 0.360 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.093 (0.095)
Train: [65][300/589]	BT 0.358 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.076 (0.095)
Train: [65][310/589]	BT 0.359 (0.464)	DT 0.000 (0.104)	lr 0.0001	loss 0.101 (0.095)
Train: [65][320/589]	BT 0.359 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.101 (0.095)
Train: [65][330/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.095 (0.095)
Train: [65][340/589]	BT 0.361 (0.465)	DT 0.000 (0.105)	lr 0.0001	loss 0.103 (0.095)
Train: [65][350/589]	BT 0.359 (0.466)	DT 0.000 (0.105)	lr 0.0001	loss 0.116 (0.095)
Train: [65][360/589]	BT 0.359 (0.467)	DT 0.000 (0.107)	lr 0.0001	loss 0.102 (0.095)
Train: [65][370/589]	BT 0.358 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.110 (0.096)
Train: [65][380/589]	BT 0.358 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.106 (0.096)
Train: [65][390/589]	BT 0.358 (0.476)	DT 0.000 (0.115)	lr 0.0001	loss 0.098 (0.096)
Train: [65][400/589]	BT 0.392 (0.478)	DT 0.000 (0.117)	lr 0.0001	loss 0.109 (0.096)
Train: [65][410/589]	BT 0.358 (0.478)	DT 0.000 (0.117)	lr 0.0001	loss 0.105 (0.096)
Train: [65][420/589]	BT 0.357 (0.482)	DT 0.000 (0.121)	lr 0.0001	loss 0.098 (0.096)
Train: [65][430/589]	BT 0.359 (0.482)	DT 0.000 (0.121)	lr 0.0001	loss 0.098 (0.096)
Train: [65][440/589]	BT 0.358 (0.483)	DT 0.000 (0.123)	lr 0.0001	loss 0.104 (0.096)
Train: [65][450/589]	BT 0.358 (0.484)	DT 0.000 (0.123)	lr 0.0001	loss 0.102 (0.096)
Train: [65][460/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0001	loss 0.075 (0.096)
Train: [65][470/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0001	loss 0.114 (0.096)
Train: [65][480/589]	BT 0.357 (0.491)	DT 0.000 (0.130)	lr 0.0001	loss 0.092 (0.096)
Train: [65][490/589]	BT 0.357 (0.491)	DT 0.000 (0.130)	lr 0.0001	loss 0.082 (0.096)
Train: [65][500/589]	BT 0.357 (0.492)	DT 0.000 (0.131)	lr 0.0001	loss 0.087 (0.096)
Train: [65][510/589]	BT 0.359 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.092 (0.096)
Train: [65][520/589]	BT 0.358 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.099 (0.096)
Train: [65][530/589]	BT 0.361 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.081 (0.096)
Train: [65][540/589]	BT 0.413 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.083 (0.096)
Train: [65][550/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.085 (0.097)
Train: [65][560/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.076 (0.097)
Train: [65][570/589]	BT 0.360 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.107 (0.097)
Train: [65][580/589]	BT 0.357 (0.498)	DT 0.000 (0.137)	lr 0.0001	loss 0.100 (0.097)
epoch 65, total time 295.14
loss: 0.0965905266267645@Epoch: 65
learning_rate: 0.0001,65
Valid: [65][10/88]	BT 0.109 (0.807)	DT 0.000 (0.693)	loss 0.174 (0.172)
Valid: [65][20/88]	BT 0.110 (0.706)	DT 0.000 (0.593)	loss 0.193 (0.177)
Valid: [65][30/88]	BT 0.110 (0.676)	DT 0.000 (0.564)	loss 0.156 (0.174)
Valid: [65][40/88]	BT 0.109 (0.673)	DT 0.000 (0.562)	loss 0.188 (0.175)
Valid: [65][50/88]	BT 0.110 (0.662)	DT 0.000 (0.551)	loss 0.213 (0.175)
Valid: [65][60/88]	BT 0.110 (0.663)	DT 0.000 (0.552)	loss 0.169 (0.174)
Valid: [65][70/88]	BT 0.109 (0.645)	DT 0.000 (0.534)	loss 0.160 (0.175)
Valid: [65][80/88]	BT 0.109 (0.638)	DT 0.000 (0.527)	loss 0.216 (0.175)
Train: [66][10/589]	BT 0.359 (0.971)	DT 0.000 (0.613)	lr 0.0001	loss 0.071 (0.097)
Train: [66][20/589]	BT 0.358 (0.715)	DT 0.000 (0.357)	lr 0.0001	loss 0.081 (0.095)
Train: [66][30/589]	BT 0.357 (0.610)	DT 0.000 (0.252)	lr 0.0001	loss 0.082 (0.094)
Train: [66][40/589]	BT 0.358 (0.592)	DT 0.000 (0.233)	lr 0.0001	loss 0.091 (0.094)
Train: [66][50/589]	BT 0.364 (0.574)	DT 0.000 (0.215)	lr 0.0001	loss 0.095 (0.095)
Train: [66][60/589]	BT 0.357 (0.541)	DT 0.000 (0.183)	lr 0.0001	loss 0.085 (0.095)
Train: [66][70/589]	BT 0.356 (0.529)	DT 0.000 (0.170)	lr 0.0001	loss 0.096 (0.095)
Train: [66][80/589]	BT 0.371 (0.521)	DT 0.000 (0.162)	lr 0.0001	loss 0.098 (0.095)
Train: [66][90/589]	BT 0.358 (0.522)	DT 0.000 (0.164)	lr 0.0001	loss 0.076 (0.094)
Train: [66][100/589]	BT 0.359 (0.516)	DT 0.000 (0.157)	lr 0.0001	loss 0.107 (0.094)
Train: [66][110/589]	BT 0.388 (0.511)	DT 0.000 (0.151)	lr 0.0001	loss 0.123 (0.094)
Train: [66][120/589]	BT 0.357 (0.505)	DT 0.000 (0.145)	lr 0.0001	loss 0.115 (0.094)
Train: [66][130/589]	BT 0.358 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.098 (0.095)
Train: [66][140/589]	BT 0.356 (0.498)	DT 0.000 (0.139)	lr 0.0001	loss 0.104 (0.095)
Train: [66][150/589]	BT 0.357 (0.497)	DT 0.000 (0.137)	lr 0.0001	loss 0.105 (0.095)
Train: [66][160/589]	BT 0.400 (0.502)	DT 0.000 (0.143)	lr 0.0001	loss 0.111 (0.096)
Train: [66][170/589]	BT 0.358 (0.506)	DT 0.000 (0.147)	lr 0.0001	loss 0.087 (0.095)
Train: [66][180/589]	BT 0.358 (0.505)	DT 0.000 (0.145)	lr 0.0001	loss 0.090 (0.095)
Train: [66][190/589]	BT 0.359 (0.503)	DT 0.000 (0.144)	lr 0.0001	loss 0.103 (0.095)
Train: [66][200/589]	BT 0.358 (0.501)	DT 0.000 (0.142)	lr 0.0001	loss 0.077 (0.095)
Train: [66][210/589]	BT 0.361 (0.506)	DT 0.000 (0.146)	lr 0.0001	loss 0.099 (0.095)
Train: [66][220/589]	BT 0.358 (0.508)	DT 0.000 (0.148)	lr 0.0001	loss 0.088 (0.095)
Train: [66][230/589]	BT 0.357 (0.503)	DT 0.000 (0.143)	lr 0.0001	loss 0.082 (0.095)
Train: [66][240/589]	BT 0.359 (0.504)	DT 0.000 (0.145)	lr 0.0001	loss 0.080 (0.095)
Train: [66][250/589]	BT 0.358 (0.503)	DT 0.000 (0.144)	lr 0.0001	loss 0.099 (0.095)
Train: [66][260/589]	BT 0.358 (0.501)	DT 0.000 (0.142)	lr 0.0001	loss 0.096 (0.095)
Train: [66][270/589]	BT 0.357 (0.499)	DT 0.000 (0.140)	lr 0.0001	loss 0.103 (0.095)
Train: [66][280/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0001	loss 0.092 (0.095)
Train: [66][290/589]	BT 0.357 (0.499)	DT 0.000 (0.139)	lr 0.0001	loss 0.092 (0.095)
Train: [66][300/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0001	loss 0.117 (0.095)
Train: [66][310/589]	BT 0.388 (0.499)	DT 0.000 (0.139)	lr 0.0001	loss 0.129 (0.095)
Train: [66][320/589]	BT 0.359 (0.501)	DT 0.000 (0.141)	lr 0.0001	loss 0.100 (0.095)
Train: [66][330/589]	BT 0.358 (0.502)	DT 0.000 (0.141)	lr 0.0001	loss 0.106 (0.095)
Train: [66][340/589]	BT 0.358 (0.499)	DT 0.000 (0.139)	lr 0.0001	loss 0.071 (0.095)
Train: [66][350/589]	BT 0.359 (0.497)	DT 0.000 (0.137)	lr 0.0001	loss 0.086 (0.095)
Train: [66][360/589]	BT 0.396 (0.497)	DT 0.000 (0.137)	lr 0.0001	loss 0.085 (0.095)
Train: [66][370/589]	BT 0.359 (0.495)	DT 0.000 (0.134)	lr 0.0001	loss 0.074 (0.095)
Train: [66][380/589]	BT 0.359 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.086 (0.095)
Train: [66][390/589]	BT 0.359 (0.492)	DT 0.000 (0.132)	lr 0.0001	loss 0.097 (0.095)
Train: [66][400/589]	BT 0.358 (0.492)	DT 0.000 (0.131)	lr 0.0001	loss 0.098 (0.095)
Train: [66][410/589]	BT 0.358 (0.493)	DT 0.000 (0.132)	lr 0.0001	loss 0.095 (0.095)
Train: [66][420/589]	BT 0.358 (0.491)	DT 0.000 (0.131)	lr 0.0001	loss 0.092 (0.095)
Train: [66][430/589]	BT 0.360 (0.490)	DT 0.000 (0.130)	lr 0.0001	loss 0.104 (0.095)
Train: [66][440/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0001	loss 0.106 (0.095)
Train: [66][450/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.089 (0.095)
Train: [66][460/589]	BT 0.357 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.109 (0.095)
Train: [66][470/589]	BT 0.357 (0.496)	DT 0.000 (0.136)	lr 0.0001	loss 0.100 (0.095)
Train: [66][480/589]	BT 0.358 (0.498)	DT 0.000 (0.138)	lr 0.0001	loss 0.089 (0.095)
Train: [66][490/589]	BT 0.359 (0.498)	DT 0.000 (0.138)	lr 0.0001	loss 0.093 (0.095)
Train: [66][500/589]	BT 0.399 (0.501)	DT 0.000 (0.141)	lr 0.0001	loss 0.085 (0.095)
Train: [66][510/589]	BT 0.358 (0.502)	DT 0.000 (0.142)	lr 0.0001	loss 0.111 (0.095)
Train: [66][520/589]	BT 0.359 (0.503)	DT 0.000 (0.143)	lr 0.0001	loss 0.099 (0.095)
Train: [66][530/589]	BT 0.359 (0.504)	DT 0.000 (0.143)	lr 0.0001	loss 0.084 (0.095)
Train: [66][540/589]	BT 0.363 (0.504)	DT 0.000 (0.144)	lr 0.0001	loss 0.096 (0.095)
Train: [66][550/589]	BT 0.358 (0.505)	DT 0.000 (0.145)	lr 0.0001	loss 0.122 (0.095)
Train: [66][560/589]	BT 0.358 (0.508)	DT 0.000 (0.148)	lr 0.0001	loss 0.079 (0.095)
Train: [66][570/589]	BT 0.360 (0.508)	DT 0.000 (0.148)	lr 0.0001	loss 0.078 (0.095)
Train: [66][580/589]	BT 0.359 (0.508)	DT 0.000 (0.148)	lr 0.0001	loss 0.112 (0.095)
epoch 66, total time 299.85
loss: 0.09529510953382293@Epoch: 66
learning_rate: 0.0001,66
Valid: [66][10/88]	BT 0.110 (0.746)	DT 0.000 (0.635)	loss 0.141 (0.180)
Valid: [66][20/88]	BT 0.109 (0.633)	DT 0.000 (0.523)	loss 0.189 (0.173)
Valid: [66][30/88]	BT 0.109 (0.627)	DT 0.000 (0.517)	loss 0.186 (0.177)
Valid: [66][40/88]	BT 0.109 (0.595)	DT 0.000 (0.484)	loss 0.202 (0.176)
Valid: [66][50/88]	BT 0.110 (0.577)	DT 0.000 (0.466)	loss 0.223 (0.177)
Valid: [66][60/88]	BT 0.109 (0.562)	DT 0.000 (0.452)	loss 0.163 (0.178)
Valid: [66][70/88]	BT 0.110 (0.558)	DT 0.000 (0.447)	loss 0.201 (0.178)
Valid: [66][80/88]	BT 0.110 (0.546)	DT 0.000 (0.435)	loss 0.169 (0.177)
Train: [67][10/589]	BT 0.356 (0.890)	DT 0.000 (0.531)	lr 0.0001	loss 0.091 (0.099)
Train: [67][20/589]	BT 0.359 (0.667)	DT 0.000 (0.309)	lr 0.0001	loss 0.082 (0.093)
Train: [67][30/589]	BT 0.357 (0.595)	DT 0.000 (0.236)	lr 0.0001	loss 0.084 (0.092)
Train: [67][40/589]	BT 0.357 (0.551)	DT 0.000 (0.192)	lr 0.0001	loss 0.087 (0.093)
Train: [67][50/589]	BT 0.360 (0.513)	DT 0.000 (0.154)	lr 0.0001	loss 0.090 (0.095)
Train: [67][60/589]	BT 0.396 (0.493)	DT 0.000 (0.132)	lr 0.0001	loss 0.081 (0.094)
Train: [67][70/589]	BT 0.376 (0.477)	DT 0.000 (0.116)	lr 0.0001	loss 0.098 (0.094)
Train: [67][80/589]	BT 0.360 (0.474)	DT 0.000 (0.113)	lr 0.0001	loss 0.086 (0.094)
Train: [67][90/589]	BT 0.384 (0.478)	DT 0.000 (0.117)	lr 0.0001	loss 0.104 (0.094)
Train: [67][100/589]	BT 0.388 (0.472)	DT 0.000 (0.111)	lr 0.0001	loss 0.096 (0.093)
Train: [67][110/589]	BT 0.358 (0.466)	DT 0.000 (0.105)	lr 0.0001	loss 0.087 (0.093)
Train: [67][120/589]	BT 0.357 (0.465)	DT 0.000 (0.103)	lr 0.0001	loss 0.096 (0.093)
Train: [67][130/589]	BT 0.396 (0.460)	DT 0.000 (0.098)	lr 0.0001	loss 0.112 (0.093)
Train: [67][140/589]	BT 0.359 (0.457)	DT 0.000 (0.095)	lr 0.0001	loss 0.096 (0.093)
Train: [67][150/589]	BT 0.359 (0.454)	DT 0.000 (0.092)	lr 0.0001	loss 0.094 (0.094)
Train: [67][160/589]	BT 0.358 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.089 (0.094)
Train: [67][170/589]	BT 0.366 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.088 (0.094)
Train: [67][180/589]	BT 0.364 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.090 (0.094)
Train: [67][190/589]	BT 0.359 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.084 (0.094)
Train: [67][200/589]	BT 0.358 (0.450)	DT 0.000 (0.088)	lr 0.0001	loss 0.103 (0.094)
Train: [67][210/589]	BT 0.358 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.085 (0.094)
Train: [67][220/589]	BT 0.394 (0.447)	DT 0.000 (0.086)	lr 0.0001	loss 0.103 (0.094)
Train: [67][230/589]	BT 0.358 (0.443)	DT 0.000 (0.082)	lr 0.0001	loss 0.090 (0.094)
Train: [67][240/589]	BT 0.359 (0.440)	DT 0.000 (0.079)	lr 0.0001	loss 0.087 (0.094)
Train: [67][250/589]	BT 0.357 (0.438)	DT 0.000 (0.077)	lr 0.0001	loss 0.106 (0.094)
Train: [67][260/589]	BT 0.361 (0.436)	DT 0.000 (0.074)	lr 0.0001	loss 0.119 (0.094)
Train: [67][270/589]	BT 0.359 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.113 (0.094)
Train: [67][280/589]	BT 0.358 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.105 (0.094)
Train: [67][290/589]	BT 0.359 (0.436)	DT 0.000 (0.075)	lr 0.0001	loss 0.105 (0.094)
Train: [67][300/589]	BT 0.357 (0.433)	DT 0.000 (0.072)	lr 0.0001	loss 0.095 (0.094)
Train: [67][310/589]	BT 0.379 (0.432)	DT 0.000 (0.071)	lr 0.0001	loss 0.095 (0.094)
Train: [67][320/589]	BT 0.358 (0.432)	DT 0.000 (0.071)	lr 0.0001	loss 0.089 (0.094)
Train: [67][330/589]	BT 0.360 (0.430)	DT 0.000 (0.068)	lr 0.0001	loss 0.093 (0.094)
Train: [67][340/589]	BT 0.361 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.105 (0.094)
Train: [67][350/589]	BT 0.357 (0.427)	DT 0.000 (0.066)	lr 0.0001	loss 0.098 (0.094)
Train: [67][360/589]	BT 0.359 (0.428)	DT 0.000 (0.067)	lr 0.0001	loss 0.104 (0.094)
Train: [67][370/589]	BT 0.359 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.090 (0.094)
Train: [67][380/589]	BT 0.359 (0.426)	DT 0.000 (0.065)	lr 0.0001	loss 0.123 (0.094)
Train: [67][390/589]	BT 0.370 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.092 (0.094)
Train: [67][400/589]	BT 0.357 (0.427)	DT 0.000 (0.065)	lr 0.0001	loss 0.088 (0.094)
Train: [67][410/589]	BT 0.359 (0.428)	DT 0.000 (0.067)	lr 0.0001	loss 0.108 (0.094)
Train: [67][420/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.082 (0.094)
Train: [67][430/589]	BT 0.361 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.080 (0.094)
Train: [67][440/589]	BT 0.359 (0.428)	DT 0.000 (0.066)	lr 0.0001	loss 0.087 (0.094)
Train: [67][450/589]	BT 0.358 (0.427)	DT 0.000 (0.066)	lr 0.0001	loss 0.109 (0.094)
Train: [67][460/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.096 (0.094)
Train: [67][470/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.098 (0.094)
Train: [67][480/589]	BT 0.359 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.108 (0.094)
Train: [67][490/589]	BT 0.359 (0.432)	DT 0.000 (0.070)	lr 0.0001	loss 0.100 (0.094)
Train: [67][500/589]	BT 0.357 (0.434)	DT 0.000 (0.073)	lr 0.0001	loss 0.096 (0.094)
Train: [67][510/589]	BT 0.358 (0.435)	DT 0.000 (0.073)	lr 0.0001	loss 0.103 (0.094)
Train: [67][520/589]	BT 0.358 (0.437)	DT 0.000 (0.075)	lr 0.0001	loss 0.074 (0.094)
Train: [67][530/589]	BT 0.359 (0.438)	DT 0.000 (0.077)	lr 0.0001	loss 0.097 (0.095)
Train: [67][540/589]	BT 0.359 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.087 (0.094)
Train: [67][550/589]	BT 0.358 (0.439)	DT 0.000 (0.077)	lr 0.0001	loss 0.084 (0.095)
Train: [67][560/589]	BT 0.358 (0.439)	DT 0.000 (0.077)	lr 0.0001	loss 0.092 (0.095)
Train: [67][570/589]	BT 0.357 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.089 (0.095)
Train: [67][580/589]	BT 0.359 (0.439)	DT 0.000 (0.078)	lr 0.0001	loss 0.092 (0.095)
epoch 67, total time 259.95
loss: 0.09461780860212823@Epoch: 67
learning_rate: 0.0001,67
Valid: [67][10/88]	BT 0.109 (0.700)	DT 0.000 (0.586)	loss 0.169 (0.185)
Valid: [67][20/88]	BT 0.110 (0.596)	DT 0.000 (0.485)	loss 0.173 (0.185)
Valid: [67][30/88]	BT 0.110 (0.558)	DT 0.000 (0.447)	loss 0.155 (0.183)
Valid: [67][40/88]	BT 0.110 (0.546)	DT 0.000 (0.436)	loss 0.157 (0.179)
Valid: [67][50/88]	BT 0.109 (0.524)	DT 0.000 (0.413)	loss 0.145 (0.176)
Valid: [67][60/88]	BT 0.110 (0.509)	DT 0.000 (0.399)	loss 0.162 (0.176)
Valid: [67][70/88]	BT 0.110 (0.499)	DT 0.000 (0.389)	loss 0.173 (0.174)
Valid: [67][80/88]	BT 0.109 (0.495)	DT 0.000 (0.385)	loss 0.183 (0.176)
Train: [68][10/589]	BT 0.356 (0.944)	DT 0.000 (0.584)	lr 0.0001	loss 0.080 (0.087)
Train: [68][20/589]	BT 0.359 (0.701)	DT 0.000 (0.340)	lr 0.0001	loss 0.062 (0.091)
Train: [68][30/589]	BT 0.358 (0.607)	DT 0.000 (0.246)	lr 0.0001	loss 0.099 (0.091)
Train: [68][40/589]	BT 0.359 (0.575)	DT 0.000 (0.214)	lr 0.0001	loss 0.079 (0.091)
Train: [68][50/589]	BT 0.359 (0.532)	DT 0.000 (0.171)	lr 0.0001	loss 0.089 (0.090)
Train: [68][60/589]	BT 0.390 (0.504)	DT 0.000 (0.143)	lr 0.0001	loss 0.113 (0.091)
Train: [68][70/589]	BT 0.358 (0.483)	DT 0.000 (0.122)	lr 0.0001	loss 0.085 (0.091)
Train: [68][80/589]	BT 0.360 (0.468)	DT 0.000 (0.107)	lr 0.0001	loss 0.070 (0.091)
Train: [68][90/589]	BT 0.358 (0.465)	DT 0.000 (0.105)	lr 0.0001	loss 0.083 (0.091)
Train: [68][100/589]	BT 0.358 (0.477)	DT 0.000 (0.116)	lr 0.0001	loss 0.089 (0.091)
Train: [68][110/589]	BT 0.358 (0.478)	DT 0.000 (0.117)	lr 0.0001	loss 0.109 (0.091)
Train: [68][120/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0001	loss 0.093 (0.092)
Train: [68][130/589]	BT 0.357 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.080 (0.092)
Train: [68][140/589]	BT 0.358 (0.500)	DT 0.000 (0.139)	lr 0.0001	loss 0.091 (0.092)
Train: [68][150/589]	BT 0.370 (0.501)	DT 0.000 (0.140)	lr 0.0001	loss 0.089 (0.092)
Train: [68][160/589]	BT 0.399 (0.499)	DT 0.000 (0.138)	lr 0.0001	loss 0.093 (0.092)
Train: [68][170/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0001	loss 0.103 (0.093)
Train: [68][180/589]	BT 0.357 (0.500)	DT 0.000 (0.139)	lr 0.0001	loss 0.102 (0.093)
Train: [68][190/589]	BT 0.356 (0.499)	DT 0.000 (0.138)	lr 0.0001	loss 0.092 (0.093)
Train: [68][200/589]	BT 0.359 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.081 (0.093)
Train: [68][210/589]	BT 0.358 (0.502)	DT 0.000 (0.141)	lr 0.0001	loss 0.088 (0.093)
Train: [68][220/589]	BT 0.358 (0.504)	DT 0.000 (0.144)	lr 0.0001	loss 0.094 (0.093)
Train: [68][230/589]	BT 0.356 (0.502)	DT 0.000 (0.141)	lr 0.0001	loss 0.094 (0.093)
Train: [68][240/589]	BT 0.357 (0.499)	DT 0.000 (0.138)	lr 0.0001	loss 0.102 (0.093)
Train: [68][250/589]	BT 0.358 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.096 (0.093)
Train: [68][260/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.075 (0.093)
Train: [68][270/589]	BT 0.359 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.081 (0.093)
Train: [68][280/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.086 (0.093)
Train: [68][290/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.116 (0.093)
Train: [68][300/589]	BT 0.367 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.099 (0.093)
Train: [68][310/589]	BT 0.364 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.075 (0.093)
Train: [68][320/589]	BT 0.359 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.115 (0.093)
Train: [68][330/589]	BT 0.358 (0.496)	DT 0.000 (0.135)	lr 0.0001	loss 0.090 (0.093)
Train: [68][340/589]	BT 0.388 (0.495)	DT 0.000 (0.134)	lr 0.0001	loss 0.095 (0.093)
Train: [68][350/589]	BT 0.358 (0.494)	DT 0.000 (0.133)	lr 0.0001	loss 0.074 (0.093)
Train: [68][360/589]	BT 0.395 (0.493)	DT 0.000 (0.132)	lr 0.0001	loss 0.092 (0.093)
Train: [68][370/589]	BT 0.359 (0.493)	DT 0.000 (0.132)	lr 0.0001	loss 0.095 (0.093)
Train: [68][380/589]	BT 0.457 (0.491)	DT 0.097 (0.130)	lr 0.0001	loss 0.098 (0.093)
Train: [68][390/589]	BT 2.008 (0.497)	DT 1.649 (0.136)	lr 0.0001	loss 0.096 (0.093)
Train: [68][400/589]	BT 1.412 (0.499)	DT 1.053 (0.138)	lr 0.0001	loss 0.092 (0.093)
Train: [68][410/589]	BT 1.953 (0.501)	DT 1.594 (0.140)	lr 0.0001	loss 0.092 (0.093)
Train: [68][420/589]	BT 2.167 (0.502)	DT 1.807 (0.141)	lr 0.0001	loss 0.093 (0.093)
Train: [68][430/589]	BT 1.358 (0.501)	DT 1.001 (0.140)	lr 0.0001	loss 0.093 (0.093)
Train: [68][440/589]	BT 1.826 (0.501)	DT 1.465 (0.140)	lr 0.0001	loss 0.091 (0.093)
Train: [68][450/589]	BT 1.329 (0.500)	DT 0.968 (0.139)	lr 0.0001	loss 0.129 (0.093)
Train: [68][460/589]	BT 1.002 (0.498)	DT 0.633 (0.137)	lr 0.0001	loss 0.104 (0.093)
Train: [68][470/589]	BT 3.293 (0.502)	DT 2.917 (0.141)	lr 0.0001	loss 0.079 (0.093)
Train: [68][480/589]	BT 1.750 (0.502)	DT 1.390 (0.141)	lr 0.0001	loss 0.091 (0.093)
Train: [68][490/589]	BT 1.729 (0.502)	DT 1.371 (0.141)	lr 0.0001	loss 0.083 (0.093)
Train: [68][500/589]	BT 2.629 (0.503)	DT 2.269 (0.142)	lr 0.0001	loss 0.099 (0.094)
Train: [68][510/589]	BT 1.925 (0.504)	DT 1.564 (0.143)	lr 0.0001	loss 0.078 (0.093)
Train: [68][520/589]	BT 1.114 (0.503)	DT 0.754 (0.142)	lr 0.0001	loss 0.104 (0.094)
Train: [68][530/589]	BT 1.457 (0.504)	DT 1.098 (0.143)	lr 0.0001	loss 0.091 (0.094)
Train: [68][540/589]	BT 1.204 (0.503)	DT 0.846 (0.143)	lr 0.0001	loss 0.103 (0.094)
Train: [68][550/589]	BT 1.137 (0.503)	DT 0.776 (0.142)	lr 0.0001	loss 0.091 (0.094)
Train: [68][560/589]	BT 0.804 (0.502)	DT 0.443 (0.141)	lr 0.0001	loss 0.101 (0.094)
Train: [68][570/589]	BT 0.752 (0.502)	DT 0.392 (0.141)	lr 0.0001	loss 0.085 (0.094)
Train: [68][580/589]	BT 0.358 (0.503)	DT 0.000 (0.142)	lr 0.0001	loss 0.106 (0.094)
epoch 68, total time 297.59
loss: 0.09402301142062254@Epoch: 68
learning_rate: 0.0001,68
Valid: [68][10/88]	BT 0.110 (0.815)	DT 0.000 (0.705)	loss 0.189 (0.179)
Valid: [68][20/88]	BT 0.110 (0.699)	DT 0.000 (0.589)	loss 0.181 (0.174)
Valid: [68][30/88]	BT 0.110 (0.666)	DT 0.000 (0.556)	loss 0.233 (0.175)
Valid: [68][40/88]	BT 0.110 (0.644)	DT 0.000 (0.534)	loss 0.165 (0.179)
Valid: [68][50/88]	BT 0.110 (0.627)	DT 0.000 (0.518)	loss 0.188 (0.179)
Valid: [68][60/88]	BT 0.110 (0.629)	DT 0.000 (0.519)	loss 0.193 (0.179)
Valid: [68][70/88]	BT 0.110 (0.614)	DT 0.000 (0.504)	loss 0.156 (0.179)
Valid: [68][80/88]	BT 0.110 (0.608)	DT 0.000 (0.498)	loss 0.193 (0.179)
Train: [69][10/589]	BT 0.357 (0.924)	DT 0.000 (0.567)	lr 0.0001	loss 0.080 (0.090)
Train: [69][20/589]	BT 0.355 (0.738)	DT 0.000 (0.379)	lr 0.0001	loss 0.070 (0.089)
Train: [69][30/589]	BT 0.356 (0.652)	DT 0.000 (0.294)	lr 0.0001	loss 0.097 (0.088)
Train: [69][40/589]	BT 0.358 (0.611)	DT 0.000 (0.253)	lr 0.0001	loss 0.091 (0.089)
Train: [69][50/589]	BT 0.359 (0.590)	DT 0.000 (0.232)	lr 0.0001	loss 0.089 (0.090)
Train: [69][60/589]	BT 0.359 (0.571)	DT 0.000 (0.212)	lr 0.0001	loss 0.080 (0.090)
Train: [69][70/589]	BT 0.357 (0.555)	DT 0.000 (0.196)	lr 0.0001	loss 0.090 (0.090)
Train: [69][80/589]	BT 0.376 (0.550)	DT 0.000 (0.191)	lr 0.0001	loss 0.093 (0.091)
Train: [69][90/589]	BT 0.372 (0.534)	DT 0.000 (0.175)	lr 0.0001	loss 0.102 (0.091)
Train: [69][100/589]	BT 0.358 (0.528)	DT 0.000 (0.169)	lr 0.0001	loss 0.085 (0.091)
Train: [69][110/589]	BT 0.356 (0.532)	DT 0.000 (0.172)	lr 0.0001	loss 0.084 (0.091)
Train: [69][120/589]	BT 0.359 (0.522)	DT 0.000 (0.163)	lr 0.0001	loss 0.097 (0.092)
Train: [69][130/589]	BT 0.358 (0.510)	DT 0.000 (0.150)	lr 0.0001	loss 0.073 (0.092)
Train: [69][140/589]	BT 0.363 (0.506)	DT 0.001 (0.146)	lr 0.0001	loss 0.094 (0.092)
Train: [69][150/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.097 (0.091)
Train: [69][160/589]	BT 0.362 (0.498)	DT 0.000 (0.138)	lr 0.0001	loss 0.113 (0.091)
Train: [69][170/589]	BT 0.359 (0.499)	DT 0.000 (0.139)	lr 0.0001	loss 0.083 (0.091)
Train: [69][180/589]	BT 0.356 (0.493)	DT 0.000 (0.133)	lr 0.0001	loss 0.084 (0.091)
Train: [69][190/589]	BT 0.357 (0.497)	DT 0.000 (0.136)	lr 0.0001	loss 0.098 (0.092)
Train: [69][200/589]	BT 0.358 (0.495)	DT 0.000 (0.135)	lr 0.0001	loss 0.095 (0.092)
Train: [69][210/589]	BT 0.359 (0.496)	DT 0.000 (0.136)	lr 0.0001	loss 0.086 (0.092)
Train: [69][220/589]	BT 0.356 (0.495)	DT 0.000 (0.135)	lr 0.0001	loss 0.098 (0.092)
Train: [69][230/589]	BT 0.358 (0.491)	DT 0.000 (0.130)	lr 0.0001	loss 0.098 (0.092)
Train: [69][240/589]	BT 0.359 (0.489)	DT 0.000 (0.129)	lr 0.0001	loss 0.090 (0.092)
Train: [69][250/589]	BT 0.358 (0.487)	DT 0.000 (0.127)	lr 0.0001	loss 0.106 (0.092)
Train: [69][260/589]	BT 0.358 (0.485)	DT 0.000 (0.124)	lr 0.0001	loss 0.090 (0.092)
Train: [69][270/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0001	loss 0.094 (0.092)
Train: [69][280/589]	BT 0.359 (0.489)	DT 0.000 (0.129)	lr 0.0001	loss 0.093 (0.092)
Train: [69][290/589]	BT 0.359 (0.487)	DT 0.000 (0.127)	lr 0.0001	loss 0.088 (0.092)
Train: [69][300/589]	BT 0.358 (0.484)	DT 0.000 (0.124)	lr 0.0001	loss 0.092 (0.092)
Train: [69][310/589]	BT 0.359 (0.482)	DT 0.000 (0.122)	lr 0.0001	loss 0.089 (0.092)
Train: [69][320/589]	BT 0.358 (0.483)	DT 0.000 (0.123)	lr 0.0001	loss 0.106 (0.092)
Train: [69][330/589]	BT 0.398 (0.480)	DT 0.000 (0.120)	lr 0.0001	loss 0.094 (0.092)
Train: [69][340/589]	BT 0.359 (0.479)	DT 0.000 (0.118)	lr 0.0001	loss 0.103 (0.092)
Train: [69][350/589]	BT 0.358 (0.477)	DT 0.000 (0.117)	lr 0.0001	loss 0.102 (0.092)
Train: [69][360/589]	BT 0.357 (0.475)	DT 0.000 (0.114)	lr 0.0001	loss 0.101 (0.092)
Train: [69][370/589]	BT 0.358 (0.473)	DT 0.000 (0.113)	lr 0.0001	loss 0.118 (0.092)
Train: [69][380/589]	BT 0.359 (0.472)	DT 0.000 (0.111)	lr 0.0001	loss 0.111 (0.092)
Train: [69][390/589]	BT 0.357 (0.469)	DT 0.000 (0.109)	lr 0.0001	loss 0.093 (0.092)
Train: [69][400/589]	BT 0.393 (0.467)	DT 0.000 (0.106)	lr 0.0001	loss 0.088 (0.093)
Train: [69][410/589]	BT 0.358 (0.465)	DT 0.000 (0.105)	lr 0.0001	loss 0.109 (0.093)
Train: [69][420/589]	BT 0.375 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.094 (0.093)
Train: [69][430/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.105 (0.093)
Train: [69][440/589]	BT 0.359 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.078 (0.093)
Train: [69][450/589]	BT 0.357 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.098 (0.093)
Train: [69][460/589]	BT 0.360 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.096 (0.093)
Train: [69][470/589]	BT 0.359 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.098 (0.093)
Train: [69][480/589]	BT 0.397 (0.461)	DT 0.000 (0.100)	lr 0.0001	loss 0.088 (0.093)
Train: [69][490/589]	BT 0.361 (0.460)	DT 0.000 (0.099)	lr 0.0001	loss 0.083 (0.093)
Train: [69][500/589]	BT 0.357 (0.462)	DT 0.000 (0.101)	lr 0.0001	loss 0.093 (0.093)
Train: [69][510/589]	BT 0.361 (0.461)	DT 0.000 (0.100)	lr 0.0001	loss 0.095 (0.093)
Train: [69][520/589]	BT 0.358 (0.461)	DT 0.000 (0.100)	lr 0.0001	loss 0.107 (0.093)
Train: [69][530/589]	BT 0.358 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.091 (0.093)
Train: [69][540/589]	BT 0.362 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.086 (0.093)
Train: [69][550/589]	BT 0.358 (0.464)	DT 0.000 (0.103)	lr 0.0001	loss 0.094 (0.093)
Train: [69][560/589]	BT 0.357 (0.469)	DT 0.000 (0.108)	lr 0.0001	loss 0.081 (0.093)
Train: [69][570/589]	BT 0.359 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.096 (0.093)
Train: [69][580/589]	BT 0.357 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.088 (0.093)
epoch 69, total time 279.47
loss: 0.09262201950723309@Epoch: 69
learning_rate: 0.0001,69
Valid: [69][10/88]	BT 0.109 (0.695)	DT 0.000 (0.586)	loss 0.190 (0.168)
Valid: [69][20/88]	BT 0.109 (0.557)	DT 0.000 (0.447)	loss 0.169 (0.173)
Valid: [69][30/88]	BT 0.110 (0.514)	DT 0.000 (0.403)	loss 0.193 (0.176)
Valid: [69][40/88]	BT 0.109 (0.495)	DT 0.000 (0.384)	loss 0.141 (0.175)
Valid: [69][50/88]	BT 0.109 (0.511)	DT 0.000 (0.400)	loss 0.202 (0.175)
Valid: [69][60/88]	BT 0.110 (0.504)	DT 0.000 (0.393)	loss 0.170 (0.175)
Valid: [69][70/88]	BT 0.109 (0.515)	DT 0.000 (0.404)	loss 0.195 (0.176)
Valid: [69][80/88]	BT 0.109 (0.502)	DT 0.000 (0.392)	loss 0.153 (0.176)
Train: [70][10/589]	BT 0.358 (0.955)	DT 0.000 (0.594)	lr 0.0001	loss 0.088 (0.092)
Train: [70][20/589]	BT 0.360 (0.698)	DT 0.000 (0.338)	lr 0.0001	loss 0.105 (0.092)
Train: [70][30/589]	BT 0.357 (0.605)	DT 0.000 (0.246)	lr 0.0001	loss 0.077 (0.093)
Train: [70][40/589]	BT 0.357 (0.554)	DT 0.000 (0.195)	lr 0.0001	loss 0.085 (0.092)
Train: [70][50/589]	BT 0.357 (0.558)	DT 0.000 (0.199)	lr 0.0001	loss 0.102 (0.092)
Train: [70][60/589]	BT 0.357 (0.539)	DT 0.000 (0.180)	lr 0.0001	loss 0.083 (0.091)
Train: [70][70/589]	BT 0.359 (0.521)	DT 0.000 (0.162)	lr 0.0001	loss 0.092 (0.091)
Train: [70][80/589]	BT 0.359 (0.508)	DT 0.000 (0.149)	lr 0.0001	loss 0.070 (0.091)
Train: [70][90/589]	BT 0.359 (0.505)	DT 0.000 (0.146)	lr 0.0001	loss 0.098 (0.091)
Train: [70][100/589]	BT 0.357 (0.496)	DT 0.000 (0.137)	lr 0.0001	loss 0.094 (0.091)
Train: [70][110/589]	BT 0.375 (0.485)	DT 0.000 (0.125)	lr 0.0001	loss 0.099 (0.091)
Train: [70][120/589]	BT 0.357 (0.475)	DT 0.000 (0.115)	lr 0.0001	loss 0.108 (0.091)
Train: [70][130/589]	BT 0.384 (0.471)	DT 0.000 (0.111)	lr 0.0001	loss 0.083 (0.091)
Train: [70][140/589]	BT 0.364 (0.464)	DT 0.000 (0.104)	lr 0.0001	loss 0.092 (0.091)
Train: [70][150/589]	BT 0.358 (0.461)	DT 0.000 (0.101)	lr 0.0001	loss 0.085 (0.091)
Train: [70][160/589]	BT 0.359 (0.460)	DT 0.000 (0.100)	lr 0.0001	loss 0.114 (0.091)
Train: [70][170/589]	BT 0.359 (0.466)	DT 0.000 (0.106)	lr 0.0001	loss 0.095 (0.091)
Train: [70][180/589]	BT 0.388 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.097 (0.091)
Train: [70][190/589]	BT 0.371 (0.462)	DT 0.000 (0.102)	lr 0.0001	loss 0.102 (0.091)
Train: [70][200/589]	BT 0.368 (0.461)	DT 0.000 (0.100)	lr 0.0001	loss 0.108 (0.091)
Train: [70][210/589]	BT 0.359 (0.459)	DT 0.000 (0.098)	lr 0.0001	loss 0.088 (0.091)
Train: [70][220/589]	BT 0.359 (0.455)	DT 0.000 (0.094)	lr 0.0001	loss 0.115 (0.091)
Train: [70][230/589]	BT 0.358 (0.454)	DT 0.000 (0.093)	lr 0.0001	loss 0.090 (0.091)
Train: [70][240/589]	BT 0.358 (0.451)	DT 0.000 (0.090)	lr 0.0001	loss 0.110 (0.091)
Train: [70][250/589]	BT 0.387 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.086 (0.091)
Train: [70][260/589]	BT 0.360 (0.452)	DT 0.000 (0.091)	lr 0.0001	loss 0.070 (0.091)
Train: [70][270/589]	BT 0.358 (0.453)	DT 0.000 (0.091)	lr 0.0001	loss 0.089 (0.091)
Train: [70][280/589]	BT 0.359 (0.452)	DT 0.000 (0.091)	lr 0.0001	loss 0.080 (0.091)
Train: [70][290/589]	BT 0.361 (0.451)	DT 0.000 (0.089)	lr 0.0001	loss 0.093 (0.091)
Train: [70][300/589]	BT 0.359 (0.450)	DT 0.000 (0.089)	lr 0.0001	loss 0.116 (0.091)
Train: [70][310/589]	BT 0.359 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.086 (0.091)
Train: [70][320/589]	BT 0.360 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.108 (0.091)
Train: [70][330/589]	BT 0.358 (0.446)	DT 0.000 (0.085)	lr 0.0001	loss 0.114 (0.091)
Train: [70][340/589]	BT 0.358 (0.446)	DT 0.000 (0.085)	lr 0.0001	loss 0.075 (0.091)
Train: [70][350/589]	BT 0.360 (0.444)	DT 0.000 (0.082)	lr 0.0001	loss 0.071 (0.091)
Train: [70][360/589]	BT 0.359 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.107 (0.091)
Train: [70][370/589]	BT 0.360 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.083 (0.091)
Train: [70][380/589]	BT 0.390 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.095 (0.091)
Train: [70][390/589]	BT 0.359 (0.449)	DT 0.000 (0.088)	lr 0.0001	loss 0.090 (0.091)
Train: [70][400/589]	BT 0.361 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.112 (0.091)
Train: [70][410/589]	BT 0.357 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.084 (0.091)
Train: [70][420/589]	BT 0.359 (0.448)	DT 0.000 (0.087)	lr 0.0001	loss 0.079 (0.091)
Train: [70][430/589]	BT 0.358 (0.449)	DT 0.000 (0.087)	lr 0.0001	loss 0.098 (0.091)
Train: [70][440/589]	BT 0.359 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.107 (0.091)
Train: [70][450/589]	BT 0.360 (0.448)	DT 0.000 (0.086)	lr 0.0001	loss 0.081 (0.091)
Train: [70][460/589]	BT 0.358 (0.447)	DT 0.000 (0.085)	lr 0.0001	loss 0.098 (0.091)
Train: [70][470/589]	BT 0.388 (0.446)	DT 0.000 (0.084)	lr 0.0001	loss 0.106 (0.091)
Train: [70][480/589]	BT 0.359 (0.445)	DT 0.000 (0.083)	lr 0.0001	loss 0.103 (0.091)
Train: [70][490/589]	BT 0.360 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.091 (0.092)
Train: [70][500/589]	BT 0.360 (0.442)	DT 0.000 (0.080)	lr 0.0001	loss 0.092 (0.092)
Train: [70][510/589]	BT 0.359 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.077 (0.092)
Train: [70][520/589]	BT 0.359 (0.442)	DT 0.000 (0.080)	lr 0.0001	loss 0.115 (0.092)
Train: [70][530/589]	BT 0.359 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.101 (0.092)
Train: [70][540/589]	BT 0.358 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.097 (0.092)
Train: [70][550/589]	BT 0.360 (0.442)	DT 0.000 (0.080)	lr 0.0001	loss 0.097 (0.092)
Train: [70][560/589]	BT 0.358 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.088 (0.092)
Train: [70][570/589]	BT 0.358 (0.442)	DT 0.000 (0.080)	lr 0.0001	loss 0.085 (0.092)
Train: [70][580/589]	BT 0.359 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.107 (0.092)
epoch 70, total time 261.30
loss: 0.0921463584137591@Epoch: 70
learning_rate: 0.0001,70
Valid: [70][10/88]	BT 0.110 (0.670)	DT 0.000 (0.559)	loss 0.148 (0.183)
Valid: [70][20/88]	BT 0.110 (0.534)	DT 0.000 (0.422)	loss 0.218 (0.181)
Valid: [70][30/88]	BT 0.110 (0.497)	DT 0.000 (0.386)	loss 0.152 (0.181)
Valid: [70][40/88]	BT 0.109 (0.478)	DT 0.000 (0.367)	loss 0.211 (0.184)
Valid: [70][50/88]	BT 0.110 (0.474)	DT 0.000 (0.363)	loss 0.189 (0.183)
Valid: [70][60/88]	BT 0.110 (0.461)	DT 0.000 (0.350)	loss 0.242 (0.184)
Valid: [70][70/88]	BT 0.109 (0.456)	DT 0.000 (0.345)	loss 0.175 (0.185)
Valid: [70][80/88]	BT 0.110 (0.458)	DT 0.000 (0.347)	loss 0.181 (0.184)
Train: [71][10/589]	BT 0.372 (0.977)	DT 0.000 (0.619)	lr 0.0001	loss 0.073 (0.086)
Train: [71][20/589]	BT 0.358 (0.718)	DT 0.000 (0.359)	lr 0.0001	loss 0.093 (0.091)
Train: [71][30/589]	BT 0.358 (0.611)	DT 0.000 (0.253)	lr 0.0001	loss 0.092 (0.089)
Train: [71][40/589]	BT 0.358 (0.557)	DT 0.000 (0.199)	lr 0.0001	loss 0.109 (0.089)
Train: [71][50/589]	BT 0.362 (0.535)	DT 0.000 (0.176)	lr 0.0001	loss 0.075 (0.090)
Train: [71][60/589]	BT 0.358 (0.518)	DT 0.000 (0.160)	lr 0.0001	loss 0.099 (0.090)
Train: [71][70/589]	BT 0.358 (0.514)	DT 0.000 (0.156)	lr 0.0001	loss 0.091 (0.089)
Train: [71][80/589]	BT 0.358 (0.495)	DT 0.000 (0.137)	lr 0.0001	loss 0.074 (0.089)
Train: [71][90/589]	BT 0.393 (0.481)	DT 0.000 (0.122)	lr 0.0001	loss 0.079 (0.089)
Train: [71][100/589]	BT 0.391 (0.476)	DT 0.000 (0.116)	lr 0.0001	loss 0.096 (0.090)
Train: [71][110/589]	BT 0.357 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.096 (0.090)
Train: [71][120/589]	BT 0.359 (0.461)	DT 0.000 (0.101)	lr 0.0001	loss 0.090 (0.090)
Train: [71][130/589]	BT 0.359 (0.456)	DT 0.000 (0.095)	lr 0.0001	loss 0.089 (0.089)
Train: [71][140/589]	BT 0.360 (0.452)	DT 0.000 (0.091)	lr 0.0001	loss 0.082 (0.089)
Train: [71][150/589]	BT 0.379 (0.449)	DT 0.000 (0.088)	lr 0.0001	loss 0.075 (0.089)
Train: [71][160/589]	BT 0.359 (0.445)	DT 0.000 (0.084)	lr 0.0001	loss 0.086 (0.089)
Train: [71][170/589]	BT 0.399 (0.445)	DT 0.000 (0.084)	lr 0.0001	loss 0.085 (0.089)
Train: [71][180/589]	BT 0.359 (0.443)	DT 0.000 (0.081)	lr 0.0001	loss 0.123 (0.089)
Train: [71][190/589]	BT 0.367 (0.440)	DT 0.000 (0.079)	lr 0.0001	loss 0.093 (0.090)
Train: [71][200/589]	BT 0.357 (0.437)	DT 0.000 (0.075)	lr 0.0001	loss 0.104 (0.090)
Train: [71][210/589]	BT 0.400 (0.433)	DT 0.000 (0.071)	lr 0.0001	loss 0.097 (0.090)
Train: [71][220/589]	BT 0.358 (0.435)	DT 0.000 (0.073)	lr 0.0001	loss 0.103 (0.090)
Train: [71][230/589]	BT 0.358 (0.433)	DT 0.000 (0.071)	lr 0.0001	loss 0.099 (0.090)
Train: [71][240/589]	BT 0.360 (0.430)	DT 0.000 (0.068)	lr 0.0001	loss 0.078 (0.090)
Train: [71][250/589]	BT 0.360 (0.427)	DT 0.000 (0.066)	lr 0.0001	loss 0.100 (0.090)
Train: [71][260/589]	BT 0.396 (0.430)	DT 0.000 (0.068)	lr 0.0001	loss 0.080 (0.090)
Train: [71][270/589]	BT 0.360 (0.427)	DT 0.000 (0.066)	lr 0.0001	loss 0.099 (0.090)
Train: [71][280/589]	BT 0.360 (0.426)	DT 0.000 (0.064)	lr 0.0001	loss 0.105 (0.091)
Train: [71][290/589]	BT 0.359 (0.425)	DT 0.000 (0.063)	lr 0.0001	loss 0.085 (0.091)
Train: [71][300/589]	BT 0.358 (0.429)	DT 0.000 (0.067)	lr 0.0001	loss 0.086 (0.091)
Train: [71][310/589]	BT 0.359 (0.430)	DT 0.000 (0.068)	lr 0.0001	loss 0.110 (0.091)
Train: [71][320/589]	BT 0.360 (0.428)	DT 0.000 (0.067)	lr 0.0001	loss 0.087 (0.091)
Train: [71][330/589]	BT 0.358 (0.430)	DT 0.000 (0.069)	lr 0.0001	loss 0.097 (0.091)
Train: [71][340/589]	BT 0.359 (0.433)	DT 0.000 (0.072)	lr 0.0001	loss 0.078 (0.091)
Train: [71][350/589]	BT 0.357 (0.431)	DT 0.000 (0.070)	lr 0.0001	loss 0.080 (0.091)
Train: [71][360/589]	BT 0.358 (0.435)	DT 0.000 (0.073)	lr 0.0001	loss 0.084 (0.091)
Train: [71][370/589]	BT 0.359 (0.441)	DT 0.000 (0.079)	lr 0.0001	loss 0.086 (0.091)
Train: [71][380/589]	BT 0.361 (0.443)	DT 0.000 (0.082)	lr 0.0001	loss 0.100 (0.091)
Train: [71][390/589]	BT 0.357 (0.445)	DT 0.000 (0.084)	lr 0.0001	loss 0.088 (0.091)
Train: [71][400/589]	BT 0.378 (0.446)	DT 0.000 (0.084)	lr 0.0001	loss 0.118 (0.091)
Train: [71][410/589]	BT 0.357 (0.446)	DT 0.000 (0.084)	lr 0.0001	loss 0.093 (0.091)
Train: [71][420/589]	BT 0.357 (0.449)	DT 0.000 (0.088)	lr 0.0001	loss 0.102 (0.091)
Train: [71][430/589]	BT 0.358 (0.451)	DT 0.000 (0.090)	lr 0.0001	loss 0.092 (0.091)
Train: [71][440/589]	BT 0.360 (0.451)	DT 0.000 (0.090)	lr 0.0001	loss 0.094 (0.091)
Train: [71][450/589]	BT 0.358 (0.451)	DT 0.000 (0.089)	lr 0.0001	loss 0.084 (0.091)
Train: [71][460/589]	BT 0.373 (0.450)	DT 0.000 (0.088)	lr 0.0001	loss 0.074 (0.091)
Train: [71][470/589]	BT 0.356 (0.453)	DT 0.000 (0.091)	lr 0.0001	loss 0.092 (0.091)
Train: [71][480/589]	BT 0.359 (0.455)	DT 0.000 (0.093)	lr 0.0001	loss 0.088 (0.091)
Train: [71][490/589]	BT 0.358 (0.459)	DT 0.000 (0.097)	lr 0.0001	loss 0.088 (0.091)
Train: [71][500/589]	BT 0.357 (0.463)	DT 0.000 (0.102)	lr 0.0001	loss 0.080 (0.091)
Train: [71][510/589]	BT 0.357 (0.465)	DT 0.000 (0.104)	lr 0.0001	loss 0.084 (0.091)
Train: [71][520/589]	BT 0.359 (0.469)	DT 0.000 (0.107)	lr 0.0001	loss 0.085 (0.091)
Train: [71][530/589]	BT 0.360 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.093 (0.091)
Train: [71][540/589]	BT 0.359 (0.471)	DT 0.000 (0.109)	lr 0.0001	loss 0.090 (0.091)
Train: [71][550/589]	BT 0.358 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.103 (0.091)
Train: [71][560/589]	BT 0.361 (0.472)	DT 0.000 (0.110)	lr 0.0001	loss 0.088 (0.091)
Train: [71][570/589]	BT 0.359 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.081 (0.091)
Train: [71][580/589]	BT 0.355 (0.472)	DT 0.000 (0.111)	lr 0.0001	loss 0.094 (0.091)
epoch 71, total time 279.70
loss: 0.09122530906278159@Epoch: 71
learning_rate: 0.0001,71
Valid: [71][10/88]	BT 0.109 (0.952)	DT 0.000 (0.839)	loss 0.199 (0.184)
Valid: [71][20/88]	BT 0.109 (0.792)	DT 0.000 (0.680)	loss 0.171 (0.190)
Valid: [71][30/88]	BT 0.109 (0.693)	DT 0.000 (0.582)	loss 0.214 (0.193)
Valid: [71][40/88]	BT 0.110 (0.643)	DT 0.000 (0.532)	loss 0.197 (0.191)
Valid: [71][50/88]	BT 0.110 (0.612)	DT 0.000 (0.501)	loss 0.228 (0.191)
Valid: [71][60/88]	BT 0.109 (0.601)	DT 0.000 (0.490)	loss 0.188 (0.192)
Valid: [71][70/88]	BT 0.109 (0.589)	DT 0.000 (0.478)	loss 0.194 (0.191)
Valid: [71][80/88]	BT 0.109 (0.581)	DT 0.000 (0.470)	loss 0.177 (0.190)
Train: [72][10/589]	BT 0.357 (1.030)	DT 0.000 (0.670)	lr 0.0001	loss 0.101 (0.088)
Train: [72][20/589]	BT 0.355 (0.785)	DT 0.000 (0.426)	lr 0.0001	loss 0.099 (0.093)
Train: [72][30/589]	BT 0.356 (0.675)	DT 0.000 (0.315)	lr 0.0001	loss 0.075 (0.091)
Train: [72][40/589]	BT 0.358 (0.634)	DT 0.000 (0.275)	lr 0.0001	loss 0.098 (0.092)
Train: [72][50/589]	BT 0.398 (0.617)	DT 0.000 (0.257)	lr 0.0001	loss 0.094 (0.093)
Train: [72][60/589]	BT 0.388 (0.587)	DT 0.000 (0.227)	lr 0.0001	loss 0.079 (0.092)
Train: [72][70/589]	BT 0.369 (0.559)	DT 0.000 (0.198)	lr 0.0001	loss 0.088 (0.092)
Train: [72][80/589]	BT 0.359 (0.545)	DT 0.000 (0.185)	lr 0.0001	loss 0.084 (0.091)
Train: [72][90/589]	BT 0.358 (0.529)	DT 0.000 (0.168)	lr 0.0001	loss 0.095 (0.091)
Train: [72][100/589]	BT 0.359 (0.522)	DT 0.000 (0.161)	lr 0.0001	loss 0.084 (0.090)
Train: [72][110/589]	BT 0.358 (0.508)	DT 0.000 (0.147)	lr 0.0001	loss 0.075 (0.090)
Train: [72][120/589]	BT 0.358 (0.504)	DT 0.000 (0.143)	lr 0.0001	loss 0.101 (0.090)
Train: [72][130/589]	BT 0.361 (0.506)	DT 0.000 (0.146)	lr 0.0001	loss 0.093 (0.090)
Train: [72][140/589]	BT 0.365 (0.502)	DT 0.000 (0.141)	lr 0.0001	loss 0.104 (0.090)
Train: [72][150/589]	BT 0.359 (0.498)	DT 0.000 (0.137)	lr 0.0001	loss 0.087 (0.090)
Train: [72][160/589]	BT 0.360 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.084 (0.090)
Train: [72][170/589]	BT 0.357 (0.497)	DT 0.000 (0.137)	lr 0.0001	loss 0.074 (0.090)
Train: [72][180/589]	BT 0.361 (0.492)	DT 0.000 (0.132)	lr 0.0001	loss 0.086 (0.090)
Train: [72][190/589]	BT 0.358 (0.489)	DT 0.000 (0.129)	lr 0.0001	loss 0.076 (0.090)
Train: [72][200/589]	BT 0.357 (0.491)	DT 0.000 (0.130)	lr 0.0001	loss 0.083 (0.090)
Train: [72][210/589]	BT 0.359 (0.487)	DT 0.000 (0.127)	lr 0.0001	loss 0.086 (0.090)
Train: [72][220/589]	BT 0.359 (0.484)	DT 0.000 (0.123)	lr 0.0001	loss 0.097 (0.090)
Train: [72][230/589]	BT 0.359 (0.480)	DT 0.000 (0.119)	lr 0.0001	loss 0.100 (0.090)
Train: [72][240/589]	BT 0.359 (0.477)	DT 0.000 (0.116)	lr 0.0001	loss 0.100 (0.090)
Train: [72][250/589]	BT 0.359 (0.475)	DT 0.000 (0.115)	lr 0.0001	loss 0.077 (0.090)
Train: [72][260/589]	BT 0.359 (0.473)	DT 0.000 (0.113)	lr 0.0001	loss 0.074 (0.090)
Train: [72][270/589]	BT 0.378 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.079 (0.090)
Train: [72][280/589]	BT 0.358 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.093 (0.090)
Train: [72][290/589]	BT 0.390 (0.474)	DT 0.000 (0.113)	lr 0.0001	loss 0.084 (0.090)
Train: [72][300/589]	BT 0.358 (0.472)	DT 0.000 (0.111)	lr 0.0001	loss 0.092 (0.090)
Train: [72][310/589]	BT 0.361 (0.470)	DT 0.000 (0.109)	lr 0.0001	loss 0.109 (0.090)
Train: [72][320/589]	BT 0.360 (0.468)	DT 0.000 (0.107)	lr 0.0001	loss 0.097 (0.090)
Train: [72][330/589]	BT 0.358 (0.469)	DT 0.000 (0.108)	lr 0.0001	loss 0.071 (0.090)
Train: [72][340/589]	BT 0.357 (0.472)	DT 0.000 (0.112)	lr 0.0001	loss 0.088 (0.090)
Train: [72][350/589]	BT 0.356 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.075 (0.090)
Train: [72][360/589]	BT 0.358 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.073 (0.090)
Train: [72][370/589]	BT 0.359 (0.469)	DT 0.000 (0.108)	lr 0.0001	loss 0.092 (0.090)
Train: [72][380/589]	BT 0.358 (0.469)	DT 0.000 (0.108)	lr 0.0001	loss 0.078 (0.090)
Train: [72][390/589]	BT 0.360 (0.471)	DT 0.000 (0.110)	lr 0.0001	loss 0.095 (0.090)
Train: [72][400/589]	BT 0.359 (0.470)	DT 0.000 (0.110)	lr 0.0001	loss 0.117 (0.090)
Train: [72][410/589]	BT 0.399 (0.474)	DT 0.000 (0.113)	lr 0.0001	loss 0.101 (0.090)
Train: [72][420/589]	BT 0.358 (0.473)	DT 0.000 (0.113)	lr 0.0001	loss 0.098 (0.090)
Train: [72][430/589]	BT 0.417 (0.472)	DT 0.000 (0.111)	lr 0.0001	loss 0.087 (0.090)
Train: [72][440/589]	BT 0.359 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.092 (0.090)
Train: [72][450/589]	BT 0.359 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.093 (0.090)
Train: [72][460/589]	BT 0.395 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.068 (0.090)
Train: [72][470/589]	BT 0.388 (0.473)	DT 0.000 (0.112)	lr 0.0001	loss 0.073 (0.090)
Train: [72][480/589]	BT 0.360 (0.476)	DT 0.000 (0.114)	lr 0.0001	loss 0.108 (0.090)
Train: [72][490/589]	BT 0.361 (0.477)	DT 0.000 (0.116)	lr 0.0001	loss 0.076 (0.090)
Train: [72][500/589]	BT 0.357 (0.480)	DT 0.000 (0.119)	lr 0.0001	loss 0.082 (0.090)
Train: [72][510/589]	BT 0.358 (0.480)	DT 0.000 (0.119)	lr 0.0001	loss 0.093 (0.090)
Train: [72][520/589]	BT 0.359 (0.485)	DT 0.000 (0.124)	lr 0.0001	loss 0.095 (0.090)
Train: [72][530/589]	BT 0.355 (0.486)	DT 0.000 (0.125)	lr 0.0001	loss 0.094 (0.090)
Train: [72][540/589]	BT 0.358 (0.488)	DT 0.000 (0.127)	lr 0.0001	loss 0.102 (0.090)
Train: [72][550/589]	BT 0.358 (0.487)	DT 0.000 (0.127)	lr 0.0001	loss 0.080 (0.090)
Train: [72][560/589]	BT 0.359 (0.489)	DT 0.000 (0.128)	lr 0.0001	loss 0.084 (0.090)
Train: [72][570/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0001	loss 0.092 (0.090)
Train: [72][580/589]	BT 0.358 (0.489)	DT 0.000 (0.128)	lr 0.0001	loss 0.097 (0.090)
epoch 72, total time 289.89
loss: 0.09037091316616103@Epoch: 72
learning_rate: 0.0001,72
Valid: [72][10/88]	BT 0.109 (0.785)	DT 0.000 (0.674)	loss 0.188 (0.198)
Valid: [72][20/88]	BT 0.109 (0.670)	DT 0.000 (0.558)	loss 0.200 (0.194)
Valid: [72][30/88]	BT 0.110 (0.632)	DT 0.000 (0.520)	loss 0.196 (0.192)
Valid: [72][40/88]	BT 0.110 (0.598)	DT 0.000 (0.486)	loss 0.172 (0.189)
Valid: [72][50/88]	BT 0.110 (0.577)	DT 0.000 (0.466)	loss 0.164 (0.191)
Valid: [72][60/88]	BT 0.109 (0.573)	DT 0.000 (0.462)	loss 0.171 (0.188)
Valid: [72][70/88]	BT 0.110 (0.559)	DT 0.000 (0.447)	loss 0.195 (0.189)
Valid: [72][80/88]	BT 0.109 (0.561)	DT 0.000 (0.450)	loss 0.238 (0.188)
Train: [73][10/589]	BT 0.361 (0.851)	DT 0.000 (0.493)	lr 0.0001	loss 0.074 (0.088)
Train: [73][20/589]	BT 0.356 (0.665)	DT 0.000 (0.307)	lr 0.0001	loss 0.085 (0.089)
Train: [73][30/589]	BT 0.358 (0.587)	DT 0.000 (0.229)	lr 0.0001	loss 0.080 (0.090)
Train: [73][40/589]	BT 0.358 (0.559)	DT 0.000 (0.200)	lr 0.0001	loss 0.087 (0.088)
Train: [73][50/589]	BT 0.357 (0.559)	DT 0.000 (0.201)	lr 0.0001	loss 0.103 (0.089)
Train: [73][60/589]	BT 0.359 (0.562)	DT 0.000 (0.203)	lr 0.0001	loss 0.074 (0.088)
Train: [73][70/589]	BT 0.355 (0.551)	DT 0.000 (0.192)	lr 0.0001	loss 0.089 (0.087)
Train: [73][80/589]	BT 0.356 (0.552)	DT 0.000 (0.193)	lr 0.0001	loss 0.090 (0.087)
Train: [73][90/589]	BT 0.358 (0.537)	DT 0.000 (0.178)	lr 0.0001	loss 0.096 (0.088)
Train: [73][100/589]	BT 0.360 (0.529)	DT 0.000 (0.170)	lr 0.0001	loss 0.085 (0.089)
Train: [73][110/589]	BT 0.358 (0.517)	DT 0.000 (0.158)	lr 0.0001	loss 0.094 (0.089)
Train: [73][120/589]	BT 0.392 (0.521)	DT 0.000 (0.162)	lr 0.0001	loss 0.081 (0.089)
Train: [73][130/589]	BT 0.358 (0.522)	DT 0.000 (0.163)	lr 0.0001	loss 0.088 (0.088)
Train: [73][140/589]	BT 0.359 (0.516)	DT 0.000 (0.157)	lr 0.0001	loss 0.091 (0.088)
Train: [73][150/589]	BT 0.360 (0.520)	DT 0.000 (0.161)	lr 0.0001	loss 0.080 (0.088)
Train: [73][160/589]	BT 0.360 (0.518)	DT 0.000 (0.158)	lr 0.0001	loss 0.100 (0.088)
Train: [73][170/589]	BT 0.358 (0.512)	DT 0.000 (0.153)	lr 0.0001	loss 0.074 (0.088)
Train: [73][180/589]	BT 0.358 (0.509)	DT 0.000 (0.150)	lr 0.0001	loss 0.082 (0.088)
Train: [73][190/589]	BT 0.358 (0.506)	DT 0.000 (0.147)	lr 0.0001	loss 0.081 (0.088)
Train: [73][200/589]	BT 0.359 (0.503)	DT 0.000 (0.144)	lr 0.0001	loss 0.089 (0.088)
Train: [73][210/589]	BT 0.359 (0.503)	DT 0.000 (0.144)	lr 0.0001	loss 0.102 (0.089)
Train: [73][220/589]	BT 0.358 (0.503)	DT 0.000 (0.143)	lr 0.0001	loss 0.087 (0.089)
Train: [73][230/589]	BT 0.357 (0.502)	DT 0.000 (0.142)	lr 0.0001	loss 0.083 (0.089)
Train: [73][240/589]	BT 0.358 (0.502)	DT 0.000 (0.143)	lr 0.0001	loss 0.091 (0.089)
Train: [73][250/589]	BT 0.358 (0.506)	DT 0.000 (0.146)	lr 0.0001	loss 0.090 (0.089)
Train: [73][260/589]	BT 0.359 (0.502)	DT 0.000 (0.143)	lr 0.0001	loss 0.077 (0.088)
Train: [73][270/589]	BT 0.359 (0.502)	DT 0.000 (0.142)	lr 0.0001	loss 0.089 (0.089)
Train: [73][280/589]	BT 0.358 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.071 (0.088)
Train: [73][290/589]	BT 0.359 (0.500)	DT 0.000 (0.140)	lr 0.0001	loss 0.084 (0.088)
Train: [73][300/589]	BT 0.358 (0.496)	DT 0.000 (0.136)	lr 0.0001	loss 0.113 (0.088)
Train: [73][310/589]	BT 0.359 (0.492)	DT 0.000 (0.133)	lr 0.0001	loss 0.110 (0.089)
Train: [73][320/589]	BT 0.358 (0.494)	DT 0.000 (0.134)	lr 0.0001	loss 0.081 (0.089)
Train: [73][330/589]	BT 0.359 (0.493)	DT 0.000 (0.133)	lr 0.0001	loss 0.113 (0.089)
Train: [73][340/589]	BT 0.358 (0.492)	DT 0.000 (0.132)	lr 0.0001	loss 0.089 (0.089)
Train: [73][350/589]	BT 0.358 (0.492)	DT 0.000 (0.133)	lr 0.0001	loss 0.091 (0.089)
Train: [73][360/589]	BT 0.358 (0.492)	DT 0.000 (0.132)	lr 0.0001	loss 0.098 (0.089)
Train: [73][370/589]	BT 0.358 (0.492)	DT 0.000 (0.133)	lr 0.0001	loss 0.093 (0.089)
Train: [73][380/589]	BT 0.358 (0.490)	DT 0.000 (0.130)	lr 0.0001	loss 0.098 (0.089)
Train: [73][390/589]	BT 0.358 (0.490)	DT 0.000 (0.131)	lr 0.0001	loss 0.104 (0.089)
Train: [73][400/589]	BT 0.358 (0.488)	DT 0.000 (0.129)	lr 0.0001	loss 0.095 (0.089)
Train: [73][410/589]	BT 0.358 (0.486)	DT 0.000 (0.126)	lr 0.0001	loss 0.084 (0.089)
Train: [73][420/589]	BT 0.358 (0.485)	DT 0.000 (0.125)	lr 0.0001	loss 0.077 (0.089)
Train: [73][430/589]	BT 0.359 (0.484)	DT 0.000 (0.124)	lr 0.0001	loss 0.099 (0.089)
Train: [73][440/589]	BT 0.384 (0.482)	DT 0.000 (0.122)	lr 0.0001	loss 0.102 (0.089)
Train: [73][450/589]	BT 0.356 (0.480)	DT 0.000 (0.120)	lr 0.0001	loss 0.082 (0.089)
Train: [73][460/589]	BT 0.358 (0.479)	DT 0.000 (0.119)	lr 0.0001	loss 0.098 (0.089)
Train: [73][470/589]	BT 0.359 (0.480)	DT 0.000 (0.120)	lr 0.0001	loss 0.088 (0.089)
Train: [73][480/589]	BT 0.360 (0.480)	DT 0.000 (0.121)	lr 0.0001	loss 0.103 (0.089)
Train: [73][490/589]	BT 0.359 (0.479)	DT 0.000 (0.120)	lr 0.0001	loss 0.107 (0.089)
Train: [73][500/589]	BT 0.357 (0.479)	DT 0.000 (0.120)	lr 0.0001	loss 0.090 (0.089)
Train: [73][510/589]	BT 0.358 (0.480)	DT 0.000 (0.121)	lr 0.0001	loss 0.104 (0.089)
Train: [73][520/589]	BT 0.359 (0.480)	DT 0.000 (0.120)	lr 0.0001	loss 0.093 (0.089)
Train: [73][530/589]	BT 0.357 (0.479)	DT 0.000 (0.119)	lr 0.0001	loss 0.084 (0.089)
Train: [73][540/589]	BT 0.359 (0.481)	DT 0.000 (0.121)	lr 0.0001	loss 0.089 (0.089)
Train: [73][550/589]	BT 0.357 (0.480)	DT 0.000 (0.120)	lr 0.0001	loss 0.080 (0.090)
Train: [73][560/589]	BT 0.360 (0.481)	DT 0.000 (0.121)	lr 0.0001	loss 0.088 (0.090)
Train: [73][570/589]	BT 0.358 (0.479)	DT 0.000 (0.120)	lr 0.0001	loss 0.082 (0.090)
Train: [73][580/589]	BT 0.359 (0.478)	DT 0.000 (0.118)	lr 0.0001	loss 0.076 (0.090)
epoch 73, total time 282.27
loss: 0.08962169781387397@Epoch: 73
learning_rate: 0.0001,73
Valid: [73][10/88]	BT 0.110 (0.661)	DT 0.000 (0.549)	loss 0.202 (0.188)
Valid: [73][20/88]	BT 0.110 (0.576)	DT 0.000 (0.465)	loss 0.220 (0.194)
Valid: [73][30/88]	BT 0.109 (0.523)	DT 0.000 (0.413)	loss 0.180 (0.192)
Valid: [73][40/88]	BT 0.109 (0.511)	DT 0.000 (0.401)	loss 0.176 (0.192)
Valid: [73][50/88]	BT 0.110 (0.495)	DT 0.000 (0.385)	loss 0.212 (0.189)
Valid: [73][60/88]	BT 0.110 (0.475)	DT 0.000 (0.365)	loss 0.174 (0.192)
Valid: [73][70/88]	BT 0.110 (0.469)	DT 0.000 (0.358)	loss 0.230 (0.194)
Valid: [73][80/88]	BT 0.110 (0.463)	DT 0.000 (0.353)	loss 0.190 (0.195)
Model does not imporove from 0.12980 for 50 epochs. Early Stop

Individual Diseases:
>> AUC = [0.7789,0.8814,0.8299,0.6925,0.8214,0.7703,0.7347,0.8385,0.754 ,0.8435,
 0.9068,0.8342,0.7763,0.9266]
>>Mean AUC = 0.8135

