
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.



Configurations:
backbone                       resnet50
batch_size                     128
data_root                      /scratch/nuislam/ChestXRay14_images/
debug_mode                     False
device                         cuda
epochs                         1000
gpu                            0,1,2,3
log_writter                    <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
lr                             0.0002
method                         nih14_resnet50_run101
model_path                     saved_models/nih14_resnet50_run101
num_workers                    10
patience                       50
run                            101
server                         agave
test_list                      data/nih_xray14/official/test_official.txt
train_list                     data/nih_xray14/official/train_official.txt
valid_list                     data/nih_xray14/official/val_official.txt
weight                         None


DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=14, bias=True)
  )
)
Train: [1][10/589]	BT 0.355 (1.105)	DT 0.000 (0.470)	lr 0.0002	loss 0.165 (0.279)
Train: [1][20/589]	BT 0.354 (0.732)	DT 0.000 (0.235)	lr 0.0002	loss 0.166 (0.226)
Train: [1][30/589]	BT 0.359 (0.607)	DT 0.000 (0.157)	lr 0.0002	loss 0.152 (0.204)
Train: [1][40/589]	BT 0.356 (0.545)	DT 0.000 (0.118)	lr 0.0002	loss 0.137 (0.194)
Train: [1][50/589]	BT 0.356 (0.507)	DT 0.000 (0.094)	lr 0.0002	loss 0.159 (0.187)
Train: [1][60/589]	BT 0.371 (0.483)	DT 0.000 (0.079)	lr 0.0002	loss 0.131 (0.182)
Train: [1][70/589]	BT 0.355 (0.466)	DT 0.000 (0.068)	lr 0.0002	loss 0.168 (0.179)
Train: [1][80/589]	BT 0.356 (0.458)	DT 0.000 (0.065)	lr 0.0002	loss 0.158 (0.177)
Train: [1][90/589]	BT 0.356 (0.456)	DT 0.000 (0.068)	lr 0.0002	loss 0.160 (0.175)
Train: [1][100/589]	BT 0.355 (0.453)	DT 0.000 (0.068)	lr 0.0002	loss 0.185 (0.174)
Train: [1][110/589]	BT 0.357 (0.449)	DT 0.000 (0.067)	lr 0.0002	loss 0.150 (0.173)
Train: [1][120/589]	BT 0.356 (0.445)	DT 0.000 (0.065)	lr 0.0002	loss 0.190 (0.172)
Train: [1][130/589]	BT 0.359 (0.441)	DT 0.000 (0.062)	lr 0.0002	loss 0.178 (0.171)
Train: [1][140/589]	BT 0.357 (0.436)	DT 0.000 (0.059)	lr 0.0002	loss 0.155 (0.170)
Train: [1][150/589]	BT 0.357 (0.433)	DT 0.001 (0.057)	lr 0.0002	loss 0.149 (0.170)
Train: [1][160/589]	BT 0.359 (0.435)	DT 0.000 (0.060)	lr 0.0002	loss 0.157 (0.170)
Train: [1][170/589]	BT 0.357 (0.432)	DT 0.000 (0.058)	lr 0.0002	loss 0.180 (0.170)
Train: [1][180/589]	BT 0.369 (0.430)	DT 0.000 (0.057)	lr 0.0002	loss 0.142 (0.169)
Train: [1][190/589]	BT 0.358 (0.427)	DT 0.000 (0.054)	lr 0.0002	loss 0.186 (0.169)
Train: [1][200/589]	BT 0.359 (0.425)	DT 0.000 (0.054)	lr 0.0002	loss 0.164 (0.169)
Train: [1][210/589]	BT 0.354 (0.426)	DT 0.000 (0.055)	lr 0.0002	loss 0.172 (0.169)
Train: [1][220/589]	BT 0.357 (0.424)	DT 0.000 (0.053)	lr 0.0002	loss 0.185 (0.168)
Train: [1][230/589]	BT 0.357 (0.422)	DT 0.000 (0.052)	lr 0.0002	loss 0.166 (0.168)
Train: [1][240/589]	BT 0.366 (0.421)	DT 0.000 (0.051)	lr 0.0002	loss 0.159 (0.168)
Train: [1][250/589]	BT 0.356 (0.421)	DT 0.000 (0.052)	lr 0.0002	loss 0.187 (0.168)
Train: [1][260/589]	BT 0.372 (0.420)	DT 0.000 (0.052)	lr 0.0002	loss 0.189 (0.168)
Train: [1][270/589]	BT 0.357 (0.419)	DT 0.000 (0.051)	lr 0.0002	loss 0.168 (0.168)
Train: [1][280/589]	BT 0.357 (0.418)	DT 0.000 (0.050)	lr 0.0002	loss 0.143 (0.167)
Train: [1][290/589]	BT 0.356 (0.417)	DT 0.000 (0.050)	lr 0.0002	loss 0.183 (0.167)
Train: [1][300/589]	BT 0.357 (0.417)	DT 0.000 (0.050)	lr 0.0002	loss 0.158 (0.167)
Train: [1][310/589]	BT 0.358 (0.416)	DT 0.000 (0.049)	lr 0.0002	loss 0.156 (0.167)
Train: [1][320/589]	BT 0.357 (0.415)	DT 0.001 (0.048)	lr 0.0002	loss 0.157 (0.166)
Train: [1][330/589]	BT 0.364 (0.415)	DT 0.000 (0.048)	lr 0.0002	loss 0.178 (0.167)
Train: [1][340/589]	BT 0.373 (0.414)	DT 0.000 (0.048)	lr 0.0002	loss 0.165 (0.166)
Train: [1][350/589]	BT 0.370 (0.414)	DT 0.000 (0.048)	lr 0.0002	loss 0.165 (0.166)
Train: [1][360/589]	BT 0.357 (0.413)	DT 0.000 (0.047)	lr 0.0002	loss 0.147 (0.166)
Train: [1][370/589]	BT 0.356 (0.413)	DT 0.000 (0.047)	lr 0.0002	loss 0.176 (0.166)
Train: [1][380/589]	BT 0.358 (0.412)	DT 0.000 (0.046)	lr 0.0002	loss 0.172 (0.165)
Train: [1][390/589]	BT 0.358 (0.412)	DT 0.000 (0.047)	lr 0.0002	loss 0.201 (0.165)
Train: [1][400/589]	BT 0.357 (0.411)	DT 0.000 (0.046)	lr 0.0002	loss 0.151 (0.165)
Train: [1][410/589]	BT 0.359 (0.410)	DT 0.000 (0.045)	lr 0.0002	loss 0.189 (0.165)
Train: [1][420/589]	BT 0.356 (0.410)	DT 0.000 (0.045)	lr 0.0002	loss 0.151 (0.165)
Train: [1][430/589]	BT 0.359 (0.411)	DT 0.000 (0.046)	lr 0.0002	loss 0.161 (0.164)
Train: [1][440/589]	BT 0.356 (0.411)	DT 0.000 (0.046)	lr 0.0002	loss 0.168 (0.164)
Train: [1][450/589]	BT 0.359 (0.410)	DT 0.000 (0.045)	lr 0.0002	loss 0.157 (0.164)
Train: [1][460/589]	BT 0.356 (0.409)	DT 0.000 (0.045)	lr 0.0002	loss 0.168 (0.164)
Train: [1][470/589]	BT 0.357 (0.409)	DT 0.000 (0.045)	lr 0.0002	loss 0.159 (0.164)
Train: [1][480/589]	BT 0.359 (0.409)	DT 0.000 (0.045)	lr 0.0002	loss 0.167 (0.164)
Train: [1][490/589]	BT 0.359 (0.409)	DT 0.000 (0.045)	lr 0.0002	loss 0.159 (0.164)
Train: [1][500/589]	BT 0.356 (0.410)	DT 0.000 (0.046)	lr 0.0002	loss 0.168 (0.163)
Train: [1][510/589]	BT 0.356 (0.410)	DT 0.000 (0.046)	lr 0.0002	loss 0.167 (0.164)
Train: [1][520/589]	BT 0.356 (0.410)	DT 0.000 (0.046)	lr 0.0002	loss 0.160 (0.164)
Train: [1][530/589]	BT 0.358 (0.409)	DT 0.000 (0.045)	lr 0.0002	loss 0.166 (0.164)
Train: [1][540/589]	BT 0.357 (0.408)	DT 0.000 (0.045)	lr 0.0002	loss 0.158 (0.163)
Train: [1][550/589]	BT 0.356 (0.408)	DT 0.000 (0.045)	lr 0.0002	loss 0.168 (0.163)
Train: [1][560/589]	BT 0.357 (0.408)	DT 0.000 (0.044)	lr 0.0002	loss 0.168 (0.163)
Train: [1][570/589]	BT 0.373 (0.408)	DT 0.000 (0.044)	lr 0.0002	loss 0.165 (0.163)
Train: [1][580/589]	BT 0.357 (0.409)	DT 0.000 (0.046)	lr 0.0002	loss 0.168 (0.163)
epoch 1, total time 243.78
loss: 0.16318575954624667@Epoch: 1
learning_rate: 0.0002,1
Valid: [1][10/88]	BT 0.109 (1.337)	DT 0.000 (1.226)	loss 0.150 (0.156)
Valid: [1][20/88]	BT 0.110 (1.157)	DT 0.000 (1.047)	loss 0.194 (0.160)
Valid: [1][30/88]	BT 0.109 (1.083)	DT 0.000 (0.974)	loss 0.158 (0.160)
Valid: [1][40/88]	BT 0.109 (1.007)	DT 0.000 (0.898)	loss 0.157 (0.159)
Valid: [1][50/88]	BT 0.109 (0.991)	DT 0.000 (0.882)	loss 0.144 (0.158)
Valid: [1][60/88]	BT 0.110 (1.031)	DT 0.000 (0.921)	loss 0.135 (0.158)
Valid: [1][70/88]	BT 0.109 (1.047)	DT 0.000 (0.937)	loss 0.161 (0.157)
Valid: [1][80/88]	BT 0.109 (1.024)	DT 0.000 (0.915)	loss 0.157 (0.157)
Epoch 0001: val_loss improved from 100000.00000 to 0.15675, saving model
==> Saving...
Train: [2][10/589]	BT 0.357 (0.763)	DT 0.000 (0.407)	lr 0.0002	loss 0.140 (0.153)
Train: [2][20/589]	BT 0.360 (0.576)	DT 0.000 (0.219)	lr 0.0002	loss 0.164 (0.157)
Train: [2][30/589]	BT 0.355 (0.511)	DT 0.000 (0.154)	lr 0.0002	loss 0.137 (0.159)
Train: [2][40/589]	BT 0.352 (0.479)	DT 0.000 (0.122)	lr 0.0002	loss 0.165 (0.158)
Train: [2][50/589]	BT 0.357 (0.459)	DT 0.000 (0.102)	lr 0.0002	loss 0.163 (0.159)
Train: [2][60/589]	BT 0.356 (0.445)	DT 0.000 (0.088)	lr 0.0002	loss 0.164 (0.159)
Train: [2][70/589]	BT 0.356 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.165 (0.159)
Train: [2][80/589]	BT 0.357 (0.432)	DT 0.000 (0.075)	lr 0.0002	loss 0.145 (0.159)
Train: [2][90/589]	BT 0.356 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.172 (0.159)
Train: [2][100/589]	BT 0.357 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.140 (0.159)
Train: [2][110/589]	BT 0.357 (0.420)	DT 0.000 (0.064)	lr 0.0002	loss 0.190 (0.159)
Train: [2][120/589]	BT 0.355 (0.419)	DT 0.000 (0.062)	lr 0.0002	loss 0.130 (0.158)
Train: [2][130/589]	BT 0.356 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.146 (0.158)
Train: [2][140/589]	BT 0.357 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.160 (0.158)
Train: [2][150/589]	BT 0.358 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.150 (0.158)
Train: [2][160/589]	BT 0.357 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.163 (0.158)
Train: [2][170/589]	BT 0.357 (0.409)	DT 0.000 (0.052)	lr 0.0002	loss 0.180 (0.158)
Train: [2][180/589]	BT 0.356 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.159 (0.157)
Train: [2][190/589]	BT 0.371 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.164 (0.158)
Train: [2][200/589]	BT 0.356 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.133 (0.158)
Train: [2][210/589]	BT 0.354 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.144 (0.158)
Train: [2][220/589]	BT 0.360 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.170 (0.158)
Train: [2][230/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.151 (0.158)
Train: [2][240/589]	BT 0.391 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.171 (0.158)
Train: [2][250/589]	BT 0.358 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.187 (0.158)
Train: [2][260/589]	BT 0.356 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.143 (0.158)
Train: [2][270/589]	BT 0.359 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.180 (0.158)
Train: [2][280/589]	BT 0.359 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.167 (0.158)
Train: [2][290/589]	BT 0.355 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.165 (0.158)
Train: [2][300/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.152 (0.158)
Train: [2][310/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.177 (0.158)
Train: [2][320/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.116 (0.158)
Train: [2][330/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.161 (0.158)
Train: [2][340/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.158)
Train: [2][350/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.169 (0.158)
Train: [2][360/589]	BT 0.359 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.192 (0.158)
Train: [2][370/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.179 (0.158)
Train: [2][380/589]	BT 0.356 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.158)
Train: [2][390/589]	BT 0.374 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.177 (0.158)
Train: [2][400/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.175 (0.158)
Train: [2][410/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.145 (0.158)
Train: [2][420/589]	BT 0.380 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.159 (0.157)
Train: [2][430/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.144 (0.158)
Train: [2][440/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.148 (0.157)
Train: [2][450/589]	BT 0.354 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.151 (0.157)
Train: [2][460/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.148 (0.157)
Train: [2][470/589]	BT 0.365 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.144 (0.157)
Train: [2][480/589]	BT 0.359 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.175 (0.158)
Train: [2][490/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.128 (0.157)
Train: [2][500/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.184 (0.157)
Train: [2][510/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.153 (0.157)
Train: [2][520/589]	BT 0.357 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.147 (0.157)
Train: [2][530/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.125 (0.157)
Train: [2][540/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.148 (0.157)
Train: [2][550/589]	BT 0.360 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.167 (0.157)
Train: [2][560/589]	BT 0.353 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.144 (0.157)
Train: [2][570/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.136 (0.157)
Train: [2][580/589]	BT 0.379 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.152 (0.157)
epoch 2, total time 233.88
loss: 0.15706934465049102@Epoch: 2
learning_rate: 0.0002,2
Valid: [2][10/88]	BT 0.109 (0.569)	DT 0.000 (0.456)	loss 0.144 (0.146)
Valid: [2][20/88]	BT 0.110 (0.502)	DT 0.000 (0.391)	loss 0.144 (0.151)
Valid: [2][30/88]	BT 0.110 (0.472)	DT 0.000 (0.361)	loss 0.173 (0.152)
Valid: [2][40/88]	BT 0.110 (0.460)	DT 0.000 (0.350)	loss 0.148 (0.152)
Valid: [2][50/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.170 (0.152)
Valid: [2][60/88]	BT 0.110 (0.444)	DT 0.000 (0.334)	loss 0.143 (0.153)
Valid: [2][70/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.144 (0.153)
Valid: [2][80/88]	BT 0.109 (0.440)	DT 0.000 (0.329)	loss 0.138 (0.152)
Epoch 0002: val_loss improved from 0.15675 to 0.15285, saving model
==> Saving...
Train: [3][10/589]	BT 0.357 (0.779)	DT 0.000 (0.424)	lr 0.0002	loss 0.164 (0.157)
Train: [3][20/589]	BT 0.355 (0.573)	DT 0.000 (0.218)	lr 0.0002	loss 0.162 (0.156)
Train: [3][30/589]	BT 0.358 (0.510)	DT 0.000 (0.154)	lr 0.0002	loss 0.144 (0.157)
Train: [3][40/589]	BT 0.367 (0.476)	DT 0.000 (0.120)	lr 0.0002	loss 0.187 (0.155)
Train: [3][50/589]	BT 0.357 (0.459)	DT 0.000 (0.103)	lr 0.0002	loss 0.170 (0.155)
Train: [3][60/589]	BT 0.369 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.163 (0.155)
Train: [3][70/589]	BT 0.381 (0.439)	DT 0.000 (0.082)	lr 0.0002	loss 0.145 (0.154)
Train: [3][80/589]	BT 0.356 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.175 (0.155)
Train: [3][90/589]	BT 0.371 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.157 (0.155)
Train: [3][100/589]	BT 0.356 (0.418)	DT 0.000 (0.061)	lr 0.0002	loss 0.145 (0.155)
Train: [3][110/589]	BT 0.356 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.161 (0.156)
Train: [3][120/589]	BT 0.380 (0.412)	DT 0.001 (0.055)	lr 0.0002	loss 0.141 (0.156)
Train: [3][130/589]	BT 0.360 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.175 (0.156)
Train: [3][140/589]	BT 0.358 (0.409)	DT 0.000 (0.052)	lr 0.0002	loss 0.148 (0.155)
Train: [3][150/589]	BT 0.357 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.136 (0.155)
Train: [3][160/589]	BT 0.360 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.135 (0.155)
Train: [3][170/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.148 (0.155)
Train: [3][180/589]	BT 0.360 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.154 (0.154)
Train: [3][190/589]	BT 0.357 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.150 (0.155)
Train: [3][200/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.154 (0.155)
Train: [3][210/589]	BT 0.359 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.195 (0.155)
Train: [3][220/589]	BT 0.362 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.162 (0.155)
Train: [3][230/589]	BT 0.356 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.145 (0.155)
Train: [3][240/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.149 (0.155)
Train: [3][250/589]	BT 0.354 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.142 (0.155)
Train: [3][260/589]	BT 0.356 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.138 (0.155)
Train: [3][270/589]	BT 0.357 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.145 (0.155)
Train: [3][280/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.160 (0.155)
Train: [3][290/589]	BT 0.374 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.129 (0.155)
Train: [3][300/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.183 (0.155)
Train: [3][310/589]	BT 0.363 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.138 (0.155)
Train: [3][320/589]	BT 0.374 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.159 (0.155)
Train: [3][330/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.142 (0.155)
Train: [3][340/589]	BT 0.359 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.163 (0.155)
Train: [3][350/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.162 (0.155)
Train: [3][360/589]	BT 0.360 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.152 (0.155)
Train: [3][370/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.163 (0.155)
Train: [3][380/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.145 (0.155)
Train: [3][390/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.144 (0.155)
Train: [3][400/589]	BT 0.361 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.158 (0.155)
Train: [3][410/589]	BT 0.357 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.152 (0.155)
Train: [3][420/589]	BT 0.355 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.143 (0.155)
Train: [3][430/589]	BT 0.393 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.173 (0.155)
Train: [3][440/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.155)
Train: [3][450/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.163 (0.155)
Train: [3][460/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.161 (0.155)
Train: [3][470/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.165 (0.155)
Train: [3][480/589]	BT 0.381 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.150 (0.155)
Train: [3][490/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.149 (0.155)
Train: [3][500/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.163 (0.155)
Train: [3][510/589]	BT 0.364 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.169 (0.155)
Train: [3][520/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.152 (0.155)
Train: [3][530/589]	BT 0.357 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.164 (0.155)
Train: [3][540/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.166 (0.155)
Train: [3][550/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.165 (0.155)
Train: [3][560/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.183 (0.155)
Train: [3][570/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.170 (0.155)
Train: [3][580/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.160 (0.155)
epoch 3, total time 235.02
loss: 0.15504793405836748@Epoch: 3
learning_rate: 0.0002,3
Valid: [3][10/88]	BT 0.110 (0.560)	DT 0.000 (0.447)	loss 0.157 (0.144)
Valid: [3][20/88]	BT 0.109 (0.486)	DT 0.000 (0.375)	loss 0.156 (0.150)
Valid: [3][30/88]	BT 0.110 (0.465)	DT 0.000 (0.354)	loss 0.189 (0.152)
Valid: [3][40/88]	BT 0.109 (0.451)	DT 0.000 (0.340)	loss 0.149 (0.150)
Valid: [3][50/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.149 (0.150)
Valid: [3][60/88]	BT 0.109 (0.442)	DT 0.000 (0.332)	loss 0.153 (0.150)
Valid: [3][70/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.151 (0.150)
Valid: [3][80/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.136 (0.150)
Epoch 0003: val_loss improved from 0.15285 to 0.15033, saving model
==> Saving...
Train: [4][10/589]	BT 0.355 (0.740)	DT 0.000 (0.383)	lr 0.0002	loss 0.141 (0.161)
Train: [4][20/589]	BT 0.355 (0.562)	DT 0.000 (0.204)	lr 0.0002	loss 0.169 (0.158)
Train: [4][30/589]	BT 0.370 (0.514)	DT 0.000 (0.156)	lr 0.0002	loss 0.171 (0.158)
Train: [4][40/589]	BT 0.371 (0.479)	DT 0.000 (0.121)	lr 0.0002	loss 0.142 (0.155)
Train: [4][50/589]	BT 0.381 (0.456)	DT 0.000 (0.098)	lr 0.0002	loss 0.137 (0.155)
Train: [4][60/589]	BT 0.357 (0.444)	DT 0.000 (0.085)	lr 0.0002	loss 0.162 (0.155)
Train: [4][70/589]	BT 0.364 (0.435)	DT 0.000 (0.077)	lr 0.0002	loss 0.170 (0.156)
Train: [4][80/589]	BT 0.369 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.155 (0.155)
Train: [4][90/589]	BT 0.356 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.156 (0.154)
Train: [4][100/589]	BT 0.356 (0.419)	DT 0.001 (0.060)	lr 0.0002	loss 0.154 (0.154)
Train: [4][110/589]	BT 0.358 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.159 (0.154)
Train: [4][120/589]	BT 0.366 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.171 (0.154)
Train: [4][130/589]	BT 0.358 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.168 (0.154)
Train: [4][140/589]	BT 0.354 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.170 (0.154)
Train: [4][150/589]	BT 0.372 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.168 (0.154)
Train: [4][160/589]	BT 0.359 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.160 (0.154)
Train: [4][170/589]	BT 0.356 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.176 (0.154)
Train: [4][180/589]	BT 0.366 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.155 (0.154)
Train: [4][190/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.136 (0.154)
Train: [4][200/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.153 (0.155)
Train: [4][210/589]	BT 0.355 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.146 (0.154)
Train: [4][220/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.154)
Train: [4][230/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.169 (0.154)
Train: [4][240/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.129 (0.154)
Train: [4][250/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.161 (0.154)
Train: [4][260/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.152 (0.154)
Train: [4][270/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.154 (0.154)
Train: [4][280/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.124 (0.154)
Train: [4][290/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.152 (0.154)
Train: [4][300/589]	BT 0.355 (0.395)	DT 0.001 (0.037)	lr 0.0002	loss 0.168 (0.154)
Train: [4][310/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.148 (0.154)
Train: [4][320/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.136 (0.154)
Train: [4][330/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.138 (0.154)
Train: [4][340/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.161 (0.154)
Train: [4][350/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.139 (0.154)
Train: [4][360/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.143 (0.154)
Train: [4][370/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.142 (0.154)
Train: [4][380/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.194 (0.154)
Train: [4][390/589]	BT 0.354 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.133 (0.154)
Train: [4][400/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.152 (0.154)
Train: [4][410/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.168 (0.154)
Train: [4][420/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.141 (0.154)
Train: [4][430/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.154)
Train: [4][440/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.151 (0.154)
Train: [4][450/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.149 (0.154)
Train: [4][460/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.160 (0.154)
Train: [4][470/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.171 (0.154)
Train: [4][480/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.160 (0.154)
Train: [4][490/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.154)
Train: [4][500/589]	BT 0.406 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.166 (0.154)
Train: [4][510/589]	BT 0.354 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.166 (0.154)
Train: [4][520/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.149 (0.154)
Train: [4][530/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.143 (0.154)
Train: [4][540/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.141 (0.154)
Train: [4][550/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.168 (0.154)
Train: [4][560/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.143 (0.154)
Train: [4][570/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.127 (0.154)
Train: [4][580/589]	BT 0.359 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.153)
epoch 4, total time 230.81
loss: 0.15355863877231207@Epoch: 4
learning_rate: 0.0002,4
Valid: [4][10/88]	BT 0.110 (0.580)	DT 0.000 (0.468)	loss 0.144 (0.154)
Valid: [4][20/88]	BT 0.109 (0.504)	DT 0.000 (0.393)	loss 0.166 (0.152)
Valid: [4][30/88]	BT 0.109 (0.479)	DT 0.000 (0.368)	loss 0.155 (0.153)
Valid: [4][40/88]	BT 0.109 (0.460)	DT 0.000 (0.350)	loss 0.179 (0.153)
Valid: [4][50/88]	BT 0.110 (0.454)	DT 0.000 (0.345)	loss 0.179 (0.153)
Valid: [4][60/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.137 (0.152)
Valid: [4][70/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.146 (0.151)
Valid: [4][80/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.162 (0.151)
Train: [5][10/589]	BT 0.369 (0.795)	DT 0.000 (0.437)	lr 0.0002	loss 0.151 (0.154)
Train: [5][20/589]	BT 0.359 (0.588)	DT 0.000 (0.231)	lr 0.0002	loss 0.170 (0.158)
Train: [5][30/589]	BT 0.383 (0.520)	DT 0.000 (0.162)	lr 0.0002	loss 0.143 (0.157)
Train: [5][40/589]	BT 0.357 (0.486)	DT 0.000 (0.129)	lr 0.0002	loss 0.154 (0.154)
Train: [5][50/589]	BT 0.358 (0.464)	DT 0.000 (0.107)	lr 0.0002	loss 0.147 (0.152)
Train: [5][60/589]	BT 0.356 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.160 (0.152)
Train: [5][70/589]	BT 0.365 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.162 (0.152)
Train: [5][80/589]	BT 0.365 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.160 (0.153)
Train: [5][90/589]	BT 0.355 (0.420)	DT 0.001 (0.063)	lr 0.0002	loss 0.148 (0.153)
Train: [5][100/589]	BT 0.366 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.161 (0.153)
Train: [5][110/589]	BT 0.370 (0.412)	DT 0.000 (0.055)	lr 0.0002	loss 0.135 (0.152)
Train: [5][120/589]	BT 0.361 (0.409)	DT 0.000 (0.052)	lr 0.0002	loss 0.124 (0.151)
Train: [5][130/589]	BT 0.356 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.146 (0.151)
Train: [5][140/589]	BT 0.358 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.143 (0.151)
Train: [5][150/589]	BT 0.377 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.164 (0.151)
Train: [5][160/589]	BT 0.377 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.159 (0.151)
Train: [5][170/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.153 (0.151)
Train: [5][180/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.157 (0.151)
Train: [5][190/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.148 (0.151)
Train: [5][200/589]	BT 0.378 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.155 (0.152)
Train: [5][210/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.148 (0.152)
Train: [5][220/589]	BT 0.366 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.154 (0.152)
Train: [5][230/589]	BT 0.359 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.120 (0.152)
Train: [5][240/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.152)
Train: [5][250/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.157 (0.152)
Train: [5][260/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.131 (0.152)
Train: [5][270/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.157 (0.152)
Train: [5][280/589]	BT 0.354 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.158 (0.152)
Train: [5][290/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.141 (0.152)
Train: [5][300/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.168 (0.152)
Train: [5][310/589]	BT 0.359 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.153 (0.152)
Train: [5][320/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.158 (0.152)
Train: [5][330/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.177 (0.152)
Train: [5][340/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.159 (0.153)
Train: [5][350/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.150 (0.153)
Train: [5][360/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.177 (0.153)
Train: [5][370/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.152 (0.153)
Train: [5][380/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.143 (0.153)
Train: [5][390/589]	BT 0.356 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.138 (0.153)
Train: [5][400/589]	BT 0.376 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.164 (0.153)
Train: [5][410/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.148 (0.153)
Train: [5][420/589]	BT 0.370 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.172 (0.153)
Train: [5][430/589]	BT 0.366 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.146 (0.153)
Train: [5][440/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.180 (0.153)
Train: [5][450/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.154 (0.153)
Train: [5][460/589]	BT 0.379 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.134 (0.153)
Train: [5][470/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.144 (0.153)
Train: [5][480/589]	BT 0.358 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.135 (0.152)
Train: [5][490/589]	BT 0.361 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.164 (0.152)
Train: [5][500/589]	BT 0.367 (0.395)	DT 0.001 (0.037)	lr 0.0002	loss 0.154 (0.152)
Train: [5][510/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.149 (0.152)
Train: [5][520/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.152 (0.152)
Train: [5][530/589]	BT 0.359 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.174 (0.152)
Train: [5][540/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.155 (0.152)
Train: [5][550/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.150 (0.152)
Train: [5][560/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.151 (0.152)
Train: [5][570/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.138 (0.152)
Train: [5][580/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.133 (0.152)
epoch 5, total time 231.87
loss: 0.1519802760389015@Epoch: 5
learning_rate: 0.0002,5
Valid: [5][10/88]	BT 0.110 (0.557)	DT 0.000 (0.446)	loss 0.160 (0.151)
Valid: [5][20/88]	BT 0.109 (0.506)	DT 0.000 (0.396)	loss 0.154 (0.152)
Valid: [5][30/88]	BT 0.109 (0.479)	DT 0.000 (0.369)	loss 0.136 (0.151)
Valid: [5][40/88]	BT 0.110 (0.467)	DT 0.000 (0.357)	loss 0.153 (0.150)
Valid: [5][50/88]	BT 0.109 (0.460)	DT 0.000 (0.350)	loss 0.127 (0.150)
Valid: [5][60/88]	BT 0.109 (0.454)	DT 0.000 (0.343)	loss 0.143 (0.150)
Valid: [5][70/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.139 (0.150)
Valid: [5][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.155 (0.151)
Train: [6][10/589]	BT 0.357 (0.776)	DT 0.000 (0.420)	lr 0.0002	loss 0.148 (0.142)
Train: [6][20/589]	BT 0.370 (0.583)	DT 0.000 (0.225)	lr 0.0002	loss 0.135 (0.145)
Train: [6][30/589]	BT 0.357 (0.518)	DT 0.000 (0.161)	lr 0.0002	loss 0.152 (0.147)
Train: [6][40/589]	BT 0.357 (0.487)	DT 0.000 (0.130)	lr 0.0002	loss 0.143 (0.147)
Train: [6][50/589]	BT 0.356 (0.469)	DT 0.000 (0.112)	lr 0.0002	loss 0.146 (0.149)
Train: [6][60/589]	BT 0.358 (0.459)	DT 0.000 (0.101)	lr 0.0002	loss 0.150 (0.150)
Train: [6][70/589]	BT 0.357 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.135 (0.149)
Train: [6][80/589]	BT 0.358 (0.443)	DT 0.000 (0.086)	lr 0.0002	loss 0.152 (0.149)
Train: [6][90/589]	BT 0.358 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.149 (0.149)
Train: [6][100/589]	BT 0.360 (0.433)	DT 0.000 (0.076)	lr 0.0002	loss 0.155 (0.149)
Train: [6][110/589]	BT 0.357 (0.430)	DT 0.000 (0.072)	lr 0.0002	loss 0.143 (0.149)
Train: [6][120/589]	BT 0.363 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.167 (0.150)
Train: [6][130/589]	BT 0.360 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.159 (0.150)
Train: [6][140/589]	BT 0.359 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.153 (0.150)
Train: [6][150/589]	BT 0.357 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.157 (0.151)
Train: [6][160/589]	BT 0.357 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.151 (0.151)
Train: [6][170/589]	BT 0.359 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.142 (0.151)
Train: [6][180/589]	BT 0.358 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.154 (0.151)
Train: [6][190/589]	BT 0.361 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.138 (0.151)
Train: [6][200/589]	BT 0.368 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.146 (0.151)
Train: [6][210/589]	BT 0.357 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.138 (0.151)
Train: [6][220/589]	BT 0.357 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.179 (0.151)
Train: [6][230/589]	BT 0.356 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.145 (0.151)
Train: [6][240/589]	BT 0.357 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.149 (0.151)
Train: [6][250/589]	BT 0.356 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.141 (0.151)
Train: [6][260/589]	BT 0.360 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.169 (0.151)
Train: [6][270/589]	BT 0.359 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.151 (0.151)
Train: [6][280/589]	BT 0.357 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.150 (0.151)
Train: [6][290/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.157 (0.151)
Train: [6][300/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.167 (0.151)
Train: [6][310/589]	BT 0.356 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.144 (0.151)
Train: [6][320/589]	BT 0.359 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.154 (0.151)
Train: [6][330/589]	BT 0.360 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.161 (0.151)
Train: [6][340/589]	BT 0.356 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.140 (0.151)
Train: [6][350/589]	BT 0.359 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.142 (0.151)
Train: [6][360/589]	BT 0.368 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.155 (0.151)
Train: [6][370/589]	BT 0.359 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.120 (0.151)
Train: [6][380/589]	BT 0.358 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.168 (0.151)
Train: [6][390/589]	BT 0.357 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.136 (0.151)
Train: [6][400/589]	BT 0.359 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.146 (0.151)
Train: [6][410/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.149 (0.151)
Train: [6][420/589]	BT 0.359 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.150 (0.151)
Train: [6][430/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.133 (0.151)
Train: [6][440/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.144 (0.151)
Train: [6][450/589]	BT 0.359 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.159 (0.151)
Train: [6][460/589]	BT 0.359 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.177 (0.151)
Train: [6][470/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.164 (0.151)
Train: [6][480/589]	BT 0.361 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.156 (0.151)
Train: [6][490/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.144 (0.151)
Train: [6][500/589]	BT 0.382 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.171 (0.151)
Train: [6][510/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.148 (0.151)
Train: [6][520/589]	BT 0.356 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.144 (0.151)
Train: [6][530/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.132 (0.151)
Train: [6][540/589]	BT 0.356 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.151)
Train: [6][550/589]	BT 0.367 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.133 (0.151)
Train: [6][560/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.167 (0.151)
Train: [6][570/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.163 (0.151)
Train: [6][580/589]	BT 0.358 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.158 (0.151)
epoch 6, total time 233.59
loss: 0.150940712904611@Epoch: 6
learning_rate: 0.0002,6
Valid: [6][10/88]	BT 0.109 (0.582)	DT 0.000 (0.470)	loss 0.136 (0.157)
Valid: [6][20/88]	BT 0.109 (0.505)	DT 0.000 (0.395)	loss 0.158 (0.155)
Valid: [6][30/88]	BT 0.109 (0.474)	DT 0.000 (0.363)	loss 0.158 (0.157)
Valid: [6][40/88]	BT 0.110 (0.463)	DT 0.000 (0.352)	loss 0.167 (0.156)
Valid: [6][50/88]	BT 0.109 (0.451)	DT 0.000 (0.340)	loss 0.142 (0.157)
Valid: [6][60/88]	BT 0.109 (0.447)	DT 0.000 (0.337)	loss 0.148 (0.157)
Valid: [6][70/88]	BT 0.109 (0.447)	DT 0.000 (0.337)	loss 0.135 (0.157)
Valid: [6][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.133 (0.156)
Train: [7][10/589]	BT 0.356 (0.748)	DT 0.000 (0.391)	lr 0.0002	loss 0.152 (0.151)
Train: [7][20/589]	BT 0.356 (0.576)	DT 0.000 (0.220)	lr 0.0002	loss 0.132 (0.151)
Train: [7][30/589]	BT 0.357 (0.513)	DT 0.000 (0.157)	lr 0.0002	loss 0.163 (0.153)
Train: [7][40/589]	BT 0.360 (0.481)	DT 0.000 (0.124)	lr 0.0002	loss 0.156 (0.152)
Train: [7][50/589]	BT 0.358 (0.467)	DT 0.001 (0.109)	lr 0.0002	loss 0.162 (0.152)
Train: [7][60/589]	BT 0.388 (0.453)	DT 0.000 (0.095)	lr 0.0002	loss 0.156 (0.151)
Train: [7][70/589]	BT 0.365 (0.445)	DT 0.000 (0.086)	lr 0.0002	loss 0.171 (0.152)
Train: [7][80/589]	BT 0.369 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.146 (0.153)
Train: [7][90/589]	BT 0.358 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.143 (0.152)
Train: [7][100/589]	BT 0.358 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.175 (0.153)
Train: [7][110/589]	BT 0.359 (0.424)	DT 0.000 (0.065)	lr 0.0002	loss 0.148 (0.152)
Train: [7][120/589]	BT 0.359 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.160 (0.152)
Train: [7][130/589]	BT 0.364 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.145 (0.152)
Train: [7][140/589]	BT 0.359 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.127 (0.152)
Train: [7][150/589]	BT 0.362 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.136 (0.151)
Train: [7][160/589]	BT 0.358 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.131 (0.151)
Train: [7][170/589]	BT 0.359 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.131 (0.151)
Train: [7][180/589]	BT 0.359 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.146 (0.151)
Train: [7][190/589]	BT 0.358 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.163 (0.151)
Train: [7][200/589]	BT 0.361 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.166 (0.151)
Train: [7][210/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.120 (0.151)
Train: [7][220/589]	BT 0.357 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.143 (0.151)
Train: [7][230/589]	BT 0.359 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.146 (0.151)
Train: [7][240/589]	BT 0.359 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.163 (0.151)
Train: [7][250/589]	BT 0.357 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.131 (0.150)
Train: [7][260/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.152 (0.150)
Train: [7][270/589]	BT 0.358 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.167 (0.150)
Train: [7][280/589]	BT 0.384 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.148 (0.150)
Train: [7][290/589]	BT 0.359 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.175 (0.150)
Train: [7][300/589]	BT 0.357 (0.400)	DT 0.001 (0.041)	lr 0.0002	loss 0.137 (0.150)
Train: [7][310/589]	BT 0.359 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.143 (0.150)
Train: [7][320/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.159 (0.150)
Train: [7][330/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.150)
Train: [7][340/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.139 (0.150)
Train: [7][350/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.150)
Train: [7][360/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.178 (0.150)
Train: [7][370/589]	BT 0.375 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.155 (0.150)
Train: [7][380/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.155 (0.150)
Train: [7][390/589]	BT 0.360 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.145 (0.150)
Train: [7][400/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.137 (0.150)
Train: [7][410/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.166 (0.150)
Train: [7][420/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.168 (0.150)
Train: [7][430/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.145 (0.150)
Train: [7][440/589]	BT 0.360 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.158 (0.150)
Train: [7][450/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.131 (0.150)
Train: [7][460/589]	BT 0.356 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.143 (0.150)
Train: [7][470/589]	BT 0.361 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.167 (0.150)
Train: [7][480/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.141 (0.150)
Train: [7][490/589]	BT 0.376 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.112 (0.149)
Train: [7][500/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.146 (0.150)
Train: [7][510/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.151 (0.150)
Train: [7][520/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.135 (0.150)
Train: [7][530/589]	BT 0.356 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.164 (0.150)
Train: [7][540/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.151 (0.150)
Train: [7][550/589]	BT 0.361 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.156 (0.150)
Train: [7][560/589]	BT 0.364 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.125 (0.150)
Train: [7][570/589]	BT 0.383 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.137 (0.150)
Train: [7][580/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.154 (0.150)
epoch 7, total time 233.53
loss: 0.14996059616267465@Epoch: 7
learning_rate: 0.0002,7
Valid: [7][10/88]	BT 0.110 (0.575)	DT 0.000 (0.464)	loss 0.143 (0.146)
Valid: [7][20/88]	BT 0.110 (0.512)	DT 0.000 (0.402)	loss 0.145 (0.146)
Valid: [7][30/88]	BT 0.110 (0.479)	DT 0.000 (0.369)	loss 0.161 (0.148)
Valid: [7][40/88]	BT 0.109 (0.466)	DT 0.000 (0.356)	loss 0.145 (0.147)
Valid: [7][50/88]	BT 0.110 (0.453)	DT 0.000 (0.344)	loss 0.117 (0.147)
Valid: [7][60/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.131 (0.147)
Valid: [7][70/88]	BT 0.110 (0.446)	DT 0.000 (0.335)	loss 0.158 (0.147)
Valid: [7][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.146 (0.146)
Epoch 0007: val_loss improved from 0.15033 to 0.14635, saving model
==> Saving...
Train: [8][10/589]	BT 0.402 (0.785)	DT 0.000 (0.425)	lr 0.0002	loss 0.145 (0.156)
Train: [8][20/589]	BT 0.387 (0.580)	DT 0.000 (0.221)	lr 0.0002	loss 0.161 (0.151)
Train: [8][30/589]	BT 0.356 (0.509)	DT 0.000 (0.151)	lr 0.0002	loss 0.162 (0.150)
Train: [8][40/589]	BT 0.359 (0.477)	DT 0.000 (0.120)	lr 0.0002	loss 0.163 (0.150)
Train: [8][50/589]	BT 0.358 (0.454)	DT 0.000 (0.097)	lr 0.0002	loss 0.144 (0.149)
Train: [8][60/589]	BT 0.358 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.158 (0.149)
Train: [8][70/589]	BT 0.354 (0.435)	DT 0.000 (0.077)	lr 0.0002	loss 0.117 (0.149)
Train: [8][80/589]	BT 0.357 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.172 (0.150)
Train: [8][90/589]	BT 0.357 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.157 (0.150)
Train: [8][100/589]	BT 0.356 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.181 (0.149)
Train: [8][110/589]	BT 0.356 (0.419)	DT 0.000 (0.062)	lr 0.0002	loss 0.138 (0.149)
Train: [8][120/589]	BT 0.363 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.151 (0.149)
Train: [8][130/589]	BT 0.358 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.144 (0.149)
Train: [8][140/589]	BT 0.356 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.159 (0.149)
Train: [8][150/589]	BT 0.358 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.158 (0.149)
Train: [8][160/589]	BT 0.384 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.156 (0.149)
Train: [8][170/589]	BT 0.356 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.159 (0.149)
Train: [8][180/589]	BT 0.366 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.151 (0.149)
Train: [8][190/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.146 (0.149)
Train: [8][200/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.149)
Train: [8][210/589]	BT 0.359 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.136 (0.149)
Train: [8][220/589]	BT 0.356 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.149)
Train: [8][230/589]	BT 0.358 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.153 (0.149)
Train: [8][240/589]	BT 0.369 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.146 (0.149)
Train: [8][250/589]	BT 0.365 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.149)
Train: [8][260/589]	BT 0.371 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.149)
Train: [8][270/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.146 (0.149)
Train: [8][280/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.173 (0.149)
Train: [8][290/589]	BT 0.357 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.170 (0.149)
Train: [8][300/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.166 (0.149)
Train: [8][310/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.130 (0.149)
Train: [8][320/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.159 (0.149)
Train: [8][330/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.153 (0.149)
Train: [8][340/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.125 (0.149)
Train: [8][350/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.148 (0.149)
Train: [8][360/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.152 (0.149)
Train: [8][370/589]	BT 0.373 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.115 (0.149)
Train: [8][380/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.156 (0.149)
Train: [8][390/589]	BT 0.373 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.161 (0.149)
Train: [8][400/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.131 (0.149)
Train: [8][410/589]	BT 0.363 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.163 (0.149)
Train: [8][420/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.149)
Train: [8][430/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.144 (0.149)
Train: [8][440/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.148 (0.149)
Train: [8][450/589]	BT 0.373 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.148)
Train: [8][460/589]	BT 0.360 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.171 (0.149)
Train: [8][470/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.152 (0.149)
Train: [8][480/589]	BT 0.355 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.172 (0.149)
Train: [8][490/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.149)
Train: [8][500/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.160 (0.149)
Train: [8][510/589]	BT 0.361 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.166 (0.149)
Train: [8][520/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.163 (0.149)
Train: [8][530/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.161 (0.149)
Train: [8][540/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.143 (0.149)
Train: [8][550/589]	BT 0.365 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.168 (0.149)
Train: [8][560/589]	BT 0.361 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.162 (0.149)
Train: [8][570/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.164 (0.149)
Train: [8][580/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.148 (0.149)
epoch 8, total time 229.85
loss: 0.1490025560086463@Epoch: 8
learning_rate: 0.0002,8
Valid: [8][10/88]	BT 0.110 (0.583)	DT 0.000 (0.471)	loss 0.142 (0.151)
Valid: [8][20/88]	BT 0.110 (0.502)	DT 0.000 (0.391)	loss 0.131 (0.151)
Valid: [8][30/88]	BT 0.109 (0.477)	DT 0.000 (0.367)	loss 0.134 (0.147)
Valid: [8][40/88]	BT 0.109 (0.460)	DT 0.000 (0.349)	loss 0.135 (0.147)
Valid: [8][50/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.181 (0.148)
Valid: [8][60/88]	BT 0.110 (0.452)	DT 0.000 (0.341)	loss 0.149 (0.147)
Valid: [8][70/88]	BT 0.109 (0.447)	DT 0.000 (0.337)	loss 0.132 (0.147)
Valid: [8][80/88]	BT 0.109 (0.445)	DT 0.000 (0.336)	loss 0.148 (0.146)
Epoch 0008: val_loss improved from 0.14635 to 0.14557, saving model
==> Saving...
Train: [9][10/589]	BT 0.357 (0.771)	DT 0.000 (0.414)	lr 0.0002	loss 0.132 (0.143)
Train: [9][20/589]	BT 0.356 (0.572)	DT 0.000 (0.214)	lr 0.0002	loss 0.132 (0.148)
Train: [9][30/589]	BT 0.356 (0.511)	DT 0.000 (0.154)	lr 0.0002	loss 0.117 (0.145)
Train: [9][40/589]	BT 0.357 (0.479)	DT 0.000 (0.121)	lr 0.0002	loss 0.166 (0.147)
Train: [9][50/589]	BT 0.356 (0.460)	DT 0.000 (0.102)	lr 0.0002	loss 0.148 (0.148)
Train: [9][60/589]	BT 0.358 (0.446)	DT 0.000 (0.088)	lr 0.0002	loss 0.163 (0.148)
Train: [9][70/589]	BT 0.358 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.133 (0.148)
Train: [9][80/589]	BT 0.370 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.141 (0.148)
Train: [9][90/589]	BT 0.356 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.168 (0.148)
Train: [9][100/589]	BT 0.358 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.158 (0.148)
Train: [9][110/589]	BT 0.357 (0.418)	DT 0.000 (0.059)	lr 0.0002	loss 0.133 (0.148)
Train: [9][120/589]	BT 0.358 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.156 (0.148)
Train: [9][130/589]	BT 0.357 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.139 (0.148)
Train: [9][140/589]	BT 0.357 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.166 (0.148)
Train: [9][150/589]	BT 0.357 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.141 (0.148)
Train: [9][160/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.180 (0.149)
Train: [9][170/589]	BT 0.356 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.146 (0.148)
Train: [9][180/589]	BT 0.358 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.121 (0.148)
Train: [9][190/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.158 (0.148)
Train: [9][200/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.115 (0.148)
Train: [9][210/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.114 (0.147)
Train: [9][220/589]	BT 0.358 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.119 (0.147)
Train: [9][230/589]	BT 0.358 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.146 (0.147)
Train: [9][240/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.167 (0.147)
Train: [9][250/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.151 (0.147)
Train: [9][260/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.148 (0.147)
Train: [9][270/589]	BT 0.384 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.139 (0.147)
Train: [9][280/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.175 (0.148)
Train: [9][290/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.153 (0.148)
Train: [9][300/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.127 (0.148)
Train: [9][310/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.127 (0.148)
Train: [9][320/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.187 (0.148)
Train: [9][330/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.168 (0.148)
Train: [9][340/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.165 (0.148)
Train: [9][350/589]	BT 0.356 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.170 (0.148)
Train: [9][360/589]	BT 0.368 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.152 (0.148)
Train: [9][370/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.153 (0.148)
Train: [9][380/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.171 (0.148)
Train: [9][390/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.167 (0.148)
Train: [9][400/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.146 (0.148)
Train: [9][410/589]	BT 0.372 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.125 (0.148)
Train: [9][420/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.154 (0.148)
Train: [9][430/589]	BT 0.368 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.148)
Train: [9][440/589]	BT 0.361 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.141 (0.148)
Train: [9][450/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.147 (0.148)
Train: [9][460/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.180 (0.148)
Train: [9][470/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.150 (0.148)
Train: [9][480/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.154 (0.148)
Train: [9][490/589]	BT 0.359 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.161 (0.148)
Train: [9][500/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.148)
Train: [9][510/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.155 (0.148)
Train: [9][520/589]	BT 0.372 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.144 (0.148)
Train: [9][530/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.144 (0.148)
Train: [9][540/589]	BT 0.356 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.149 (0.148)
Train: [9][550/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.136 (0.148)
Train: [9][560/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.130 (0.148)
Train: [9][570/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.166 (0.148)
Train: [9][580/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.156 (0.148)
epoch 9, total time 230.12
loss: 0.1478595530987419@Epoch: 9
learning_rate: 0.0002,9
Valid: [9][10/88]	BT 0.110 (0.603)	DT 0.000 (0.490)	loss 0.134 (0.150)
Valid: [9][20/88]	BT 0.110 (0.515)	DT 0.000 (0.402)	loss 0.160 (0.154)
Valid: [9][30/88]	BT 0.109 (0.487)	DT 0.000 (0.375)	loss 0.165 (0.153)
Valid: [9][40/88]	BT 0.109 (0.467)	DT 0.000 (0.356)	loss 0.144 (0.150)
Valid: [9][50/88]	BT 0.110 (0.460)	DT 0.000 (0.348)	loss 0.144 (0.149)
Valid: [9][60/88]	BT 0.109 (0.453)	DT 0.000 (0.341)	loss 0.127 (0.146)
Valid: [9][70/88]	BT 0.109 (0.447)	DT 0.000 (0.335)	loss 0.138 (0.146)
Valid: [9][80/88]	BT 0.116 (0.444)	DT 0.000 (0.333)	loss 0.159 (0.145)
Epoch 0009: val_loss improved from 0.14557 to 0.14477, saving model
==> Saving...
Train: [10][10/589]	BT 0.377 (0.767)	DT 0.000 (0.407)	lr 0.0002	loss 0.151 (0.150)
Train: [10][20/589]	BT 0.358 (0.572)	DT 0.000 (0.212)	lr 0.0002	loss 0.138 (0.152)
Train: [10][30/589]	BT 0.375 (0.503)	DT 0.000 (0.143)	lr 0.0002	loss 0.165 (0.154)
Train: [10][40/589]	BT 0.354 (0.474)	DT 0.000 (0.114)	lr 0.0002	loss 0.154 (0.153)
Train: [10][50/589]	BT 0.356 (0.457)	DT 0.000 (0.098)	lr 0.0002	loss 0.169 (0.151)
Train: [10][60/589]	BT 0.364 (0.448)	DT 0.000 (0.089)	lr 0.0002	loss 0.147 (0.150)
Train: [10][70/589]	BT 0.358 (0.441)	DT 0.000 (0.081)	lr 0.0002	loss 0.137 (0.148)
Train: [10][80/589]	BT 0.357 (0.432)	DT 0.000 (0.073)	lr 0.0002	loss 0.113 (0.147)
Train: [10][90/589]	BT 0.356 (0.427)	DT 0.000 (0.068)	lr 0.0002	loss 0.174 (0.147)
Train: [10][100/589]	BT 0.358 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.150 (0.147)
Train: [10][110/589]	BT 0.357 (0.420)	DT 0.000 (0.061)	lr 0.0002	loss 0.157 (0.148)
Train: [10][120/589]	BT 0.359 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.128 (0.148)
Train: [10][130/589]	BT 0.357 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.142 (0.147)
Train: [10][140/589]	BT 0.357 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.131 (0.147)
Train: [10][150/589]	BT 0.359 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.150 (0.148)
Train: [10][160/589]	BT 0.368 (0.411)	DT 0.000 (0.051)	lr 0.0002	loss 0.147 (0.147)
Train: [10][170/589]	BT 0.385 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.152 (0.148)
Train: [10][180/589]	BT 0.357 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.146 (0.148)
Train: [10][190/589]	BT 0.359 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.136 (0.148)
Train: [10][200/589]	BT 0.369 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.125 (0.147)
Train: [10][210/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.155 (0.147)
Train: [10][220/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.126 (0.147)
Train: [10][230/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.152 (0.147)
Train: [10][240/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.151 (0.147)
Train: [10][250/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.143 (0.147)
Train: [10][260/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.178 (0.148)
Train: [10][270/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.146 (0.148)
Train: [10][280/589]	BT 0.370 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.130 (0.148)
Train: [10][290/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.175 (0.148)
Train: [10][300/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.148 (0.148)
Train: [10][310/589]	BT 0.375 (0.397)	DT 0.001 (0.037)	lr 0.0002	loss 0.143 (0.148)
Train: [10][320/589]	BT 0.373 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.149 (0.148)
Train: [10][330/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.178 (0.147)
Train: [10][340/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.148 (0.147)
Train: [10][350/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.148 (0.147)
Train: [10][360/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.159 (0.147)
Train: [10][370/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.135 (0.147)
Train: [10][380/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.160 (0.147)
Train: [10][390/589]	BT 0.358 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.147)
Train: [10][400/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.158 (0.147)
Train: [10][410/589]	BT 0.372 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.153 (0.147)
Train: [10][420/589]	BT 0.371 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.147 (0.147)
Train: [10][430/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.165 (0.147)
Train: [10][440/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.148 (0.147)
Train: [10][450/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.148 (0.147)
Train: [10][460/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.155 (0.147)
Train: [10][470/589]	BT 0.379 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.165 (0.147)
Train: [10][480/589]	BT 0.379 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.158 (0.147)
Train: [10][490/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.157 (0.147)
Train: [10][500/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.144 (0.148)
Train: [10][510/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.142 (0.148)
Train: [10][520/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.148)
Train: [10][530/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.136 (0.147)
Train: [10][540/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.162 (0.147)
Train: [10][550/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.171 (0.148)
Train: [10][560/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.139 (0.147)
Train: [10][570/589]	BT 0.356 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.147)
Train: [10][580/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.181 (0.148)
epoch 10, total time 230.23
loss: 0.1474666521887073@Epoch: 10
learning_rate: 0.0002,10
Valid: [10][10/88]	BT 0.109 (0.561)	DT 0.000 (0.450)	loss 0.167 (0.151)
Valid: [10][20/88]	BT 0.110 (0.501)	DT 0.000 (0.390)	loss 0.143 (0.149)
Valid: [10][30/88]	BT 0.109 (0.484)	DT 0.000 (0.372)	loss 0.159 (0.151)
Valid: [10][40/88]	BT 0.110 (0.467)	DT 0.000 (0.356)	loss 0.152 (0.151)
Valid: [10][50/88]	BT 0.109 (0.457)	DT 0.000 (0.346)	loss 0.139 (0.150)
Valid: [10][60/88]	BT 0.110 (0.450)	DT 0.000 (0.339)	loss 0.147 (0.150)
Valid: [10][70/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.156 (0.148)
Valid: [10][80/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.151 (0.149)
Train: [11][10/589]	BT 0.378 (0.766)	DT 0.000 (0.406)	lr 0.0002	loss 0.129 (0.148)
Train: [11][20/589]	BT 0.364 (0.585)	DT 0.000 (0.225)	lr 0.0002	loss 0.174 (0.150)
Train: [11][30/589]	BT 0.356 (0.514)	DT 0.000 (0.155)	lr 0.0002	loss 0.144 (0.150)
Train: [11][40/589]	BT 0.364 (0.481)	DT 0.000 (0.122)	lr 0.0002	loss 0.122 (0.148)
Train: [11][50/589]	BT 0.357 (0.463)	DT 0.000 (0.105)	lr 0.0002	loss 0.132 (0.148)
Train: [11][60/589]	BT 0.361 (0.449)	DT 0.000 (0.091)	lr 0.0002	loss 0.152 (0.148)
Train: [11][70/589]	BT 0.366 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.135 (0.148)
Train: [11][80/589]	BT 0.358 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.166 (0.147)
Train: [11][90/589]	BT 0.358 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.135 (0.147)
Train: [11][100/589]	BT 0.357 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.159 (0.148)
Train: [11][110/589]	BT 0.369 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.169 (0.148)
Train: [11][120/589]	BT 0.363 (0.413)	DT 0.001 (0.054)	lr 0.0002	loss 0.143 (0.148)
Train: [11][130/589]	BT 0.364 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.124 (0.148)
Train: [11][140/589]	BT 0.358 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.138 (0.148)
Train: [11][150/589]	BT 0.364 (0.410)	DT 0.000 (0.050)	lr 0.0002	loss 0.149 (0.148)
Train: [11][160/589]	BT 0.357 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.144 (0.148)
Train: [11][170/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.135 (0.148)
Train: [11][180/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.161 (0.148)
Train: [11][190/589]	BT 0.359 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.166 (0.148)
Train: [11][200/589]	BT 0.372 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.135 (0.148)
Train: [11][210/589]	BT 0.358 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.148 (0.148)
Train: [11][220/589]	BT 0.358 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.133 (0.148)
Train: [11][230/589]	BT 0.357 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.145 (0.147)
Train: [11][240/589]	BT 0.357 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.117 (0.147)
Train: [11][250/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.140 (0.147)
Train: [11][260/589]	BT 0.356 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.153 (0.148)
Train: [11][270/589]	BT 0.356 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.165 (0.148)
Train: [11][280/589]	BT 0.386 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.145 (0.148)
Train: [11][290/589]	BT 0.360 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.163 (0.148)
Train: [11][300/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.145 (0.148)
Train: [11][310/589]	BT 0.359 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.144 (0.148)
Train: [11][320/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.149 (0.148)
Train: [11][330/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.130 (0.148)
Train: [11][340/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.148)
Train: [11][350/589]	BT 0.358 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.148)
Train: [11][360/589]	BT 0.356 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.144 (0.147)
Train: [11][370/589]	BT 0.371 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.143 (0.147)
Train: [11][380/589]	BT 0.358 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.139 (0.147)
Train: [11][390/589]	BT 0.364 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.128 (0.147)
Train: [11][400/589]	BT 0.357 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.145 (0.147)
Train: [11][410/589]	BT 0.358 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.131 (0.147)
Train: [11][420/589]	BT 0.383 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.142 (0.147)
Train: [11][430/589]	BT 0.356 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.136 (0.147)
Train: [11][440/589]	BT 0.358 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.157 (0.147)
Train: [11][450/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.149 (0.147)
Train: [11][460/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.147)
Train: [11][470/589]	BT 0.363 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.150 (0.147)
Train: [11][480/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.123 (0.147)
Train: [11][490/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.137 (0.147)
Train: [11][500/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.147 (0.147)
Train: [11][510/589]	BT 0.369 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.133 (0.147)
Train: [11][520/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.144 (0.147)
Train: [11][530/589]	BT 0.357 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.132 (0.147)
Train: [11][540/589]	BT 0.373 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.152 (0.147)
Train: [11][550/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.144 (0.147)
Train: [11][560/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.150 (0.147)
Train: [11][570/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.145 (0.147)
Train: [11][580/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.165 (0.147)
epoch 11, total time 234.89
loss: 0.14654625968705678@Epoch: 11
learning_rate: 0.0002,11
Valid: [11][10/88]	BT 0.110 (0.592)	DT 0.000 (0.480)	loss 0.148 (0.146)
Valid: [11][20/88]	BT 0.110 (0.512)	DT 0.000 (0.402)	loss 0.140 (0.143)
Valid: [11][30/88]	BT 0.109 (0.488)	DT 0.000 (0.378)	loss 0.138 (0.145)
Valid: [11][40/88]	BT 0.110 (0.469)	DT 0.000 (0.359)	loss 0.165 (0.145)
Valid: [11][50/88]	BT 0.109 (0.461)	DT 0.000 (0.351)	loss 0.145 (0.145)
Valid: [11][60/88]	BT 0.109 (0.457)	DT 0.000 (0.347)	loss 0.153 (0.145)
Valid: [11][70/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.180 (0.144)
Valid: [11][80/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.121 (0.144)
Epoch 0011: val_loss improved from 0.14477 to 0.14332, saving model
==> Saving...
Train: [12][10/589]	BT 0.356 (0.765)	DT 0.000 (0.407)	lr 0.0002	loss 0.139 (0.143)
Train: [12][20/589]	BT 0.357 (0.569)	DT 0.000 (0.211)	lr 0.0002	loss 0.138 (0.147)
Train: [12][30/589]	BT 0.355 (0.507)	DT 0.000 (0.148)	lr 0.0002	loss 0.144 (0.149)
Train: [12][40/589]	BT 0.358 (0.481)	DT 0.000 (0.122)	lr 0.0002	loss 0.138 (0.148)
Train: [12][50/589]	BT 0.357 (0.464)	DT 0.000 (0.106)	lr 0.0002	loss 0.130 (0.148)
Train: [12][60/589]	BT 0.358 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.144 (0.148)
Train: [12][70/589]	BT 0.361 (0.440)	DT 0.000 (0.082)	lr 0.0002	loss 0.156 (0.147)
Train: [12][80/589]	BT 0.360 (0.433)	DT 0.000 (0.075)	lr 0.0002	loss 0.143 (0.148)
Train: [12][90/589]	BT 0.360 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.143 (0.147)
Train: [12][100/589]	BT 0.357 (0.423)	DT 0.000 (0.065)	lr 0.0002	loss 0.126 (0.147)
Train: [12][110/589]	BT 0.357 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.135 (0.146)
Train: [12][120/589]	BT 0.356 (0.423)	DT 0.000 (0.065)	lr 0.0002	loss 0.174 (0.146)
Train: [12][130/589]	BT 0.358 (0.422)	DT 0.000 (0.064)	lr 0.0002	loss 0.140 (0.146)
Train: [12][140/589]	BT 0.356 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.136 (0.146)
Train: [12][150/589]	BT 0.359 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.155 (0.146)
Train: [12][160/589]	BT 0.358 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.157 (0.146)
Train: [12][170/589]	BT 0.358 (0.418)	DT 0.000 (0.059)	lr 0.0002	loss 0.127 (0.146)
Train: [12][180/589]	BT 0.356 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.125 (0.146)
Train: [12][190/589]	BT 0.356 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.138 (0.146)
Train: [12][200/589]	BT 0.359 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.141 (0.146)
Train: [12][210/589]	BT 0.359 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.152 (0.146)
Train: [12][220/589]	BT 0.360 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.152 (0.147)
Train: [12][230/589]	BT 0.357 (0.414)	DT 0.000 (0.055)	lr 0.0002	loss 0.129 (0.147)
Train: [12][240/589]	BT 0.360 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.152 (0.147)
Train: [12][250/589]	BT 0.361 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.158 (0.147)
Train: [12][260/589]	BT 0.359 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.135 (0.147)
Train: [12][270/589]	BT 0.357 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.127 (0.147)
Train: [12][280/589]	BT 0.368 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.170 (0.147)
Train: [12][290/589]	BT 0.357 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.120 (0.147)
Train: [12][300/589]	BT 0.360 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.143 (0.147)
Train: [12][310/589]	BT 0.359 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.162 (0.147)
Train: [12][320/589]	BT 0.356 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.150 (0.147)
Train: [12][330/589]	BT 0.358 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.154 (0.146)
Train: [12][340/589]	BT 0.358 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.159 (0.146)
Train: [12][350/589]	BT 0.365 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.191 (0.147)
Train: [12][360/589]	BT 0.360 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.142 (0.147)
Train: [12][370/589]	BT 0.355 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.131 (0.147)
Train: [12][380/589]	BT 0.359 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.150 (0.146)
Train: [12][390/589]	BT 0.360 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.144 (0.146)
Train: [12][400/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.138 (0.146)
Train: [12][410/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.163 (0.147)
Train: [12][420/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.123 (0.147)
Train: [12][430/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.137 (0.146)
Train: [12][440/589]	BT 0.357 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.145 (0.146)
Train: [12][450/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.185 (0.146)
Train: [12][460/589]	BT 0.359 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.130 (0.146)
Train: [12][470/589]	BT 0.359 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.140 (0.146)
Train: [12][480/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.136 (0.146)
Train: [12][490/589]	BT 0.358 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.164 (0.146)
Train: [12][500/589]	BT 0.356 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.156 (0.146)
Train: [12][510/589]	BT 0.367 (0.407)	DT 0.001 (0.048)	lr 0.0002	loss 0.136 (0.146)
Train: [12][520/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.136 (0.146)
Train: [12][530/589]	BT 0.362 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.154 (0.146)
Train: [12][540/589]	BT 0.365 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.161 (0.146)
Train: [12][550/589]	BT 0.361 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.158 (0.146)
Train: [12][560/589]	BT 0.356 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.150 (0.146)
Train: [12][570/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.139 (0.146)
Train: [12][580/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.153 (0.146)
epoch 12, total time 238.27
loss: 0.14600300664149046@Epoch: 12
learning_rate: 0.0002,12
Valid: [12][10/88]	BT 0.109 (0.602)	DT 0.000 (0.491)	loss 0.152 (0.139)
Valid: [12][20/88]	BT 0.109 (0.530)	DT 0.000 (0.420)	loss 0.133 (0.138)
Valid: [12][30/88]	BT 0.110 (0.495)	DT 0.000 (0.385)	loss 0.144 (0.141)
Valid: [12][40/88]	BT 0.109 (0.478)	DT 0.000 (0.368)	loss 0.153 (0.142)
Valid: [12][50/88]	BT 0.109 (0.467)	DT 0.000 (0.358)	loss 0.147 (0.142)
Valid: [12][60/88]	BT 0.109 (0.462)	DT 0.000 (0.352)	loss 0.141 (0.142)
Valid: [12][70/88]	BT 0.109 (0.457)	DT 0.000 (0.348)	loss 0.138 (0.143)
Valid: [12][80/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.145 (0.142)
Epoch 0012: val_loss improved from 0.14332 to 0.14191, saving model
==> Saving...
Train: [13][10/589]	BT 0.356 (0.763)	DT 0.000 (0.408)	lr 0.0002	loss 0.153 (0.149)
Train: [13][20/589]	BT 0.358 (0.583)	DT 0.000 (0.226)	lr 0.0002	loss 0.175 (0.150)
Train: [13][30/589]	BT 0.355 (0.518)	DT 0.000 (0.162)	lr 0.0002	loss 0.129 (0.147)
Train: [13][40/589]	BT 0.357 (0.484)	DT 0.000 (0.127)	lr 0.0002	loss 0.112 (0.145)
Train: [13][50/589]	BT 0.355 (0.461)	DT 0.000 (0.104)	lr 0.0002	loss 0.162 (0.145)
Train: [13][60/589]	BT 0.381 (0.455)	DT 0.000 (0.097)	lr 0.0002	loss 0.161 (0.145)
Train: [13][70/589]	BT 0.366 (0.442)	DT 0.000 (0.084)	lr 0.0002	loss 0.154 (0.146)
Train: [13][80/589]	BT 0.375 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.139 (0.145)
Train: [13][90/589]	BT 0.359 (0.433)	DT 0.000 (0.075)	lr 0.0002	loss 0.144 (0.145)
Train: [13][100/589]	BT 0.356 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.147 (0.146)
Train: [13][110/589]	BT 0.355 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.158 (0.146)
Train: [13][120/589]	BT 0.358 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.140 (0.146)
Train: [13][130/589]	BT 0.357 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.144 (0.146)
Train: [13][140/589]	BT 0.359 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.131 (0.146)
Train: [13][150/589]	BT 0.357 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.146 (0.145)
Train: [13][160/589]	BT 0.358 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.146 (0.145)
Train: [13][170/589]	BT 0.355 (0.416)	DT 0.000 (0.056)	lr 0.0002	loss 0.129 (0.145)
Train: [13][180/589]	BT 0.358 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.146 (0.145)
Train: [13][190/589]	BT 0.359 (0.414)	DT 0.000 (0.055)	lr 0.0002	loss 0.149 (0.145)
Train: [13][200/589]	BT 0.357 (0.414)	DT 0.000 (0.054)	lr 0.0002	loss 0.130 (0.145)
Train: [13][210/589]	BT 0.355 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.145 (0.145)
Train: [13][220/589]	BT 0.360 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.142 (0.145)
Train: [13][230/589]	BT 0.357 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.150 (0.145)
Train: [13][240/589]	BT 0.358 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.125 (0.145)
Train: [13][250/589]	BT 0.356 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.157 (0.145)
Train: [13][260/589]	BT 0.358 (0.411)	DT 0.000 (0.051)	lr 0.0002	loss 0.136 (0.145)
Train: [13][270/589]	BT 0.357 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.145 (0.145)
Train: [13][280/589]	BT 0.359 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.164 (0.145)
Train: [13][290/589]	BT 0.358 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.139 (0.145)
Train: [13][300/589]	BT 0.357 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.165 (0.145)
Train: [13][310/589]	BT 0.357 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.165 (0.145)
Train: [13][320/589]	BT 0.357 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.155 (0.145)
Train: [13][330/589]	BT 0.357 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.128 (0.145)
Train: [13][340/589]	BT 0.356 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.131 (0.145)
Train: [13][350/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.179 (0.145)
Train: [13][360/589]	BT 0.373 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.145 (0.145)
Train: [13][370/589]	BT 0.377 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.153 (0.145)
Train: [13][380/589]	BT 0.357 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.121 (0.145)
Train: [13][390/589]	BT 0.358 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.121 (0.145)
Train: [13][400/589]	BT 0.359 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.145 (0.145)
Train: [13][410/589]	BT 0.356 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.140 (0.145)
Train: [13][420/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.157 (0.145)
Train: [13][430/589]	BT 0.359 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.152 (0.145)
Train: [13][440/589]	BT 0.356 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.145)
Train: [13][450/589]	BT 0.358 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.131 (0.145)
Train: [13][460/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.155 (0.145)
Train: [13][470/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.134 (0.145)
Train: [13][480/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.142 (0.145)
Train: [13][490/589]	BT 0.359 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.152 (0.145)
Train: [13][500/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.144 (0.145)
Train: [13][510/589]	BT 0.359 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.155 (0.145)
Train: [13][520/589]	BT 0.358 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.157 (0.145)
Train: [13][530/589]	BT 0.358 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.143 (0.145)
Train: [13][540/589]	BT 0.359 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.135 (0.145)
Train: [13][550/589]	BT 0.365 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.146 (0.145)
Train: [13][560/589]	BT 0.359 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.145 (0.145)
Train: [13][570/589]	BT 0.358 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.154 (0.145)
Train: [13][580/589]	BT 0.358 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.146 (0.145)
epoch 13, total time 237.28
loss: 0.14508883582259127@Epoch: 13
learning_rate: 0.0002,13
Valid: [13][10/88]	BT 0.109 (0.548)	DT 0.000 (0.434)	loss 0.145 (0.139)
Valid: [13][20/88]	BT 0.110 (0.488)	DT 0.000 (0.375)	loss 0.160 (0.139)
Valid: [13][30/88]	BT 0.109 (0.467)	DT 0.000 (0.354)	loss 0.113 (0.139)
Valid: [13][40/88]	BT 0.109 (0.455)	DT 0.000 (0.342)	loss 0.133 (0.139)
Valid: [13][50/88]	BT 0.109 (0.448)	DT 0.000 (0.336)	loss 0.158 (0.139)
Valid: [13][60/88]	BT 0.109 (0.442)	DT 0.000 (0.331)	loss 0.161 (0.139)
Valid: [13][70/88]	BT 0.109 (0.439)	DT 0.000 (0.328)	loss 0.114 (0.140)
Valid: [13][80/88]	BT 0.110 (0.438)	DT 0.000 (0.327)	loss 0.146 (0.140)
Epoch 0013: val_loss improved from 0.14191 to 0.13976, saving model
==> Saving...
Train: [14][10/589]	BT 0.356 (0.792)	DT 0.000 (0.436)	lr 0.0002	loss 0.149 (0.144)
Train: [14][20/589]	BT 0.365 (0.588)	DT 0.000 (0.232)	lr 0.0002	loss 0.154 (0.148)
Train: [14][30/589]	BT 0.355 (0.521)	DT 0.001 (0.164)	lr 0.0002	loss 0.129 (0.144)
Train: [14][40/589]	BT 0.371 (0.483)	DT 0.001 (0.127)	lr 0.0002	loss 0.180 (0.142)
Train: [14][50/589]	BT 0.358 (0.459)	DT 0.001 (0.102)	lr 0.0002	loss 0.133 (0.142)
Train: [14][60/589]	BT 0.379 (0.445)	DT 0.000 (0.088)	lr 0.0002	loss 0.144 (0.143)
Train: [14][70/589]	BT 0.357 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.147 (0.144)
Train: [14][80/589]	BT 0.367 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.140 (0.144)
Train: [14][90/589]	BT 0.359 (0.423)	DT 0.000 (0.065)	lr 0.0002	loss 0.134 (0.144)
Train: [14][100/589]	BT 0.380 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.144 (0.144)
Train: [14][110/589]	BT 0.356 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.148 (0.144)
Train: [14][120/589]	BT 0.376 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.152 (0.144)
Train: [14][130/589]	BT 0.366 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.159 (0.144)
Train: [14][140/589]	BT 0.366 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.151 (0.144)
Train: [14][150/589]	BT 0.388 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.148 (0.144)
Train: [14][160/589]	BT 0.374 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.138 (0.145)
Train: [14][170/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.143 (0.145)
Train: [14][180/589]	BT 0.354 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.140 (0.145)
Train: [14][190/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.137 (0.145)
Train: [14][200/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.119 (0.145)
Train: [14][210/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.156 (0.145)
Train: [14][220/589]	BT 0.358 (0.397)	DT 0.001 (0.039)	lr 0.0002	loss 0.135 (0.145)
Train: [14][230/589]	BT 0.504 (0.398)	DT 0.150 (0.039)	lr 0.0002	loss 0.145 (0.145)
Train: [14][240/589]	BT 0.764 (0.398)	DT 0.409 (0.040)	lr 0.0002	loss 0.140 (0.145)
Train: [14][250/589]	BT 0.715 (0.398)	DT 0.360 (0.040)	lr 0.0002	loss 0.151 (0.145)
Train: [14][260/589]	BT 0.744 (0.398)	DT 0.389 (0.040)	lr 0.0002	loss 0.141 (0.145)
Train: [14][270/589]	BT 0.595 (0.398)	DT 0.240 (0.039)	lr 0.0002	loss 0.139 (0.145)
Train: [14][280/589]	BT 0.676 (0.397)	DT 0.321 (0.039)	lr 0.0002	loss 0.129 (0.145)
Train: [14][290/589]	BT 0.484 (0.397)	DT 0.129 (0.038)	lr 0.0002	loss 0.143 (0.145)
Train: [14][300/589]	BT 0.849 (0.397)	DT 0.492 (0.038)	lr 0.0002	loss 0.132 (0.145)
Train: [14][310/589]	BT 0.589 (0.397)	DT 0.233 (0.038)	lr 0.0002	loss 0.145 (0.146)
Train: [14][320/589]	BT 0.676 (0.397)	DT 0.320 (0.038)	lr 0.0002	loss 0.148 (0.146)
Train: [14][330/589]	BT 0.673 (0.397)	DT 0.307 (0.038)	lr 0.0002	loss 0.140 (0.146)
Train: [14][340/589]	BT 0.661 (0.396)	DT 0.306 (0.038)	lr 0.0002	loss 0.109 (0.146)
Train: [14][350/589]	BT 0.600 (0.396)	DT 0.244 (0.037)	lr 0.0002	loss 0.144 (0.145)
Train: [14][360/589]	BT 0.692 (0.396)	DT 0.337 (0.037)	lr 0.0002	loss 0.160 (0.146)
Train: [14][370/589]	BT 0.552 (0.395)	DT 0.195 (0.037)	lr 0.0002	loss 0.146 (0.146)
Train: [14][380/589]	BT 0.461 (0.395)	DT 0.107 (0.036)	lr 0.0002	loss 0.128 (0.146)
Train: [14][390/589]	BT 0.600 (0.395)	DT 0.245 (0.036)	lr 0.0002	loss 0.113 (0.146)
Train: [14][400/589]	BT 0.580 (0.395)	DT 0.224 (0.036)	lr 0.0002	loss 0.148 (0.146)
Train: [14][410/589]	BT 0.604 (0.394)	DT 0.234 (0.036)	lr 0.0002	loss 0.117 (0.145)
Train: [14][420/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.155 (0.146)
Train: [14][430/589]	BT 0.403 (0.394)	DT 0.048 (0.035)	lr 0.0002	loss 0.167 (0.145)
Train: [14][440/589]	BT 0.472 (0.394)	DT 0.117 (0.035)	lr 0.0002	loss 0.139 (0.145)
Train: [14][450/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.142 (0.145)
Train: [14][460/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.134 (0.146)
Train: [14][470/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.149 (0.145)
Train: [14][480/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.143 (0.145)
Train: [14][490/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.130 (0.145)
Train: [14][500/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.162 (0.145)
Train: [14][510/589]	BT 0.362 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.145)
Train: [14][520/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.142 (0.145)
Train: [14][530/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.170 (0.145)
Train: [14][540/589]	BT 0.360 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.145)
Train: [14][550/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.146 (0.145)
Train: [14][560/589]	BT 0.530 (0.392)	DT 0.176 (0.033)	lr 0.0002	loss 0.166 (0.145)
Train: [14][570/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.136 (0.145)
Train: [14][580/589]	BT 0.532 (0.391)	DT 0.179 (0.033)	lr 0.0002	loss 0.148 (0.145)
epoch 14, total time 230.12
loss: 0.14488880649376806@Epoch: 14
learning_rate: 0.0002,14
Valid: [14][10/88]	BT 0.110 (0.594)	DT 0.000 (0.483)	loss 0.109 (0.132)
Valid: [14][20/88]	BT 0.109 (0.509)	DT 0.000 (0.398)	loss 0.153 (0.133)
Valid: [14][30/88]	BT 0.110 (0.483)	DT 0.000 (0.373)	loss 0.128 (0.137)
Valid: [14][40/88]	BT 0.109 (0.471)	DT 0.000 (0.361)	loss 0.142 (0.139)
Valid: [14][50/88]	BT 0.110 (0.466)	DT 0.000 (0.356)	loss 0.132 (0.138)
Valid: [14][60/88]	BT 0.109 (0.458)	DT 0.000 (0.348)	loss 0.146 (0.138)
Valid: [14][70/88]	BT 0.109 (0.453)	DT 0.000 (0.343)	loss 0.128 (0.138)
Valid: [14][80/88]	BT 0.109 (0.451)	DT 0.000 (0.342)	loss 0.159 (0.139)
Epoch 0014: val_loss improved from 0.13976 to 0.13874, saving model
==> Saving...
Train: [15][10/589]	BT 0.356 (0.767)	DT 0.000 (0.410)	lr 0.0002	loss 0.159 (0.141)
Train: [15][20/589]	BT 0.355 (0.573)	DT 0.000 (0.216)	lr 0.0002	loss 0.145 (0.144)
Train: [15][30/589]	BT 0.358 (0.505)	DT 0.000 (0.148)	lr 0.0002	loss 0.146 (0.145)
Train: [15][40/589]	BT 0.354 (0.480)	DT 0.000 (0.123)	lr 0.0002	loss 0.148 (0.144)
Train: [15][50/589]	BT 0.382 (0.463)	DT 0.000 (0.105)	lr 0.0002	loss 0.149 (0.143)
Train: [15][60/589]	BT 0.374 (0.452)	DT 0.000 (0.094)	lr 0.0002	loss 0.141 (0.143)
Train: [15][70/589]	BT 0.355 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.158 (0.144)
Train: [15][80/589]	BT 0.358 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.132 (0.144)
Train: [15][90/589]	BT 0.356 (0.433)	DT 0.000 (0.075)	lr 0.0002	loss 0.150 (0.144)
Train: [15][100/589]	BT 0.357 (0.428)	DT 0.000 (0.069)	lr 0.0002	loss 0.122 (0.143)
Train: [15][110/589]	BT 0.357 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.159 (0.144)
Train: [15][120/589]	BT 0.357 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.150 (0.144)
Train: [15][130/589]	BT 0.358 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.145 (0.144)
Train: [15][140/589]	BT 0.357 (0.420)	DT 0.000 (0.061)	lr 0.0002	loss 0.144 (0.144)
Train: [15][150/589]	BT 0.357 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.161 (0.144)
Train: [15][160/589]	BT 0.356 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.153 (0.145)
Train: [15][170/589]	BT 0.359 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.136 (0.145)
Train: [15][180/589]	BT 0.359 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.124 (0.145)
Train: [15][190/589]	BT 0.357 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.128 (0.144)
Train: [15][200/589]	BT 0.359 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.152 (0.144)
Train: [15][210/589]	BT 0.357 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.147 (0.144)
Train: [15][220/589]	BT 0.357 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.142 (0.144)
Train: [15][230/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.138 (0.144)
Train: [15][240/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.147 (0.144)
Train: [15][250/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.136 (0.144)
Train: [15][260/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.134 (0.144)
Train: [15][270/589]	BT 0.370 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.132 (0.144)
Train: [15][280/589]	BT 0.358 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.153 (0.144)
Train: [15][290/589]	BT 0.359 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.152 (0.144)
Train: [15][300/589]	BT 0.359 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.175 (0.144)
Train: [15][310/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.156 (0.144)
Train: [15][320/589]	BT 0.358 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.110 (0.144)
Train: [15][330/589]	BT 0.358 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.141 (0.144)
Train: [15][340/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.142 (0.144)
Train: [15][350/589]	BT 0.356 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.165 (0.144)
Train: [15][360/589]	BT 0.359 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.152 (0.144)
Train: [15][370/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.131 (0.144)
Train: [15][380/589]	BT 0.358 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.152 (0.145)
Train: [15][390/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.112 (0.145)
Train: [15][400/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.129 (0.144)
Train: [15][410/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.137 (0.145)
Train: [15][420/589]	BT 0.359 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.155 (0.144)
Train: [15][430/589]	BT 0.360 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.129 (0.144)
Train: [15][440/589]	BT 0.360 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.169 (0.144)
Train: [15][450/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.125 (0.144)
Train: [15][460/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.135 (0.144)
Train: [15][470/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.136 (0.144)
Train: [15][480/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.175 (0.144)
Train: [15][490/589]	BT 0.359 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.152 (0.144)
Train: [15][500/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.158 (0.144)
Train: [15][510/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.147 (0.144)
Train: [15][520/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.154 (0.144)
Train: [15][530/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.129 (0.144)
Train: [15][540/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.126 (0.144)
Train: [15][550/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.172 (0.144)
Train: [15][560/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.176 (0.144)
Train: [15][570/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.169 (0.144)
Train: [15][580/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.143 (0.144)
epoch 15, total time 233.92
loss: 0.14442438899280413@Epoch: 15
learning_rate: 0.0002,15
Valid: [15][10/88]	BT 0.110 (0.583)	DT 0.000 (0.471)	loss 0.137 (0.139)
Valid: [15][20/88]	BT 0.110 (0.505)	DT 0.000 (0.395)	loss 0.152 (0.144)
Valid: [15][30/88]	BT 0.109 (0.479)	DT 0.000 (0.369)	loss 0.151 (0.142)
Valid: [15][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.148 (0.143)
Valid: [15][50/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.146 (0.143)
Valid: [15][60/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.151 (0.143)
Valid: [15][70/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.163 (0.143)
Valid: [15][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.139 (0.142)
Train: [16][10/589]	BT 0.356 (0.744)	DT 0.000 (0.384)	lr 0.0002	loss 0.143 (0.146)
Train: [16][20/589]	BT 0.367 (0.562)	DT 0.000 (0.202)	lr 0.0002	loss 0.146 (0.144)
Train: [16][30/589]	BT 0.363 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.135 (0.146)
Train: [16][40/589]	BT 0.371 (0.473)	DT 0.000 (0.114)	lr 0.0002	loss 0.147 (0.147)
Train: [16][50/589]	BT 0.371 (0.452)	DT 0.000 (0.093)	lr 0.0002	loss 0.151 (0.145)
Train: [16][60/589]	BT 0.372 (0.441)	DT 0.000 (0.082)	lr 0.0002	loss 0.134 (0.145)
Train: [16][70/589]	BT 0.357 (0.431)	DT 0.000 (0.072)	lr 0.0002	loss 0.134 (0.145)
Train: [16][80/589]	BT 0.357 (0.424)	DT 0.000 (0.065)	lr 0.0002	loss 0.148 (0.146)
Train: [16][90/589]	BT 0.358 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.144 (0.145)
Train: [16][100/589]	BT 0.359 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.123 (0.145)
Train: [16][110/589]	BT 0.366 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.124 (0.144)
Train: [16][120/589]	BT 0.378 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.145 (0.144)
Train: [16][130/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.139 (0.144)
Train: [16][140/589]	BT 0.370 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.120 (0.144)
Train: [16][150/589]	BT 0.372 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.139 (0.144)
Train: [16][160/589]	BT 0.365 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.133 (0.144)
Train: [16][170/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.144 (0.144)
Train: [16][180/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.112 (0.144)
Train: [16][190/589]	BT 0.365 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.144 (0.144)
Train: [16][200/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.153 (0.143)
Train: [16][210/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.140 (0.143)
Train: [16][220/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.158 (0.143)
Train: [16][230/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.147 (0.143)
Train: [16][240/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.143)
Train: [16][250/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.143)
Train: [16][260/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.143)
Train: [16][270/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.143)
Train: [16][280/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.143)
Train: [16][290/589]	BT 0.379 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.159 (0.143)
Train: [16][300/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.136 (0.143)
Train: [16][310/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.153 (0.143)
Train: [16][320/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.145 (0.143)
Train: [16][330/589]	BT 0.373 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.166 (0.143)
Train: [16][340/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.126 (0.143)
Train: [16][350/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.136 (0.143)
Train: [16][360/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.148 (0.143)
Train: [16][370/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.146 (0.144)
Train: [16][380/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.170 (0.144)
Train: [16][390/589]	BT 0.355 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.150 (0.144)
Train: [16][400/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.151 (0.144)
Train: [16][410/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.157 (0.144)
Train: [16][420/589]	BT 0.366 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.131 (0.144)
Train: [16][430/589]	BT 0.356 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.119 (0.144)
Train: [16][440/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.149 (0.144)
Train: [16][450/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.161 (0.143)
Train: [16][460/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.139 (0.143)
Train: [16][470/589]	BT 0.375 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.142 (0.143)
Train: [16][480/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.129 (0.143)
Train: [16][490/589]	BT 0.360 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.146 (0.143)
Train: [16][500/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.137 (0.143)
Train: [16][510/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.143)
Train: [16][520/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.117 (0.143)
Train: [16][530/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.133 (0.143)
Train: [16][540/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.129 (0.143)
Train: [16][550/589]	BT 0.368 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.153 (0.144)
Train: [16][560/589]	BT 0.360 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.144 (0.144)
Train: [16][570/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.133 (0.144)
Train: [16][580/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.146 (0.144)
epoch 16, total time 233.38
loss: 0.14375685121359935@Epoch: 16
learning_rate: 0.0002,16
Valid: [16][10/88]	BT 0.109 (0.605)	DT 0.000 (0.494)	loss 0.143 (0.137)
Valid: [16][20/88]	BT 0.109 (0.514)	DT 0.000 (0.404)	loss 0.140 (0.139)
Valid: [16][30/88]	BT 0.109 (0.490)	DT 0.000 (0.381)	loss 0.125 (0.138)
Valid: [16][40/88]	BT 0.110 (0.480)	DT 0.000 (0.370)	loss 0.137 (0.138)
Valid: [16][50/88]	BT 0.109 (0.469)	DT 0.000 (0.359)	loss 0.155 (0.138)
Valid: [16][60/88]	BT 0.109 (0.463)	DT 0.000 (0.354)	loss 0.127 (0.137)
Valid: [16][70/88]	BT 0.109 (0.459)	DT 0.000 (0.350)	loss 0.144 (0.138)
Valid: [16][80/88]	BT 0.109 (0.454)	DT 0.000 (0.345)	loss 0.127 (0.138)
Train: [17][10/589]	BT 0.396 (0.795)	DT 0.000 (0.436)	lr 0.0002	loss 0.128 (0.147)
Train: [17][20/589]	BT 0.380 (0.588)	DT 0.000 (0.229)	lr 0.0002	loss 0.131 (0.143)
Train: [17][30/589]	BT 0.357 (0.521)	DT 0.000 (0.163)	lr 0.0002	loss 0.153 (0.145)
Train: [17][40/589]	BT 0.368 (0.487)	DT 0.000 (0.129)	lr 0.0002	loss 0.140 (0.145)
Train: [17][50/589]	BT 0.358 (0.462)	DT 0.000 (0.103)	lr 0.0002	loss 0.158 (0.144)
Train: [17][60/589]	BT 0.371 (0.445)	DT 0.000 (0.086)	lr 0.0002	loss 0.129 (0.144)
Train: [17][70/589]	BT 0.360 (0.435)	DT 0.000 (0.076)	lr 0.0002	loss 0.135 (0.144)
Train: [17][80/589]	BT 0.370 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.120 (0.143)
Train: [17][90/589]	BT 0.366 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.137 (0.143)
Train: [17][100/589]	BT 0.374 (0.420)	DT 0.000 (0.061)	lr 0.0002	loss 0.148 (0.144)
Train: [17][110/589]	BT 0.369 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.138 (0.144)
Train: [17][120/589]	BT 0.383 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.168 (0.144)
Train: [17][130/589]	BT 0.357 (0.414)	DT 0.001 (0.055)	lr 0.0002	loss 0.172 (0.144)
Train: [17][140/589]	BT 0.360 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.180 (0.144)
Train: [17][150/589]	BT 0.358 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.161 (0.144)
Train: [17][160/589]	BT 0.358 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.131 (0.144)
Train: [17][170/589]	BT 0.359 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.120 (0.144)
Train: [17][180/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.156 (0.144)
Train: [17][190/589]	BT 0.357 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.143 (0.144)
Train: [17][200/589]	BT 0.360 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.130 (0.144)
Train: [17][210/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.110 (0.143)
Train: [17][220/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.153 (0.144)
Train: [17][230/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.168 (0.144)
Train: [17][240/589]	BT 0.359 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.133 (0.144)
Train: [17][250/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.148 (0.144)
Train: [17][260/589]	BT 0.357 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.155 (0.144)
Train: [17][270/589]	BT 0.358 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.138 (0.144)
Train: [17][280/589]	BT 0.357 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.132 (0.144)
Train: [17][290/589]	BT 0.358 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.115 (0.144)
Train: [17][300/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.127 (0.144)
Train: [17][310/589]	BT 0.358 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.136 (0.144)
Train: [17][320/589]	BT 0.358 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.134 (0.144)
Train: [17][330/589]	BT 0.357 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.158 (0.144)
Train: [17][340/589]	BT 0.365 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.134 (0.144)
Train: [17][350/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.143 (0.143)
Train: [17][360/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.139 (0.143)
Train: [17][370/589]	BT 0.363 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.138 (0.143)
Train: [17][380/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.138 (0.144)
Train: [17][390/589]	BT 0.358 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.130 (0.144)
Train: [17][400/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.154 (0.144)
Train: [17][410/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.144)
Train: [17][420/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.133 (0.144)
Train: [17][430/589]	BT 0.364 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.143 (0.144)
Train: [17][440/589]	BT 0.359 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.159 (0.144)
Train: [17][450/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.146 (0.144)
Train: [17][460/589]	BT 0.374 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.164 (0.144)
Train: [17][470/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.138 (0.144)
Train: [17][480/589]	BT 0.357 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.132 (0.144)
Train: [17][490/589]	BT 0.357 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.150 (0.144)
Train: [17][500/589]	BT 0.359 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.125 (0.144)
Train: [17][510/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.150 (0.144)
Train: [17][520/589]	BT 0.356 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.144)
Train: [17][530/589]	BT 0.387 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.136 (0.144)
Train: [17][540/589]	BT 0.360 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.135 (0.143)
Train: [17][550/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.139 (0.144)
Train: [17][560/589]	BT 0.362 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.145 (0.144)
Train: [17][570/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.125 (0.144)
Train: [17][580/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.153 (0.143)
epoch 17, total time 236.60
loss: 0.14350257458733934@Epoch: 17
learning_rate: 0.0002,17
Valid: [17][10/88]	BT 0.110 (0.572)	DT 0.000 (0.459)	loss 0.125 (0.138)
Valid: [17][20/88]	BT 0.110 (0.505)	DT 0.000 (0.393)	loss 0.120 (0.144)
Valid: [17][30/88]	BT 0.109 (0.476)	DT 0.000 (0.364)	loss 0.136 (0.143)
Valid: [17][40/88]	BT 0.109 (0.464)	DT 0.000 (0.353)	loss 0.150 (0.142)
Valid: [17][50/88]	BT 0.109 (0.456)	DT 0.000 (0.345)	loss 0.159 (0.140)
Valid: [17][60/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.158 (0.142)
Valid: [17][70/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.135 (0.141)
Valid: [17][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.141 (0.140)
Train: [18][10/589]	BT 0.356 (0.750)	DT 0.000 (0.391)	lr 0.0002	loss 0.130 (0.138)
Train: [18][20/589]	BT 0.354 (0.570)	DT 0.000 (0.212)	lr 0.0002	loss 0.144 (0.139)
Train: [18][30/589]	BT 0.359 (0.509)	DT 0.000 (0.151)	lr 0.0002	loss 0.158 (0.139)
Train: [18][40/589]	BT 0.370 (0.477)	DT 0.000 (0.118)	lr 0.0002	loss 0.135 (0.142)
Train: [18][50/589]	BT 0.358 (0.455)	DT 0.000 (0.097)	lr 0.0002	loss 0.128 (0.141)
Train: [18][60/589]	BT 0.356 (0.440)	DT 0.000 (0.082)	lr 0.0002	loss 0.142 (0.142)
Train: [18][70/589]	BT 0.369 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.164 (0.143)
Train: [18][80/589]	BT 0.358 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.147 (0.144)
Train: [18][90/589]	BT 0.358 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.128 (0.145)
Train: [18][100/589]	BT 0.356 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.119 (0.144)
Train: [18][110/589]	BT 0.358 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.139 (0.144)
Train: [18][120/589]	BT 0.358 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.137 (0.144)
Train: [18][130/589]	BT 0.368 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.163 (0.144)
Train: [18][140/589]	BT 0.380 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.163 (0.144)
Train: [18][150/589]	BT 0.378 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.129 (0.144)
Train: [18][160/589]	BT 0.354 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.169 (0.144)
Train: [18][170/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.127 (0.144)
Train: [18][180/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.139 (0.144)
Train: [18][190/589]	BT 0.357 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.144)
Train: [18][200/589]	BT 0.356 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.150 (0.144)
Train: [18][210/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.144 (0.144)
Train: [18][220/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.143)
Train: [18][230/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.153 (0.143)
Train: [18][240/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.134 (0.144)
Train: [18][250/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.155 (0.144)
Train: [18][260/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.155 (0.144)
Train: [18][270/589]	BT 0.360 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.148 (0.144)
Train: [18][280/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.146 (0.144)
Train: [18][290/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.128 (0.144)
Train: [18][300/589]	BT 0.356 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.151 (0.144)
Train: [18][310/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.145 (0.144)
Train: [18][320/589]	BT 0.356 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.146 (0.144)
Train: [18][330/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.159 (0.144)
Train: [18][340/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.120 (0.143)
Train: [18][350/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.158 (0.143)
Train: [18][360/589]	BT 0.369 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.164 (0.143)
Train: [18][370/589]	BT 0.355 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.154 (0.143)
Train: [18][380/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.142 (0.143)
Train: [18][390/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.148 (0.143)
Train: [18][400/589]	BT 0.356 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.151 (0.144)
Train: [18][410/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.160 (0.144)
Train: [18][420/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.172 (0.143)
Train: [18][430/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.131 (0.143)
Train: [18][440/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.143 (0.143)
Train: [18][450/589]	BT 0.360 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.141 (0.143)
Train: [18][460/589]	BT 0.380 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.148 (0.143)
Train: [18][470/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.153 (0.143)
Train: [18][480/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.153 (0.143)
Train: [18][490/589]	BT 0.356 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.149 (0.143)
Train: [18][500/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.143)
Train: [18][510/589]	BT 0.364 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.172 (0.143)
Train: [18][520/589]	BT 0.355 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.135 (0.143)
Train: [18][530/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.124 (0.143)
Train: [18][540/589]	BT 0.364 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.155 (0.143)
Train: [18][550/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.141 (0.143)
Train: [18][560/589]	BT 0.374 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.156 (0.143)
Train: [18][570/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.150 (0.143)
Train: [18][580/589]	BT 0.356 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.139 (0.143)
epoch 18, total time 230.87
loss: 0.14312701863684876@Epoch: 18
learning_rate: 0.0002,18
Valid: [18][10/88]	BT 0.110 (0.589)	DT 0.000 (0.478)	loss 0.158 (0.141)
Valid: [18][20/88]	BT 0.109 (0.508)	DT 0.000 (0.398)	loss 0.130 (0.136)
Valid: [18][30/88]	BT 0.110 (0.477)	DT 0.000 (0.366)	loss 0.141 (0.137)
Valid: [18][40/88]	BT 0.109 (0.462)	DT 0.000 (0.352)	loss 0.140 (0.136)
Valid: [18][50/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.139 (0.138)
Valid: [18][60/88]	BT 0.110 (0.452)	DT 0.000 (0.342)	loss 0.131 (0.137)
Valid: [18][70/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.153 (0.138)
Valid: [18][80/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.152 (0.139)
Train: [19][10/589]	BT 0.377 (0.771)	DT 0.000 (0.409)	lr 0.0002	loss 0.133 (0.142)
Train: [19][20/589]	BT 0.358 (0.571)	DT 0.000 (0.211)	lr 0.0002	loss 0.149 (0.143)
Train: [19][30/589]	BT 0.356 (0.510)	DT 0.000 (0.150)	lr 0.0002	loss 0.159 (0.143)
Train: [19][40/589]	BT 0.354 (0.482)	DT 0.000 (0.122)	lr 0.0002	loss 0.152 (0.143)
Train: [19][50/589]	BT 0.366 (0.465)	DT 0.000 (0.105)	lr 0.0002	loss 0.160 (0.144)
Train: [19][60/589]	BT 0.379 (0.453)	DT 0.000 (0.093)	lr 0.0002	loss 0.184 (0.144)
Train: [19][70/589]	BT 0.360 (0.445)	DT 0.000 (0.085)	lr 0.0002	loss 0.173 (0.144)
Train: [19][80/589]	BT 0.356 (0.441)	DT 0.000 (0.082)	lr 0.0002	loss 0.127 (0.143)
Train: [19][90/589]	BT 0.357 (0.435)	DT 0.000 (0.075)	lr 0.0002	loss 0.144 (0.144)
Train: [19][100/589]	BT 0.357 (0.430)	DT 0.000 (0.070)	lr 0.0002	loss 0.121 (0.143)
Train: [19][110/589]	BT 0.357 (0.424)	DT 0.000 (0.065)	lr 0.0002	loss 0.144 (0.143)
Train: [19][120/589]	BT 0.357 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.142 (0.144)
Train: [19][130/589]	BT 0.357 (0.420)	DT 0.000 (0.061)	lr 0.0002	loss 0.137 (0.143)
Train: [19][140/589]	BT 0.356 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.142 (0.144)
Train: [19][150/589]	BT 0.357 (0.413)	DT 0.000 (0.053)	lr 0.0002	loss 0.134 (0.144)
Train: [19][160/589]	BT 0.357 (0.410)	DT 0.000 (0.050)	lr 0.0002	loss 0.128 (0.144)
Train: [19][170/589]	BT 0.364 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.137 (0.144)
Train: [19][180/589]	BT 0.358 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.117 (0.143)
Train: [19][190/589]	BT 0.359 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.148 (0.143)
Train: [19][200/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.139 (0.143)
Train: [19][210/589]	BT 0.359 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.133 (0.143)
Train: [19][220/589]	BT 0.358 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.154 (0.143)
Train: [19][230/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.138 (0.143)
Train: [19][240/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.136 (0.143)
Train: [19][250/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.154 (0.143)
Train: [19][260/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.143 (0.143)
Train: [19][270/589]	BT 0.357 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.143)
Train: [19][280/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.126 (0.143)
Train: [19][290/589]	BT 0.360 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.176 (0.143)
Train: [19][300/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.143)
Train: [19][310/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.142)
Train: [19][320/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.142)
Train: [19][330/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.143)
Train: [19][340/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.142)
Train: [19][350/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.138 (0.142)
Train: [19][360/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.157 (0.142)
Train: [19][370/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.144 (0.142)
Train: [19][380/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.157 (0.142)
Train: [19][390/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.177 (0.143)
Train: [19][400/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.149 (0.143)
Train: [19][410/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.126 (0.142)
Train: [19][420/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.166 (0.142)
Train: [19][430/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.144 (0.142)
Train: [19][440/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.168 (0.142)
Train: [19][450/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.146 (0.142)
Train: [19][460/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.148 (0.142)
Train: [19][470/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.142)
Train: [19][480/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.146 (0.142)
Train: [19][490/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.150 (0.142)
Train: [19][500/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.142)
Train: [19][510/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.142)
Train: [19][520/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.154 (0.142)
Train: [19][530/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.137 (0.142)
Train: [19][540/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.137 (0.143)
Train: [19][550/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.124 (0.143)
Train: [19][560/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.143)
Train: [19][570/589]	BT 0.356 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.169 (0.143)
Train: [19][580/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.149 (0.143)
epoch 19, total time 227.35
loss: 0.14257762104823682@Epoch: 19
learning_rate: 0.0002,19
Valid: [19][10/88]	BT 0.109 (0.555)	DT 0.000 (0.444)	loss 0.147 (0.147)
Valid: [19][20/88]	BT 0.109 (0.505)	DT 0.000 (0.395)	loss 0.126 (0.141)
Valid: [19][30/88]	BT 0.109 (0.471)	DT 0.000 (0.361)	loss 0.123 (0.140)
Valid: [19][40/88]	BT 0.109 (0.459)	DT 0.000 (0.349)	loss 0.138 (0.139)
Valid: [19][50/88]	BT 0.109 (0.450)	DT 0.000 (0.341)	loss 0.133 (0.140)
Valid: [19][60/88]	BT 0.110 (0.442)	DT 0.000 (0.332)	loss 0.139 (0.139)
Valid: [19][70/88]	BT 0.109 (0.437)	DT 0.000 (0.328)	loss 0.148 (0.139)
Valid: [19][80/88]	BT 0.109 (0.433)	DT 0.000 (0.324)	loss 0.136 (0.139)
Train: [20][10/589]	BT 0.395 (0.766)	DT 0.000 (0.407)	lr 0.0002	loss 0.133 (0.140)
Train: [20][20/589]	BT 0.362 (0.568)	DT 0.000 (0.210)	lr 0.0002	loss 0.171 (0.141)
Train: [20][30/589]	BT 0.397 (0.509)	DT 0.000 (0.150)	lr 0.0002	loss 0.133 (0.141)
Train: [20][40/589]	BT 0.354 (0.471)	DT 0.000 (0.112)	lr 0.0002	loss 0.127 (0.141)
Train: [20][50/589]	BT 0.356 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.151 (0.141)
Train: [20][60/589]	BT 0.364 (0.439)	DT 0.000 (0.081)	lr 0.0002	loss 0.123 (0.140)
Train: [20][70/589]	BT 0.375 (0.430)	DT 0.000 (0.072)	lr 0.0002	loss 0.124 (0.140)
Train: [20][80/589]	BT 0.365 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.120 (0.140)
Train: [20][90/589]	BT 0.363 (0.418)	DT 0.000 (0.060)	lr 0.0002	loss 0.133 (0.140)
Train: [20][100/589]	BT 0.357 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.127 (0.140)
Train: [20][110/589]	BT 0.356 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.135 (0.140)
Train: [20][120/589]	BT 0.357 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.129 (0.141)
Train: [20][130/589]	BT 0.364 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.133 (0.141)
Train: [20][140/589]	BT 0.361 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.146 (0.141)
Train: [20][150/589]	BT 0.365 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.138 (0.141)
Train: [20][160/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.129 (0.141)
Train: [20][170/589]	BT 0.373 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.149 (0.142)
Train: [20][180/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.118 (0.142)
Train: [20][190/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.141 (0.142)
Train: [20][200/589]	BT 0.378 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.119 (0.142)
Train: [20][210/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.125 (0.142)
Train: [20][220/589]	BT 0.359 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.148 (0.142)
Train: [20][230/589]	BT 0.357 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.142)
Train: [20][240/589]	BT 0.361 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.150 (0.142)
Train: [20][250/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.147 (0.142)
Train: [20][260/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.137 (0.142)
Train: [20][270/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.148 (0.142)
Train: [20][280/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.142)
Train: [20][290/589]	BT 0.360 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.142)
Train: [20][300/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.132 (0.142)
Train: [20][310/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.149 (0.142)
Train: [20][320/589]	BT 0.356 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.144 (0.142)
Train: [20][330/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.139 (0.142)
Train: [20][340/589]	BT 0.355 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.142)
Train: [20][350/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.142)
Train: [20][360/589]	BT 0.360 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.142)
Train: [20][370/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.163 (0.142)
Train: [20][380/589]	BT 0.365 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.155 (0.142)
Train: [20][390/589]	BT 0.372 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.142)
Train: [20][400/589]	BT 0.367 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.142)
Train: [20][410/589]	BT 0.378 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.142)
Train: [20][420/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.173 (0.142)
Train: [20][430/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.142)
Train: [20][440/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.142)
Train: [20][450/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.142)
Train: [20][460/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.162 (0.142)
Train: [20][470/589]	BT 0.355 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.142)
Train: [20][480/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.142)
Train: [20][490/589]	BT 0.378 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.142)
Train: [20][500/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.138 (0.142)
Train: [20][510/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.142)
Train: [20][520/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.142)
Train: [20][530/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.145 (0.142)
Train: [20][540/589]	BT 0.362 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.132 (0.142)
Train: [20][550/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.121 (0.142)
Train: [20][560/589]	BT 0.361 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.155 (0.142)
Train: [20][570/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.146 (0.142)
Train: [20][580/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.138 (0.142)
epoch 20, total time 223.09
loss: 0.14223524929200967@Epoch: 20
learning_rate: 0.0002,20
Valid: [20][10/88]	BT 0.109 (0.574)	DT 0.000 (0.463)	loss 0.130 (0.150)
Valid: [20][20/88]	BT 0.110 (0.484)	DT 0.000 (0.373)	loss 0.143 (0.146)
Valid: [20][30/88]	BT 0.110 (0.452)	DT 0.000 (0.341)	loss 0.134 (0.143)
Valid: [20][40/88]	BT 0.109 (0.447)	DT 0.000 (0.336)	loss 0.145 (0.143)
Valid: [20][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.102 (0.140)
Valid: [20][60/88]	BT 0.109 (0.440)	DT 0.000 (0.329)	loss 0.140 (0.141)
Valid: [20][70/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.122 (0.141)
Valid: [20][80/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.130 (0.141)
Train: [21][10/589]	BT 0.374 (0.748)	DT 0.000 (0.390)	lr 0.0002	loss 0.159 (0.145)
Train: [21][20/589]	BT 0.363 (0.552)	DT 0.000 (0.195)	lr 0.0002	loss 0.141 (0.141)
Train: [21][30/589]	BT 0.357 (0.488)	DT 0.000 (0.131)	lr 0.0002	loss 0.160 (0.141)
Train: [21][40/589]	BT 0.359 (0.457)	DT 0.000 (0.101)	lr 0.0002	loss 0.121 (0.141)
Train: [21][50/589]	BT 0.357 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.110 (0.141)
Train: [21][60/589]	BT 0.381 (0.430)	DT 0.000 (0.073)	lr 0.0002	loss 0.131 (0.140)
Train: [21][70/589]	BT 0.357 (0.420)	DT 0.000 (0.063)	lr 0.0002	loss 0.125 (0.139)
Train: [21][80/589]	BT 0.357 (0.412)	DT 0.000 (0.055)	lr 0.0002	loss 0.141 (0.140)
Train: [21][90/589]	BT 0.359 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.160 (0.140)
Train: [21][100/589]	BT 0.359 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.135 (0.141)
Train: [21][110/589]	BT 0.365 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.137 (0.141)
Train: [21][120/589]	BT 0.360 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.135 (0.140)
Train: [21][130/589]	BT 0.355 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.142 (0.141)
Train: [21][140/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.146 (0.141)
Train: [21][150/589]	BT 0.369 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.157 (0.141)
Train: [21][160/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.132 (0.142)
Train: [21][170/589]	BT 0.368 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.156 (0.142)
Train: [21][180/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.192 (0.142)
Train: [21][190/589]	BT 0.373 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.143)
Train: [21][200/589]	BT 0.365 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.131 (0.143)
Train: [21][210/589]	BT 0.365 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.153 (0.142)
Train: [21][220/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.155 (0.143)
Train: [21][230/589]	BT 0.361 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.143)
Train: [21][240/589]	BT 0.369 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.144 (0.143)
Train: [21][250/589]	BT 0.364 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.142)
Train: [21][260/589]	BT 0.366 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.143)
Train: [21][270/589]	BT 0.364 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.142)
Train: [21][280/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.142)
Train: [21][290/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.137 (0.142)
Train: [21][300/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.143)
Train: [21][310/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.143)
Train: [21][320/589]	BT 0.362 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.143)
Train: [21][330/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.146 (0.143)
Train: [21][340/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.143)
Train: [21][350/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.157 (0.143)
Train: [21][360/589]	BT 0.360 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.121 (0.143)
Train: [21][370/589]	BT 0.362 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.159 (0.143)
Train: [21][380/589]	BT 0.371 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.147 (0.143)
Train: [21][390/589]	BT 0.373 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.143)
Train: [21][400/589]	BT 0.367 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.122 (0.143)
Train: [21][410/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.192 (0.143)
Train: [21][420/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.157 (0.142)
Train: [21][430/589]	BT 0.379 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.152 (0.142)
Train: [21][440/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.139 (0.143)
Train: [21][450/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.143)
Train: [21][460/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.177 (0.143)
Train: [21][470/589]	BT 0.375 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.150 (0.143)
Train: [21][480/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.131 (0.142)
Train: [21][490/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.166 (0.142)
Train: [21][500/589]	BT 0.356 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.114 (0.142)
Train: [21][510/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.141 (0.142)
Train: [21][520/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.132 (0.142)
Train: [21][530/589]	BT 0.356 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.125 (0.142)
Train: [21][540/589]	BT 0.372 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.133 (0.142)
Train: [21][550/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.138 (0.142)
Train: [21][560/589]	BT 0.354 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.158 (0.142)
Train: [21][570/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.172 (0.142)
Train: [21][580/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.136 (0.142)
epoch 21, total time 220.51
loss: 0.14209047527969934@Epoch: 21
learning_rate: 0.0002,21
Valid: [21][10/88]	BT 0.109 (0.565)	DT 0.000 (0.454)	loss 0.123 (0.138)
Valid: [21][20/88]	BT 0.109 (0.480)	DT 0.000 (0.370)	loss 0.125 (0.137)
Valid: [21][30/88]	BT 0.110 (0.457)	DT 0.000 (0.347)	loss 0.154 (0.138)
Valid: [21][40/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.157 (0.139)
Valid: [21][50/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.175 (0.139)
Valid: [21][60/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.142 (0.139)
Valid: [21][70/88]	BT 0.109 (0.425)	DT 0.000 (0.316)	loss 0.122 (0.137)
Valid: [21][80/88]	BT 0.109 (0.423)	DT 0.000 (0.313)	loss 0.139 (0.137)
Epoch 0021: val_loss improved from 0.13874 to 0.13753, saving model
==> Saving...
Train: [22][10/589]	BT 0.357 (0.743)	DT 0.000 (0.386)	lr 0.0002	loss 0.136 (0.150)
Train: [22][20/589]	BT 0.355 (0.551)	DT 0.000 (0.194)	lr 0.0002	loss 0.124 (0.146)
Train: [22][30/589]	BT 0.364 (0.490)	DT 0.000 (0.133)	lr 0.0002	loss 0.131 (0.146)
Train: [22][40/589]	BT 0.366 (0.464)	DT 0.000 (0.107)	lr 0.0002	loss 0.169 (0.144)
Train: [22][50/589]	BT 0.372 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.127 (0.142)
Train: [22][60/589]	BT 0.358 (0.434)	DT 0.000 (0.077)	lr 0.0002	loss 0.161 (0.144)
Train: [22][70/589]	BT 0.359 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.124 (0.143)
Train: [22][80/589]	BT 0.374 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.133 (0.142)
Train: [22][90/589]	BT 0.358 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.128 (0.141)
Train: [22][100/589]	BT 0.364 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.137 (0.142)
Train: [22][110/589]	BT 0.370 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.147 (0.142)
Train: [22][120/589]	BT 0.366 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.141 (0.142)
Train: [22][130/589]	BT 0.366 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.138 (0.142)
Train: [22][140/589]	BT 0.356 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.140 (0.143)
Train: [22][150/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.142 (0.143)
Train: [22][160/589]	BT 0.366 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.127 (0.143)
Train: [22][170/589]	BT 0.359 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.147 (0.143)
Train: [22][180/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.125 (0.142)
Train: [22][190/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.142 (0.143)
Train: [22][200/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.142 (0.143)
Train: [22][210/589]	BT 0.356 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.152 (0.142)
Train: [22][220/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.126 (0.142)
Train: [22][230/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.123 (0.142)
Train: [22][240/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.142)
Train: [22][250/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.142)
Train: [22][260/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.138 (0.142)
Train: [22][270/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.142 (0.142)
Train: [22][280/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.133 (0.142)
Train: [22][290/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.142)
Train: [22][300/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.156 (0.142)
Train: [22][310/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.138 (0.142)
Train: [22][320/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.152 (0.142)
Train: [22][330/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.142)
Train: [22][340/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.147 (0.142)
Train: [22][350/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.149 (0.142)
Train: [22][360/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.165 (0.142)
Train: [22][370/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.142)
Train: [22][380/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.142)
Train: [22][390/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.142 (0.142)
Train: [22][400/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.164 (0.141)
Train: [22][410/589]	BT 0.360 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.141)
Train: [22][420/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.142 (0.141)
Train: [22][430/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.130 (0.142)
Train: [22][440/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.138 (0.142)
Train: [22][450/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.148 (0.141)
Train: [22][460/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.162 (0.141)
Train: [22][470/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.141)
Train: [22][480/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.141)
Train: [22][490/589]	BT 0.360 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.135 (0.141)
Train: [22][500/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.134 (0.141)
Train: [22][510/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.156 (0.142)
Train: [22][520/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.141)
Train: [22][530/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.141)
Train: [22][540/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.158 (0.142)
Train: [22][550/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.144 (0.141)
Train: [22][560/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.154 (0.142)
Train: [22][570/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.125 (0.142)
Train: [22][580/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.142)
epoch 22, total time 221.66
loss: 0.1415909132760929@Epoch: 22
learning_rate: 0.0002,22
Valid: [22][10/88]	BT 0.110 (0.563)	DT 0.000 (0.451)	loss 0.139 (0.142)
Valid: [22][20/88]	BT 0.109 (0.480)	DT 0.000 (0.369)	loss 0.129 (0.140)
Valid: [22][30/88]	BT 0.110 (0.459)	DT 0.000 (0.349)	loss 0.138 (0.139)
Valid: [22][40/88]	BT 0.109 (0.442)	DT 0.000 (0.332)	loss 0.152 (0.138)
Valid: [22][50/88]	BT 0.110 (0.434)	DT 0.000 (0.324)	loss 0.132 (0.136)
Valid: [22][60/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.165 (0.136)
Valid: [22][70/88]	BT 0.109 (0.426)	DT 0.000 (0.316)	loss 0.137 (0.137)
Valid: [22][80/88]	BT 0.109 (0.423)	DT 0.000 (0.313)	loss 0.138 (0.138)
Train: [23][10/589]	BT 0.356 (0.737)	DT 0.000 (0.377)	lr 0.0002	loss 0.137 (0.143)
Train: [23][20/589]	BT 0.361 (0.554)	DT 0.000 (0.194)	lr 0.0002	loss 0.153 (0.141)
Train: [23][30/589]	BT 0.357 (0.495)	DT 0.000 (0.137)	lr 0.0002	loss 0.132 (0.139)
Train: [23][40/589]	BT 0.359 (0.463)	DT 0.000 (0.106)	lr 0.0002	loss 0.116 (0.140)
Train: [23][50/589]	BT 0.358 (0.447)	DT 0.000 (0.089)	lr 0.0002	loss 0.151 (0.141)
Train: [23][60/589]	BT 0.358 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.156 (0.141)
Train: [23][70/589]	BT 0.363 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.149 (0.141)
Train: [23][80/589]	BT 0.357 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.163 (0.142)
Train: [23][90/589]	BT 0.356 (0.409)	DT 0.000 (0.052)	lr 0.0002	loss 0.121 (0.142)
Train: [23][100/589]	BT 0.357 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.141 (0.141)
Train: [23][110/589]	BT 0.378 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.128 (0.142)
Train: [23][120/589]	BT 0.367 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.144 (0.141)
Train: [23][130/589]	BT 0.357 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.146 (0.142)
Train: [23][140/589]	BT 0.364 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.136 (0.141)
Train: [23][150/589]	BT 0.378 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.141)
Train: [23][160/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.159 (0.141)
Train: [23][170/589]	BT 0.370 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.127 (0.141)
Train: [23][180/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.163 (0.140)
Train: [23][190/589]	BT 0.369 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.156 (0.140)
Train: [23][200/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.140)
Train: [23][210/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.140)
Train: [23][220/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.131 (0.140)
Train: [23][230/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.129 (0.140)
Train: [23][240/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.150 (0.140)
Train: [23][250/589]	BT 0.362 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.140)
Train: [23][260/589]	BT 0.360 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.122 (0.140)
Train: [23][270/589]	BT 0.361 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.172 (0.140)
Train: [23][280/589]	BT 0.367 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.141)
Train: [23][290/589]	BT 0.368 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.184 (0.141)
Train: [23][300/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.121 (0.141)
Train: [23][310/589]	BT 0.381 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.141)
Train: [23][320/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.156 (0.141)
Train: [23][330/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.148 (0.141)
Train: [23][340/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.141)
Train: [23][350/589]	BT 0.369 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.139 (0.141)
Train: [23][360/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.143 (0.141)
Train: [23][370/589]	BT 0.361 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.153 (0.142)
Train: [23][380/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.134 (0.142)
Train: [23][390/589]	BT 0.361 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.145 (0.141)
Train: [23][400/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.118 (0.141)
Train: [23][410/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.118 (0.141)
Train: [23][420/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.141)
Train: [23][430/589]	BT 0.355 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.141)
Train: [23][440/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.141)
Train: [23][450/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.114 (0.141)
Train: [23][460/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.170 (0.141)
Train: [23][470/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.167 (0.141)
Train: [23][480/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.161 (0.141)
Train: [23][490/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.141)
Train: [23][500/589]	BT 0.373 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.155 (0.141)
Train: [23][510/589]	BT 0.364 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.121 (0.141)
Train: [23][520/589]	BT 0.354 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.133 (0.141)
Train: [23][530/589]	BT 0.356 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.126 (0.141)
Train: [23][540/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.135 (0.141)
Train: [23][550/589]	BT 0.359 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.140 (0.141)
Train: [23][560/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.133 (0.141)
Train: [23][570/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.139 (0.141)
Train: [23][580/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.138 (0.141)
epoch 23, total time 220.40
loss: 0.14123029268950396@Epoch: 23
learning_rate: 0.0002,23
Valid: [23][10/88]	BT 0.110 (0.548)	DT 0.000 (0.437)	loss 0.161 (0.147)
Valid: [23][20/88]	BT 0.109 (0.485)	DT 0.000 (0.375)	loss 0.154 (0.147)
Valid: [23][30/88]	BT 0.109 (0.465)	DT 0.000 (0.356)	loss 0.146 (0.144)
Valid: [23][40/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.150 (0.143)
Valid: [23][50/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.129 (0.142)
Valid: [23][60/88]	BT 0.110 (0.441)	DT 0.000 (0.331)	loss 0.114 (0.142)
Valid: [23][70/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.151 (0.142)
Valid: [23][80/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.123 (0.141)
Train: [24][10/589]	BT 0.356 (0.743)	DT 0.000 (0.386)	lr 0.0002	loss 0.146 (0.149)
Train: [24][20/589]	BT 0.357 (0.566)	DT 0.000 (0.209)	lr 0.0002	loss 0.149 (0.145)
Train: [24][30/589]	BT 0.371 (0.498)	DT 0.000 (0.140)	lr 0.0002	loss 0.139 (0.143)
Train: [24][40/589]	BT 0.357 (0.464)	DT 0.000 (0.106)	lr 0.0002	loss 0.143 (0.142)
Train: [24][50/589]	BT 0.357 (0.443)	DT 0.000 (0.085)	lr 0.0002	loss 0.148 (0.142)
Train: [24][60/589]	BT 0.357 (0.430)	DT 0.000 (0.073)	lr 0.0002	loss 0.154 (0.143)
Train: [24][70/589]	BT 0.355 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.163 (0.141)
Train: [24][80/589]	BT 0.359 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.123 (0.141)
Train: [24][90/589]	BT 0.356 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.137 (0.141)
Train: [24][100/589]	BT 0.373 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.123 (0.140)
Train: [24][110/589]	BT 0.355 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.150 (0.141)
Train: [24][120/589]	BT 0.354 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.158 (0.141)
Train: [24][130/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.140 (0.141)
Train: [24][140/589]	BT 0.366 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.133 (0.141)
Train: [24][150/589]	BT 0.364 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.157 (0.140)
Train: [24][160/589]	BT 0.364 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.187 (0.141)
Train: [24][170/589]	BT 0.378 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.166 (0.141)
Train: [24][180/589]	BT 0.359 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.161 (0.141)
Train: [24][190/589]	BT 0.356 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.131 (0.141)
Train: [24][200/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.159 (0.141)
Train: [24][210/589]	BT 0.376 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.141)
Train: [24][220/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.141)
Train: [24][230/589]	BT 0.364 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.155 (0.141)
Train: [24][240/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.144 (0.141)
Train: [24][250/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.184 (0.141)
Train: [24][260/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.150 (0.141)
Train: [24][270/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.141)
Train: [24][280/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.141)
Train: [24][290/589]	BT 0.354 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.175 (0.141)
Train: [24][300/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.148 (0.141)
Train: [24][310/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.155 (0.141)
Train: [24][320/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.130 (0.141)
Train: [24][330/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.148 (0.141)
Train: [24][340/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.120 (0.141)
Train: [24][350/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.141)
Train: [24][360/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.157 (0.141)
Train: [24][370/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.156 (0.141)
Train: [24][380/589]	BT 0.381 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.146 (0.141)
Train: [24][390/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.134 (0.141)
Train: [24][400/589]	BT 0.375 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.145 (0.141)
Train: [24][410/589]	BT 0.363 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.149 (0.141)
Train: [24][420/589]	BT 0.374 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.151 (0.141)
Train: [24][430/589]	BT 0.365 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.141)
Train: [24][440/589]	BT 0.368 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.141)
Train: [24][450/589]	BT 0.361 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.150 (0.141)
Train: [24][460/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.141)
Train: [24][470/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.141)
Train: [24][480/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.141)
Train: [24][490/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.141)
Train: [24][500/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.150 (0.141)
Train: [24][510/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.141)
Train: [24][520/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.146 (0.141)
Train: [24][530/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.155 (0.141)
Train: [24][540/589]	BT 0.367 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.139 (0.141)
Train: [24][550/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.149 (0.141)
Train: [24][560/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.146 (0.141)
Train: [24][570/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.121 (0.141)
Train: [24][580/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.143 (0.141)
epoch 24, total time 221.99
loss: 0.14083220853227096@Epoch: 24
learning_rate: 0.0002,24
Valid: [24][10/88]	BT 0.110 (0.565)	DT 0.000 (0.453)	loss 0.132 (0.135)
Valid: [24][20/88]	BT 0.109 (0.485)	DT 0.000 (0.374)	loss 0.142 (0.136)
Valid: [24][30/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.119 (0.135)
Valid: [24][40/88]	BT 0.109 (0.451)	DT 0.000 (0.341)	loss 0.125 (0.136)
Valid: [24][50/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.128 (0.136)
Valid: [24][60/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.129 (0.136)
Valid: [24][70/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.127 (0.136)
Valid: [24][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.141 (0.137)
Epoch 0024: val_loss improved from 0.13753 to 0.13620, saving model
==> Saving...
Train: [25][10/589]	BT 0.372 (0.750)	DT 0.000 (0.390)	lr 0.0002	loss 0.138 (0.140)
Train: [25][20/589]	BT 0.374 (0.564)	DT 0.000 (0.205)	lr 0.0002	loss 0.122 (0.136)
Train: [25][30/589]	BT 0.358 (0.495)	DT 0.000 (0.137)	lr 0.0002	loss 0.126 (0.137)
Train: [25][40/589]	BT 0.360 (0.463)	DT 0.000 (0.105)	lr 0.0002	loss 0.139 (0.138)
Train: [25][50/589]	BT 0.356 (0.443)	DT 0.000 (0.084)	lr 0.0002	loss 0.156 (0.139)
Train: [25][60/589]	BT 0.356 (0.431)	DT 0.000 (0.073)	lr 0.0002	loss 0.152 (0.140)
Train: [25][70/589]	BT 0.379 (0.426)	DT 0.000 (0.067)	lr 0.0002	loss 0.150 (0.140)
Train: [25][80/589]	BT 0.363 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.138 (0.139)
Train: [25][90/589]	BT 0.373 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.115 (0.139)
Train: [25][100/589]	BT 0.355 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.159 (0.140)
Train: [25][110/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.124 (0.140)
Train: [25][120/589]	BT 0.353 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.129 (0.140)
Train: [25][130/589]	BT 0.359 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.136 (0.141)
Train: [25][140/589]	BT 0.357 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.126 (0.140)
Train: [25][150/589]	BT 0.357 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.139 (0.140)
Train: [25][160/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.140 (0.140)
Train: [25][170/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.160 (0.141)
Train: [25][180/589]	BT 0.357 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.139 (0.140)
Train: [25][190/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.161 (0.141)
Train: [25][200/589]	BT 0.356 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.149 (0.141)
Train: [25][210/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.154 (0.141)
Train: [25][220/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.139 (0.141)
Train: [25][230/589]	BT 0.360 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.133 (0.141)
Train: [25][240/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.140)
Train: [25][250/589]	BT 0.381 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.140)
Train: [25][260/589]	BT 0.366 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.152 (0.141)
Train: [25][270/589]	BT 0.355 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.141)
Train: [25][280/589]	BT 0.361 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.135 (0.141)
Train: [25][290/589]	BT 0.373 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.161 (0.141)
Train: [25][300/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.141)
Train: [25][310/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.149 (0.141)
Train: [25][320/589]	BT 0.359 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.148 (0.141)
Train: [25][330/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.126 (0.141)
Train: [25][340/589]	BT 0.361 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.141)
Train: [25][350/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.141)
Train: [25][360/589]	BT 0.371 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.168 (0.141)
Train: [25][370/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.151 (0.141)
Train: [25][380/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.128 (0.141)
Train: [25][390/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.141)
Train: [25][400/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.150 (0.141)
Train: [25][410/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.141)
Train: [25][420/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.155 (0.141)
Train: [25][430/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.141)
Train: [25][440/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.128 (0.141)
Train: [25][450/589]	BT 0.359 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.143 (0.141)
Train: [25][460/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.139 (0.141)
Train: [25][470/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.141)
Train: [25][480/589]	BT 0.359 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.141)
Train: [25][490/589]	BT 0.367 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.149 (0.141)
Train: [25][500/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.141)
Train: [25][510/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.164 (0.141)
Train: [25][520/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.159 (0.141)
Train: [25][530/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.144 (0.141)
Train: [25][540/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.141)
Train: [25][550/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.115 (0.141)
Train: [25][560/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.142 (0.141)
Train: [25][570/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.141)
Train: [25][580/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.157 (0.141)
epoch 25, total time 222.15
loss: 0.14073604940481693@Epoch: 25
learning_rate: 0.0002,25
Valid: [25][10/88]	BT 0.110 (0.561)	DT 0.000 (0.448)	loss 0.107 (0.135)
Valid: [25][20/88]	BT 0.109 (0.488)	DT 0.000 (0.376)	loss 0.139 (0.138)
Valid: [25][30/88]	BT 0.109 (0.458)	DT 0.000 (0.346)	loss 0.124 (0.136)
Valid: [25][40/88]	BT 0.109 (0.449)	DT 0.000 (0.338)	loss 0.131 (0.137)
Valid: [25][50/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.126 (0.136)
Valid: [25][60/88]	BT 0.109 (0.436)	DT 0.000 (0.325)	loss 0.154 (0.136)
Valid: [25][70/88]	BT 0.109 (0.434)	DT 0.000 (0.323)	loss 0.115 (0.136)
Valid: [25][80/88]	BT 0.109 (0.429)	DT 0.000 (0.318)	loss 0.142 (0.136)
Train: [26][10/589]	BT 0.364 (0.756)	DT 0.000 (0.400)	lr 0.0002	loss 0.139 (0.145)
Train: [26][20/589]	BT 0.377 (0.565)	DT 0.000 (0.208)	lr 0.0002	loss 0.145 (0.141)
Train: [26][30/589]	BT 0.375 (0.502)	DT 0.000 (0.144)	lr 0.0002	loss 0.142 (0.142)
Train: [26][40/589]	BT 0.356 (0.465)	DT 0.000 (0.108)	lr 0.0002	loss 0.125 (0.141)
Train: [26][50/589]	BT 0.358 (0.447)	DT 0.000 (0.089)	lr 0.0002	loss 0.142 (0.140)
Train: [26][60/589]	BT 0.356 (0.435)	DT 0.000 (0.078)	lr 0.0002	loss 0.136 (0.139)
Train: [26][70/589]	BT 0.376 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.158 (0.139)
Train: [26][80/589]	BT 0.358 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.136 (0.139)
Train: [26][90/589]	BT 0.357 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.144 (0.138)
Train: [26][100/589]	BT 0.354 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.126 (0.138)
Train: [26][110/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.176 (0.139)
Train: [26][120/589]	BT 0.363 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.146 (0.140)
Train: [26][130/589]	BT 0.358 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.182 (0.140)
Train: [26][140/589]	BT 0.385 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.140)
Train: [26][150/589]	BT 0.358 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.144 (0.140)
Train: [26][160/589]	BT 0.358 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.150 (0.139)
Train: [26][170/589]	BT 0.357 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.164 (0.140)
Train: [26][180/589]	BT 0.370 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.140)
Train: [26][190/589]	BT 0.362 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.147 (0.139)
Train: [26][200/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.138 (0.139)
Train: [26][210/589]	BT 0.374 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.140)
Train: [26][220/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.139)
Train: [26][230/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.137 (0.139)
Train: [26][240/589]	BT 0.370 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.139)
Train: [26][250/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.140 (0.140)
Train: [26][260/589]	BT 0.366 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.150 (0.139)
Train: [26][270/589]	BT 0.373 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.140)
Train: [26][280/589]	BT 0.371 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.151 (0.140)
Train: [26][290/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.140)
Train: [26][300/589]	BT 0.360 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.153 (0.140)
Train: [26][310/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.140)
Train: [26][320/589]	BT 0.381 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.165 (0.140)
Train: [26][330/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.141)
Train: [26][340/589]	BT 0.356 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.141)
Train: [26][350/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.105 (0.140)
Train: [26][360/589]	BT 0.363 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.140)
Train: [26][370/589]	BT 0.377 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.140)
Train: [26][380/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.134 (0.140)
Train: [26][390/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.140 (0.141)
Train: [26][400/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.140)
Train: [26][410/589]	BT 0.362 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.134 (0.140)
Train: [26][420/589]	BT 0.373 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.140)
Train: [26][430/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.140)
Train: [26][440/589]	BT 0.356 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.141 (0.140)
Train: [26][450/589]	BT 0.363 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.143 (0.140)
Train: [26][460/589]	BT 0.361 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.144 (0.140)
Train: [26][470/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.140)
Train: [26][480/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.150 (0.141)
Train: [26][490/589]	BT 0.374 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.123 (0.140)
Train: [26][500/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.156 (0.140)
Train: [26][510/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.141 (0.140)
Train: [26][520/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.140 (0.141)
Train: [26][530/589]	BT 0.356 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.142 (0.141)
Train: [26][540/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.157 (0.140)
Train: [26][550/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.122 (0.140)
Train: [26][560/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.111 (0.140)
Train: [26][570/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.140)
Train: [26][580/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.168 (0.140)
epoch 26, total time 221.27
loss: 0.14026624042187016@Epoch: 26
learning_rate: 0.0002,26
Valid: [26][10/88]	BT 0.109 (0.553)	DT 0.000 (0.443)	loss 0.156 (0.141)
Valid: [26][20/88]	BT 0.110 (0.485)	DT 0.000 (0.375)	loss 0.145 (0.137)
Valid: [26][30/88]	BT 0.109 (0.464)	DT 0.000 (0.354)	loss 0.150 (0.137)
Valid: [26][40/88]	BT 0.109 (0.455)	DT 0.000 (0.345)	loss 0.149 (0.137)
Valid: [26][50/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.120 (0.137)
Valid: [26][60/88]	BT 0.110 (0.444)	DT 0.000 (0.334)	loss 0.120 (0.137)
Valid: [26][70/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.135 (0.137)
Valid: [26][80/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.133 (0.137)
Train: [27][10/589]	BT 0.380 (0.758)	DT 0.000 (0.399)	lr 0.0002	loss 0.130 (0.140)
Train: [27][20/589]	BT 0.361 (0.566)	DT 0.000 (0.208)	lr 0.0002	loss 0.165 (0.140)
Train: [27][30/589]	BT 0.358 (0.499)	DT 0.000 (0.142)	lr 0.0002	loss 0.143 (0.143)
Train: [27][40/589]	BT 0.357 (0.466)	DT 0.000 (0.109)	lr 0.0002	loss 0.148 (0.142)
Train: [27][50/589]	BT 0.377 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.127 (0.142)
Train: [27][60/589]	BT 0.357 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.139 (0.142)
Train: [27][70/589]	BT 0.359 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.126 (0.142)
Train: [27][80/589]	BT 0.364 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.165 (0.143)
Train: [27][90/589]	BT 0.361 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.122 (0.142)
Train: [27][100/589]	BT 0.364 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.136 (0.141)
Train: [27][110/589]	BT 0.358 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.119 (0.140)
Train: [27][120/589]	BT 0.357 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.150 (0.140)
Train: [27][130/589]	BT 0.358 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.123 (0.140)
Train: [27][140/589]	BT 0.357 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.171 (0.140)
Train: [27][150/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.119 (0.140)
Train: [27][160/589]	BT 0.360 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.151 (0.140)
Train: [27][170/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.147 (0.140)
Train: [27][180/589]	BT 0.366 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.126 (0.139)
Train: [27][190/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.128 (0.139)
Train: [27][200/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.146 (0.140)
Train: [27][210/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.155 (0.140)
Train: [27][220/589]	BT 0.362 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.167 (0.140)
Train: [27][230/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.139)
Train: [27][240/589]	BT 0.375 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.145 (0.139)
Train: [27][250/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.123 (0.140)
Train: [27][260/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.139)
Train: [27][270/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.139)
Train: [27][280/589]	BT 0.360 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.146 (0.139)
Train: [27][290/589]	BT 0.359 (0.380)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.139)
Train: [27][300/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.116 (0.139)
Train: [27][310/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.151 (0.139)
Train: [27][320/589]	BT 0.364 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.149 (0.139)
Train: [27][330/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.149 (0.139)
Train: [27][340/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.159 (0.140)
Train: [27][350/589]	BT 0.369 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.140)
Train: [27][360/589]	BT 0.366 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.153 (0.140)
Train: [27][370/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.133 (0.140)
Train: [27][380/589]	BT 0.360 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.140)
Train: [27][390/589]	BT 0.363 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.141 (0.140)
Train: [27][400/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.137 (0.140)
Train: [27][410/589]	BT 0.370 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.115 (0.139)
Train: [27][420/589]	BT 0.361 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.142 (0.140)
Train: [27][430/589]	BT 0.367 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.145 (0.140)
Train: [27][440/589]	BT 0.356 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.168 (0.140)
Train: [27][450/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.149 (0.140)
Train: [27][460/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.147 (0.140)
Train: [27][470/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.126 (0.140)
Train: [27][480/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.154 (0.140)
Train: [27][490/589]	BT 0.363 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.153 (0.140)
Train: [27][500/589]	BT 0.364 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.146 (0.140)
Train: [27][510/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.111 (0.140)
Train: [27][520/589]	BT 0.385 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.133 (0.140)
Train: [27][530/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.133 (0.140)
Train: [27][540/589]	BT 0.365 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.128 (0.140)
Train: [27][550/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.145 (0.140)
Train: [27][560/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.127 (0.140)
Train: [27][570/589]	BT 0.359 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.136 (0.140)
Train: [27][580/589]	BT 0.356 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.123 (0.140)
epoch 27, total time 220.26
loss: 0.14003509937266978@Epoch: 27
learning_rate: 0.0002,27
Valid: [27][10/88]	BT 0.110 (0.582)	DT 0.000 (0.471)	loss 0.132 (0.137)
Valid: [27][20/88]	BT 0.109 (0.495)	DT 0.000 (0.385)	loss 0.128 (0.132)
Valid: [27][30/88]	BT 0.109 (0.466)	DT 0.000 (0.356)	loss 0.141 (0.133)
Valid: [27][40/88]	BT 0.109 (0.455)	DT 0.000 (0.346)	loss 0.141 (0.135)
Valid: [27][50/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.143 (0.136)
Valid: [27][60/88]	BT 0.109 (0.441)	DT 0.000 (0.332)	loss 0.132 (0.136)
Valid: [27][70/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.160 (0.136)
Valid: [27][80/88]	BT 0.109 (0.429)	DT 0.000 (0.320)	loss 0.143 (0.137)
Train: [28][10/589]	BT 0.365 (0.722)	DT 0.000 (0.364)	lr 0.0002	loss 0.138 (0.143)
Train: [28][20/589]	BT 0.371 (0.541)	DT 0.000 (0.183)	lr 0.0002	loss 0.122 (0.143)
Train: [28][30/589]	BT 0.357 (0.480)	DT 0.000 (0.122)	lr 0.0002	loss 0.136 (0.142)
Train: [28][40/589]	BT 0.355 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.138 (0.141)
Train: [28][50/589]	BT 0.357 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.131 (0.141)
Train: [28][60/589]	BT 0.356 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.136 (0.141)
Train: [28][70/589]	BT 0.358 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.143 (0.142)
Train: [28][80/589]	BT 0.366 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.134 (0.141)
Train: [28][90/589]	BT 0.356 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.128 (0.141)
Train: [28][100/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.163 (0.141)
Train: [28][110/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.154 (0.141)
Train: [28][120/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.135 (0.141)
Train: [28][130/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.145 (0.141)
Train: [28][140/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.127 (0.141)
Train: [28][150/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.141)
Train: [28][160/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.141)
Train: [28][170/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.139 (0.141)
Train: [28][180/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.127 (0.141)
Train: [28][190/589]	BT 0.360 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.122 (0.141)
Train: [28][200/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.141)
Train: [28][210/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.149 (0.140)
Train: [28][220/589]	BT 0.360 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.132 (0.140)
Train: [28][230/589]	BT 0.375 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.111 (0.140)
Train: [28][240/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.140)
Train: [28][250/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.161 (0.140)
Train: [28][260/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.145 (0.140)
Train: [28][270/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.140)
Train: [28][280/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.140)
Train: [28][290/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.140)
Train: [28][300/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.153 (0.140)
Train: [28][310/589]	BT 0.362 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.151 (0.140)
Train: [28][320/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.156 (0.140)
Train: [28][330/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.114 (0.140)
Train: [28][340/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.124 (0.140)
Train: [28][350/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.139)
Train: [28][360/589]	BT 0.364 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.156 (0.139)
Train: [28][370/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.133 (0.140)
Train: [28][380/589]	BT 0.371 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.140)
Train: [28][390/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.140)
Train: [28][400/589]	BT 0.361 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.147 (0.140)
Train: [28][410/589]	BT 0.369 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.140)
Train: [28][420/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.122 (0.140)
Train: [28][430/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.116 (0.140)
Train: [28][440/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.140)
Train: [28][450/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.158 (0.140)
Train: [28][460/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.140)
Train: [28][470/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.140)
Train: [28][480/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.140)
Train: [28][490/589]	BT 0.366 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.140)
Train: [28][500/589]	BT 0.367 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.140)
Train: [28][510/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.140)
Train: [28][520/589]	BT 0.356 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.162 (0.140)
Train: [28][530/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.140)
Train: [28][540/589]	BT 0.366 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.140)
Train: [28][550/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.149 (0.140)
Train: [28][560/589]	BT 0.354 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.140)
Train: [28][570/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.139)
Train: [28][580/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.168 (0.139)
epoch 28, total time 223.99
loss: 0.13956431428452118@Epoch: 28
learning_rate: 0.0002,28
Valid: [28][10/88]	BT 0.110 (0.569)	DT 0.000 (0.458)	loss 0.154 (0.138)
Valid: [28][20/88]	BT 0.109 (0.503)	DT 0.000 (0.393)	loss 0.129 (0.138)
Valid: [28][30/88]	BT 0.110 (0.479)	DT 0.000 (0.369)	loss 0.141 (0.137)
Valid: [28][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.151 (0.136)
Valid: [28][50/88]	BT 0.109 (0.458)	DT 0.000 (0.348)	loss 0.126 (0.135)
Valid: [28][60/88]	BT 0.109 (0.451)	DT 0.000 (0.342)	loss 0.134 (0.134)
Valid: [28][70/88]	BT 0.109 (0.446)	DT 0.000 (0.337)	loss 0.134 (0.135)
Valid: [28][80/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.152 (0.135)
Epoch 0028: val_loss improved from 0.13620 to 0.13556, saving model
==> Saving...
Train: [29][10/589]	BT 0.362 (0.771)	DT 0.000 (0.416)	lr 0.0002	loss 0.130 (0.138)
Train: [29][20/589]	BT 0.357 (0.572)	DT 0.000 (0.216)	lr 0.0002	loss 0.138 (0.140)
Train: [29][30/589]	BT 0.357 (0.507)	DT 0.000 (0.151)	lr 0.0002	loss 0.145 (0.143)
Train: [29][40/589]	BT 0.356 (0.478)	DT 0.000 (0.121)	lr 0.0002	loss 0.101 (0.143)
Train: [29][50/589]	BT 0.356 (0.457)	DT 0.000 (0.101)	lr 0.0002	loss 0.152 (0.142)
Train: [29][60/589]	BT 0.368 (0.445)	DT 0.000 (0.088)	lr 0.0002	loss 0.157 (0.142)
Train: [29][70/589]	BT 0.358 (0.434)	DT 0.000 (0.077)	lr 0.0002	loss 0.132 (0.141)
Train: [29][80/589]	BT 0.371 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.154 (0.142)
Train: [29][90/589]	BT 0.362 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.162 (0.141)
Train: [29][100/589]	BT 0.360 (0.418)	DT 0.000 (0.061)	lr 0.0002	loss 0.125 (0.141)
Train: [29][110/589]	BT 0.356 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.138 (0.141)
Train: [29][120/589]	BT 0.358 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.131 (0.141)
Train: [29][130/589]	BT 0.354 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.120 (0.142)
Train: [29][140/589]	BT 0.359 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.117 (0.141)
Train: [29][150/589]	BT 0.357 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.123 (0.141)
Train: [29][160/589]	BT 0.357 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.126 (0.141)
Train: [29][170/589]	BT 0.359 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.147 (0.141)
Train: [29][180/589]	BT 0.359 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.151 (0.141)
Train: [29][190/589]	BT 0.355 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.141)
Train: [29][200/589]	BT 0.358 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.123 (0.141)
Train: [29][210/589]	BT 0.356 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.114 (0.140)
Train: [29][220/589]	BT 0.358 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.104 (0.140)
Train: [29][230/589]	BT 0.368 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.110 (0.140)
Train: [29][240/589]	BT 0.374 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.137 (0.140)
Train: [29][250/589]	BT 0.359 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.140 (0.140)
Train: [29][260/589]	BT 0.365 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.155 (0.140)
Train: [29][270/589]	BT 0.361 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.127 (0.140)
Train: [29][280/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.155 (0.140)
Train: [29][290/589]	BT 0.373 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.097 (0.139)
Train: [29][300/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.147 (0.140)
Train: [29][310/589]	BT 0.356 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.135 (0.140)
Train: [29][320/589]	BT 0.366 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.145 (0.140)
Train: [29][330/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.172 (0.140)
Train: [29][340/589]	BT 0.384 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.157 (0.140)
Train: [29][350/589]	BT 0.360 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.151 (0.140)
Train: [29][360/589]	BT 0.356 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.123 (0.140)
Train: [29][370/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.137 (0.140)
Train: [29][380/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.140)
Train: [29][390/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.149 (0.140)
Train: [29][400/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.140)
Train: [29][410/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.140)
Train: [29][420/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.118 (0.140)
Train: [29][430/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.151 (0.140)
Train: [29][440/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.154 (0.140)
Train: [29][450/589]	BT 0.356 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.126 (0.140)
Train: [29][460/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.140)
Train: [29][470/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.141 (0.140)
Train: [29][480/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.116 (0.140)
Train: [29][490/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.135 (0.140)
Train: [29][500/589]	BT 0.374 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.126 (0.140)
Train: [29][510/589]	BT 0.375 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.119 (0.140)
Train: [29][520/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.128 (0.140)
Train: [29][530/589]	BT 0.376 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.142 (0.140)
Train: [29][540/589]	BT 0.365 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.140)
Train: [29][550/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.140)
Train: [29][560/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.161 (0.140)
Train: [29][570/589]	BT 0.370 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.140)
Train: [29][580/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.140)
epoch 29, total time 225.19
loss: 0.13948311300725472@Epoch: 29
learning_rate: 0.0002,29
Valid: [29][10/88]	BT 0.110 (0.551)	DT 0.000 (0.441)	loss 0.137 (0.140)
Valid: [29][20/88]	BT 0.109 (0.488)	DT 0.000 (0.378)	loss 0.148 (0.141)
Valid: [29][30/88]	BT 0.109 (0.455)	DT 0.000 (0.345)	loss 0.144 (0.141)
Valid: [29][40/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.133 (0.140)
Valid: [29][50/88]	BT 0.110 (0.433)	DT 0.000 (0.323)	loss 0.138 (0.140)
Valid: [29][60/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.126 (0.139)
Valid: [29][70/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.122 (0.139)
Valid: [29][80/88]	BT 0.110 (0.429)	DT 0.000 (0.319)	loss 0.132 (0.139)
Train: [30][10/589]	BT 0.357 (0.745)	DT 0.000 (0.388)	lr 0.0002	loss 0.153 (0.141)
Train: [30][20/589]	BT 0.391 (0.567)	DT 0.000 (0.209)	lr 0.0002	loss 0.120 (0.136)
Train: [30][30/589]	BT 0.356 (0.497)	DT 0.000 (0.140)	lr 0.0002	loss 0.112 (0.133)
Train: [30][40/589]	BT 0.358 (0.464)	DT 0.000 (0.107)	lr 0.0002	loss 0.156 (0.135)
Train: [30][50/589]	BT 0.358 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.148 (0.135)
Train: [30][60/589]	BT 0.376 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.133 (0.135)
Train: [30][70/589]	BT 0.357 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.127 (0.136)
Train: [30][80/589]	BT 0.376 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.151 (0.137)
Train: [30][90/589]	BT 0.357 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.137 (0.138)
Train: [30][100/589]	BT 0.358 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.139 (0.137)
Train: [30][110/589]	BT 0.365 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.130 (0.137)
Train: [30][120/589]	BT 0.357 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.131 (0.138)
Train: [30][130/589]	BT 0.382 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.112 (0.138)
Train: [30][140/589]	BT 0.362 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.148 (0.139)
Train: [30][150/589]	BT 0.368 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.128 (0.138)
Train: [30][160/589]	BT 0.374 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.180 (0.139)
Train: [30][170/589]	BT 0.357 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.123 (0.139)
Train: [30][180/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.159 (0.139)
Train: [30][190/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.144 (0.139)
Train: [30][200/589]	BT 0.368 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.139)
Train: [30][210/589]	BT 0.372 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.142 (0.139)
Train: [30][220/589]	BT 0.364 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.116 (0.139)
Train: [30][230/589]	BT 0.355 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.114 (0.139)
Train: [30][240/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.138)
Train: [30][250/589]	BT 0.382 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.133 (0.139)
Train: [30][260/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.165 (0.139)
Train: [30][270/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.153 (0.139)
Train: [30][280/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.138 (0.139)
Train: [30][290/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.156 (0.139)
Train: [30][300/589]	BT 0.356 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.139)
Train: [30][310/589]	BT 0.373 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.153 (0.139)
Train: [30][320/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.139)
Train: [30][330/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.138 (0.139)
Train: [30][340/589]	BT 0.369 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.139)
Train: [30][350/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.172 (0.139)
Train: [30][360/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.139)
Train: [30][370/589]	BT 0.356 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.134 (0.139)
Train: [30][380/589]	BT 0.368 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.152 (0.140)
Train: [30][390/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.140)
Train: [30][400/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.129 (0.139)
Train: [30][410/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.116 (0.139)
Train: [30][420/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.145 (0.139)
Train: [30][430/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.139)
Train: [30][440/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.117 (0.139)
Train: [30][450/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.158 (0.139)
Train: [30][460/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.139)
Train: [30][470/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.139)
Train: [30][480/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.146 (0.139)
Train: [30][490/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.139)
Train: [30][500/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.143 (0.139)
Train: [30][510/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.146 (0.139)
Train: [30][520/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.142 (0.139)
Train: [30][530/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.138 (0.139)
Train: [30][540/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.126 (0.139)
Train: [30][550/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.139 (0.139)
Train: [30][560/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.134 (0.139)
Train: [30][570/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.132 (0.139)
Train: [30][580/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.154 (0.139)
epoch 30, total time 221.34
loss: 0.13931154945815016@Epoch: 30
learning_rate: 0.0002,30
Valid: [30][10/88]	BT 0.110 (0.626)	DT 0.000 (0.515)	loss 0.136 (0.136)
Valid: [30][20/88]	BT 0.110 (0.531)	DT 0.000 (0.421)	loss 0.108 (0.137)
Valid: [30][30/88]	BT 0.109 (0.489)	DT 0.000 (0.379)	loss 0.145 (0.138)
Valid: [30][40/88]	BT 0.109 (0.474)	DT 0.000 (0.364)	loss 0.139 (0.138)
Valid: [30][50/88]	BT 0.109 (0.460)	DT 0.000 (0.351)	loss 0.122 (0.136)
Valid: [30][60/88]	BT 0.109 (0.453)	DT 0.000 (0.344)	loss 0.144 (0.136)
Valid: [30][70/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.137 (0.136)
Valid: [30][80/88]	BT 0.109 (0.440)	DT 0.000 (0.330)	loss 0.124 (0.136)
Epoch 0030: val_loss improved from 0.13556 to 0.13546, saving model
==> Saving...
Train: [31][10/589]	BT 0.357 (0.726)	DT 0.000 (0.369)	lr 0.0002	loss 0.160 (0.133)
Train: [31][20/589]	BT 0.369 (0.550)	DT 0.000 (0.192)	lr 0.0002	loss 0.127 (0.136)
Train: [31][30/589]	BT 0.356 (0.490)	DT 0.000 (0.132)	lr 0.0002	loss 0.137 (0.139)
Train: [31][40/589]	BT 0.356 (0.461)	DT 0.000 (0.103)	lr 0.0002	loss 0.153 (0.139)
Train: [31][50/589]	BT 0.358 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.133 (0.140)
Train: [31][60/589]	BT 0.357 (0.430)	DT 0.000 (0.073)	lr 0.0002	loss 0.144 (0.140)
Train: [31][70/589]	BT 0.355 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.152 (0.140)
Train: [31][80/589]	BT 0.356 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.153 (0.140)
Train: [31][90/589]	BT 0.358 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.115 (0.140)
Train: [31][100/589]	BT 0.370 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.156 (0.140)
Train: [31][110/589]	BT 0.357 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.138 (0.139)
Train: [31][120/589]	BT 0.377 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.139 (0.139)
Train: [31][130/589]	BT 0.363 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.124 (0.139)
Train: [31][140/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.146 (0.139)
Train: [31][150/589]	BT 0.371 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.112 (0.139)
Train: [31][160/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.139)
Train: [31][170/589]	BT 0.359 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.147 (0.139)
Train: [31][180/589]	BT 0.367 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.139)
Train: [31][190/589]	BT 0.382 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.165 (0.139)
Train: [31][200/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.138)
Train: [31][210/589]	BT 0.362 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.138)
Train: [31][220/589]	BT 0.367 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.138)
Train: [31][230/589]	BT 0.397 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.139 (0.138)
Train: [31][240/589]	BT 0.386 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.138)
Train: [31][250/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.138)
Train: [31][260/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.138)
Train: [31][270/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.138)
Train: [31][280/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.139)
Train: [31][290/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.139)
Train: [31][300/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.139)
Train: [31][310/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.129 (0.139)
Train: [31][320/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.112 (0.139)
Train: [31][330/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.153 (0.139)
Train: [31][340/589]	BT 0.355 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.139)
Train: [31][350/589]	BT 0.356 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.139)
Train: [31][360/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.153 (0.139)
Train: [31][370/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.157 (0.139)
Train: [31][380/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.159 (0.139)
Train: [31][390/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.116 (0.139)
Train: [31][400/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.148 (0.139)
Train: [31][410/589]	BT 0.356 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.140 (0.139)
Train: [31][420/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.139)
Train: [31][430/589]	BT 0.366 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.108 (0.139)
Train: [31][440/589]	BT 0.360 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.155 (0.139)
Train: [31][450/589]	BT 0.372 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.139)
Train: [31][460/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.154 (0.139)
Train: [31][470/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.149 (0.139)
Train: [31][480/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.139)
Train: [31][490/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.139)
Train: [31][500/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.131 (0.139)
Train: [31][510/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.165 (0.139)
Train: [31][520/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.131 (0.139)
Train: [31][530/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.139 (0.139)
Train: [31][540/589]	BT 0.368 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.139)
Train: [31][550/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.147 (0.139)
Train: [31][560/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.141 (0.139)
Train: [31][570/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.127 (0.139)
Train: [31][580/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.142 (0.139)
epoch 31, total time 221.00
loss: 0.1389031470999587@Epoch: 31
learning_rate: 0.0002,31
Valid: [31][10/88]	BT 0.110 (0.529)	DT 0.000 (0.416)	loss 0.145 (0.140)
Valid: [31][20/88]	BT 0.109 (0.475)	DT 0.000 (0.364)	loss 0.138 (0.143)
Valid: [31][30/88]	BT 0.110 (0.449)	DT 0.000 (0.338)	loss 0.147 (0.141)
Valid: [31][40/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.182 (0.142)
Valid: [31][50/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.133 (0.139)
Valid: [31][60/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.150 (0.138)
Valid: [31][70/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.104 (0.137)
Valid: [31][80/88]	BT 0.109 (0.429)	DT 0.000 (0.318)	loss 0.122 (0.136)
Train: [32][10/589]	BT 0.361 (0.752)	DT 0.000 (0.396)	lr 0.0002	loss 0.137 (0.143)
Train: [32][20/589]	BT 0.357 (0.561)	DT 0.000 (0.205)	lr 0.0002	loss 0.126 (0.140)
Train: [32][30/589]	BT 0.368 (0.499)	DT 0.000 (0.143)	lr 0.0002	loss 0.121 (0.138)
Train: [32][40/589]	BT 0.361 (0.471)	DT 0.000 (0.114)	lr 0.0002	loss 0.127 (0.138)
Train: [32][50/589]	BT 0.356 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.124 (0.137)
Train: [32][60/589]	BT 0.367 (0.436)	DT 0.000 (0.080)	lr 0.0002	loss 0.163 (0.138)
Train: [32][70/589]	BT 0.354 (0.425)	DT 0.000 (0.068)	lr 0.0002	loss 0.131 (0.138)
Train: [32][80/589]	BT 0.381 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.144 (0.138)
Train: [32][90/589]	BT 0.357 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.162 (0.138)
Train: [32][100/589]	BT 0.357 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.162 (0.138)
Train: [32][110/589]	BT 0.358 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.134 (0.138)
Train: [32][120/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.133 (0.138)
Train: [32][130/589]	BT 0.375 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.140 (0.138)
Train: [32][140/589]	BT 0.359 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.123 (0.138)
Train: [32][150/589]	BT 0.356 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.150 (0.138)
Train: [32][160/589]	BT 0.362 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.113 (0.138)
Train: [32][170/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.134 (0.138)
Train: [32][180/589]	BT 0.358 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.138)
Train: [32][190/589]	BT 0.360 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.128 (0.138)
Train: [32][200/589]	BT 0.368 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.122 (0.138)
Train: [32][210/589]	BT 0.369 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.131 (0.138)
Train: [32][220/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.122 (0.138)
Train: [32][230/589]	BT 0.367 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.138)
Train: [32][240/589]	BT 0.368 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.167 (0.138)
Train: [32][250/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.155 (0.138)
Train: [32][260/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.138)
Train: [32][270/589]	BT 0.370 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.131 (0.138)
Train: [32][280/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.138)
Train: [32][290/589]	BT 0.393 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.138)
Train: [32][300/589]	BT 0.368 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.166 (0.138)
Train: [32][310/589]	BT 0.362 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.145 (0.138)
Train: [32][320/589]	BT 0.364 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.144 (0.138)
Train: [32][330/589]	BT 0.365 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.138)
Train: [32][340/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.138)
Train: [32][350/589]	BT 0.367 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.138)
Train: [32][360/589]	BT 0.370 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.138)
Train: [32][370/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.138)
Train: [32][380/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.115 (0.139)
Train: [32][390/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.147 (0.139)
Train: [32][400/589]	BT 0.361 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.153 (0.139)
Train: [32][410/589]	BT 0.355 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.178 (0.139)
Train: [32][420/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.142 (0.139)
Train: [32][430/589]	BT 0.376 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.138)
Train: [32][440/589]	BT 0.356 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.140 (0.138)
Train: [32][450/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.123 (0.138)
Train: [32][460/589]	BT 0.355 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.136 (0.138)
Train: [32][470/589]	BT 0.356 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.122 (0.138)
Train: [32][480/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.168 (0.138)
Train: [32][490/589]	BT 0.374 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.132 (0.138)
Train: [32][500/589]	BT 0.359 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.144 (0.138)
Train: [32][510/589]	BT 0.356 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.134 (0.138)
Train: [32][520/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.145 (0.138)
Train: [32][530/589]	BT 0.359 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.137 (0.138)
Train: [32][540/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.141 (0.138)
Train: [32][550/589]	BT 0.355 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.137 (0.138)
Train: [32][560/589]	BT 0.359 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.164 (0.138)
Train: [32][570/589]	BT 0.356 (0.374)	DT 0.000 (0.015)	lr 0.0002	loss 0.145 (0.138)
Train: [32][580/589]	BT 0.356 (0.374)	DT 0.000 (0.015)	lr 0.0002	loss 0.132 (0.138)
epoch 32, total time 220.80
loss: 0.13847330791291243@Epoch: 32
learning_rate: 0.0002,32
Valid: [32][10/88]	BT 0.110 (0.555)	DT 0.000 (0.444)	loss 0.117 (0.122)
Valid: [32][20/88]	BT 0.109 (0.476)	DT 0.000 (0.366)	loss 0.167 (0.131)
Valid: [32][30/88]	BT 0.109 (0.455)	DT 0.000 (0.344)	loss 0.141 (0.130)
Valid: [32][40/88]	BT 0.110 (0.447)	DT 0.000 (0.337)	loss 0.131 (0.130)
Valid: [32][50/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.122 (0.131)
Valid: [32][60/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.158 (0.133)
Valid: [32][70/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.138 (0.134)
Valid: [32][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.144 (0.135)
Epoch 0032: val_loss improved from 0.13546 to 0.13526, saving model
==> Saving...
Train: [33][10/589]	BT 0.358 (0.752)	DT 0.000 (0.395)	lr 0.0002	loss 0.134 (0.134)
Train: [33][20/589]	BT 0.356 (0.555)	DT 0.000 (0.198)	lr 0.0002	loss 0.132 (0.135)
Train: [33][30/589]	BT 0.357 (0.493)	DT 0.000 (0.136)	lr 0.0002	loss 0.142 (0.137)
Train: [33][40/589]	BT 0.371 (0.464)	DT 0.000 (0.106)	lr 0.0002	loss 0.146 (0.139)
Train: [33][50/589]	BT 0.356 (0.443)	DT 0.000 (0.085)	lr 0.0002	loss 0.142 (0.139)
Train: [33][60/589]	BT 0.356 (0.432)	DT 0.000 (0.075)	lr 0.0002	loss 0.126 (0.138)
Train: [33][70/589]	BT 0.363 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.177 (0.138)
Train: [33][80/589]	BT 0.358 (0.415)	DT 0.000 (0.058)	lr 0.0002	loss 0.132 (0.138)
Train: [33][90/589]	BT 0.358 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.137 (0.138)
Train: [33][100/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.144 (0.138)
Train: [33][110/589]	BT 0.356 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.134 (0.139)
Train: [33][120/589]	BT 0.372 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.122 (0.139)
Train: [33][130/589]	BT 0.360 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.137 (0.139)
Train: [33][140/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.145 (0.139)
Train: [33][150/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.124 (0.139)
Train: [33][160/589]	BT 0.360 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.146 (0.139)
Train: [33][170/589]	BT 0.358 (0.391)	DT 0.005 (0.033)	lr 0.0002	loss 0.167 (0.138)
Train: [33][180/589]	BT 0.357 (0.389)	DT 0.000 (0.032)	lr 0.0002	loss 0.114 (0.138)
Train: [33][190/589]	BT 0.364 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.171 (0.138)
Train: [33][200/589]	BT 0.364 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.141 (0.138)
Train: [33][210/589]	BT 0.359 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.152 (0.139)
Train: [33][220/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.169 (0.139)
Train: [33][230/589]	BT 0.376 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.108 (0.138)
Train: [33][240/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.155 (0.138)
Train: [33][250/589]	BT 0.362 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.138)
Train: [33][260/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.154 (0.138)
Train: [33][270/589]	BT 0.378 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.149 (0.139)
Train: [33][280/589]	BT 0.353 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.137 (0.139)
Train: [33][290/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.139)
Train: [33][300/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.139)
Train: [33][310/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.139)
Train: [33][320/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.139)
Train: [33][330/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.138)
Train: [33][340/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.130 (0.138)
Train: [33][350/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.167 (0.138)
Train: [33][360/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.140 (0.139)
Train: [33][370/589]	BT 0.364 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.139)
Train: [33][380/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.140 (0.139)
Train: [33][390/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.145 (0.138)
Train: [33][400/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.138)
Train: [33][410/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.161 (0.138)
Train: [33][420/589]	BT 0.356 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.142 (0.138)
Train: [33][430/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.138)
Train: [33][440/589]	BT 0.356 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.151 (0.138)
Train: [33][450/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.149 (0.138)
Train: [33][460/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.123 (0.138)
Train: [33][470/589]	BT 0.356 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.153 (0.138)
Train: [33][480/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.107 (0.138)
Train: [33][490/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.124 (0.138)
Train: [33][500/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.138)
Train: [33][510/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.118 (0.138)
Train: [33][520/589]	BT 0.364 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.132 (0.138)
Train: [33][530/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.132 (0.138)
Train: [33][540/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.164 (0.138)
Train: [33][550/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.138 (0.138)
Train: [33][560/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.137 (0.138)
Train: [33][570/589]	BT 0.374 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.157 (0.138)
Train: [33][580/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.142 (0.138)
epoch 33, total time 221.27
loss: 0.1380724929778065@Epoch: 33
learning_rate: 0.0002,33
Valid: [33][10/88]	BT 0.109 (0.561)	DT 0.000 (0.450)	loss 0.119 (0.136)
Valid: [33][20/88]	BT 0.109 (0.497)	DT 0.000 (0.387)	loss 0.136 (0.135)
Valid: [33][30/88]	BT 0.110 (0.466)	DT 0.000 (0.356)	loss 0.129 (0.133)
Valid: [33][40/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.147 (0.135)
Valid: [33][50/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.137 (0.136)
Valid: [33][60/88]	BT 0.110 (0.445)	DT 0.000 (0.335)	loss 0.151 (0.135)
Valid: [33][70/88]	BT 0.110 (0.440)	DT 0.000 (0.331)	loss 0.122 (0.135)
Valid: [33][80/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.126 (0.135)
Epoch 0033: val_loss improved from 0.13526 to 0.13499, saving model
==> Saving...
Train: [34][10/589]	BT 0.353 (0.753)	DT 0.000 (0.395)	lr 0.0002	loss 0.124 (0.139)
Train: [34][20/589]	BT 0.373 (0.562)	DT 0.000 (0.204)	lr 0.0002	loss 0.136 (0.139)
Train: [34][30/589]	BT 0.356 (0.494)	DT 0.000 (0.136)	lr 0.0002	loss 0.143 (0.140)
Train: [34][40/589]	BT 0.354 (0.463)	DT 0.000 (0.105)	lr 0.0002	loss 0.127 (0.140)
Train: [34][50/589]	BT 0.354 (0.446)	DT 0.000 (0.088)	lr 0.0002	loss 0.129 (0.140)
Train: [34][60/589]	BT 0.356 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.135 (0.140)
Train: [34][70/589]	BT 0.356 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.132 (0.140)
Train: [34][80/589]	BT 0.360 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.150 (0.139)
Train: [34][90/589]	BT 0.361 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.130 (0.139)
Train: [34][100/589]	BT 0.356 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.153 (0.139)
Train: [34][110/589]	BT 0.374 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.126 (0.140)
Train: [34][120/589]	BT 0.356 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.153 (0.139)
Train: [34][130/589]	BT 0.359 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.142 (0.139)
Train: [34][140/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.156 (0.139)
Train: [34][150/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.168 (0.139)
Train: [34][160/589]	BT 0.355 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.145 (0.139)
Train: [34][170/589]	BT 0.361 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.131 (0.139)
Train: [34][180/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.152 (0.139)
Train: [34][190/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.139)
Train: [34][200/589]	BT 0.367 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.139)
Train: [34][210/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.139)
Train: [34][220/589]	BT 0.359 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.135 (0.139)
Train: [34][230/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.136 (0.139)
Train: [34][240/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.129 (0.139)
Train: [34][250/589]	BT 0.362 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.158 (0.139)
Train: [34][260/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.139)
Train: [34][270/589]	BT 0.356 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.128 (0.139)
Train: [34][280/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.153 (0.139)
Train: [34][290/589]	BT 0.363 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.166 (0.139)
Train: [34][300/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.139)
Train: [34][310/589]	BT 0.356 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.124 (0.139)
Train: [34][320/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.139)
Train: [34][330/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.139)
Train: [34][340/589]	BT 0.364 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.149 (0.139)
Train: [34][350/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.139)
Train: [34][360/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.139)
Train: [34][370/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.138)
Train: [34][380/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.138)
Train: [34][390/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.121 (0.138)
Train: [34][400/589]	BT 0.376 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.138)
Train: [34][410/589]	BT 0.373 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.138)
Train: [34][420/589]	BT 0.384 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.138)
Train: [34][430/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.144 (0.138)
Train: [34][440/589]	BT 0.365 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.149 (0.138)
Train: [34][450/589]	BT 0.359 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.138)
Train: [34][460/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.138)
Train: [34][470/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.123 (0.138)
Train: [34][480/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.145 (0.138)
Train: [34][490/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.163 (0.138)
Train: [34][500/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.138)
Train: [34][510/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.123 (0.138)
Train: [34][520/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.180 (0.138)
Train: [34][530/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.141 (0.138)
Train: [34][540/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.156 (0.138)
Train: [34][550/589]	BT 0.364 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.148 (0.138)
Train: [34][560/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.158 (0.138)
Train: [34][570/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.123 (0.138)
Train: [34][580/589]	BT 0.361 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.132 (0.138)
epoch 34, total time 221.68
loss: 0.13813651667320984@Epoch: 34
learning_rate: 0.0002,34
Valid: [34][10/88]	BT 0.109 (0.558)	DT 0.000 (0.447)	loss 0.108 (0.137)
Valid: [34][20/88]	BT 0.109 (0.490)	DT 0.000 (0.379)	loss 0.126 (0.140)
Valid: [34][30/88]	BT 0.110 (0.468)	DT 0.000 (0.358)	loss 0.139 (0.139)
Valid: [34][40/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.114 (0.138)
Valid: [34][50/88]	BT 0.109 (0.449)	DT 0.000 (0.340)	loss 0.130 (0.137)
Valid: [34][60/88]	BT 0.109 (0.442)	DT 0.000 (0.333)	loss 0.130 (0.137)
Valid: [34][70/88]	BT 0.109 (0.438)	DT 0.000 (0.329)	loss 0.169 (0.136)
Valid: [34][80/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.139 (0.136)
Train: [35][10/589]	BT 0.357 (0.741)	DT 0.000 (0.383)	lr 0.0002	loss 0.146 (0.141)
Train: [35][20/589]	BT 0.364 (0.564)	DT 0.000 (0.207)	lr 0.0002	loss 0.142 (0.141)
Train: [35][30/589]	BT 0.379 (0.495)	DT 0.000 (0.138)	lr 0.0002	loss 0.156 (0.140)
Train: [35][40/589]	BT 0.363 (0.461)	DT 0.000 (0.104)	lr 0.0002	loss 0.126 (0.137)
Train: [35][50/589]	BT 0.363 (0.442)	DT 0.000 (0.085)	lr 0.0002	loss 0.125 (0.138)
Train: [35][60/589]	BT 0.357 (0.428)	DT 0.000 (0.071)	lr 0.0002	loss 0.144 (0.139)
Train: [35][70/589]	BT 0.358 (0.418)	DT 0.000 (0.061)	lr 0.0002	loss 0.153 (0.139)
Train: [35][80/589]	BT 0.358 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.132 (0.139)
Train: [35][90/589]	BT 0.375 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.132 (0.138)
Train: [35][100/589]	BT 0.357 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.153 (0.139)
Train: [35][110/589]	BT 0.364 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.131 (0.139)
Train: [35][120/589]	BT 0.358 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.139 (0.139)
Train: [35][130/589]	BT 0.354 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.152 (0.138)
Train: [35][140/589]	BT 0.356 (0.392)	DT 0.000 (0.035)	lr 0.0002	loss 0.133 (0.138)
Train: [35][150/589]	BT 0.367 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.125 (0.139)
Train: [35][160/589]	BT 0.358 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.125 (0.138)
Train: [35][170/589]	BT 0.356 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.138)
Train: [35][180/589]	BT 0.355 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.139)
Train: [35][190/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.147 (0.138)
Train: [35][200/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.132 (0.138)
Train: [35][210/589]	BT 0.361 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.138)
Train: [35][220/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.116 (0.138)
Train: [35][230/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.152 (0.138)
Train: [35][240/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.138)
Train: [35][250/589]	BT 0.372 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.138)
Train: [35][260/589]	BT 0.360 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.157 (0.138)
Train: [35][270/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.138)
Train: [35][280/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.128 (0.138)
Train: [35][290/589]	BT 0.371 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.147 (0.138)
Train: [35][300/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.138)
Train: [35][310/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.122 (0.138)
Train: [35][320/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.138)
Train: [35][330/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.138)
Train: [35][340/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.162 (0.138)
Train: [35][350/589]	BT 0.365 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.145 (0.138)
Train: [35][360/589]	BT 0.367 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.138)
Train: [35][370/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.151 (0.138)
Train: [35][380/589]	BT 0.361 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.128 (0.138)
Train: [35][390/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.136 (0.138)
Train: [35][400/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.152 (0.138)
Train: [35][410/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.148 (0.138)
Train: [35][420/589]	BT 0.359 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.167 (0.138)
Train: [35][430/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.127 (0.138)
Train: [35][440/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.130 (0.138)
Train: [35][450/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.126 (0.137)
Train: [35][460/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.146 (0.138)
Train: [35][470/589]	BT 0.357 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.151 (0.138)
Train: [35][480/589]	BT 0.359 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.153 (0.138)
Train: [35][490/589]	BT 0.359 (0.374)	DT 0.000 (0.015)	lr 0.0002	loss 0.157 (0.138)
Train: [35][500/589]	BT 0.359 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.121 (0.138)
Train: [35][510/589]	BT 0.358 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.123 (0.138)
Train: [35][520/589]	BT 0.358 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.145 (0.138)
Train: [35][530/589]	BT 0.359 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.137 (0.138)
Train: [35][540/589]	BT 0.358 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.144 (0.138)
Train: [35][550/589]	BT 0.361 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.140 (0.138)
Train: [35][560/589]	BT 0.356 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.128 (0.138)
Train: [35][570/589]	BT 0.357 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.149 (0.138)
Train: [35][580/589]	BT 0.358 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.117 (0.138)
epoch 35, total time 219.66
loss: 0.13764420300817096@Epoch: 35
learning_rate: 0.0002,35
Valid: [35][10/88]	BT 0.109 (0.542)	DT 0.000 (0.430)	loss 0.129 (0.136)
Valid: [35][20/88]	BT 0.110 (0.487)	DT 0.000 (0.377)	loss 0.145 (0.137)
Valid: [35][30/88]	BT 0.109 (0.461)	DT 0.000 (0.351)	loss 0.126 (0.136)
Valid: [35][40/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.137 (0.137)
Valid: [35][50/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.130 (0.135)
Valid: [35][60/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.133 (0.133)
Valid: [35][70/88]	BT 0.109 (0.427)	DT 0.000 (0.317)	loss 0.148 (0.133)
Valid: [35][80/88]	BT 0.109 (0.425)	DT 0.000 (0.315)	loss 0.098 (0.135)
Epoch 0035: val_loss improved from 0.13499 to 0.13462, saving model
==> Saving...
Train: [36][10/589]	BT 0.355 (0.749)	DT 0.000 (0.390)	lr 0.0002	loss 0.119 (0.132)
Train: [36][20/589]	BT 0.357 (0.553)	DT 0.000 (0.195)	lr 0.0002	loss 0.114 (0.133)
Train: [36][30/589]	BT 0.362 (0.488)	DT 0.000 (0.130)	lr 0.0002	loss 0.148 (0.135)
Train: [36][40/589]	BT 0.355 (0.456)	DT 0.000 (0.098)	lr 0.0002	loss 0.132 (0.136)
Train: [36][50/589]	BT 0.356 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.133 (0.134)
Train: [36][60/589]	BT 0.357 (0.423)	DT 0.000 (0.065)	lr 0.0002	loss 0.130 (0.135)
Train: [36][70/589]	BT 0.358 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.171 (0.136)
Train: [36][80/589]	BT 0.356 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.126 (0.136)
Train: [36][90/589]	BT 0.359 (0.407)	DT 0.000 (0.050)	lr 0.0002	loss 0.149 (0.137)
Train: [36][100/589]	BT 0.357 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.131 (0.137)
Train: [36][110/589]	BT 0.357 (0.402)	DT 0.000 (0.045)	lr 0.0002	loss 0.137 (0.137)
Train: [36][120/589]	BT 0.358 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.125 (0.137)
Train: [36][130/589]	BT 0.370 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.146 (0.137)
Train: [36][140/589]	BT 0.359 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.131 (0.138)
Train: [36][150/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.134 (0.138)
Train: [36][160/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.168 (0.138)
Train: [36][170/589]	BT 0.369 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.138)
Train: [36][180/589]	BT 0.356 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.138)
Train: [36][190/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.138)
Train: [36][200/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.138)
Train: [36][210/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.138)
Train: [36][220/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.131 (0.138)
Train: [36][230/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.138)
Train: [36][240/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.138)
Train: [36][250/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.137 (0.137)
Train: [36][260/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.166 (0.137)
Train: [36][270/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.144 (0.137)
Train: [36][280/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.138)
Train: [36][290/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.148 (0.138)
Train: [36][300/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.138)
Train: [36][310/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.138)
Train: [36][320/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.152 (0.138)
Train: [36][330/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.137)
Train: [36][340/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.193 (0.138)
Train: [36][350/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.140 (0.138)
Train: [36][360/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.137)
Train: [36][370/589]	BT 0.355 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.113 (0.137)
Train: [36][380/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.137)
Train: [36][390/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.137)
Train: [36][400/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.160 (0.137)
Train: [36][410/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.130 (0.137)
Train: [36][420/589]	BT 0.373 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.135 (0.137)
Train: [36][430/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.124 (0.137)
Train: [36][440/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.146 (0.137)
Train: [36][450/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.127 (0.137)
Train: [36][460/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.145 (0.137)
Train: [36][470/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.129 (0.137)
Train: [36][480/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.138)
Train: [36][490/589]	BT 0.360 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.172 (0.138)
Train: [36][500/589]	BT 0.362 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.138)
Train: [36][510/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.134 (0.137)
Train: [36][520/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.137)
Train: [36][530/589]	BT 0.356 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.148 (0.138)
Train: [36][540/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.137 (0.138)
Train: [36][550/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.130 (0.138)
Train: [36][560/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.124 (0.138)
Train: [36][570/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.124 (0.138)
Train: [36][580/589]	BT 0.357 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.110 (0.138)
epoch 36, total time 220.99
loss: 0.1378675530911353@Epoch: 36
learning_rate: 0.0002,36
Valid: [36][10/88]	BT 0.110 (0.549)	DT 0.000 (0.438)	loss 0.128 (0.140)
Valid: [36][20/88]	BT 0.109 (0.478)	DT 0.000 (0.366)	loss 0.143 (0.140)
Valid: [36][30/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.119 (0.134)
Valid: [36][40/88]	BT 0.109 (0.437)	DT 0.000 (0.326)	loss 0.122 (0.133)
Valid: [36][50/88]	BT 0.109 (0.433)	DT 0.000 (0.322)	loss 0.142 (0.134)
Valid: [36][60/88]	BT 0.109 (0.431)	DT 0.000 (0.320)	loss 0.135 (0.135)
Valid: [36][70/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.153 (0.134)
Valid: [36][80/88]	BT 0.109 (0.425)	DT 0.000 (0.315)	loss 0.139 (0.134)
Train: [37][10/589]	BT 0.355 (0.749)	DT 0.000 (0.395)	lr 0.0002	loss 0.160 (0.138)
Train: [37][20/589]	BT 0.357 (0.553)	DT 0.000 (0.197)	lr 0.0002	loss 0.125 (0.139)
Train: [37][30/589]	BT 0.357 (0.502)	DT 0.000 (0.146)	lr 0.0002	loss 0.149 (0.139)
Train: [37][40/589]	BT 0.354 (0.471)	DT 0.000 (0.116)	lr 0.0002	loss 0.133 (0.137)
Train: [37][50/589]	BT 0.378 (0.450)	DT 0.000 (0.094)	lr 0.0002	loss 0.137 (0.136)
Train: [37][60/589]	BT 0.363 (0.438)	DT 0.000 (0.082)	lr 0.0002	loss 0.129 (0.136)
Train: [37][70/589]	BT 0.370 (0.427)	DT 0.000 (0.071)	lr 0.0002	loss 0.138 (0.136)
Train: [37][80/589]	BT 0.361 (0.418)	DT 0.000 (0.062)	lr 0.0002	loss 0.134 (0.136)
Train: [37][90/589]	BT 0.367 (0.412)	DT 0.000 (0.055)	lr 0.0002	loss 0.136 (0.137)
Train: [37][100/589]	BT 0.388 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.151 (0.137)
Train: [37][110/589]	BT 0.376 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.171 (0.137)
Train: [37][120/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.164 (0.137)
Train: [37][130/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.138 (0.137)
Train: [37][140/589]	BT 0.358 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.167 (0.137)
Train: [37][150/589]	BT 0.355 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.117 (0.137)
Train: [37][160/589]	BT 0.379 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.149 (0.137)
Train: [37][170/589]	BT 0.355 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.177 (0.137)
Train: [37][180/589]	BT 0.373 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.137)
Train: [37][190/589]	BT 0.367 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.125 (0.137)
Train: [37][200/589]	BT 0.358 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.144 (0.138)
Train: [37][210/589]	BT 0.360 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.138)
Train: [37][220/589]	BT 0.368 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.137)
Train: [37][230/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.110 (0.137)
Train: [37][240/589]	BT 0.368 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.160 (0.137)
Train: [37][250/589]	BT 0.375 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.126 (0.137)
Train: [37][260/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.137)
Train: [37][270/589]	BT 0.368 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.137)
Train: [37][280/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.132 (0.137)
Train: [37][290/589]	BT 0.355 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.143 (0.137)
Train: [37][300/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.117 (0.137)
Train: [37][310/589]	BT 0.355 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.150 (0.137)
Train: [37][320/589]	BT 0.380 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.151 (0.137)
Train: [37][330/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.116 (0.137)
Train: [37][340/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.146 (0.137)
Train: [37][350/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.137)
Train: [37][360/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.130 (0.137)
Train: [37][370/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.151 (0.137)
Train: [37][380/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.109 (0.137)
Train: [37][390/589]	BT 0.368 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.149 (0.137)
Train: [37][400/589]	BT 0.379 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.143 (0.136)
Train: [37][410/589]	BT 0.361 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.160 (0.137)
Train: [37][420/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.118 (0.136)
Train: [37][430/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.137)
Train: [37][440/589]	BT 0.373 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.139 (0.137)
Train: [37][450/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.130 (0.137)
Train: [37][460/589]	BT 0.357 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.140 (0.137)
Train: [37][470/589]	BT 0.356 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.140 (0.137)
Train: [37][480/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.140 (0.137)
Train: [37][490/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.155 (0.137)
Train: [37][500/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.136 (0.137)
Train: [37][510/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.159 (0.137)
Train: [37][520/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.158 (0.137)
Train: [37][530/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.128 (0.137)
Train: [37][540/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.137 (0.137)
Train: [37][550/589]	BT 0.361 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.145 (0.137)
Train: [37][560/589]	BT 0.359 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.140 (0.137)
Train: [37][570/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.127 (0.137)
Train: [37][580/589]	BT 0.354 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.150 (0.137)
epoch 37, total time 220.87
loss: 0.13720878827640248@Epoch: 37
learning_rate: 0.0002,37
Valid: [37][10/88]	BT 0.109 (0.587)	DT 0.000 (0.476)	loss 0.130 (0.137)
Valid: [37][20/88]	BT 0.110 (0.489)	DT 0.000 (0.379)	loss 0.123 (0.136)
Valid: [37][30/88]	BT 0.109 (0.470)	DT 0.000 (0.360)	loss 0.141 (0.136)
Valid: [37][40/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.124 (0.134)
Valid: [37][50/88]	BT 0.110 (0.437)	DT 0.000 (0.327)	loss 0.143 (0.136)
Valid: [37][60/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.145 (0.136)
Valid: [37][70/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.132 (0.136)
Valid: [37][80/88]	BT 0.109 (0.425)	DT 0.000 (0.315)	loss 0.134 (0.136)
Train: [38][10/589]	BT 0.359 (0.749)	DT 0.000 (0.393)	lr 0.0002	loss 0.150 (0.143)
Train: [38][20/589]	BT 0.357 (0.556)	DT 0.000 (0.200)	lr 0.0002	loss 0.136 (0.139)
Train: [38][30/589]	BT 0.397 (0.500)	DT 0.000 (0.143)	lr 0.0002	loss 0.165 (0.139)
Train: [38][40/589]	BT 0.362 (0.472)	DT 0.000 (0.115)	lr 0.0002	loss 0.134 (0.138)
Train: [38][50/589]	BT 0.355 (0.453)	DT 0.000 (0.097)	lr 0.0002	loss 0.147 (0.138)
Train: [38][60/589]	BT 0.374 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.132 (0.137)
Train: [38][70/589]	BT 0.355 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.154 (0.137)
Train: [38][80/589]	BT 0.355 (0.418)	DT 0.000 (0.060)	lr 0.0002	loss 0.150 (0.137)
Train: [38][90/589]	BT 0.357 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.126 (0.136)
Train: [38][100/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.135 (0.137)
Train: [38][110/589]	BT 0.373 (0.405)	DT 0.000 (0.048)	lr 0.0002	loss 0.134 (0.137)
Train: [38][120/589]	BT 0.358 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.127 (0.137)
Train: [38][130/589]	BT 0.379 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.151 (0.137)
Train: [38][140/589]	BT 0.369 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.116 (0.137)
Train: [38][150/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.112 (0.137)
Train: [38][160/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.162 (0.137)
Train: [38][170/589]	BT 0.359 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.130 (0.137)
Train: [38][180/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.137)
Train: [38][190/589]	BT 0.363 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.137)
Train: [38][200/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.145 (0.138)
Train: [38][210/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.113 (0.137)
Train: [38][220/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.122 (0.137)
Train: [38][230/589]	BT 0.370 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.135 (0.137)
Train: [38][240/589]	BT 0.369 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.136 (0.137)
Train: [38][250/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.123 (0.137)
Train: [38][260/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.167 (0.137)
Train: [38][270/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.154 (0.137)
Train: [38][280/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.125 (0.137)
Train: [38][290/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.185 (0.137)
Train: [38][300/589]	BT 0.359 (0.382)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.137)
Train: [38][310/589]	BT 0.360 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.137)
Train: [38][320/589]	BT 0.355 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.137)
Train: [38][330/589]	BT 0.354 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.137)
Train: [38][340/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.131 (0.137)
Train: [38][350/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.154 (0.137)
Train: [38][360/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.137)
Train: [38][370/589]	BT 0.367 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.137)
Train: [38][380/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.137)
Train: [38][390/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.137)
Train: [38][400/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.157 (0.137)
Train: [38][410/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.135 (0.137)
Train: [38][420/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.135 (0.137)
Train: [38][430/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.136 (0.137)
Train: [38][440/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.144 (0.137)
Train: [38][450/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.137)
Train: [38][460/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.137)
Train: [38][470/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.119 (0.137)
Train: [38][480/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.140 (0.137)
Train: [38][490/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.137)
Train: [38][500/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.120 (0.137)
Train: [38][510/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.123 (0.137)
Train: [38][520/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.152 (0.137)
Train: [38][530/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.137)
Train: [38][540/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.113 (0.137)
Train: [38][550/589]	BT 0.371 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.133 (0.137)
Train: [38][560/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.137)
Train: [38][570/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.138 (0.137)
Train: [38][580/589]	BT 0.354 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.130 (0.137)
epoch 38, total time 221.19
loss: 0.1370769517770461@Epoch: 38
learning_rate: 0.0002,38
Valid: [38][10/88]	BT 0.110 (0.567)	DT 0.000 (0.456)	loss 0.139 (0.136)
Valid: [38][20/88]	BT 0.109 (0.477)	DT 0.000 (0.366)	loss 0.130 (0.136)
Valid: [38][30/88]	BT 0.110 (0.460)	DT 0.000 (0.349)	loss 0.134 (0.135)
Valid: [38][40/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.139 (0.134)
Valid: [38][50/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.134 (0.135)
Valid: [38][60/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.128 (0.133)
Valid: [38][70/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.121 (0.134)
Valid: [38][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.113 (0.134)
Train: [39][10/589]	BT 0.368 (0.749)	DT 0.000 (0.393)	lr 0.0002	loss 0.141 (0.137)
Train: [39][20/589]	BT 0.370 (0.557)	DT 0.000 (0.200)	lr 0.0002	loss 0.129 (0.137)
Train: [39][30/589]	BT 0.356 (0.492)	DT 0.000 (0.135)	lr 0.0002	loss 0.158 (0.137)
Train: [39][40/589]	BT 0.359 (0.463)	DT 0.000 (0.106)	lr 0.0002	loss 0.101 (0.137)
Train: [39][50/589]	BT 0.373 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.125 (0.137)
Train: [39][60/589]	BT 0.364 (0.432)	DT 0.000 (0.075)	lr 0.0002	loss 0.132 (0.136)
Train: [39][70/589]	BT 0.357 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.149 (0.136)
Train: [39][80/589]	BT 0.374 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.112 (0.135)
Train: [39][90/589]	BT 0.362 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.166 (0.135)
Train: [39][100/589]	BT 0.357 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.168 (0.135)
Train: [39][110/589]	BT 0.357 (0.402)	DT 0.000 (0.045)	lr 0.0002	loss 0.127 (0.135)
Train: [39][120/589]	BT 0.358 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.104 (0.135)
Train: [39][130/589]	BT 0.357 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.135 (0.135)
Train: [39][140/589]	BT 0.367 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.116 (0.135)
Train: [39][150/589]	BT 0.358 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.136 (0.135)
Train: [39][160/589]	BT 0.373 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.124 (0.136)
Train: [39][170/589]	BT 0.357 (0.389)	DT 0.000 (0.032)	lr 0.0002	loss 0.121 (0.136)
Train: [39][180/589]	BT 0.377 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.161 (0.136)
Train: [39][190/589]	BT 0.363 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.136)
Train: [39][200/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.129 (0.136)
Train: [39][210/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.137)
Train: [39][220/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.136)
Train: [39][230/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.136)
Train: [39][240/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.137)
Train: [39][250/589]	BT 0.375 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.137)
Train: [39][260/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.136)
Train: [39][270/589]	BT 0.366 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.145 (0.137)
Train: [39][280/589]	BT 0.374 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.116 (0.137)
Train: [39][290/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.137)
Train: [39][300/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.134 (0.137)
Train: [39][310/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.136)
Train: [39][320/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.137)
Train: [39][330/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.136)
Train: [39][340/589]	BT 0.357 (0.378)	DT 0.001 (0.020)	lr 0.0002	loss 0.117 (0.136)
Train: [39][350/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.121 (0.136)
Train: [39][360/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.136)
Train: [39][370/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.144 (0.136)
Train: [39][380/589]	BT 0.363 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.150 (0.136)
Train: [39][390/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.119 (0.136)
Train: [39][400/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.166 (0.136)
Train: [39][410/589]	BT 0.363 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.140 (0.137)
Train: [39][420/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.159 (0.137)
Train: [39][430/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.137 (0.137)
Train: [39][440/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.137)
Train: [39][450/589]	BT 0.373 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.115 (0.137)
Train: [39][460/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.124 (0.137)
Train: [39][470/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.126 (0.136)
Train: [39][480/589]	BT 0.377 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.127 (0.136)
Train: [39][490/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.120 (0.136)
Train: [39][500/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.152 (0.136)
Train: [39][510/589]	BT 0.363 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.141 (0.137)
Train: [39][520/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.146 (0.137)
Train: [39][530/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.138 (0.137)
Train: [39][540/589]	BT 0.359 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.181 (0.137)
Train: [39][550/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.149 (0.137)
Train: [39][560/589]	BT 0.357 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.121 (0.137)
Train: [39][570/589]	BT 0.359 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.109 (0.137)
Train: [39][580/589]	BT 0.360 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.136 (0.137)
epoch 39, total time 220.15
loss: 0.1366531032271919@Epoch: 39
learning_rate: 0.0002,39
Valid: [39][10/88]	BT 0.110 (0.544)	DT 0.000 (0.431)	loss 0.150 (0.134)
Valid: [39][20/88]	BT 0.109 (0.476)	DT 0.000 (0.365)	loss 0.135 (0.136)
Valid: [39][30/88]	BT 0.110 (0.452)	DT 0.000 (0.341)	loss 0.139 (0.137)
Valid: [39][40/88]	BT 0.109 (0.438)	DT 0.000 (0.327)	loss 0.142 (0.136)
Valid: [39][50/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.140 (0.138)
Valid: [39][60/88]	BT 0.109 (0.432)	DT 0.000 (0.321)	loss 0.142 (0.136)
Valid: [39][70/88]	BT 0.109 (0.426)	DT 0.000 (0.316)	loss 0.126 (0.136)
Valid: [39][80/88]	BT 0.109 (0.422)	DT 0.000 (0.312)	loss 0.154 (0.137)
Train: [40][10/589]	BT 0.361 (0.727)	DT 0.000 (0.372)	lr 0.0002	loss 0.133 (0.134)
Train: [40][20/589]	BT 0.356 (0.548)	DT 0.000 (0.192)	lr 0.0002	loss 0.145 (0.134)
Train: [40][30/589]	BT 0.356 (0.490)	DT 0.000 (0.134)	lr 0.0002	loss 0.135 (0.134)
Train: [40][40/589]	BT 0.357 (0.461)	DT 0.000 (0.105)	lr 0.0002	loss 0.141 (0.135)
Train: [40][50/589]	BT 0.355 (0.447)	DT 0.000 (0.091)	lr 0.0002	loss 0.145 (0.135)
Train: [40][60/589]	BT 0.355 (0.434)	DT 0.000 (0.078)	lr 0.0002	loss 0.133 (0.136)
Train: [40][70/589]	BT 0.376 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.120 (0.135)
Train: [40][80/589]	BT 0.365 (0.420)	DT 0.000 (0.064)	lr 0.0002	loss 0.173 (0.135)
Train: [40][90/589]	BT 0.356 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.152 (0.136)
Train: [40][100/589]	BT 0.360 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.144 (0.135)
Train: [40][110/589]	BT 0.354 (0.407)	DT 0.000 (0.051)	lr 0.0002	loss 0.124 (0.135)
Train: [40][120/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.148 (0.136)
Train: [40][130/589]	BT 0.355 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.127 (0.135)
Train: [40][140/589]	BT 0.358 (0.398)	DT 0.000 (0.042)	lr 0.0002	loss 0.138 (0.135)
Train: [40][150/589]	BT 0.357 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.136 (0.136)
Train: [40][160/589]	BT 0.359 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.152 (0.136)
Train: [40][170/589]	BT 0.358 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.133 (0.136)
Train: [40][180/589]	BT 0.373 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.160 (0.136)
Train: [40][190/589]	BT 0.368 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.148 (0.135)
Train: [40][200/589]	BT 0.391 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.147 (0.136)
Train: [40][210/589]	BT 0.374 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.116 (0.136)
Train: [40][220/589]	BT 0.372 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.136)
Train: [40][230/589]	BT 0.365 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.119 (0.136)
Train: [40][240/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.110 (0.135)
Train: [40][250/589]	BT 0.363 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.128 (0.136)
Train: [40][260/589]	BT 0.360 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.127 (0.135)
Train: [40][270/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.134 (0.136)
Train: [40][280/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.149 (0.136)
Train: [40][290/589]	BT 0.358 (0.384)	DT 0.000 (0.027)	lr 0.0002	loss 0.142 (0.136)
Train: [40][300/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.146 (0.136)
Train: [40][310/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.136)
Train: [40][320/589]	BT 0.355 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.137)
Train: [40][330/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.144 (0.136)
Train: [40][340/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.115 (0.136)
Train: [40][350/589]	BT 0.358 (0.381)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.137)
Train: [40][360/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.144 (0.136)
Train: [40][370/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.136)
Train: [40][380/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.136)
Train: [40][390/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.129 (0.136)
Train: [40][400/589]	BT 0.372 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.121 (0.136)
Train: [40][410/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.136)
Train: [40][420/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.136)
Train: [40][430/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.118 (0.136)
Train: [40][440/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.136 (0.136)
Train: [40][450/589]	BT 0.354 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.137)
Train: [40][460/589]	BT 0.360 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.147 (0.136)
Train: [40][470/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.119 (0.136)
Train: [40][480/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.114 (0.136)
Train: [40][490/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.136)
Train: [40][500/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.136)
Train: [40][510/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.136 (0.136)
Train: [40][520/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.136)
Train: [40][530/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.143 (0.136)
Train: [40][540/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.127 (0.136)
Train: [40][550/589]	BT 0.360 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.130 (0.136)
Train: [40][560/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.136)
Train: [40][570/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.151 (0.136)
Train: [40][580/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.127 (0.136)
epoch 40, total time 222.33
loss: 0.13638421628780115@Epoch: 40
learning_rate: 0.0002,40
Valid: [40][10/88]	BT 0.110 (0.566)	DT 0.000 (0.455)	loss 0.140 (0.139)
Valid: [40][20/88]	BT 0.109 (0.485)	DT 0.000 (0.375)	loss 0.140 (0.137)
Valid: [40][30/88]	BT 0.109 (0.459)	DT 0.000 (0.349)	loss 0.144 (0.135)
Valid: [40][40/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.146 (0.136)
Valid: [40][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.145 (0.134)
Valid: [40][60/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.133 (0.134)
Valid: [40][70/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.117 (0.134)
Valid: [40][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.126 (0.134)
Epoch 0040: val_loss improved from 0.13462 to 0.13404, saving model
==> Saving...
Train: [41][10/589]	BT 0.355 (0.744)	DT 0.000 (0.388)	lr 0.0002	loss 0.137 (0.133)
Train: [41][20/589]	BT 0.357 (0.550)	DT 0.000 (0.194)	lr 0.0002	loss 0.130 (0.137)
Train: [41][30/589]	BT 0.356 (0.487)	DT 0.000 (0.129)	lr 0.0002	loss 0.135 (0.137)
Train: [41][40/589]	BT 0.357 (0.455)	DT 0.000 (0.097)	lr 0.0002	loss 0.118 (0.137)
Train: [41][50/589]	BT 0.357 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.135 (0.136)
Train: [41][60/589]	BT 0.355 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.130 (0.136)
Train: [41][70/589]	BT 0.358 (0.415)	DT 0.000 (0.058)	lr 0.0002	loss 0.126 (0.136)
Train: [41][80/589]	BT 0.356 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.139 (0.136)
Train: [41][90/589]	BT 0.358 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.132 (0.136)
Train: [41][100/589]	BT 0.359 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.143 (0.136)
Train: [41][110/589]	BT 0.357 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.136)
Train: [41][120/589]	BT 0.355 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.155 (0.136)
Train: [41][130/589]	BT 0.360 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.149 (0.136)
Train: [41][140/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.121 (0.136)
Train: [41][150/589]	BT 0.361 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.136)
Train: [41][160/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.136)
Train: [41][170/589]	BT 0.373 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.140 (0.136)
Train: [41][180/589]	BT 0.359 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.136)
Train: [41][190/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.148 (0.136)
Train: [41][200/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.139 (0.137)
Train: [41][210/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.128 (0.136)
Train: [41][220/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.140 (0.136)
Train: [41][230/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.157 (0.136)
Train: [41][240/589]	BT 0.363 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.138 (0.136)
Train: [41][250/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.119 (0.136)
Train: [41][260/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.136)
Train: [41][270/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.151 (0.136)
Train: [41][280/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.136)
Train: [41][290/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.142 (0.136)
Train: [41][300/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.148 (0.136)
Train: [41][310/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.125 (0.136)
Train: [41][320/589]	BT 0.369 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.136)
Train: [41][330/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.121 (0.136)
Train: [41][340/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.153 (0.136)
Train: [41][350/589]	BT 0.374 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.137)
Train: [41][360/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.137)
Train: [41][370/589]	BT 0.380 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.137)
Train: [41][380/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.136)
Train: [41][390/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.155 (0.137)
Train: [41][400/589]	BT 0.365 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.137)
Train: [41][410/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.137)
Train: [41][420/589]	BT 0.376 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.126 (0.137)
Train: [41][430/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.118 (0.137)
Train: [41][440/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.115 (0.136)
Train: [41][450/589]	BT 0.360 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.158 (0.136)
Train: [41][460/589]	BT 0.363 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.137)
Train: [41][470/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.144 (0.136)
Train: [41][480/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.147 (0.136)
Train: [41][490/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.139 (0.137)
Train: [41][500/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.117 (0.137)
Train: [41][510/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.137)
Train: [41][520/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.137)
Train: [41][530/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.128 (0.137)
Train: [41][540/589]	BT 0.374 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.136)
Train: [41][550/589]	BT 0.361 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.146 (0.136)
Train: [41][560/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.136)
Train: [41][570/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.136 (0.136)
Train: [41][580/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.136)
epoch 41, total time 223.50
loss: 0.13626627792769083@Epoch: 41
learning_rate: 0.0002,41
Valid: [41][10/88]	BT 0.110 (0.573)	DT 0.000 (0.461)	loss 0.131 (0.142)
Valid: [41][20/88]	BT 0.109 (0.495)	DT 0.000 (0.385)	loss 0.149 (0.136)
Valid: [41][30/88]	BT 0.109 (0.473)	DT 0.000 (0.363)	loss 0.140 (0.138)
Valid: [41][40/88]	BT 0.109 (0.460)	DT 0.000 (0.350)	loss 0.146 (0.137)
Valid: [41][50/88]	BT 0.109 (0.451)	DT 0.000 (0.341)	loss 0.135 (0.135)
Valid: [41][60/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.133 (0.134)
Valid: [41][70/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.138 (0.133)
Valid: [41][80/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.125 (0.134)
Train: [42][10/589]	BT 0.356 (0.750)	DT 0.000 (0.393)	lr 0.0002	loss 0.120 (0.136)
Train: [42][20/589]	BT 0.355 (0.564)	DT 0.000 (0.208)	lr 0.0002	loss 0.126 (0.135)
Train: [42][30/589]	BT 0.356 (0.503)	DT 0.000 (0.148)	lr 0.0002	loss 0.134 (0.136)
Train: [42][40/589]	BT 0.355 (0.475)	DT 0.000 (0.119)	lr 0.0002	loss 0.157 (0.136)
Train: [42][50/589]	BT 0.356 (0.458)	DT 0.000 (0.102)	lr 0.0002	loss 0.131 (0.137)
Train: [42][60/589]	BT 0.356 (0.445)	DT 0.000 (0.089)	lr 0.0002	loss 0.132 (0.137)
Train: [42][70/589]	BT 0.356 (0.439)	DT 0.000 (0.083)	lr 0.0002	loss 0.126 (0.136)
Train: [42][80/589]	BT 0.369 (0.431)	DT 0.000 (0.075)	lr 0.0002	loss 0.127 (0.137)
Train: [42][90/589]	BT 0.354 (0.423)	DT 0.000 (0.067)	lr 0.0002	loss 0.121 (0.137)
Train: [42][100/589]	BT 0.374 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.112 (0.135)
Train: [42][110/589]	BT 0.354 (0.411)	DT 0.000 (0.055)	lr 0.0002	loss 0.124 (0.135)
Train: [42][120/589]	BT 0.358 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.153 (0.135)
Train: [42][130/589]	BT 0.373 (0.405)	DT 0.000 (0.048)	lr 0.0002	loss 0.124 (0.135)
Train: [42][140/589]	BT 0.364 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.144 (0.136)
Train: [42][150/589]	BT 0.358 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.149 (0.136)
Train: [42][160/589]	BT 0.376 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.135 (0.136)
Train: [42][170/589]	BT 0.358 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.127 (0.136)
Train: [42][180/589]	BT 0.374 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.115 (0.136)
Train: [42][190/589]	BT 0.359 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.131 (0.136)
Train: [42][200/589]	BT 0.374 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.136)
Train: [42][210/589]	BT 0.364 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.136)
Train: [42][220/589]	BT 0.385 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.136)
Train: [42][230/589]	BT 0.374 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.148 (0.136)
Train: [42][240/589]	BT 0.360 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.136)
Train: [42][250/589]	BT 0.374 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.136)
Train: [42][260/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.175 (0.136)
Train: [42][270/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.133 (0.136)
Train: [42][280/589]	BT 0.360 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.136)
Train: [42][290/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.136)
Train: [42][300/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.142 (0.136)
Train: [42][310/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.154 (0.136)
Train: [42][320/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.136)
Train: [42][330/589]	BT 0.361 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.145 (0.136)
Train: [42][340/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.136)
Train: [42][350/589]	BT 0.373 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.161 (0.136)
Train: [42][360/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.136)
Train: [42][370/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.136)
Train: [42][380/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.129 (0.136)
Train: [42][390/589]	BT 0.366 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.137 (0.136)
Train: [42][400/589]	BT 0.372 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.123 (0.136)
Train: [42][410/589]	BT 0.373 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.155 (0.136)
Train: [42][420/589]	BT 0.385 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.132 (0.136)
Train: [42][430/589]	BT 0.377 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.159 (0.136)
Train: [42][440/589]	BT 0.372 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.145 (0.136)
Train: [42][450/589]	BT 0.367 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.153 (0.136)
Train: [42][460/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.136)
Train: [42][470/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.136)
Train: [42][480/589]	BT 0.360 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.141 (0.136)
Train: [42][490/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.134 (0.136)
Train: [42][500/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.151 (0.136)
Train: [42][510/589]	BT 0.364 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.136)
Train: [42][520/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.128 (0.136)
Train: [42][530/589]	BT 0.358 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.123 (0.136)
Train: [42][540/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.136)
Train: [42][550/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.136 (0.136)
Train: [42][560/589]	BT 0.360 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.126 (0.136)
Train: [42][570/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.133 (0.136)
Train: [42][580/589]	BT 0.357 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.131 (0.136)
epoch 42, total time 221.26
loss: 0.13613557578437466@Epoch: 42
learning_rate: 0.0002,42
Valid: [42][10/88]	BT 0.110 (0.566)	DT 0.000 (0.455)	loss 0.170 (0.138)
Valid: [42][20/88]	BT 0.110 (0.488)	DT 0.000 (0.376)	loss 0.138 (0.137)
Valid: [42][30/88]	BT 0.109 (0.463)	DT 0.000 (0.352)	loss 0.147 (0.138)
Valid: [42][40/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.150 (0.138)
Valid: [42][50/88]	BT 0.110 (0.443)	DT 0.000 (0.333)	loss 0.149 (0.136)
Valid: [42][60/88]	BT 0.110 (0.440)	DT 0.000 (0.330)	loss 0.149 (0.135)
Valid: [42][70/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.134 (0.134)
Valid: [42][80/88]	BT 0.109 (0.427)	DT 0.000 (0.317)	loss 0.150 (0.135)
Train: [43][10/589]	BT 0.361 (0.733)	DT 0.000 (0.377)	lr 0.0002	loss 0.160 (0.139)
Train: [43][20/589]	BT 0.363 (0.569)	DT 0.000 (0.212)	lr 0.0002	loss 0.127 (0.136)
Train: [43][30/589]	BT 0.353 (0.504)	DT 0.000 (0.147)	lr 0.0002	loss 0.133 (0.134)
Train: [43][40/589]	BT 0.369 (0.468)	DT 0.000 (0.111)	lr 0.0002	loss 0.109 (0.133)
Train: [43][50/589]	BT 0.364 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.140 (0.133)
Train: [43][60/589]	BT 0.373 (0.435)	DT 0.000 (0.078)	lr 0.0002	loss 0.114 (0.134)
Train: [43][70/589]	BT 0.365 (0.425)	DT 0.000 (0.068)	lr 0.0002	loss 0.141 (0.134)
Train: [43][80/589]	BT 0.354 (0.418)	DT 0.000 (0.060)	lr 0.0002	loss 0.108 (0.134)
Train: [43][90/589]	BT 0.358 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.137 (0.134)
Train: [43][100/589]	BT 0.360 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.153 (0.134)
Train: [43][110/589]	BT 0.357 (0.407)	DT 0.000 (0.050)	lr 0.0002	loss 0.137 (0.134)
Train: [43][120/589]	BT 0.356 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.133 (0.134)
Train: [43][130/589]	BT 0.374 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.141 (0.134)
Train: [43][140/589]	BT 0.368 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.130 (0.134)
Train: [43][150/589]	BT 0.358 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.153 (0.134)
Train: [43][160/589]	BT 0.355 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.119 (0.135)
Train: [43][170/589]	BT 0.370 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.119 (0.135)
Train: [43][180/589]	BT 0.378 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.138 (0.135)
Train: [43][190/589]	BT 0.360 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.135)
Train: [43][200/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.160 (0.135)
Train: [43][210/589]	BT 0.367 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.135)
Train: [43][220/589]	BT 0.367 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.145 (0.135)
Train: [43][230/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.137 (0.135)
Train: [43][240/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.135)
Train: [43][250/589]	BT 0.391 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.126 (0.135)
Train: [43][260/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.119 (0.135)
Train: [43][270/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.143 (0.135)
Train: [43][280/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.118 (0.135)
Train: [43][290/589]	BT 0.356 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.135)
Train: [43][300/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.135)
Train: [43][310/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.135)
Train: [43][320/589]	BT 0.356 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.149 (0.135)
Train: [43][330/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.135)
Train: [43][340/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.119 (0.136)
Train: [43][350/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.136)
Train: [43][360/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.131 (0.136)
Train: [43][370/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.152 (0.136)
Train: [43][380/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.175 (0.136)
Train: [43][390/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.136)
Train: [43][400/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.136)
Train: [43][410/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.136)
Train: [43][420/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.150 (0.136)
Train: [43][430/589]	BT 0.372 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.136)
Train: [43][440/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.135 (0.136)
Train: [43][450/589]	BT 0.366 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.120 (0.136)
Train: [43][460/589]	BT 0.373 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.136)
Train: [43][470/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.148 (0.136)
Train: [43][480/589]	BT 0.355 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.136)
Train: [43][490/589]	BT 0.357 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.136)
Train: [43][500/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.136)
Train: [43][510/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.158 (0.136)
Train: [43][520/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.136)
Train: [43][530/589]	BT 0.356 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.133 (0.136)
Train: [43][540/589]	BT 0.357 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.136)
Train: [43][550/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.136)
Train: [43][560/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.136)
Train: [43][570/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.128 (0.136)
Train: [43][580/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.124 (0.136)
epoch 43, total time 222.82
loss: 0.13594014944545474@Epoch: 43
learning_rate: 0.0002,43
Valid: [43][10/88]	BT 0.109 (0.569)	DT 0.000 (0.459)	loss 0.130 (0.128)
Valid: [43][20/88]	BT 0.109 (0.491)	DT 0.000 (0.381)	loss 0.131 (0.133)
Valid: [43][30/88]	BT 0.109 (0.462)	DT 0.000 (0.353)	loss 0.135 (0.133)
Valid: [43][40/88]	BT 0.110 (0.452)	DT 0.000 (0.342)	loss 0.136 (0.134)
Valid: [43][50/88]	BT 0.110 (0.446)	DT 0.000 (0.336)	loss 0.125 (0.134)
Valid: [43][60/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.132 (0.134)
Valid: [43][70/88]	BT 0.109 (0.436)	DT 0.000 (0.327)	loss 0.152 (0.134)
Valid: [43][80/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.140 (0.133)
Epoch 0043: val_loss improved from 0.13404 to 0.13370, saving model
==> Saving...
Train: [44][10/589]	BT 0.363 (0.760)	DT 0.000 (0.404)	lr 0.0002	loss 0.136 (0.132)
Train: [44][20/589]	BT 0.353 (0.565)	DT 0.000 (0.207)	lr 0.0002	loss 0.146 (0.135)
Train: [44][30/589]	BT 0.357 (0.509)	DT 0.000 (0.153)	lr 0.0002	loss 0.130 (0.135)
Train: [44][40/589]	BT 0.372 (0.478)	DT 0.000 (0.121)	lr 0.0002	loss 0.128 (0.135)
Train: [44][50/589]	BT 0.354 (0.454)	DT 0.000 (0.097)	lr 0.0002	loss 0.144 (0.135)
Train: [44][60/589]	BT 0.357 (0.440)	DT 0.000 (0.083)	lr 0.0002	loss 0.121 (0.137)
Train: [44][70/589]	BT 0.357 (0.430)	DT 0.000 (0.073)	lr 0.0002	loss 0.121 (0.136)
Train: [44][80/589]	BT 0.356 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.113 (0.136)
Train: [44][90/589]	BT 0.356 (0.418)	DT 0.000 (0.061)	lr 0.0002	loss 0.128 (0.135)
Train: [44][100/589]	BT 0.358 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.158 (0.135)
Train: [44][110/589]	BT 0.364 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.144 (0.136)
Train: [44][120/589]	BT 0.357 (0.408)	DT 0.000 (0.051)	lr 0.0002	loss 0.142 (0.136)
Train: [44][130/589]	BT 0.357 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.113 (0.135)
Train: [44][140/589]	BT 0.356 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.146 (0.136)
Train: [44][150/589]	BT 0.358 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.143 (0.136)
Train: [44][160/589]	BT 0.359 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.152 (0.136)
Train: [44][170/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.126 (0.136)
Train: [44][180/589]	BT 0.359 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.137 (0.136)
Train: [44][190/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.140 (0.136)
Train: [44][200/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.121 (0.136)
Train: [44][210/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.138 (0.136)
Train: [44][220/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.136)
Train: [44][230/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.136)
Train: [44][240/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.136)
Train: [44][250/589]	BT 0.356 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.163 (0.136)
Train: [44][260/589]	BT 0.379 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.136)
Train: [44][270/589]	BT 0.362 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.136)
Train: [44][280/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.136)
Train: [44][290/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.136)
Train: [44][300/589]	BT 0.362 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.136 (0.136)
Train: [44][310/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.115 (0.136)
Train: [44][320/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.136)
Train: [44][330/589]	BT 0.357 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.136)
Train: [44][340/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.136)
Train: [44][350/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.147 (0.136)
Train: [44][360/589]	BT 0.364 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.136)
Train: [44][370/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.136)
Train: [44][380/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.136)
Train: [44][390/589]	BT 0.360 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.136)
Train: [44][400/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.176 (0.136)
Train: [44][410/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.136)
Train: [44][420/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.131 (0.136)
Train: [44][430/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.136)
Train: [44][440/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.136)
Train: [44][450/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.136)
Train: [44][460/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.136)
Train: [44][470/589]	BT 0.376 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.136)
Train: [44][480/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.136)
Train: [44][490/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.136)
Train: [44][500/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.150 (0.136)
Train: [44][510/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.153 (0.136)
Train: [44][520/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.136)
Train: [44][530/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.114 (0.136)
Train: [44][540/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.141 (0.136)
Train: [44][550/589]	BT 0.367 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.122 (0.136)
Train: [44][560/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.121 (0.136)
Train: [44][570/589]	BT 0.355 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.134 (0.136)
Train: [44][580/589]	BT 0.357 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.172 (0.136)
epoch 44, total time 222.89
loss: 0.13566210391429268@Epoch: 44
learning_rate: 0.0002,44
Valid: [44][10/88]	BT 0.109 (0.548)	DT 0.000 (0.436)	loss 0.126 (0.141)
Valid: [44][20/88]	BT 0.110 (0.481)	DT 0.000 (0.370)	loss 0.132 (0.136)
Valid: [44][30/88]	BT 0.109 (0.462)	DT 0.000 (0.351)	loss 0.119 (0.136)
Valid: [44][40/88]	BT 0.109 (0.452)	DT 0.000 (0.341)	loss 0.127 (0.135)
Valid: [44][50/88]	BT 0.109 (0.442)	DT 0.000 (0.331)	loss 0.136 (0.135)
Valid: [44][60/88]	BT 0.109 (0.434)	DT 0.000 (0.323)	loss 0.139 (0.136)
Valid: [44][70/88]	BT 0.110 (0.429)	DT 0.000 (0.318)	loss 0.136 (0.135)
Valid: [44][80/88]	BT 0.109 (0.428)	DT 0.000 (0.318)	loss 0.133 (0.135)
Train: [45][10/589]	BT 0.355 (0.731)	DT 0.000 (0.376)	lr 0.0002	loss 0.131 (0.135)
Train: [45][20/589]	BT 0.356 (0.546)	DT 0.000 (0.191)	lr 0.0002	loss 0.151 (0.139)
Train: [45][30/589]	BT 0.354 (0.487)	DT 0.000 (0.132)	lr 0.0002	loss 0.125 (0.136)
Train: [45][40/589]	BT 0.356 (0.462)	DT 0.000 (0.106)	lr 0.0002	loss 0.111 (0.133)
Train: [45][50/589]	BT 0.356 (0.444)	DT 0.000 (0.088)	lr 0.0002	loss 0.138 (0.133)
Train: [45][60/589]	BT 0.375 (0.434)	DT 0.000 (0.078)	lr 0.0002	loss 0.138 (0.134)
Train: [45][70/589]	BT 0.357 (0.423)	DT 0.000 (0.067)	lr 0.0002	loss 0.130 (0.133)
Train: [45][80/589]	BT 0.356 (0.415)	DT 0.000 (0.059)	lr 0.0002	loss 0.129 (0.133)
Train: [45][90/589]	BT 0.357 (0.410)	DT 0.000 (0.054)	lr 0.0002	loss 0.118 (0.133)
Train: [45][100/589]	BT 0.361 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.111 (0.134)
Train: [45][110/589]	BT 0.357 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.116 (0.134)
Train: [45][120/589]	BT 0.357 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.132 (0.134)
Train: [45][130/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.148 (0.133)
Train: [45][140/589]	BT 0.359 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.150 (0.134)
Train: [45][150/589]	BT 0.357 (0.392)	DT 0.000 (0.035)	lr 0.0002	loss 0.132 (0.134)
Train: [45][160/589]	BT 0.370 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.156 (0.134)
Train: [45][170/589]	BT 0.375 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.153 (0.134)
Train: [45][180/589]	BT 0.360 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.142 (0.134)
Train: [45][190/589]	BT 0.358 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.134)
Train: [45][200/589]	BT 0.355 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.173 (0.135)
Train: [45][210/589]	BT 0.354 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.137 (0.135)
Train: [45][220/589]	BT 0.372 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.133 (0.135)
Train: [45][230/589]	BT 0.359 (0.384)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.135)
Train: [45][240/589]	BT 0.359 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.118 (0.135)
Train: [45][250/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.116 (0.135)
Train: [45][260/589]	BT 0.365 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.135)
Train: [45][270/589]	BT 0.360 (0.381)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.135)
Train: [45][280/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.140 (0.135)
Train: [45][290/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.117 (0.135)
Train: [45][300/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.136 (0.135)
Train: [45][310/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.135)
Train: [45][320/589]	BT 0.360 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.135)
Train: [45][330/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.135)
Train: [45][340/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.121 (0.135)
Train: [45][350/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.130 (0.135)
Train: [45][360/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.169 (0.135)
Train: [45][370/589]	BT 0.356 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.122 (0.135)
Train: [45][380/589]	BT 0.360 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.151 (0.135)
Train: [45][390/589]	BT 0.373 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.135)
Train: [45][400/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.162 (0.135)
Train: [45][410/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.145 (0.135)
Train: [45][420/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.117 (0.135)
Train: [45][430/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.135)
Train: [45][440/589]	BT 0.365 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.130 (0.135)
Train: [45][450/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.134 (0.135)
Train: [45][460/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.135)
Train: [45][470/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.134 (0.135)
Train: [45][480/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.108 (0.135)
Train: [45][490/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.169 (0.135)
Train: [45][500/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.145 (0.135)
Train: [45][510/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.151 (0.135)
Train: [45][520/589]	BT 0.360 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.113 (0.135)
Train: [45][530/589]	BT 0.357 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.127 (0.135)
Train: [45][540/589]	BT 0.365 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.135 (0.135)
Train: [45][550/589]	BT 0.363 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.151 (0.135)
Train: [45][560/589]	BT 0.358 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.125 (0.135)
Train: [45][570/589]	BT 0.358 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.147 (0.135)
Train: [45][580/589]	BT 0.356 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.125 (0.135)
epoch 45, total time 220.14
loss: 0.13534131056378038@Epoch: 45
learning_rate: 0.0002,45
Valid: [45][10/88]	BT 0.109 (0.576)	DT 0.000 (0.464)	loss 0.156 (0.149)
Valid: [45][20/88]	BT 0.110 (0.492)	DT 0.000 (0.381)	loss 0.140 (0.141)
Valid: [45][30/88]	BT 0.109 (0.467)	DT 0.000 (0.357)	loss 0.132 (0.137)
Valid: [45][40/88]	BT 0.109 (0.458)	DT 0.000 (0.349)	loss 0.149 (0.136)
Valid: [45][50/88]	BT 0.109 (0.448)	DT 0.000 (0.339)	loss 0.114 (0.136)
Valid: [45][60/88]	BT 0.109 (0.440)	DT 0.000 (0.330)	loss 0.155 (0.135)
Valid: [45][70/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.132 (0.136)
Valid: [45][80/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.149 (0.135)
Train: [46][10/589]	BT 0.356 (0.740)	DT 0.000 (0.383)	lr 0.0002	loss 0.124 (0.136)
Train: [46][20/589]	BT 0.356 (0.552)	DT 0.000 (0.196)	lr 0.0002	loss 0.122 (0.135)
Train: [46][30/589]	BT 0.359 (0.494)	DT 0.000 (0.138)	lr 0.0002	loss 0.132 (0.135)
Train: [46][40/589]	BT 0.367 (0.467)	DT 0.000 (0.110)	lr 0.0002	loss 0.147 (0.134)
Train: [46][50/589]	BT 0.355 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.114 (0.134)
Train: [46][60/589]	BT 0.357 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.147 (0.135)
Train: [46][70/589]	BT 0.357 (0.436)	DT 0.000 (0.080)	lr 0.0002	loss 0.119 (0.135)
Train: [46][80/589]	BT 0.365 (0.428)	DT 0.000 (0.071)	lr 0.0002	loss 0.124 (0.134)
Train: [46][90/589]	BT 0.367 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.133 (0.134)
Train: [46][100/589]	BT 0.358 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.122 (0.134)
Train: [46][110/589]	BT 0.369 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.114 (0.134)
Train: [46][120/589]	BT 0.357 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.156 (0.133)
Train: [46][130/589]	BT 0.358 (0.407)	DT 0.000 (0.050)	lr 0.0002	loss 0.114 (0.133)
Train: [46][140/589]	BT 0.362 (0.405)	DT 0.000 (0.048)	lr 0.0002	loss 0.128 (0.133)
Train: [46][150/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.123 (0.133)
Train: [46][160/589]	BT 0.359 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.155 (0.133)
Train: [46][170/589]	BT 0.364 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.130 (0.133)
Train: [46][180/589]	BT 0.360 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.134)
Train: [46][190/589]	BT 0.360 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.134)
Train: [46][200/589]	BT 0.371 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.148 (0.134)
Train: [46][210/589]	BT 0.374 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.113 (0.134)
Train: [46][220/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.121 (0.134)
Train: [46][230/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.129 (0.134)
Train: [46][240/589]	BT 0.360 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.135 (0.134)
Train: [46][250/589]	BT 0.355 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.135 (0.134)
Train: [46][260/589]	BT 0.366 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.134)
Train: [46][270/589]	BT 0.360 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.117 (0.134)
Train: [46][280/589]	BT 0.354 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.125 (0.134)
Train: [46][290/589]	BT 0.358 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.131 (0.134)
Train: [46][300/589]	BT 0.358 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.133 (0.134)
Train: [46][310/589]	BT 0.359 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.146 (0.134)
Train: [46][320/589]	BT 0.357 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.131 (0.134)
Train: [46][330/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.123 (0.134)
Train: [46][340/589]	BT 0.356 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.146 (0.134)
Train: [46][350/589]	BT 0.356 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.153 (0.134)
Train: [46][360/589]	BT 0.356 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.132 (0.134)
Train: [46][370/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.138 (0.134)
Train: [46][380/589]	BT 0.357 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.131 (0.134)
Train: [46][390/589]	BT 0.357 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.132 (0.134)
Train: [46][400/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.187 (0.134)
Train: [46][410/589]	BT 0.359 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.150 (0.134)
Train: [46][420/589]	BT 0.356 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.135)
Train: [46][430/589]	BT 0.358 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.131 (0.135)
Train: [46][440/589]	BT 0.359 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.153 (0.135)
Train: [46][450/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.110 (0.135)
Train: [46][460/589]	BT 0.372 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.111 (0.135)
Train: [46][470/589]	BT 0.360 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.115 (0.135)
Train: [46][480/589]	BT 0.355 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.135)
Train: [46][490/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.137 (0.135)
Train: [46][500/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.123 (0.135)
Train: [46][510/589]	BT 0.366 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.145 (0.135)
Train: [46][520/589]	BT 0.356 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.135)
Train: [46][530/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.144 (0.135)
Train: [46][540/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.113 (0.135)
Train: [46][550/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.168 (0.135)
Train: [46][560/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.158 (0.135)
Train: [46][570/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.148 (0.135)
Train: [46][580/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.135)
epoch 46, total time 229.01
loss: 0.13523940145906077@Epoch: 46
learning_rate: 0.0002,46
Valid: [46][10/88]	BT 0.109 (0.535)	DT 0.000 (0.424)	loss 0.119 (0.137)
Valid: [46][20/88]	BT 0.109 (0.478)	DT 0.000 (0.368)	loss 0.124 (0.138)
Valid: [46][30/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.152 (0.138)
Valid: [46][40/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.138 (0.135)
Valid: [46][50/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.119 (0.133)
Valid: [46][60/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.124 (0.134)
Valid: [46][70/88]	BT 0.109 (0.426)	DT 0.000 (0.317)	loss 0.123 (0.134)
Valid: [46][80/88]	BT 0.109 (0.423)	DT 0.000 (0.314)	loss 0.166 (0.134)
Train: [47][10/589]	BT 0.356 (0.763)	DT 0.000 (0.408)	lr 0.0002	loss 0.132 (0.135)
Train: [47][20/589]	BT 0.355 (0.579)	DT 0.000 (0.224)	lr 0.0002	loss 0.129 (0.135)
Train: [47][30/589]	BT 0.367 (0.508)	DT 0.000 (0.152)	lr 0.0002	loss 0.128 (0.139)
Train: [47][40/589]	BT 0.367 (0.472)	DT 0.000 (0.116)	lr 0.0002	loss 0.127 (0.137)
Train: [47][50/589]	BT 0.356 (0.450)	DT 0.000 (0.094)	lr 0.0002	loss 0.109 (0.136)
Train: [47][60/589]	BT 0.368 (0.437)	DT 0.000 (0.081)	lr 0.0002	loss 0.105 (0.135)
Train: [47][70/589]	BT 0.374 (0.426)	DT 0.000 (0.070)	lr 0.0002	loss 0.123 (0.137)
Train: [47][80/589]	BT 0.356 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.134 (0.136)
Train: [47][90/589]	BT 0.362 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.165 (0.136)
Train: [47][100/589]	BT 0.377 (0.408)	DT 0.000 (0.052)	lr 0.0002	loss 0.147 (0.137)
Train: [47][110/589]	BT 0.364 (0.404)	DT 0.000 (0.048)	lr 0.0002	loss 0.148 (0.137)
Train: [47][120/589]	BT 0.378 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.136)
Train: [47][130/589]	BT 0.356 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.123 (0.136)
Train: [47][140/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.130 (0.136)
Train: [47][150/589]	BT 0.357 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.131 (0.136)
Train: [47][160/589]	BT 0.363 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.120 (0.136)
Train: [47][170/589]	BT 0.360 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.136)
Train: [47][180/589]	BT 0.357 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.125 (0.136)
Train: [47][190/589]	BT 0.358 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.135 (0.135)
Train: [47][200/589]	BT 0.360 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.135)
Train: [47][210/589]	BT 0.361 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.136 (0.135)
Train: [47][220/589]	BT 0.359 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.135)
Train: [47][230/589]	BT 0.359 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.145 (0.135)
Train: [47][240/589]	BT 0.372 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.138 (0.135)
Train: [47][250/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.121 (0.135)
Train: [47][260/589]	BT 0.365 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.135)
Train: [47][270/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.135)
Train: [47][280/589]	BT 0.354 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.151 (0.135)
Train: [47][290/589]	BT 0.366 (0.382)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.135)
Train: [47][300/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.135)
Train: [47][310/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.135)
Train: [47][320/589]	BT 0.356 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.135)
Train: [47][330/589]	BT 0.359 (0.381)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.135)
Train: [47][340/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.135)
Train: [47][350/589]	BT 0.364 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.135)
Train: [47][360/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.125 (0.135)
Train: [47][370/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.142 (0.135)
Train: [47][380/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.135)
Train: [47][390/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.135)
Train: [47][400/589]	BT 0.365 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.135)
Train: [47][410/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.143 (0.135)
Train: [47][420/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.135)
Train: [47][430/589]	BT 0.356 (0.380)	DT 0.001 (0.022)	lr 0.0002	loss 0.116 (0.135)
Train: [47][440/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.138 (0.135)
Train: [47][450/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.149 (0.135)
Train: [47][460/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.156 (0.135)
Train: [47][470/589]	BT 0.360 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.156 (0.135)
Train: [47][480/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.153 (0.135)
Train: [47][490/589]	BT 0.361 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.152 (0.135)
Train: [47][500/589]	BT 0.366 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.135)
Train: [47][510/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.140 (0.135)
Train: [47][520/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.135)
Train: [47][530/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.146 (0.135)
Train: [47][540/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.117 (0.135)
Train: [47][550/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.135)
Train: [47][560/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.135 (0.135)
Train: [47][570/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.119 (0.135)
Train: [47][580/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.158 (0.135)
epoch 47, total time 222.16
loss: 0.13511083034324828@Epoch: 47
learning_rate: 0.0002,47
Valid: [47][10/88]	BT 0.110 (0.547)	DT 0.000 (0.435)	loss 0.168 (0.143)
Valid: [47][20/88]	BT 0.109 (0.490)	DT 0.000 (0.378)	loss 0.148 (0.141)
Valid: [47][30/88]	BT 0.109 (0.466)	DT 0.000 (0.356)	loss 0.150 (0.140)
Valid: [47][40/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.147 (0.140)
Valid: [47][50/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.123 (0.138)
Valid: [47][60/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.117 (0.136)
Valid: [47][70/88]	BT 0.109 (0.433)	DT 0.000 (0.322)	loss 0.132 (0.135)
Valid: [47][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.165 (0.135)
Train: [48][10/589]	BT 0.366 (0.750)	DT 0.000 (0.393)	lr 0.0002	loss 0.141 (0.135)
Train: [48][20/589]	BT 0.367 (0.564)	DT 0.000 (0.208)	lr 0.0002	loss 0.143 (0.133)
Train: [48][30/589]	BT 0.376 (0.501)	DT 0.000 (0.144)	lr 0.0002	loss 0.132 (0.135)
Train: [48][40/589]	BT 0.356 (0.465)	DT 0.000 (0.108)	lr 0.0002	loss 0.122 (0.136)
Train: [48][50/589]	BT 0.371 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.155 (0.136)
Train: [48][60/589]	BT 0.357 (0.432)	DT 0.000 (0.075)	lr 0.0002	loss 0.114 (0.134)
Train: [48][70/589]	BT 0.358 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.124 (0.134)
Train: [48][80/589]	BT 0.358 (0.415)	DT 0.000 (0.058)	lr 0.0002	loss 0.147 (0.134)
Train: [48][90/589]	BT 0.369 (0.408)	DT 0.000 (0.052)	lr 0.0002	loss 0.155 (0.134)
Train: [48][100/589]	BT 0.374 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.143 (0.134)
Train: [48][110/589]	BT 0.357 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.125 (0.134)
Train: [48][120/589]	BT 0.358 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.121 (0.134)
Train: [48][130/589]	BT 0.356 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.111 (0.133)
Train: [48][140/589]	BT 0.363 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.137 (0.134)
Train: [48][150/589]	BT 0.357 (0.389)	DT 0.000 (0.032)	lr 0.0002	loss 0.127 (0.134)
Train: [48][160/589]	BT 0.376 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.135)
Train: [48][170/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.135 (0.135)
Train: [48][180/589]	BT 0.357 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.142 (0.135)
Train: [48][190/589]	BT 0.355 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.151 (0.135)
Train: [48][200/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.136 (0.135)
Train: [48][210/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.151 (0.135)
Train: [48][220/589]	BT 0.356 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.138 (0.135)
Train: [48][230/589]	BT 0.360 (0.383)	DT 0.000 (0.026)	lr 0.0002	loss 0.119 (0.135)
Train: [48][240/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.127 (0.134)
Train: [48][250/589]	BT 0.363 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.134)
Train: [48][260/589]	BT 0.358 (0.382)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.135)
Train: [48][270/589]	BT 0.359 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.158 (0.135)
Train: [48][280/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.135)
Train: [48][290/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.135)
Train: [48][300/589]	BT 0.361 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.145 (0.134)
Train: [48][310/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.135)
Train: [48][320/589]	BT 0.357 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.134)
Train: [48][330/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.134)
Train: [48][340/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.134)
Train: [48][350/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.134)
Train: [48][360/589]	BT 0.357 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.134)
Train: [48][370/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.148 (0.134)
Train: [48][380/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.133 (0.134)
Train: [48][390/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.135)
Train: [48][400/589]	BT 0.359 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.156 (0.134)
Train: [48][410/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.169 (0.135)
Train: [48][420/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.136 (0.135)
Train: [48][430/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.113 (0.135)
Train: [48][440/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.135)
Train: [48][450/589]	BT 0.366 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.134)
Train: [48][460/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.128 (0.134)
Train: [48][470/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.155 (0.135)
Train: [48][480/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.135)
Train: [48][490/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.156 (0.135)
Train: [48][500/589]	BT 0.360 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.135)
Train: [48][510/589]	BT 0.356 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.137 (0.135)
Train: [48][520/589]	BT 0.360 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.123 (0.135)
Train: [48][530/589]	BT 0.366 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.136 (0.135)
Train: [48][540/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.143 (0.135)
Train: [48][550/589]	BT 0.356 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.145 (0.135)
Train: [48][560/589]	BT 0.355 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.132 (0.135)
Train: [48][570/589]	BT 0.374 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.127 (0.135)
Train: [48][580/589]	BT 0.359 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.123 (0.135)
epoch 48, total time 221.22
loss: 0.13491530393196666@Epoch: 48
learning_rate: 0.0002,48
Valid: [48][10/88]	BT 0.110 (0.570)	DT 0.000 (0.458)	loss 0.127 (0.129)
Valid: [48][20/88]	BT 0.109 (0.500)	DT 0.000 (0.388)	loss 0.142 (0.140)
Valid: [48][30/88]	BT 0.109 (0.471)	DT 0.000 (0.360)	loss 0.154 (0.140)
Valid: [48][40/88]	BT 0.110 (0.453)	DT 0.000 (0.342)	loss 0.126 (0.138)
Valid: [48][50/88]	BT 0.110 (0.440)	DT 0.000 (0.329)	loss 0.135 (0.138)
Valid: [48][60/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.117 (0.138)
Valid: [48][70/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.151 (0.138)
Valid: [48][80/88]	BT 0.109 (0.432)	DT 0.000 (0.321)	loss 0.141 (0.138)
Train: [49][10/589]	BT 0.360 (0.746)	DT 0.000 (0.390)	lr 0.0002	loss 0.114 (0.130)
Train: [49][20/589]	BT 0.365 (0.566)	DT 0.000 (0.210)	lr 0.0002	loss 0.110 (0.135)
Train: [49][30/589]	BT 0.355 (0.503)	DT 0.000 (0.147)	lr 0.0002	loss 0.144 (0.134)
Train: [49][40/589]	BT 0.358 (0.469)	DT 0.000 (0.113)	lr 0.0002	loss 0.144 (0.137)
Train: [49][50/589]	BT 0.371 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.136 (0.136)
Train: [49][60/589]	BT 0.357 (0.434)	DT 0.000 (0.078)	lr 0.0002	loss 0.131 (0.135)
Train: [49][70/589]	BT 0.355 (0.426)	DT 0.000 (0.070)	lr 0.0002	loss 0.147 (0.135)
Train: [49][80/589]	BT 0.356 (0.418)	DT 0.000 (0.062)	lr 0.0002	loss 0.139 (0.135)
Train: [49][90/589]	BT 0.384 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.116 (0.135)
Train: [49][100/589]	BT 0.361 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.165 (0.136)
Train: [49][110/589]	BT 0.360 (0.407)	DT 0.000 (0.050)	lr 0.0002	loss 0.115 (0.136)
Train: [49][120/589]	BT 0.376 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.117 (0.135)
Train: [49][130/589]	BT 0.355 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.146 (0.135)
Train: [49][140/589]	BT 0.356 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.123 (0.135)
Train: [49][150/589]	BT 0.367 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.128 (0.135)
Train: [49][160/589]	BT 0.360 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.127 (0.135)
Train: [49][170/589]	BT 0.357 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.131 (0.135)
Train: [49][180/589]	BT 0.372 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.097 (0.134)
Train: [49][190/589]	BT 0.369 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.142 (0.134)
Train: [49][200/589]	BT 0.357 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.151 (0.135)
Train: [49][210/589]	BT 0.357 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.141 (0.135)
Train: [49][220/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.117 (0.135)
Train: [49][230/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.136 (0.135)
Train: [49][240/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.156 (0.135)
Train: [49][250/589]	BT 0.356 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.120 (0.135)
Train: [49][260/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.135)
Train: [49][270/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.129 (0.135)
Train: [49][280/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.151 (0.135)
Train: [49][290/589]	BT 0.363 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.147 (0.135)
Train: [49][300/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.128 (0.135)
Train: [49][310/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.137 (0.135)
Train: [49][320/589]	BT 0.359 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.135)
Train: [49][330/589]	BT 0.358 (0.382)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.135)
Train: [49][340/589]	BT 0.359 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.135)
Train: [49][350/589]	BT 0.360 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.135)
Train: [49][360/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.143 (0.135)
Train: [49][370/589]	BT 0.376 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.114 (0.135)
Train: [49][380/589]	BT 0.358 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.135)
Train: [49][390/589]	BT 0.374 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.135)
Train: [49][400/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.135)
Train: [49][410/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.153 (0.135)
Train: [49][420/589]	BT 0.355 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.133 (0.135)
Train: [49][430/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.134)
Train: [49][440/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.134)
Train: [49][450/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.134)
Train: [49][460/589]	BT 0.375 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.134)
Train: [49][470/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.148 (0.135)
Train: [49][480/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.139 (0.135)
Train: [49][490/589]	BT 0.355 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.136 (0.134)
Train: [49][500/589]	BT 0.356 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.109 (0.134)
Train: [49][510/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.116 (0.134)
Train: [49][520/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.131 (0.134)
Train: [49][530/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.151 (0.135)
Train: [49][540/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.156 (0.135)
Train: [49][550/589]	BT 0.355 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.118 (0.135)
Train: [49][560/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.142 (0.135)
Train: [49][570/589]	BT 0.358 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.135)
Train: [49][580/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.135)
epoch 49, total time 222.96
loss: 0.13477753403841727@Epoch: 49
learning_rate: 0.0002,49
Valid: [49][10/88]	BT 0.109 (0.561)	DT 0.000 (0.451)	loss 0.151 (0.136)
Valid: [49][20/88]	BT 0.109 (0.476)	DT 0.000 (0.366)	loss 0.142 (0.137)
Valid: [49][30/88]	BT 0.109 (0.451)	DT 0.000 (0.340)	loss 0.115 (0.137)
Valid: [49][40/88]	BT 0.110 (0.440)	DT 0.000 (0.330)	loss 0.139 (0.135)
Valid: [49][50/88]	BT 0.110 (0.435)	DT 0.000 (0.325)	loss 0.149 (0.136)
Valid: [49][60/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.126 (0.135)
Valid: [49][70/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.120 (0.135)
Valid: [49][80/88]	BT 0.109 (0.426)	DT 0.000 (0.316)	loss 0.147 (0.134)
Train: [50][10/589]	BT 0.357 (0.758)	DT 0.000 (0.403)	lr 0.0002	loss 0.131 (0.129)
Train: [50][20/589]	BT 0.356 (0.569)	DT 0.000 (0.212)	lr 0.0002	loss 0.128 (0.135)
Train: [50][30/589]	BT 0.356 (0.503)	DT 0.000 (0.147)	lr 0.0002	loss 0.138 (0.132)
Train: [50][40/589]	BT 0.369 (0.472)	DT 0.000 (0.115)	lr 0.0002	loss 0.132 (0.131)
Train: [50][50/589]	BT 0.357 (0.450)	DT 0.000 (0.094)	lr 0.0002	loss 0.131 (0.132)
Train: [50][60/589]	BT 0.360 (0.439)	DT 0.000 (0.082)	lr 0.0002	loss 0.138 (0.132)
Train: [50][70/589]	BT 0.356 (0.429)	DT 0.000 (0.073)	lr 0.0002	loss 0.137 (0.132)
Train: [50][80/589]	BT 0.383 (0.421)	DT 0.000 (0.065)	lr 0.0002	loss 0.132 (0.132)
Train: [50][90/589]	BT 0.383 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.137 (0.133)
Train: [50][100/589]	BT 0.359 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.127 (0.133)
Train: [50][110/589]	BT 0.368 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.143 (0.134)
Train: [50][120/589]	BT 0.357 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.144 (0.134)
Train: [50][130/589]	BT 0.363 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.112 (0.134)
Train: [50][140/589]	BT 0.360 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.150 (0.135)
Train: [50][150/589]	BT 0.357 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.132 (0.134)
Train: [50][160/589]	BT 0.358 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.146 (0.135)
Train: [50][170/589]	BT 0.355 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.156 (0.135)
Train: [50][180/589]	BT 0.362 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.128 (0.134)
Train: [50][190/589]	BT 0.392 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.159 (0.134)
Train: [50][200/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.140 (0.135)
Train: [50][210/589]	BT 0.358 (0.392)	DT 0.000 (0.035)	lr 0.0002	loss 0.138 (0.135)
Train: [50][220/589]	BT 0.377 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.122 (0.135)
Train: [50][230/589]	BT 0.375 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.147 (0.135)
Train: [50][240/589]	BT 0.357 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.152 (0.135)
Train: [50][250/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.104 (0.135)
Train: [50][260/589]	BT 0.360 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.142 (0.135)
Train: [50][270/589]	BT 0.368 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.135)
Train: [50][280/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.140 (0.135)
Train: [50][290/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.135)
Train: [50][300/589]	BT 0.354 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.135)
Train: [50][310/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.126 (0.134)
Train: [50][320/589]	BT 0.355 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.158 (0.135)
Train: [50][330/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.135)
Train: [50][340/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.135)
Train: [50][350/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.135)
Train: [50][360/589]	BT 0.369 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.179 (0.135)
Train: [50][370/589]	BT 0.356 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.109 (0.135)
Train: [50][380/589]	BT 0.377 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.134)
Train: [50][390/589]	BT 0.359 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.146 (0.135)
Train: [50][400/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.134)
Train: [50][410/589]	BT 0.356 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.163 (0.134)
Train: [50][420/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.106 (0.134)
Train: [50][430/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.135)
Train: [50][440/589]	BT 0.358 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.146 (0.135)
Train: [50][450/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.114 (0.135)
Train: [50][460/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.151 (0.135)
Train: [50][470/589]	BT 0.361 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.128 (0.135)
Train: [50][480/589]	BT 0.365 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.135)
Train: [50][490/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.116 (0.134)
Train: [50][500/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.112 (0.134)
Train: [50][510/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.141 (0.134)
Train: [50][520/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.147 (0.134)
Train: [50][530/589]	BT 0.364 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.141 (0.134)
Train: [50][540/589]	BT 0.357 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.134)
Train: [50][550/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.134)
Train: [50][560/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.134)
Train: [50][570/589]	BT 0.358 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.143 (0.134)
Train: [50][580/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.134)
epoch 50, total time 222.53
loss: 0.13436094541217405@Epoch: 50
learning_rate: 0.0002,50
Valid: [50][10/88]	BT 0.110 (0.567)	DT 0.000 (0.456)	loss 0.153 (0.138)
Valid: [50][20/88]	BT 0.109 (0.486)	DT 0.000 (0.376)	loss 0.158 (0.135)
Valid: [50][30/88]	BT 0.109 (0.464)	DT 0.000 (0.354)	loss 0.132 (0.133)
Valid: [50][40/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.143 (0.132)
Valid: [50][50/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.134 (0.132)
Valid: [50][60/88]	BT 0.109 (0.438)	DT 0.000 (0.329)	loss 0.141 (0.134)
Valid: [50][70/88]	BT 0.109 (0.434)	DT 0.000 (0.325)	loss 0.143 (0.134)
Valid: [50][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.151 (0.134)
Train: [51][10/589]	BT 0.358 (0.745)	DT 0.000 (0.389)	lr 0.0002	loss 0.151 (0.136)
Train: [51][20/589]	BT 0.361 (0.562)	DT 0.000 (0.205)	lr 0.0002	loss 0.142 (0.134)
Train: [51][30/589]	BT 0.356 (0.498)	DT 0.000 (0.141)	lr 0.0002	loss 0.127 (0.134)
Train: [51][40/589]	BT 0.358 (0.467)	DT 0.000 (0.110)	lr 0.0002	loss 0.144 (0.134)
Train: [51][50/589]	BT 0.356 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.144 (0.134)
Train: [51][60/589]	BT 0.374 (0.434)	DT 0.000 (0.077)	lr 0.0002	loss 0.113 (0.133)
Train: [51][70/589]	BT 0.377 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.149 (0.134)
Train: [51][80/589]	BT 0.370 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.154 (0.133)
Train: [51][90/589]	BT 0.358 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.140 (0.133)
Train: [51][100/589]	BT 0.362 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.156 (0.133)
Train: [51][110/589]	BT 0.358 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.112 (0.133)
Train: [51][120/589]	BT 0.366 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.124 (0.133)
Train: [51][130/589]	BT 0.365 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.132)
Train: [51][140/589]	BT 0.371 (0.395)	DT 0.000 (0.038)	lr 0.0002	loss 0.125 (0.132)
Train: [51][150/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.145 (0.133)
Train: [51][160/589]	BT 0.358 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.133)
Train: [51][170/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.126 (0.133)
Train: [51][180/589]	BT 0.359 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.137 (0.133)
Train: [51][190/589]	BT 0.362 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.133)
Train: [51][200/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.134)
Train: [51][210/589]	BT 0.358 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.141 (0.134)
Train: [51][220/589]	BT 0.357 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.160 (0.134)
Train: [51][230/589]	BT 0.358 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.132 (0.134)
Train: [51][240/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.134)
Train: [51][250/589]	BT 0.360 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.134)
Train: [51][260/589]	BT 0.354 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.162 (0.135)
Train: [51][270/589]	BT 0.355 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.153 (0.135)
Train: [51][280/589]	BT 0.357 (0.379)	DT 0.000 (0.022)	lr 0.0002	loss 0.150 (0.135)
Train: [51][290/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.153 (0.135)
Train: [51][300/589]	BT 0.382 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.135)
Train: [51][310/589]	BT 0.387 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.135)
Train: [51][320/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.125 (0.134)
Train: [51][330/589]	BT 0.367 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.173 (0.135)
Train: [51][340/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.135)
Train: [51][350/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.126 (0.135)
Train: [51][360/589]	BT 0.382 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.118 (0.135)
Train: [51][370/589]	BT 0.368 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.122 (0.135)
Train: [51][380/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.131 (0.135)
Train: [51][390/589]	BT 0.359 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.110 (0.135)
Train: [51][400/589]	BT 0.355 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.161 (0.135)
Train: [51][410/589]	BT 0.356 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.122 (0.135)
Train: [51][420/589]	BT 0.360 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.128 (0.135)
Train: [51][430/589]	BT 0.355 (0.375)	DT 0.000 (0.016)	lr 0.0002	loss 0.135 (0.135)
Train: [51][440/589]	BT 0.359 (0.374)	DT 0.000 (0.016)	lr 0.0002	loss 0.127 (0.135)
Train: [51][450/589]	BT 0.367 (0.374)	DT 0.000 (0.015)	lr 0.0002	loss 0.160 (0.135)
Train: [51][460/589]	BT 0.358 (0.374)	DT 0.000 (0.015)	lr 0.0002	loss 0.146 (0.135)
Train: [51][470/589]	BT 0.356 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.143 (0.135)
Train: [51][480/589]	BT 0.375 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.135 (0.135)
Train: [51][490/589]	BT 0.362 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.129 (0.135)
Train: [51][500/589]	BT 0.360 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.171 (0.135)
Train: [51][510/589]	BT 0.366 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.147 (0.135)
Train: [51][520/589]	BT 0.360 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.121 (0.134)
Train: [51][530/589]	BT 0.361 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.142 (0.135)
Train: [51][540/589]	BT 0.365 (0.373)	DT 0.000 (0.015)	lr 0.0002	loss 0.113 (0.134)
Train: [51][550/589]	BT 0.358 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.098 (0.134)
Train: [51][560/589]	BT 0.362 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.136 (0.134)
Train: [51][570/589]	BT 0.357 (0.372)	DT 0.000 (0.014)	lr 0.0002	loss 0.158 (0.134)
Train: [51][580/589]	BT 0.356 (0.373)	DT 0.000 (0.014)	lr 0.0002	loss 0.139 (0.134)
epoch 51, total time 219.22
loss: 0.13427718479161763@Epoch: 51
learning_rate: 0.0002,51
Valid: [51][10/88]	BT 0.109 (0.543)	DT 0.000 (0.432)	loss 0.132 (0.138)
Valid: [51][20/88]	BT 0.110 (0.472)	DT 0.000 (0.362)	loss 0.136 (0.133)
Valid: [51][30/88]	BT 0.110 (0.451)	DT 0.000 (0.341)	loss 0.124 (0.132)
Valid: [51][40/88]	BT 0.109 (0.440)	DT 0.000 (0.329)	loss 0.124 (0.132)
Valid: [51][50/88]	BT 0.110 (0.434)	DT 0.000 (0.323)	loss 0.145 (0.134)
Valid: [51][60/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.160 (0.135)
Valid: [51][70/88]	BT 0.226 (0.427)	DT 0.117 (0.317)	loss 0.155 (0.135)
Valid: [51][80/88]	BT 0.206 (0.422)	DT 0.097 (0.312)	loss 0.143 (0.134)
Train: [52][10/589]	BT 0.387 (0.749)	DT 0.000 (0.390)	lr 0.0002	loss 0.133 (0.130)
Train: [52][20/589]	BT 0.356 (0.562)	DT 0.000 (0.205)	lr 0.0002	loss 0.125 (0.133)
Train: [52][30/589]	BT 0.356 (0.497)	DT 0.000 (0.141)	lr 0.0002	loss 0.116 (0.133)
Train: [52][40/589]	BT 0.357 (0.467)	DT 0.000 (0.111)	lr 0.0002	loss 0.118 (0.132)
Train: [52][50/589]	BT 0.355 (0.445)	DT 0.000 (0.089)	lr 0.0002	loss 0.160 (0.133)
Train: [52][60/589]	BT 0.356 (0.431)	DT 0.000 (0.074)	lr 0.0002	loss 0.132 (0.132)
Train: [52][70/589]	BT 0.358 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.127 (0.132)
Train: [52][80/589]	BT 0.359 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.137 (0.132)
Train: [52][90/589]	BT 0.356 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.128 (0.132)
Train: [52][100/589]	BT 0.357 (0.405)	DT 0.000 (0.048)	lr 0.0002	loss 0.161 (0.133)
Train: [52][110/589]	BT 0.358 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.147 (0.133)
Train: [52][120/589]	BT 0.358 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.127 (0.133)
Train: [52][130/589]	BT 0.361 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.116 (0.133)
Train: [52][140/589]	BT 0.361 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.116 (0.133)
Train: [52][150/589]	BT 0.356 (0.392)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.133)
Train: [52][160/589]	BT 0.358 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.144 (0.133)
Train: [52][170/589]	BT 0.354 (0.389)	DT 0.000 (0.032)	lr 0.0002	loss 0.146 (0.133)
Train: [52][180/589]	BT 0.360 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.133)
Train: [52][190/589]	BT 0.360 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.134)
Train: [52][200/589]	BT 0.360 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.133)
Train: [52][210/589]	BT 0.367 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.121 (0.133)
Train: [52][220/589]	BT 0.358 (0.385)	DT 0.000 (0.027)	lr 0.0002	loss 0.122 (0.134)
Train: [52][230/589]	BT 0.364 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.158 (0.133)
Train: [52][240/589]	BT 0.372 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.129 (0.133)
Train: [52][250/589]	BT 0.367 (0.384)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.134)
Train: [52][260/589]	BT 0.357 (0.383)	DT 0.000 (0.025)	lr 0.0002	loss 0.157 (0.134)
Train: [52][270/589]	BT 0.356 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.134)
Train: [52][280/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.110 (0.134)
Train: [52][290/589]	BT 0.357 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.134 (0.134)
Train: [52][300/589]	BT 0.359 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.134)
Train: [52][310/589]	BT 0.355 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.150 (0.134)
Train: [52][320/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.143 (0.134)
Train: [52][330/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.147 (0.134)
Train: [52][340/589]	BT 0.355 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.131 (0.134)
Train: [52][350/589]	BT 0.365 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.116 (0.134)
Train: [52][360/589]	BT 0.357 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.134)
Train: [52][370/589]	BT 0.356 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.117 (0.134)
Train: [52][380/589]	BT 0.360 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.146 (0.134)
Train: [52][390/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.134)
Train: [52][400/589]	BT 0.364 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.134)
Train: [52][410/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.142 (0.134)
Train: [52][420/589]	BT 0.379 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.110 (0.134)
Train: [52][430/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.154 (0.134)
Train: [52][440/589]	BT 0.362 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.149 (0.134)
Train: [52][450/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.106 (0.134)
Train: [52][460/589]	BT 0.363 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.141 (0.134)
Train: [52][470/589]	BT 0.356 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.142 (0.134)
Train: [52][480/589]	BT 0.359 (0.377)	DT 0.000 (0.018)	lr 0.0002	loss 0.133 (0.134)
Train: [52][490/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.134)
Train: [52][500/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.139 (0.133)
Train: [52][510/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.134)
Train: [52][520/589]	BT 0.366 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.134)
Train: [52][530/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.134)
Train: [52][540/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.134)
Train: [52][550/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.122 (0.134)
Train: [52][560/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.134)
Train: [52][570/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.135 (0.134)
Train: [52][580/589]	BT 0.367 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.163 (0.134)
epoch 52, total time 221.77
loss: 0.13392752734419897@Epoch: 52
learning_rate: 0.0002,52
Valid: [52][10/88]	BT 0.110 (0.540)	DT 0.000 (0.427)	loss 0.119 (0.139)
Valid: [52][20/88]	BT 0.109 (0.471)	DT 0.000 (0.359)	loss 0.131 (0.139)
Valid: [52][30/88]	BT 0.109 (0.458)	DT 0.000 (0.347)	loss 0.138 (0.138)
Valid: [52][40/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.122 (0.138)
Valid: [52][50/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.147 (0.136)
Valid: [52][60/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.124 (0.137)
Valid: [52][70/88]	BT 0.109 (0.428)	DT 0.000 (0.318)	loss 0.127 (0.137)
Valid: [52][80/88]	BT 0.109 (0.422)	DT 0.000 (0.312)	loss 0.145 (0.138)
Train: [53][10/589]	BT 0.362 (0.737)	DT 0.000 (0.381)	lr 0.0002	loss 0.117 (0.124)
Train: [53][20/589]	BT 0.356 (0.553)	DT 0.000 (0.196)	lr 0.0002	loss 0.156 (0.130)
Train: [53][30/589]	BT 0.358 (0.498)	DT 0.000 (0.141)	lr 0.0002	loss 0.130 (0.131)
Train: [53][40/589]	BT 0.354 (0.479)	DT 0.000 (0.122)	lr 0.0002	loss 0.135 (0.130)
Train: [53][50/589]	BT 0.370 (0.459)	DT 0.000 (0.102)	lr 0.0002	loss 0.141 (0.130)
Train: [53][60/589]	BT 0.362 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.115 (0.130)
Train: [53][70/589]	BT 0.359 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.141 (0.130)
Train: [53][80/589]	BT 0.358 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.119 (0.131)
Train: [53][90/589]	BT 0.369 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.120 (0.131)
Train: [53][100/589]	BT 0.356 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.136 (0.131)
Train: [53][110/589]	BT 0.369 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.115 (0.131)
Train: [53][120/589]	BT 0.357 (0.409)	DT 0.000 (0.052)	lr 0.0002	loss 0.131 (0.131)
Train: [53][130/589]	BT 0.358 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.133 (0.131)
Train: [53][140/589]	BT 0.365 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.135 (0.132)
Train: [53][150/589]	BT 0.356 (0.402)	DT 0.000 (0.045)	lr 0.0002	loss 0.135 (0.132)
Train: [53][160/589]	BT 0.358 (0.406)	DT 0.000 (0.049)	lr 0.0002	loss 0.128 (0.132)
Train: [53][170/589]	BT 0.355 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.144 (0.132)
Train: [53][180/589]	BT 0.356 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.140 (0.132)
Train: [53][190/589]	BT 0.357 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.160 (0.132)
Train: [53][200/589]	BT 0.357 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.155 (0.132)
Train: [53][210/589]	BT 0.360 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.166 (0.132)
Train: [53][220/589]	BT 0.358 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.134 (0.133)
Train: [53][230/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.123 (0.133)
Train: [53][240/589]	BT 0.357 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.133)
Train: [53][250/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.143 (0.133)
Train: [53][260/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.114 (0.133)
Train: [53][270/589]	BT 0.356 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.152 (0.133)
Train: [53][280/589]	BT 0.359 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.119 (0.133)
Train: [53][290/589]	BT 0.377 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.141 (0.133)
Train: [53][300/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.121 (0.133)
Train: [53][310/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.135 (0.133)
Train: [53][320/589]	BT 0.359 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.137 (0.133)
Train: [53][330/589]	BT 0.358 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.133)
Train: [53][340/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.150 (0.133)
Train: [53][350/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.137 (0.133)
Train: [53][360/589]	BT 0.356 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.133)
Train: [53][370/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.133)
Train: [53][380/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.158 (0.133)
Train: [53][390/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.133)
Train: [53][400/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.133)
Train: [53][410/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.141 (0.133)
Train: [53][420/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.146 (0.133)
Train: [53][430/589]	BT 0.356 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.133)
Train: [53][440/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.118 (0.133)
Train: [53][450/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.149 (0.134)
Train: [53][460/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.133)
Train: [53][470/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.147 (0.133)
Train: [53][480/589]	BT 0.356 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.141 (0.134)
Train: [53][490/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.144 (0.134)
Train: [53][500/589]	BT 0.356 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.123 (0.134)
Train: [53][510/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.134)
Train: [53][520/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.159 (0.134)
Train: [53][530/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.143 (0.134)
Train: [53][540/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.134)
Train: [53][550/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.127 (0.134)
Train: [53][560/589]	BT 0.357 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.125 (0.133)
Train: [53][570/589]	BT 0.359 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.141 (0.134)
Train: [53][580/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.132 (0.134)
epoch 53, total time 227.31
loss: 0.1336436645352007@Epoch: 53
learning_rate: 0.0002,53
Valid: [53][10/88]	BT 0.109 (0.623)	DT 0.000 (0.512)	loss 0.180 (0.136)
Valid: [53][20/88]	BT 0.109 (0.569)	DT 0.000 (0.459)	loss 0.144 (0.134)
Valid: [53][30/88]	BT 0.109 (0.542)	DT 0.000 (0.432)	loss 0.115 (0.134)
Valid: [53][40/88]	BT 0.109 (0.530)	DT 0.000 (0.420)	loss 0.129 (0.135)
Valid: [53][50/88]	BT 0.109 (0.527)	DT 0.000 (0.418)	loss 0.121 (0.133)
Valid: [53][60/88]	BT 0.109 (0.521)	DT 0.000 (0.411)	loss 0.142 (0.134)
Valid: [53][70/88]	BT 0.109 (0.515)	DT 0.000 (0.405)	loss 0.127 (0.134)
Valid: [53][80/88]	BT 0.109 (0.505)	DT 0.000 (0.395)	loss 0.142 (0.136)
Train: [54][10/589]	BT 0.356 (0.826)	DT 0.000 (0.471)	lr 0.0002	loss 0.120 (0.135)
Train: [54][20/589]	BT 0.356 (0.612)	DT 0.000 (0.257)	lr 0.0002	loss 0.147 (0.136)
Train: [54][30/589]	BT 0.355 (0.543)	DT 0.000 (0.187)	lr 0.0002	loss 0.128 (0.134)
Train: [54][40/589]	BT 0.356 (0.514)	DT 0.000 (0.158)	lr 0.0002	loss 0.122 (0.134)
Train: [54][50/589]	BT 0.357 (0.493)	DT 0.000 (0.137)	lr 0.0002	loss 0.146 (0.134)
Train: [54][60/589]	BT 0.358 (0.480)	DT 0.000 (0.124)	lr 0.0002	loss 0.139 (0.133)
Train: [54][70/589]	BT 0.352 (0.474)	DT 0.000 (0.117)	lr 0.0002	loss 0.150 (0.133)
Train: [54][80/589]	BT 0.364 (0.468)	DT 0.000 (0.112)	lr 0.0002	loss 0.123 (0.132)
Train: [54][90/589]	BT 0.358 (0.460)	DT 0.000 (0.104)	lr 0.0002	loss 0.116 (0.132)
Train: [54][100/589]	BT 0.356 (0.457)	DT 0.000 (0.101)	lr 0.0002	loss 0.129 (0.133)
Train: [54][110/589]	BT 0.355 (0.452)	DT 0.000 (0.096)	lr 0.0002	loss 0.138 (0.132)
Train: [54][120/589]	BT 0.355 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.120 (0.133)
Train: [54][130/589]	BT 0.357 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.137 (0.133)
Train: [54][140/589]	BT 0.355 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.130 (0.133)
Train: [54][150/589]	BT 0.357 (0.454)	DT 0.000 (0.097)	lr 0.0002	loss 0.120 (0.132)
Train: [54][160/589]	BT 0.355 (0.453)	DT 0.000 (0.096)	lr 0.0002	loss 0.151 (0.133)
Train: [54][170/589]	BT 0.356 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.128 (0.133)
Train: [54][180/589]	BT 0.357 (0.449)	DT 0.000 (0.093)	lr 0.0002	loss 0.147 (0.133)
Train: [54][190/589]	BT 0.359 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.117 (0.133)
Train: [54][200/589]	BT 0.356 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.153 (0.133)
Train: [54][210/589]	BT 0.357 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.134 (0.133)
Train: [54][220/589]	BT 0.358 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.134 (0.133)
Train: [54][230/589]	BT 0.356 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.127 (0.133)
Train: [54][240/589]	BT 0.357 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.138 (0.133)
Train: [54][250/589]	BT 0.359 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.155 (0.133)
Train: [54][260/589]	BT 0.356 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.123 (0.133)
Train: [54][270/589]	BT 0.357 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.113 (0.133)
Train: [54][280/589]	BT 0.357 (0.448)	DT 0.000 (0.092)	lr 0.0002	loss 0.134 (0.134)
Train: [54][290/589]	BT 0.358 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.139 (0.134)
Train: [54][300/589]	BT 0.358 (0.446)	DT 0.000 (0.090)	lr 0.0002	loss 0.119 (0.134)
Train: [54][310/589]	BT 0.356 (0.445)	DT 0.000 (0.088)	lr 0.0002	loss 0.145 (0.134)
Train: [54][320/589]	BT 0.358 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.128 (0.134)
Train: [54][330/589]	BT 0.358 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.141 (0.134)
Train: [54][340/589]	BT 0.357 (0.443)	DT 0.000 (0.086)	lr 0.0002	loss 0.119 (0.134)
Train: [54][350/589]	BT 0.356 (0.443)	DT 0.000 (0.086)	lr 0.0002	loss 0.119 (0.134)
Train: [54][360/589]	BT 0.357 (0.443)	DT 0.000 (0.087)	lr 0.0002	loss 0.111 (0.134)
Train: [54][370/589]	BT 0.362 (0.443)	DT 0.000 (0.087)	lr 0.0002	loss 0.124 (0.134)
Train: [54][380/589]	BT 0.357 (0.442)	DT 0.000 (0.085)	lr 0.0002	loss 0.137 (0.134)
Train: [54][390/589]	BT 0.356 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.126 (0.134)
Train: [54][400/589]	BT 0.358 (0.439)	DT 0.000 (0.083)	lr 0.0002	loss 0.157 (0.134)
Train: [54][410/589]	BT 0.357 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.135 (0.134)
Train: [54][420/589]	BT 0.355 (0.440)	DT 0.000 (0.083)	lr 0.0002	loss 0.149 (0.134)
Train: [54][430/589]	BT 0.356 (0.439)	DT 0.000 (0.082)	lr 0.0002	loss 0.166 (0.134)
Train: [54][440/589]	BT 0.357 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.139 (0.134)
Train: [54][450/589]	BT 0.358 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.120 (0.134)
Train: [54][460/589]	BT 0.356 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.136 (0.134)
Train: [54][470/589]	BT 0.357 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.116 (0.134)
Train: [54][480/589]	BT 0.359 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.124 (0.134)
Train: [54][490/589]	BT 0.361 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.149 (0.134)
Train: [54][500/589]	BT 0.357 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.140 (0.134)
Train: [54][510/589]	BT 0.357 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.128 (0.134)
Train: [54][520/589]	BT 0.355 (0.438)	DT 0.000 (0.081)	lr 0.0002	loss 0.127 (0.134)
Train: [54][530/589]	BT 0.356 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.165 (0.134)
Train: [54][540/589]	BT 0.359 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.110 (0.134)
Train: [54][550/589]	BT 0.356 (0.436)	DT 0.000 (0.080)	lr 0.0002	loss 0.150 (0.134)
Train: [54][560/589]	BT 0.356 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.128 (0.134)
Train: [54][570/589]	BT 0.357 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.134 (0.134)
Train: [54][580/589]	BT 0.356 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.130 (0.134)
epoch 54, total time 256.68
loss: 0.13357296246352254@Epoch: 54
learning_rate: 0.0002,54
Valid: [54][10/88]	BT 0.109 (0.533)	DT 0.000 (0.420)	loss 0.126 (0.137)
Valid: [54][20/88]	BT 0.110 (0.487)	DT 0.000 (0.376)	loss 0.126 (0.134)
Valid: [54][30/88]	BT 0.109 (0.463)	DT 0.000 (0.352)	loss 0.160 (0.136)
Valid: [54][40/88]	BT 0.113 (0.458)	DT 0.000 (0.348)	loss 0.124 (0.135)
Valid: [54][50/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.114 (0.134)
Valid: [54][60/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.131 (0.134)
Valid: [54][70/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.126 (0.133)
Valid: [54][80/88]	BT 0.110 (0.435)	DT 0.000 (0.324)	loss 0.127 (0.134)
Epoch 0054: val_loss improved from 0.13370 to 0.13362, saving model
==> Saving...
Train: [55][10/589]	BT 0.355 (0.768)	DT 0.000 (0.412)	lr 0.0002	loss 0.126 (0.131)
Train: [55][20/589]	BT 0.357 (0.575)	DT 0.000 (0.219)	lr 0.0002	loss 0.123 (0.132)
Train: [55][30/589]	BT 0.356 (0.504)	DT 0.000 (0.148)	lr 0.0002	loss 0.148 (0.133)
Train: [55][40/589]	BT 0.364 (0.471)	DT 0.000 (0.115)	lr 0.0002	loss 0.138 (0.134)
Train: [55][50/589]	BT 0.378 (0.449)	DT 0.000 (0.092)	lr 0.0002	loss 0.133 (0.135)
Train: [55][60/589]	BT 0.358 (0.433)	DT 0.000 (0.077)	lr 0.0002	loss 0.128 (0.134)
Train: [55][70/589]	BT 0.355 (0.422)	DT 0.000 (0.066)	lr 0.0002	loss 0.145 (0.134)
Train: [55][80/589]	BT 0.356 (0.416)	DT 0.000 (0.060)	lr 0.0002	loss 0.143 (0.134)
Train: [55][90/589]	BT 0.356 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.150 (0.134)
Train: [55][100/589]	BT 0.357 (0.404)	DT 0.000 (0.048)	lr 0.0002	loss 0.137 (0.136)
Train: [55][110/589]	BT 0.356 (0.401)	DT 0.000 (0.045)	lr 0.0002	loss 0.137 (0.135)
Train: [55][120/589]	BT 0.357 (0.398)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.135)
Train: [55][130/589]	BT 0.355 (0.396)	DT 0.000 (0.039)	lr 0.0002	loss 0.119 (0.135)
Train: [55][140/589]	BT 0.355 (0.394)	DT 0.000 (0.037)	lr 0.0002	loss 0.136 (0.135)
Train: [55][150/589]	BT 0.358 (0.392)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.135)
Train: [55][160/589]	BT 0.358 (0.391)	DT 0.000 (0.034)	lr 0.0002	loss 0.105 (0.134)
Train: [55][170/589]	BT 0.358 (0.390)	DT 0.000 (0.033)	lr 0.0002	loss 0.116 (0.134)
Train: [55][180/589]	BT 0.357 (0.389)	DT 0.000 (0.032)	lr 0.0002	loss 0.132 (0.134)
Train: [55][190/589]	BT 0.357 (0.388)	DT 0.000 (0.031)	lr 0.0002	loss 0.153 (0.134)
Train: [55][200/589]	BT 0.357 (0.387)	DT 0.000 (0.030)	lr 0.0002	loss 0.172 (0.134)
Train: [55][210/589]	BT 0.358 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.108 (0.134)
Train: [55][220/589]	BT 0.358 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.150 (0.133)
Train: [55][230/589]	BT 0.357 (0.386)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.133)
Train: [55][240/589]	BT 0.374 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.114 (0.133)
Train: [55][250/589]	BT 0.367 (0.385)	DT 0.000 (0.028)	lr 0.0002	loss 0.120 (0.132)
Train: [55][260/589]	BT 0.355 (0.384)	DT 0.001 (0.027)	lr 0.0002	loss 0.122 (0.133)
Train: [55][270/589]	BT 0.355 (0.383)	DT 0.000 (0.026)	lr 0.0002	loss 0.113 (0.133)
Train: [55][280/589]	BT 0.386 (0.382)	DT 0.000 (0.025)	lr 0.0002	loss 0.103 (0.133)
Train: [55][290/589]	BT 0.358 (0.382)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.133)
Train: [55][300/589]	BT 0.357 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.125 (0.133)
Train: [55][310/589]	BT 0.356 (0.381)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.133)
Train: [55][320/589]	BT 0.359 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.133)
Train: [55][330/589]	BT 0.358 (0.380)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.133)
Train: [55][340/589]	BT 0.356 (0.379)	DT 0.000 (0.022)	lr 0.0002	loss 0.122 (0.133)
Train: [55][350/589]	BT 0.359 (0.379)	DT 0.000 (0.021)	lr 0.0002	loss 0.150 (0.133)
Train: [55][360/589]	BT 0.370 (0.378)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.133)
Train: [55][370/589]	BT 0.354 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.132)
Train: [55][380/589]	BT 0.357 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.162 (0.133)
Train: [55][390/589]	BT 0.356 (0.378)	DT 0.000 (0.020)	lr 0.0002	loss 0.109 (0.133)
Train: [55][400/589]	BT 0.364 (0.377)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.133)
Train: [55][410/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.133)
Train: [55][420/589]	BT 0.357 (0.377)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.133)
Train: [55][430/589]	BT 0.356 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.128 (0.133)
Train: [55][440/589]	BT 0.357 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.133)
Train: [55][450/589]	BT 0.355 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.173 (0.133)
Train: [55][460/589]	BT 0.359 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.129 (0.133)
Train: [55][470/589]	BT 0.358 (0.377)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.133)
Train: [55][480/589]	BT 0.356 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.143 (0.133)
Train: [55][490/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.135 (0.133)
Train: [55][500/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.161 (0.133)
Train: [55][510/589]	BT 0.360 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.140 (0.133)
Train: [55][520/589]	BT 0.359 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.151 (0.134)
Train: [55][530/589]	BT 0.357 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.120 (0.133)
Train: [55][540/589]	BT 0.358 (0.376)	DT 0.000 (0.018)	lr 0.0002	loss 0.115 (0.133)
Train: [55][550/589]	BT 0.358 (0.376)	DT 0.000 (0.017)	lr 0.0002	loss 0.139 (0.133)
Train: [55][560/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.123 (0.133)
Train: [55][570/589]	BT 0.360 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.105 (0.133)
Train: [55][580/589]	BT 0.358 (0.375)	DT 0.000 (0.017)	lr 0.0002	loss 0.137 (0.133)
epoch 55, total time 220.85
loss: 0.13325052342902127@Epoch: 55
learning_rate: 0.0002,55
Valid: [55][10/88]	BT 0.110 (0.568)	DT 0.000 (0.456)	loss 0.153 (0.138)
Valid: [55][20/88]	BT 0.110 (0.491)	DT 0.000 (0.380)	loss 0.145 (0.133)
Valid: [55][30/88]	BT 0.110 (0.463)	DT 0.000 (0.352)	loss 0.134 (0.131)
Valid: [55][40/88]	BT 0.109 (0.451)	DT 0.000 (0.341)	loss 0.138 (0.132)
Valid: [55][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.140 (0.133)
Valid: [55][60/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.135 (0.133)
Valid: [55][70/88]	BT 0.109 (0.437)	DT 0.000 (0.328)	loss 0.137 (0.134)
Valid: [55][80/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.127 (0.133)
Epoch 0055: val_loss improved from 0.13362 to 0.13308, saving model
==> Saving...
Train: [56][10/589]	BT 0.356 (0.764)	DT 0.000 (0.406)	lr 0.0002	loss 0.121 (0.133)
Train: [56][20/589]	BT 0.387 (0.571)	DT 0.000 (0.212)	lr 0.0002	loss 0.122 (0.132)
Train: [56][30/589]	BT 0.362 (0.506)	DT 0.000 (0.148)	lr 0.0002	loss 0.130 (0.132)
Train: [56][40/589]	BT 0.394 (0.475)	DT 0.000 (0.117)	lr 0.0002	loss 0.133 (0.133)
Train: [56][50/589]	BT 0.359 (0.454)	DT 0.000 (0.097)	lr 0.0002	loss 0.152 (0.134)
Train: [56][60/589]	BT 0.399 (0.441)	DT 0.000 (0.083)	lr 0.0002	loss 0.134 (0.136)
Train: [56][70/589]	BT 0.400 (0.433)	DT 0.000 (0.074)	lr 0.0002	loss 0.138 (0.136)
Train: [56][80/589]	BT 0.367 (0.427)	DT 0.000 (0.068)	lr 0.0002	loss 0.134 (0.136)
Train: [56][90/589]	BT 0.357 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.138 (0.136)
Train: [56][100/589]	BT 0.357 (0.418)	DT 0.000 (0.059)	lr 0.0002	loss 0.127 (0.135)
Train: [56][110/589]	BT 0.362 (0.415)	DT 0.000 (0.055)	lr 0.0002	loss 0.153 (0.135)
Train: [56][120/589]	BT 0.357 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.135 (0.135)
Train: [56][130/589]	BT 0.368 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.143 (0.134)
Train: [56][140/589]	BT 0.355 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.125 (0.134)
Train: [56][150/589]	BT 0.355 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.139 (0.135)
Train: [56][160/589]	BT 0.380 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.134 (0.135)
Train: [56][170/589]	BT 0.374 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.149 (0.135)
Train: [56][180/589]	BT 0.356 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.139 (0.135)
Train: [56][190/589]	BT 0.357 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.122 (0.134)
Train: [56][200/589]	BT 0.365 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.131 (0.135)
Train: [56][210/589]	BT 0.357 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.114 (0.134)
Train: [56][220/589]	BT 0.357 (0.395)	DT 0.000 (0.034)	lr 0.0002	loss 0.147 (0.134)
Train: [56][230/589]	BT 0.356 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.123 (0.134)
Train: [56][240/589]	BT 0.356 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.117 (0.134)
Train: [56][250/589]	BT 0.356 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.136 (0.134)
Train: [56][260/589]	BT 0.357 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.115 (0.134)
Train: [56][270/589]	BT 0.360 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.135 (0.133)
Train: [56][280/589]	BT 0.356 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.120 (0.133)
Train: [56][290/589]	BT 0.374 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.133)
Train: [56][300/589]	BT 0.354 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.146 (0.133)
Train: [56][310/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.133)
Train: [56][320/589]	BT 0.356 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.158 (0.133)
Train: [56][330/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.133)
Train: [56][340/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.134)
Train: [56][350/589]	BT 0.360 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.172 (0.134)
Train: [56][360/589]	BT 0.360 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.151 (0.134)
Train: [56][370/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.111 (0.134)
Train: [56][380/589]	BT 0.375 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.136 (0.134)
Train: [56][390/589]	BT 0.368 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.141 (0.134)
Train: [56][400/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.134)
Train: [56][410/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.150 (0.134)
Train: [56][420/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.123 (0.134)
Train: [56][430/589]	BT 0.356 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.135 (0.134)
Train: [56][440/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.141 (0.134)
Train: [56][450/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.134)
Train: [56][460/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.134)
Train: [56][470/589]	BT 0.355 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.137 (0.134)
Train: [56][480/589]	BT 0.358 (0.385)	DT 0.001 (0.025)	lr 0.0002	loss 0.120 (0.134)
Train: [56][490/589]	BT 0.384 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.134)
Train: [56][500/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.117 (0.134)
Train: [56][510/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.134)
Train: [56][520/589]	BT 0.360 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.134)
Train: [56][530/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.134)
Train: [56][540/589]	BT 0.379 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.132 (0.134)
Train: [56][550/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.134)
Train: [56][560/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.134)
Train: [56][570/589]	BT 0.361 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.115 (0.134)
Train: [56][580/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.115 (0.133)
epoch 56, total time 226.92
loss: 0.1334539422654969@Epoch: 56
learning_rate: 0.0002,56
Valid: [56][10/88]	BT 0.110 (0.558)	DT 0.000 (0.447)	loss 0.125 (0.140)
Valid: [56][20/88]	BT 0.110 (0.477)	DT 0.000 (0.365)	loss 0.138 (0.132)
Valid: [56][30/88]	BT 0.110 (0.459)	DT 0.000 (0.347)	loss 0.116 (0.133)
Valid: [56][40/88]	BT 0.109 (0.451)	DT 0.000 (0.339)	loss 0.156 (0.134)
Valid: [56][50/88]	BT 0.109 (0.438)	DT 0.000 (0.327)	loss 0.123 (0.133)
Valid: [56][60/88]	BT 0.109 (0.437)	DT 0.000 (0.326)	loss 0.121 (0.134)
Valid: [56][70/88]	BT 0.109 (0.432)	DT 0.000 (0.321)	loss 0.126 (0.135)
Valid: [56][80/88]	BT 0.109 (0.428)	DT 0.000 (0.317)	loss 0.112 (0.135)
Train: [57][10/589]	BT 0.357 (0.728)	DT 0.000 (0.371)	lr 0.0002	loss 0.112 (0.124)
Train: [57][20/589]	BT 0.357 (0.552)	DT 0.000 (0.196)	lr 0.0002	loss 0.119 (0.124)
Train: [57][30/589]	BT 0.356 (0.493)	DT 0.000 (0.136)	lr 0.0002	loss 0.139 (0.129)
Train: [57][40/589]	BT 0.358 (0.460)	DT 0.000 (0.103)	lr 0.0002	loss 0.143 (0.129)
Train: [57][50/589]	BT 0.355 (0.448)	DT 0.000 (0.090)	lr 0.0002	loss 0.136 (0.130)
Train: [57][60/589]	BT 0.391 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.131 (0.130)
Train: [57][70/589]	BT 0.379 (0.426)	DT 0.000 (0.067)	lr 0.0002	loss 0.121 (0.130)
Train: [57][80/589]	BT 0.356 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.176 (0.130)
Train: [57][90/589]	BT 0.369 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.106 (0.130)
Train: [57][100/589]	BT 0.384 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.127 (0.130)
Train: [57][110/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.104 (0.130)
Train: [57][120/589]	BT 0.356 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.127 (0.130)
Train: [57][130/589]	BT 0.385 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.132 (0.131)
Train: [57][140/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.152 (0.131)
Train: [57][150/589]	BT 0.360 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.135 (0.131)
Train: [57][160/589]	BT 0.357 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.143 (0.131)
Train: [57][170/589]	BT 0.358 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.148 (0.131)
Train: [57][180/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.117 (0.131)
Train: [57][190/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.124 (0.131)
Train: [57][200/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.151 (0.132)
Train: [57][210/589]	BT 0.382 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.145 (0.132)
Train: [57][220/589]	BT 0.356 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.116 (0.132)
Train: [57][230/589]	BT 0.368 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.116 (0.132)
Train: [57][240/589]	BT 0.356 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.166 (0.132)
Train: [57][250/589]	BT 0.396 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.154 (0.132)
Train: [57][260/589]	BT 0.360 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.103 (0.132)
Train: [57][270/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.120 (0.132)
Train: [57][280/589]	BT 0.355 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.145 (0.132)
Train: [57][290/589]	BT 0.356 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.108 (0.132)
Train: [57][300/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.132)
Train: [57][310/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.114 (0.132)
Train: [57][320/589]	BT 0.354 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.137 (0.132)
Train: [57][330/589]	BT 0.363 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.138 (0.132)
Train: [57][340/589]	BT 0.362 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.133 (0.132)
Train: [57][350/589]	BT 0.386 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.146 (0.132)
Train: [57][360/589]	BT 0.355 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.132)
Train: [57][370/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.132)
Train: [57][380/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.131 (0.132)
Train: [57][390/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.133 (0.132)
Train: [57][400/589]	BT 0.371 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.132)
Train: [57][410/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.132)
Train: [57][420/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.132)
Train: [57][430/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.143 (0.132)
Train: [57][440/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.114 (0.132)
Train: [57][450/589]	BT 0.385 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.128 (0.132)
Train: [57][460/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.132)
Train: [57][470/589]	BT 0.363 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.133)
Train: [57][480/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.133)
Train: [57][490/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.132)
Train: [57][500/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.140 (0.132)
Train: [57][510/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.156 (0.133)
Train: [57][520/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.133)
Train: [57][530/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.154 (0.133)
Train: [57][540/589]	BT 0.360 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.139 (0.133)
Train: [57][550/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.133)
Train: [57][560/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.120 (0.133)
Train: [57][570/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.133)
Train: [57][580/589]	BT 0.364 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.147 (0.133)
epoch 57, total time 223.65
loss: 0.13305188194376308@Epoch: 57
learning_rate: 0.0002,57
Valid: [57][10/88]	BT 0.112 (0.546)	DT 0.000 (0.435)	loss 0.150 (0.137)
Valid: [57][20/88]	BT 0.110 (0.479)	DT 0.000 (0.367)	loss 0.126 (0.137)
Valid: [57][30/88]	BT 0.109 (0.461)	DT 0.000 (0.350)	loss 0.138 (0.137)
Valid: [57][40/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.181 (0.137)
Valid: [57][50/88]	BT 0.109 (0.436)	DT 0.000 (0.324)	loss 0.139 (0.137)
Valid: [57][60/88]	BT 0.110 (0.432)	DT 0.000 (0.321)	loss 0.135 (0.137)
Valid: [57][70/88]	BT 0.110 (0.430)	DT 0.000 (0.319)	loss 0.136 (0.137)
Valid: [57][80/88]	BT 0.110 (0.427)	DT 0.000 (0.316)	loss 0.130 (0.137)
Train: [58][10/589]	BT 0.364 (0.725)	DT 0.000 (0.367)	lr 0.0002	loss 0.140 (0.135)
Train: [58][20/589]	BT 0.356 (0.543)	DT 0.000 (0.185)	lr 0.0002	loss 0.143 (0.138)
Train: [58][30/589]	BT 0.356 (0.486)	DT 0.000 (0.129)	lr 0.0002	loss 0.138 (0.138)
Train: [58][40/589]	BT 0.356 (0.461)	DT 0.000 (0.104)	lr 0.0002	loss 0.132 (0.138)
Train: [58][50/589]	BT 0.357 (0.444)	DT 0.000 (0.086)	lr 0.0002	loss 0.153 (0.137)
Train: [58][60/589]	BT 0.376 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.133 (0.136)
Train: [58][70/589]	BT 0.359 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.134 (0.136)
Train: [58][80/589]	BT 0.357 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.126 (0.134)
Train: [58][90/589]	BT 0.379 (0.414)	DT 0.000 (0.055)	lr 0.0002	loss 0.143 (0.135)
Train: [58][100/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.131 (0.135)
Train: [58][110/589]	BT 0.390 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.139 (0.134)
Train: [58][120/589]	BT 0.358 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.139 (0.134)
Train: [58][130/589]	BT 0.359 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.133)
Train: [58][140/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.133 (0.133)
Train: [58][150/589]	BT 0.361 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.126 (0.133)
Train: [58][160/589]	BT 0.358 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.143 (0.132)
Train: [58][170/589]	BT 0.359 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.167 (0.132)
Train: [58][180/589]	BT 0.375 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.139 (0.132)
Train: [58][190/589]	BT 0.356 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.133)
Train: [58][200/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.133 (0.132)
Train: [58][210/589]	BT 0.364 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.137 (0.132)
Train: [58][220/589]	BT 0.355 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.133)
Train: [58][230/589]	BT 0.356 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.130 (0.133)
Train: [58][240/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.118 (0.133)
Train: [58][250/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.114 (0.132)
Train: [58][260/589]	BT 0.372 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.167 (0.133)
Train: [58][270/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.129 (0.133)
Train: [58][280/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.133)
Train: [58][290/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.131 (0.133)
Train: [58][300/589]	BT 0.356 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.139 (0.133)
Train: [58][310/589]	BT 0.363 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.124 (0.133)
Train: [58][320/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.141 (0.133)
Train: [58][330/589]	BT 0.356 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.107 (0.133)
Train: [58][340/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.133)
Train: [58][350/589]	BT 0.378 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.113 (0.133)
Train: [58][360/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.133)
Train: [58][370/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.115 (0.133)
Train: [58][380/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.142 (0.133)
Train: [58][390/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.106 (0.133)
Train: [58][400/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.132 (0.133)
Train: [58][410/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.133)
Train: [58][420/589]	BT 0.378 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.142 (0.133)
Train: [58][430/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.131 (0.133)
Train: [58][440/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.145 (0.133)
Train: [58][450/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.133)
Train: [58][460/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.133)
Train: [58][470/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.133)
Train: [58][480/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.133)
Train: [58][490/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.147 (0.133)
Train: [58][500/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.138 (0.133)
Train: [58][510/589]	BT 0.354 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.131 (0.133)
Train: [58][520/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.133)
Train: [58][530/589]	BT 0.356 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.133)
Train: [58][540/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.119 (0.133)
Train: [58][550/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.133)
Train: [58][560/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.149 (0.133)
Train: [58][570/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.133)
Train: [58][580/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.133)
epoch 58, total time 225.38
loss: 0.1327041162283577@Epoch: 58
learning_rate: 0.0002,58
Valid: [58][10/88]	BT 0.109 (0.590)	DT 0.000 (0.479)	loss 0.133 (0.137)
Valid: [58][20/88]	BT 0.110 (0.506)	DT 0.000 (0.395)	loss 0.134 (0.130)
Valid: [58][30/88]	BT 0.109 (0.486)	DT 0.000 (0.376)	loss 0.141 (0.133)
Valid: [58][40/88]	BT 0.109 (0.461)	DT 0.000 (0.351)	loss 0.137 (0.133)
Valid: [58][50/88]	BT 0.109 (0.458)	DT 0.000 (0.348)	loss 0.142 (0.133)
Valid: [58][60/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.133 (0.133)
Valid: [58][70/88]	BT 0.110 (0.446)	DT 0.000 (0.336)	loss 0.145 (0.134)
Valid: [58][80/88]	BT 0.109 (0.445)	DT 0.000 (0.336)	loss 0.122 (0.134)
Train: [59][10/589]	BT 0.369 (0.771)	DT 0.000 (0.413)	lr 0.0002	loss 0.132 (0.127)
Train: [59][20/589]	BT 0.357 (0.571)	DT 0.000 (0.213)	lr 0.0002	loss 0.138 (0.133)
Train: [59][30/589]	BT 0.362 (0.505)	DT 0.000 (0.148)	lr 0.0002	loss 0.147 (0.133)
Train: [59][40/589]	BT 0.358 (0.478)	DT 0.000 (0.121)	lr 0.0002	loss 0.140 (0.133)
Train: [59][50/589]	BT 0.356 (0.460)	DT 0.000 (0.103)	lr 0.0002	loss 0.140 (0.133)
Train: [59][60/589]	BT 0.356 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.137 (0.133)
Train: [59][70/589]	BT 0.382 (0.436)	DT 0.000 (0.079)	lr 0.0002	loss 0.130 (0.133)
Train: [59][80/589]	BT 0.358 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.152 (0.132)
Train: [59][90/589]	BT 0.358 (0.424)	DT 0.000 (0.067)	lr 0.0002	loss 0.120 (0.133)
Train: [59][100/589]	BT 0.357 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.120 (0.132)
Train: [59][110/589]	BT 0.381 (0.418)	DT 0.000 (0.061)	lr 0.0002	loss 0.153 (0.133)
Train: [59][120/589]	BT 0.401 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.125 (0.132)
Train: [59][130/589]	BT 0.410 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.124 (0.133)
Train: [59][140/589]	BT 0.376 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.135 (0.133)
Train: [59][150/589]	BT 0.384 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.120 (0.133)
Train: [59][160/589]	BT 0.373 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.156 (0.133)
Train: [59][170/589]	BT 0.364 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.121 (0.133)
Train: [59][180/589]	BT 0.376 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.128 (0.133)
Train: [59][190/589]	BT 0.370 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.127 (0.133)
Train: [59][200/589]	BT 0.385 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.123 (0.133)
Train: [59][210/589]	BT 0.360 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.114 (0.133)
Train: [59][220/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.105 (0.133)
Train: [59][230/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.115 (0.133)
Train: [59][240/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.147 (0.133)
Train: [59][250/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.134 (0.133)
Train: [59][260/589]	BT 0.358 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.153 (0.132)
Train: [59][270/589]	BT 0.356 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.133 (0.132)
Train: [59][280/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.161 (0.132)
Train: [59][290/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.132)
Train: [59][300/589]	BT 0.361 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.132)
Train: [59][310/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.112 (0.133)
Train: [59][320/589]	BT 0.381 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.112 (0.133)
Train: [59][330/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.105 (0.132)
Train: [59][340/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.133)
Train: [59][350/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.149 (0.133)
Train: [59][360/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.170 (0.133)
Train: [59][370/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.133)
Train: [59][380/589]	BT 0.383 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.114 (0.133)
Train: [59][390/589]	BT 0.361 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.146 (0.133)
Train: [59][400/589]	BT 0.354 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.133 (0.133)
Train: [59][410/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.128 (0.133)
Train: [59][420/589]	BT 0.367 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.127 (0.133)
Train: [59][430/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.116 (0.133)
Train: [59][440/589]	BT 0.356 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.133)
Train: [59][450/589]	BT 0.383 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.126 (0.133)
Train: [59][460/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.145 (0.133)
Train: [59][470/589]	BT 0.367 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.133)
Train: [59][480/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.126 (0.133)
Train: [59][490/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.106 (0.133)
Train: [59][500/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.118 (0.133)
Train: [59][510/589]	BT 0.374 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.133)
Train: [59][520/589]	BT 0.380 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.126 (0.133)
Train: [59][530/589]	BT 0.378 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.126 (0.133)
Train: [59][540/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.133)
Train: [59][550/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.131 (0.133)
Train: [59][560/589]	BT 0.375 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.133)
Train: [59][570/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.133)
Train: [59][580/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.133)
epoch 59, total time 225.40
loss: 0.1325944558827518@Epoch: 59
learning_rate: 0.0002,59
Valid: [59][10/88]	BT 0.109 (0.544)	DT 0.000 (0.434)	loss 0.141 (0.136)
Valid: [59][20/88]	BT 0.109 (0.479)	DT 0.000 (0.368)	loss 0.133 (0.139)
Valid: [59][30/88]	BT 0.109 (0.458)	DT 0.000 (0.348)	loss 0.128 (0.137)
Valid: [59][40/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.136 (0.136)
Valid: [59][50/88]	BT 0.110 (0.444)	DT 0.000 (0.334)	loss 0.137 (0.135)
Valid: [59][60/88]	BT 0.109 (0.438)	DT 0.000 (0.329)	loss 0.125 (0.135)
Valid: [59][70/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.124 (0.134)
Valid: [59][80/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.120 (0.134)
Train: [60][10/589]	BT 0.367 (0.759)	DT 0.000 (0.401)	lr 0.0002	loss 0.139 (0.138)
Train: [60][20/589]	BT 0.386 (0.582)	DT 0.000 (0.224)	lr 0.0002	loss 0.123 (0.131)
Train: [60][30/589]	BT 0.401 (0.508)	DT 0.000 (0.149)	lr 0.0002	loss 0.115 (0.131)
Train: [60][40/589]	BT 0.391 (0.473)	DT 0.000 (0.114)	lr 0.0002	loss 0.111 (0.130)
Train: [60][50/589]	BT 0.356 (0.450)	DT 0.000 (0.091)	lr 0.0002	loss 0.133 (0.131)
Train: [60][60/589]	BT 0.358 (0.438)	DT 0.000 (0.079)	lr 0.0002	loss 0.140 (0.131)
Train: [60][70/589]	BT 0.360 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.158 (0.132)
Train: [60][80/589]	BT 0.363 (0.422)	DT 0.000 (0.064)	lr 0.0002	loss 0.143 (0.132)
Train: [60][90/589]	BT 0.375 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.113 (0.132)
Train: [60][100/589]	BT 0.358 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.107 (0.131)
Train: [60][110/589]	BT 0.358 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.120 (0.132)
Train: [60][120/589]	BT 0.362 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.135 (0.132)
Train: [60][130/589]	BT 0.394 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.120 (0.132)
Train: [60][140/589]	BT 0.379 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.148 (0.133)
Train: [60][150/589]	BT 0.376 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.132 (0.133)
Train: [60][160/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.131 (0.132)
Train: [60][170/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.117 (0.132)
Train: [60][180/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.138 (0.132)
Train: [60][190/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.134 (0.132)
Train: [60][200/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.138 (0.132)
Train: [60][210/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.132)
Train: [60][220/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.131 (0.132)
Train: [60][230/589]	BT 0.359 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.131 (0.132)
Train: [60][240/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.132)
Train: [60][250/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.136 (0.132)
Train: [60][260/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.174 (0.132)
Train: [60][270/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.131 (0.132)
Train: [60][280/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.132)
Train: [60][290/589]	BT 0.380 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.122 (0.132)
Train: [60][300/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.132)
Train: [60][310/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.132)
Train: [60][320/589]	BT 0.355 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.099 (0.132)
Train: [60][330/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.128 (0.132)
Train: [60][340/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.132)
Train: [60][350/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.132)
Train: [60][360/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.132)
Train: [60][370/589]	BT 0.388 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.132)
Train: [60][380/589]	BT 0.356 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.137 (0.132)
Train: [60][390/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.155 (0.132)
Train: [60][400/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.141 (0.132)
Train: [60][410/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.122 (0.132)
Train: [60][420/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.118 (0.132)
Train: [60][430/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.132)
Train: [60][440/589]	BT 0.360 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.133 (0.132)
Train: [60][450/589]	BT 0.383 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.132 (0.132)
Train: [60][460/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.195 (0.133)
Train: [60][470/589]	BT 0.376 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.130 (0.133)
Train: [60][480/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.133)
Train: [60][490/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.133)
Train: [60][500/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.133)
Train: [60][510/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.133)
Train: [60][520/589]	BT 0.355 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.153 (0.133)
Train: [60][530/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.118 (0.133)
Train: [60][540/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.132)
Train: [60][550/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.133)
Train: [60][560/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.133)
Train: [60][570/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.118 (0.133)
Train: [60][580/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.133)
epoch 60, total time 225.74
loss: 0.13245570336414897@Epoch: 60
learning_rate: 0.0002,60
Valid: [60][10/88]	BT 0.110 (0.571)	DT 0.000 (0.459)	loss 0.149 (0.137)
Valid: [60][20/88]	BT 0.110 (0.498)	DT 0.000 (0.388)	loss 0.124 (0.134)
Valid: [60][30/88]	BT 0.109 (0.466)	DT 0.000 (0.356)	loss 0.132 (0.135)
Valid: [60][40/88]	BT 0.109 (0.451)	DT 0.000 (0.342)	loss 0.127 (0.134)
Valid: [60][50/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.133 (0.134)
Valid: [60][60/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.158 (0.134)
Valid: [60][70/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.136 (0.134)
Valid: [60][80/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.146 (0.135)
Train: [61][10/589]	BT 0.357 (0.766)	DT 0.000 (0.410)	lr 0.0002	loss 0.105 (0.123)
Train: [61][20/589]	BT 0.366 (0.567)	DT 0.000 (0.211)	lr 0.0002	loss 0.125 (0.127)
Train: [61][30/589]	BT 0.383 (0.501)	DT 0.000 (0.144)	lr 0.0002	loss 0.106 (0.128)
Train: [61][40/589]	BT 0.357 (0.467)	DT 0.000 (0.109)	lr 0.0002	loss 0.116 (0.127)
Train: [61][50/589]	BT 0.374 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.143 (0.127)
Train: [61][60/589]	BT 0.360 (0.437)	DT 0.000 (0.080)	lr 0.0002	loss 0.137 (0.128)
Train: [61][70/589]	BT 0.363 (0.427)	DT 0.000 (0.070)	lr 0.0002	loss 0.148 (0.129)
Train: [61][80/589]	BT 0.357 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.123 (0.129)
Train: [61][90/589]	BT 0.355 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.132 (0.129)
Train: [61][100/589]	BT 0.368 (0.412)	DT 0.000 (0.055)	lr 0.0002	loss 0.135 (0.130)
Train: [61][110/589]	BT 0.391 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.108 (0.129)
Train: [61][120/589]	BT 0.355 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.121 (0.130)
Train: [61][130/589]	BT 0.355 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.135 (0.131)
Train: [61][140/589]	BT 0.367 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.148 (0.130)
Train: [61][150/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.157 (0.131)
Train: [61][160/589]	BT 0.409 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.134 (0.131)
Train: [61][170/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.134 (0.131)
Train: [61][180/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.138 (0.131)
Train: [61][190/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.114 (0.132)
Train: [61][200/589]	BT 0.362 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.108 (0.131)
Train: [61][210/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.132)
Train: [61][220/589]	BT 0.368 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.123 (0.132)
Train: [61][230/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.121 (0.132)
Train: [61][240/589]	BT 0.368 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.120 (0.132)
Train: [61][250/589]	BT 0.359 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.142 (0.132)
Train: [61][260/589]	BT 0.363 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.156 (0.132)
Train: [61][270/589]	BT 0.361 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.130 (0.132)
Train: [61][280/589]	BT 0.381 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.151 (0.132)
Train: [61][290/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.128 (0.132)
Train: [61][300/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.147 (0.132)
Train: [61][310/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.118 (0.132)
Train: [61][320/589]	BT 0.373 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.123 (0.132)
Train: [61][330/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.107 (0.133)
Train: [61][340/589]	BT 0.378 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.120 (0.133)
Train: [61][350/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.126 (0.133)
Train: [61][360/589]	BT 0.355 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.114 (0.132)
Train: [61][370/589]	BT 0.365 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.132)
Train: [61][380/589]	BT 0.363 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.132)
Train: [61][390/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.150 (0.132)
Train: [61][400/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.132)
Train: [61][410/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.142 (0.132)
Train: [61][420/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.123 (0.132)
Train: [61][430/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.158 (0.132)
Train: [61][440/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.124 (0.132)
Train: [61][450/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.142 (0.133)
Train: [61][460/589]	BT 0.369 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.133)
Train: [61][470/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.163 (0.132)
Train: [61][480/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.157 (0.133)
Train: [61][490/589]	BT 0.365 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.133)
Train: [61][500/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.138 (0.133)
Train: [61][510/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.119 (0.133)
Train: [61][520/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.132)
Train: [61][530/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.133)
Train: [61][540/589]	BT 0.367 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.164 (0.133)
Train: [61][550/589]	BT 0.356 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.132)
Train: [61][560/589]	BT 0.386 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.109 (0.132)
Train: [61][570/589]	BT 0.364 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.156 (0.132)
Train: [61][580/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.132)
epoch 61, total time 224.37
loss: 0.13212193413502046@Epoch: 61
learning_rate: 0.0002,61
Valid: [61][10/88]	BT 0.110 (0.545)	DT 0.000 (0.431)	loss 0.128 (0.136)
Valid: [61][20/88]	BT 0.109 (0.487)	DT 0.000 (0.375)	loss 0.118 (0.135)
Valid: [61][30/88]	BT 0.109 (0.463)	DT 0.000 (0.352)	loss 0.122 (0.134)
Valid: [61][40/88]	BT 0.109 (0.450)	DT 0.000 (0.338)	loss 0.128 (0.134)
Valid: [61][50/88]	BT 0.109 (0.446)	DT 0.000 (0.334)	loss 0.149 (0.135)
Valid: [61][60/88]	BT 0.109 (0.440)	DT 0.000 (0.328)	loss 0.158 (0.135)
Valid: [61][70/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.128 (0.135)
Valid: [61][80/88]	BT 0.110 (0.432)	DT 0.000 (0.321)	loss 0.126 (0.136)
Train: [62][10/589]	BT 0.374 (0.769)	DT 0.000 (0.412)	lr 0.0002	loss 0.146 (0.128)
Train: [62][20/589]	BT 0.356 (0.570)	DT 0.000 (0.212)	lr 0.0002	loss 0.159 (0.132)
Train: [62][30/589]	BT 0.358 (0.505)	DT 0.000 (0.148)	lr 0.0002	loss 0.121 (0.133)
Train: [62][40/589]	BT 0.358 (0.472)	DT 0.000 (0.114)	lr 0.0002	loss 0.120 (0.131)
Train: [62][50/589]	BT 0.361 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.135 (0.131)
Train: [62][60/589]	BT 0.373 (0.439)	DT 0.000 (0.081)	lr 0.0002	loss 0.141 (0.132)
Train: [62][70/589]	BT 0.359 (0.432)	DT 0.000 (0.074)	lr 0.0002	loss 0.126 (0.132)
Train: [62][80/589]	BT 0.412 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.114 (0.132)
Train: [62][90/589]	BT 0.372 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.117 (0.132)
Train: [62][100/589]	BT 0.400 (0.414)	DT 0.000 (0.055)	lr 0.0002	loss 0.140 (0.133)
Train: [62][110/589]	BT 0.371 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.103 (0.133)
Train: [62][120/589]	BT 0.394 (0.409)	DT 0.000 (0.049)	lr 0.0002	loss 0.129 (0.132)
Train: [62][130/589]	BT 0.366 (0.405)	DT 0.000 (0.045)	lr 0.0002	loss 0.126 (0.132)
Train: [62][140/589]	BT 0.384 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.149 (0.133)
Train: [62][150/589]	BT 0.380 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.133)
Train: [62][160/589]	BT 0.368 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.140 (0.133)
Train: [62][170/589]	BT 0.375 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.138 (0.133)
Train: [62][180/589]	BT 0.397 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.133)
Train: [62][190/589]	BT 0.400 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.133)
Train: [62][200/589]	BT 0.381 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.141 (0.133)
Train: [62][210/589]	BT 0.360 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.133)
Train: [62][220/589]	BT 0.364 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.123 (0.133)
Train: [62][230/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.118 (0.133)
Train: [62][240/589]	BT 0.374 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.133)
Train: [62][250/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.120 (0.133)
Train: [62][260/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.136 (0.133)
Train: [62][270/589]	BT 0.369 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.133)
Train: [62][280/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.133)
Train: [62][290/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.151 (0.133)
Train: [62][300/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.109 (0.133)
Train: [62][310/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.138 (0.133)
Train: [62][320/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.124 (0.133)
Train: [62][330/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.143 (0.133)
Train: [62][340/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.125 (0.132)
Train: [62][350/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.132)
Train: [62][360/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.139 (0.132)
Train: [62][370/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.133 (0.133)
Train: [62][380/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.132 (0.132)
Train: [62][390/589]	BT 0.388 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.132)
Train: [62][400/589]	BT 0.388 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.132)
Train: [62][410/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.152 (0.132)
Train: [62][420/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.132)
Train: [62][430/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.143 (0.132)
Train: [62][440/589]	BT 0.361 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.132)
Train: [62][450/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.111 (0.132)
Train: [62][460/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.105 (0.132)
Train: [62][470/589]	BT 0.382 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.152 (0.132)
Train: [62][480/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.157 (0.132)
Train: [62][490/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.115 (0.132)
Train: [62][500/589]	BT 0.369 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.132)
Train: [62][510/589]	BT 0.374 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.150 (0.132)
Train: [62][520/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.149 (0.132)
Train: [62][530/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.132)
Train: [62][540/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.132)
Train: [62][550/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.132)
Train: [62][560/589]	BT 0.363 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.143 (0.132)
Train: [62][570/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.132)
Train: [62][580/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.132)
epoch 62, total time 225.08
loss: 0.13186236129512144@Epoch: 62
learning_rate: 0.0002,62
Valid: [62][10/88]	BT 0.109 (0.555)	DT 0.000 (0.442)	loss 0.134 (0.139)
Valid: [62][20/88]	BT 0.110 (0.484)	DT 0.000 (0.372)	loss 0.120 (0.137)
Valid: [62][30/88]	BT 0.109 (0.456)	DT 0.000 (0.345)	loss 0.154 (0.136)
Valid: [62][40/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.109 (0.136)
Valid: [62][50/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.136 (0.135)
Valid: [62][60/88]	BT 0.109 (0.452)	DT 0.000 (0.342)	loss 0.113 (0.135)
Valid: [62][70/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.126 (0.135)
Valid: [62][80/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.142 (0.135)
Train: [63][10/589]	BT 0.356 (0.727)	DT 0.000 (0.370)	lr 0.0002	loss 0.126 (0.140)
Train: [63][20/589]	BT 0.357 (0.554)	DT 0.000 (0.197)	lr 0.0002	loss 0.114 (0.135)
Train: [63][30/589]	BT 0.361 (0.497)	DT 0.000 (0.139)	lr 0.0002	loss 0.109 (0.132)
Train: [63][40/589]	BT 0.382 (0.467)	DT 0.000 (0.109)	lr 0.0002	loss 0.150 (0.131)
Train: [63][50/589]	BT 0.359 (0.448)	DT 0.000 (0.090)	lr 0.0002	loss 0.147 (0.131)
Train: [63][60/589]	BT 0.371 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.144 (0.131)
Train: [63][70/589]	BT 0.371 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.122 (0.131)
Train: [63][80/589]	BT 0.355 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.117 (0.132)
Train: [63][90/589]	BT 0.357 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.127 (0.132)
Train: [63][100/589]	BT 0.381 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.148 (0.132)
Train: [63][110/589]	BT 0.366 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.139 (0.133)
Train: [63][120/589]	BT 0.390 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.132 (0.132)
Train: [63][130/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.137 (0.132)
Train: [63][140/589]	BT 0.363 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.144 (0.132)
Train: [63][150/589]	BT 0.374 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.131 (0.132)
Train: [63][160/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.130 (0.132)
Train: [63][170/589]	BT 0.361 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.117 (0.131)
Train: [63][180/589]	BT 0.368 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.146 (0.132)
Train: [63][190/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.101 (0.131)
Train: [63][200/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.153 (0.132)
Train: [63][210/589]	BT 0.367 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.131 (0.132)
Train: [63][220/589]	BT 0.362 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.120 (0.132)
Train: [63][230/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.162 (0.132)
Train: [63][240/589]	BT 0.355 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.143 (0.132)
Train: [63][250/589]	BT 0.368 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.109 (0.132)
Train: [63][260/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.132)
Train: [63][270/589]	BT 0.355 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.108 (0.132)
Train: [63][280/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.132)
Train: [63][290/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.132)
Train: [63][300/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.156 (0.132)
Train: [63][310/589]	BT 0.364 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.105 (0.132)
Train: [63][320/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.106 (0.132)
Train: [63][330/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.158 (0.132)
Train: [63][340/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.132)
Train: [63][350/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.132)
Train: [63][360/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.132)
Train: [63][370/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.132)
Train: [63][380/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.132)
Train: [63][390/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.126 (0.132)
Train: [63][400/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.139 (0.132)
Train: [63][410/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.132)
Train: [63][420/589]	BT 0.360 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.131)
Train: [63][430/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.132)
Train: [63][440/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.146 (0.131)
Train: [63][450/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.114 (0.131)
Train: [63][460/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.131)
Train: [63][470/589]	BT 0.359 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.156 (0.131)
Train: [63][480/589]	BT 0.378 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.133 (0.132)
Train: [63][490/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.132)
Train: [63][500/589]	BT 0.360 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.140 (0.132)
Train: [63][510/589]	BT 0.362 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.149 (0.132)
Train: [63][520/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.120 (0.132)
Train: [63][530/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.156 (0.132)
Train: [63][540/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.150 (0.132)
Train: [63][550/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.112 (0.132)
Train: [63][560/589]	BT 0.357 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.132)
Train: [63][570/589]	BT 0.363 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.132)
Train: [63][580/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.132)
epoch 63, total time 222.62
loss: 0.13165706531596785@Epoch: 63
learning_rate: 0.0002,63
Valid: [63][10/88]	BT 0.110 (0.584)	DT 0.000 (0.473)	loss 0.117 (0.130)
Valid: [63][20/88]	BT 0.110 (0.504)	DT 0.000 (0.394)	loss 0.130 (0.132)
Valid: [63][30/88]	BT 0.109 (0.475)	DT 0.000 (0.365)	loss 0.127 (0.131)
Valid: [63][40/88]	BT 0.109 (0.456)	DT 0.000 (0.347)	loss 0.107 (0.131)
Valid: [63][50/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.139 (0.134)
Valid: [63][60/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.129 (0.133)
Valid: [63][70/88]	BT 0.109 (0.433)	DT 0.000 (0.322)	loss 0.150 (0.134)
Valid: [63][80/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.123 (0.135)
Train: [64][10/589]	BT 0.371 (0.768)	DT 0.000 (0.409)	lr 0.0002	loss 0.117 (0.132)
Train: [64][20/589]	BT 0.381 (0.570)	DT 0.000 (0.211)	lr 0.0002	loss 0.109 (0.131)
Train: [64][30/589]	BT 0.370 (0.501)	DT 0.000 (0.142)	lr 0.0002	loss 0.169 (0.131)
Train: [64][40/589]	BT 0.369 (0.468)	DT 0.000 (0.109)	lr 0.0002	loss 0.144 (0.130)
Train: [64][50/589]	BT 0.359 (0.447)	DT 0.000 (0.088)	lr 0.0002	loss 0.139 (0.130)
Train: [64][60/589]	BT 0.365 (0.436)	DT 0.000 (0.077)	lr 0.0002	loss 0.133 (0.131)
Train: [64][70/589]	BT 0.356 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.116 (0.131)
Train: [64][80/589]	BT 0.357 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.153 (0.132)
Train: [64][90/589]	BT 0.359 (0.411)	DT 0.000 (0.051)	lr 0.0002	loss 0.149 (0.133)
Train: [64][100/589]	BT 0.358 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.135 (0.134)
Train: [64][110/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.133)
Train: [64][120/589]	BT 0.386 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.121 (0.133)
Train: [64][130/589]	BT 0.369 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.173 (0.133)
Train: [64][140/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.123 (0.132)
Train: [64][150/589]	BT 0.358 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.142 (0.133)
Train: [64][160/589]	BT 0.382 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.136 (0.133)
Train: [64][170/589]	BT 0.385 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.147 (0.133)
Train: [64][180/589]	BT 0.391 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.114 (0.133)
Train: [64][190/589]	BT 0.362 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.159 (0.133)
Train: [64][200/589]	BT 0.370 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.115 (0.132)
Train: [64][210/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.104 (0.132)
Train: [64][220/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.155 (0.132)
Train: [64][230/589]	BT 0.371 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.131 (0.132)
Train: [64][240/589]	BT 0.379 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.106 (0.132)
Train: [64][250/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.132)
Train: [64][260/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.133 (0.132)
Train: [64][270/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.108 (0.132)
Train: [64][280/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.125 (0.132)
Train: [64][290/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.132)
Train: [64][300/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.121 (0.132)
Train: [64][310/589]	BT 0.364 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.131)
Train: [64][320/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.132)
Train: [64][330/589]	BT 0.397 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.131)
Train: [64][340/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.131)
Train: [64][350/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.131)
Train: [64][360/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.131)
Train: [64][370/589]	BT 0.364 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.130 (0.131)
Train: [64][380/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.131)
Train: [64][390/589]	BT 0.353 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.140 (0.132)
Train: [64][400/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.128 (0.132)
Train: [64][410/589]	BT 0.356 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.132)
Train: [64][420/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.132)
Train: [64][430/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.131)
Train: [64][440/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.132)
Train: [64][450/589]	BT 0.356 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.131)
Train: [64][460/589]	BT 0.362 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.136 (0.132)
Train: [64][470/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.138 (0.132)
Train: [64][480/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.132)
Train: [64][490/589]	BT 0.356 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.142 (0.132)
Train: [64][500/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.141 (0.132)
Train: [64][510/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.132)
Train: [64][520/589]	BT 0.360 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.123 (0.132)
Train: [64][530/589]	BT 0.374 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.144 (0.132)
Train: [64][540/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.119 (0.132)
Train: [64][550/589]	BT 0.360 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.129 (0.131)
Train: [64][560/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.128 (0.131)
Train: [64][570/589]	BT 0.356 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.131)
Train: [64][580/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.131)
epoch 64, total time 223.78
loss: 0.13145481635993875@Epoch: 64
learning_rate: 0.0002,64
Valid: [64][10/88]	BT 0.110 (0.595)	DT 0.000 (0.484)	loss 0.145 (0.140)
Valid: [64][20/88]	BT 0.110 (0.501)	DT 0.000 (0.390)	loss 0.137 (0.138)
Valid: [64][30/88]	BT 0.109 (0.464)	DT 0.000 (0.353)	loss 0.143 (0.136)
Valid: [64][40/88]	BT 0.109 (0.449)	DT 0.000 (0.338)	loss 0.147 (0.136)
Valid: [64][50/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.140 (0.135)
Valid: [64][60/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.168 (0.134)
Valid: [64][70/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.131 (0.134)
Valid: [64][80/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.137 (0.135)
Train: [65][10/589]	BT 0.356 (0.751)	DT 0.000 (0.395)	lr 0.0002	loss 0.137 (0.130)
Train: [65][20/589]	BT 0.378 (0.560)	DT 0.000 (0.203)	lr 0.0002	loss 0.131 (0.134)
Train: [65][30/589]	BT 0.362 (0.498)	DT 0.000 (0.140)	lr 0.0002	loss 0.151 (0.134)
Train: [65][40/589]	BT 0.390 (0.465)	DT 0.000 (0.106)	lr 0.0002	loss 0.142 (0.132)
Train: [65][50/589]	BT 0.359 (0.446)	DT 0.000 (0.086)	lr 0.0002	loss 0.150 (0.131)
Train: [65][60/589]	BT 0.383 (0.432)	DT 0.000 (0.072)	lr 0.0002	loss 0.109 (0.130)
Train: [65][70/589]	BT 0.369 (0.422)	DT 0.000 (0.062)	lr 0.0002	loss 0.108 (0.130)
Train: [65][80/589]	BT 0.356 (0.418)	DT 0.000 (0.058)	lr 0.0002	loss 0.132 (0.131)
Train: [65][90/589]	BT 0.386 (0.412)	DT 0.000 (0.052)	lr 0.0002	loss 0.129 (0.131)
Train: [65][100/589]	BT 0.369 (0.407)	DT 0.000 (0.047)	lr 0.0002	loss 0.132 (0.131)
Train: [65][110/589]	BT 0.393 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.134 (0.132)
Train: [65][120/589]	BT 0.387 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.132 (0.131)
Train: [65][130/589]	BT 0.377 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.125 (0.131)
Train: [65][140/589]	BT 0.359 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.131)
Train: [65][150/589]	BT 0.356 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.131)
Train: [65][160/589]	BT 0.376 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.131)
Train: [65][170/589]	BT 0.401 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.145 (0.132)
Train: [65][180/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.130 (0.132)
Train: [65][190/589]	BT 0.356 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.132)
Train: [65][200/589]	BT 0.358 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.116 (0.132)
Train: [65][210/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.132)
Train: [65][220/589]	BT 0.354 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.124 (0.132)
Train: [65][230/589]	BT 0.355 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.131)
Train: [65][240/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.146 (0.132)
Train: [65][250/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.097 (0.132)
Train: [65][260/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.118 (0.131)
Train: [65][270/589]	BT 0.356 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.147 (0.131)
Train: [65][280/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.126 (0.131)
Train: [65][290/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.143 (0.131)
Train: [65][300/589]	BT 0.363 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.114 (0.131)
Train: [65][310/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.132)
Train: [65][320/589]	BT 0.362 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.131)
Train: [65][330/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.132)
Train: [65][340/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.131)
Train: [65][350/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.131)
Train: [65][360/589]	BT 0.366 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.142 (0.131)
Train: [65][370/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.131)
Train: [65][380/589]	BT 0.375 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.131)
Train: [65][390/589]	BT 0.357 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.131)
Train: [65][400/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.131 (0.131)
Train: [65][410/589]	BT 0.357 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.131)
Train: [65][420/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.131)
Train: [65][430/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.131)
Train: [65][440/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.147 (0.131)
Train: [65][450/589]	BT 0.359 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.135 (0.131)
Train: [65][460/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.128 (0.131)
Train: [65][470/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.132)
Train: [65][480/589]	BT 0.355 (0.381)	DT 0.000 (0.020)	lr 0.0002	loss 0.124 (0.132)
Train: [65][490/589]	BT 0.359 (0.381)	DT 0.000 (0.020)	lr 0.0002	loss 0.104 (0.131)
Train: [65][500/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.131)
Train: [65][510/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.121 (0.131)
Train: [65][520/589]	BT 0.356 (0.380)	DT 0.000 (0.019)	lr 0.0002	loss 0.109 (0.131)
Train: [65][530/589]	BT 0.357 (0.380)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.131)
Train: [65][540/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.131)
Train: [65][550/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.145 (0.131)
Train: [65][560/589]	BT 0.356 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.149 (0.131)
Train: [65][570/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.131)
Train: [65][580/589]	BT 0.357 (0.380)	DT 0.000 (0.019)	lr 0.0002	loss 0.133 (0.131)
epoch 65, total time 223.30
loss: 0.13126724006163737@Epoch: 65
learning_rate: 0.0002,65
Valid: [65][10/88]	BT 0.109 (0.576)	DT 0.000 (0.465)	loss 0.140 (0.136)
Valid: [65][20/88]	BT 0.110 (0.488)	DT 0.000 (0.378)	loss 0.154 (0.139)
Valid: [65][30/88]	BT 0.110 (0.465)	DT 0.000 (0.355)	loss 0.136 (0.139)
Valid: [65][40/88]	BT 0.110 (0.454)	DT 0.000 (0.344)	loss 0.143 (0.137)
Valid: [65][50/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.131 (0.137)
Valid: [65][60/88]	BT 0.114 (0.437)	DT 0.000 (0.326)	loss 0.124 (0.136)
Valid: [65][70/88]	BT 0.109 (0.436)	DT 0.000 (0.325)	loss 0.152 (0.136)
Valid: [65][80/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.153 (0.136)
Train: [66][10/589]	BT 0.356 (0.744)	DT 0.000 (0.389)	lr 0.0002	loss 0.144 (0.123)
Train: [66][20/589]	BT 0.357 (0.552)	DT 0.000 (0.195)	lr 0.0002	loss 0.128 (0.128)
Train: [66][30/589]	BT 0.357 (0.494)	DT 0.000 (0.136)	lr 0.0002	loss 0.150 (0.128)
Train: [66][40/589]	BT 0.369 (0.463)	DT 0.000 (0.104)	lr 0.0002	loss 0.138 (0.131)
Train: [66][50/589]	BT 0.356 (0.443)	DT 0.000 (0.083)	lr 0.0002	loss 0.118 (0.132)
Train: [66][60/589]	BT 0.355 (0.431)	DT 0.000 (0.072)	lr 0.0002	loss 0.133 (0.132)
Train: [66][70/589]	BT 0.361 (0.424)	DT 0.000 (0.064)	lr 0.0002	loss 0.133 (0.131)
Train: [66][80/589]	BT 0.371 (0.417)	DT 0.000 (0.057)	lr 0.0002	loss 0.185 (0.132)
Train: [66][90/589]	BT 0.357 (0.412)	DT 0.000 (0.052)	lr 0.0002	loss 0.121 (0.132)
Train: [66][100/589]	BT 0.359 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.130 (0.131)
Train: [66][110/589]	BT 0.356 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.135 (0.131)
Train: [66][120/589]	BT 0.358 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.123 (0.131)
Train: [66][130/589]	BT 0.359 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.150 (0.131)
Train: [66][140/589]	BT 0.356 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.167 (0.131)
Train: [66][150/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.140 (0.132)
Train: [66][160/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.132 (0.132)
Train: [66][170/589]	BT 0.353 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.109 (0.131)
Train: [66][180/589]	BT 0.354 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.131)
Train: [66][190/589]	BT 0.356 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.113 (0.131)
Train: [66][200/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.120 (0.131)
Train: [66][210/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.116 (0.131)
Train: [66][220/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.137 (0.131)
Train: [66][230/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.135 (0.131)
Train: [66][240/589]	BT 0.356 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.131)
Train: [66][250/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.131 (0.131)
Train: [66][260/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.127 (0.131)
Train: [66][270/589]	BT 0.360 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.137 (0.131)
Train: [66][280/589]	BT 0.388 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.135 (0.131)
Train: [66][290/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.156 (0.131)
Train: [66][300/589]	BT 0.356 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.129 (0.131)
Train: [66][310/589]	BT 0.355 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.137 (0.131)
Train: [66][320/589]	BT 0.363 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.122 (0.131)
Train: [66][330/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.131)
Train: [66][340/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.114 (0.131)
Train: [66][350/589]	BT 0.356 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.145 (0.131)
Train: [66][360/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.126 (0.131)
Train: [66][370/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.117 (0.131)
Train: [66][380/589]	BT 0.355 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.131)
Train: [66][390/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.151 (0.131)
Train: [66][400/589]	BT 0.356 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.131)
Train: [66][410/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.131)
Train: [66][420/589]	BT 0.379 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.157 (0.131)
Train: [66][430/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.125 (0.131)
Train: [66][440/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.131)
Train: [66][450/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.131)
Train: [66][460/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.131)
Train: [66][470/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.159 (0.131)
Train: [66][480/589]	BT 0.375 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.126 (0.131)
Train: [66][490/589]	BT 0.398 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.137 (0.131)
Train: [66][500/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.120 (0.131)
Train: [66][510/589]	BT 0.361 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.108 (0.131)
Train: [66][520/589]	BT 0.380 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.150 (0.131)
Train: [66][530/589]	BT 0.356 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.125 (0.131)
Train: [66][540/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.119 (0.131)
Train: [66][550/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.142 (0.131)
Train: [66][560/589]	BT 0.370 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.159 (0.131)
Train: [66][570/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.131)
Train: [66][580/589]	BT 0.354 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.158 (0.131)
epoch 66, total time 223.26
loss: 0.13092819422274504@Epoch: 66
learning_rate: 0.0002,66
Valid: [66][10/88]	BT 0.110 (0.587)	DT 0.000 (0.476)	loss 0.119 (0.134)
Valid: [66][20/88]	BT 0.109 (0.502)	DT 0.000 (0.391)	loss 0.133 (0.135)
Valid: [66][30/88]	BT 0.109 (0.478)	DT 0.000 (0.368)	loss 0.131 (0.136)
Valid: [66][40/88]	BT 0.110 (0.457)	DT 0.000 (0.347)	loss 0.125 (0.134)
Valid: [66][50/88]	BT 0.110 (0.447)	DT 0.000 (0.337)	loss 0.155 (0.135)
Valid: [66][60/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.136 (0.135)
Valid: [66][70/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.154 (0.134)
Valid: [66][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.126 (0.134)
Train: [67][10/589]	BT 0.409 (0.780)	DT 0.000 (0.418)	lr 0.0002	loss 0.159 (0.132)
Train: [67][20/589]	BT 0.372 (0.569)	DT 0.000 (0.209)	lr 0.0002	loss 0.142 (0.131)
Train: [67][30/589]	BT 0.355 (0.501)	DT 0.000 (0.142)	lr 0.0002	loss 0.126 (0.131)
Train: [67][40/589]	BT 0.356 (0.471)	DT 0.000 (0.113)	lr 0.0002	loss 0.138 (0.129)
Train: [67][50/589]	BT 0.413 (0.455)	DT 0.000 (0.096)	lr 0.0002	loss 0.094 (0.128)
Train: [67][60/589]	BT 0.358 (0.444)	DT 0.000 (0.085)	lr 0.0002	loss 0.145 (0.129)
Train: [67][70/589]	BT 0.373 (0.432)	DT 0.000 (0.073)	lr 0.0002	loss 0.145 (0.130)
Train: [67][80/589]	BT 0.363 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.148 (0.130)
Train: [67][90/589]	BT 0.386 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.153 (0.130)
Train: [67][100/589]	BT 0.360 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.135 (0.130)
Train: [67][110/589]	BT 0.353 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.121 (0.130)
Train: [67][120/589]	BT 0.379 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.151 (0.130)
Train: [67][130/589]	BT 0.360 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.151 (0.130)
Train: [67][140/589]	BT 0.361 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.123 (0.130)
Train: [67][150/589]	BT 0.355 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.119 (0.130)
Train: [67][160/589]	BT 0.387 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.126 (0.130)
Train: [67][170/589]	BT 0.382 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.135 (0.130)
Train: [67][180/589]	BT 0.362 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.130)
Train: [67][190/589]	BT 0.359 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.130 (0.130)
Train: [67][200/589]	BT 0.375 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.132 (0.130)
Train: [67][210/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.131)
Train: [67][220/589]	BT 0.360 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.148 (0.131)
Train: [67][230/589]	BT 0.357 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.136 (0.131)
Train: [67][240/589]	BT 0.365 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.131)
Train: [67][250/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.142 (0.131)
Train: [67][260/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.131)
Train: [67][270/589]	BT 0.382 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.134 (0.131)
Train: [67][280/589]	BT 0.360 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.128 (0.131)
Train: [67][290/589]	BT 0.371 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.130)
Train: [67][300/589]	BT 0.363 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.129 (0.130)
Train: [67][310/589]	BT 0.371 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.130)
Train: [67][320/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.131)
Train: [67][330/589]	BT 0.383 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.130)
Train: [67][340/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.131 (0.130)
Train: [67][350/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.130)
Train: [67][360/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.137 (0.130)
Train: [67][370/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.105 (0.130)
Train: [67][380/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.156 (0.130)
Train: [67][390/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.130 (0.130)
Train: [67][400/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.151 (0.131)
Train: [67][410/589]	BT 0.354 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.131)
Train: [67][420/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.115 (0.131)
Train: [67][430/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.112 (0.131)
Train: [67][440/589]	BT 0.361 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.131)
Train: [67][450/589]	BT 0.363 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.113 (0.131)
Train: [67][460/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.146 (0.131)
Train: [67][470/589]	BT 0.372 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.148 (0.131)
Train: [67][480/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.131)
Train: [67][490/589]	BT 0.360 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.118 (0.131)
Train: [67][500/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.098 (0.131)
Train: [67][510/589]	BT 0.361 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.131)
Train: [67][520/589]	BT 0.373 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.126 (0.131)
Train: [67][530/589]	BT 0.369 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.124 (0.130)
Train: [67][540/589]	BT 0.407 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.131)
Train: [67][550/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.131)
Train: [67][560/589]	BT 0.378 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.131)
Train: [67][570/589]	BT 0.376 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.156 (0.131)
Train: [67][580/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.131)
epoch 67, total time 225.50
loss: 0.13076544617464367@Epoch: 67
learning_rate: 0.0002,67
Valid: [67][10/88]	BT 0.110 (0.560)	DT 0.000 (0.449)	loss 0.129 (0.136)
Valid: [67][20/88]	BT 0.110 (0.483)	DT 0.000 (0.371)	loss 0.131 (0.133)
Valid: [67][30/88]	BT 0.110 (0.462)	DT 0.000 (0.351)	loss 0.186 (0.136)
Valid: [67][40/88]	BT 0.109 (0.450)	DT 0.000 (0.339)	loss 0.125 (0.135)
Valid: [67][50/88]	BT 0.110 (0.442)	DT 0.000 (0.331)	loss 0.140 (0.135)
Valid: [67][60/88]	BT 0.109 (0.443)	DT 0.000 (0.332)	loss 0.131 (0.135)
Valid: [67][70/88]	BT 0.109 (0.438)	DT 0.000 (0.327)	loss 0.137 (0.135)
Valid: [67][80/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.131 (0.135)
Train: [68][10/589]	BT 0.399 (0.765)	DT 0.000 (0.404)	lr 0.0002	loss 0.138 (0.139)
Train: [68][20/589]	BT 0.385 (0.573)	DT 0.000 (0.213)	lr 0.0002	loss 0.127 (0.136)
Train: [68][30/589]	BT 0.357 (0.505)	DT 0.000 (0.146)	lr 0.0002	loss 0.123 (0.135)
Train: [68][40/589]	BT 0.356 (0.470)	DT 0.000 (0.111)	lr 0.0002	loss 0.133 (0.133)
Train: [68][50/589]	BT 0.356 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.114 (0.131)
Train: [68][60/589]	BT 0.368 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.138 (0.130)
Train: [68][70/589]	BT 0.356 (0.427)	DT 0.000 (0.068)	lr 0.0002	loss 0.107 (0.129)
Train: [68][80/589]	BT 0.358 (0.420)	DT 0.000 (0.061)	lr 0.0002	loss 0.130 (0.130)
Train: [68][90/589]	BT 0.357 (0.414)	DT 0.000 (0.055)	lr 0.0002	loss 0.130 (0.131)
Train: [68][100/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.127 (0.131)
Train: [68][110/589]	BT 0.358 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.117 (0.131)
Train: [68][120/589]	BT 0.359 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.127 (0.131)
Train: [68][130/589]	BT 0.366 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.110 (0.131)
Train: [68][140/589]	BT 0.385 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.139 (0.131)
Train: [68][150/589]	BT 0.367 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.131 (0.131)
Train: [68][160/589]	BT 0.367 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.181 (0.131)
Train: [68][170/589]	BT 0.381 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.155 (0.131)
Train: [68][180/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.152 (0.131)
Train: [68][190/589]	BT 0.368 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.131)
Train: [68][200/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.131)
Train: [68][210/589]	BT 0.370 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.131)
Train: [68][220/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.159 (0.131)
Train: [68][230/589]	BT 0.392 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.131)
Train: [68][240/589]	BT 0.362 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.130 (0.131)
Train: [68][250/589]	BT 0.382 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.131)
Train: [68][260/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.117 (0.131)
Train: [68][270/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.131)
Train: [68][280/589]	BT 0.371 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.143 (0.131)
Train: [68][290/589]	BT 0.386 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.175 (0.131)
Train: [68][300/589]	BT 0.357 (0.384)	DT 0.000 (0.023)	lr 0.0002	loss 0.130 (0.132)
Train: [68][310/589]	BT 0.368 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.165 (0.132)
Train: [68][320/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.132)
Train: [68][330/589]	BT 0.360 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.132)
Train: [68][340/589]	BT 0.356 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.132)
Train: [68][350/589]	BT 0.354 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.148 (0.132)
Train: [68][360/589]	BT 0.363 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.144 (0.132)
Train: [68][370/589]	BT 0.360 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.132)
Train: [68][380/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.131)
Train: [68][390/589]	BT 0.355 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.131)
Train: [68][400/589]	BT 0.359 (0.380)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.131)
Train: [68][410/589]	BT 0.360 (0.380)	DT 0.000 (0.019)	lr 0.0002	loss 0.128 (0.131)
Train: [68][420/589]	BT 0.383 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.108 (0.131)
Train: [68][430/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.128 (0.131)
Train: [68][440/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.114 (0.131)
Train: [68][450/589]	BT 0.357 (0.381)	DT 0.000 (0.020)	lr 0.0002	loss 0.134 (0.131)
Train: [68][460/589]	BT 0.360 (0.381)	DT 0.000 (0.020)	lr 0.0002	loss 0.125 (0.131)
Train: [68][470/589]	BT 0.357 (0.381)	DT 0.000 (0.020)	lr 0.0002	loss 0.109 (0.131)
Train: [68][480/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.118 (0.131)
Train: [68][490/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.131)
Train: [68][500/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.131)
Train: [68][510/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.130 (0.131)
Train: [68][520/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.131)
Train: [68][530/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.120 (0.131)
Train: [68][540/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.131)
Train: [68][550/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.111 (0.131)
Train: [68][560/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.123 (0.131)
Train: [68][570/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.140 (0.131)
Train: [68][580/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.154 (0.131)
epoch 68, total time 225.60
loss: 0.1309750453365794@Epoch: 68
learning_rate: 0.0002,68
Valid: [68][10/88]	BT 0.109 (0.570)	DT 0.000 (0.459)	loss 0.147 (0.141)
Valid: [68][20/88]	BT 0.109 (0.492)	DT 0.000 (0.381)	loss 0.124 (0.139)
Valid: [68][30/88]	BT 0.117 (0.471)	DT 0.000 (0.360)	loss 0.138 (0.140)
Valid: [68][40/88]	BT 0.110 (0.463)	DT 0.000 (0.352)	loss 0.128 (0.138)
Valid: [68][50/88]	BT 0.109 (0.455)	DT 0.000 (0.343)	loss 0.127 (0.137)
Valid: [68][60/88]	BT 0.109 (0.448)	DT 0.000 (0.337)	loss 0.133 (0.137)
Valid: [68][70/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.130 (0.136)
Valid: [68][80/88]	BT 0.109 (0.439)	DT 0.000 (0.328)	loss 0.126 (0.136)
Train: [69][10/589]	BT 0.356 (0.774)	DT 0.000 (0.420)	lr 0.0002	loss 0.111 (0.132)
Train: [69][20/589]	BT 0.372 (0.568)	DT 0.000 (0.212)	lr 0.0002	loss 0.143 (0.131)
Train: [69][30/589]	BT 0.375 (0.507)	DT 0.000 (0.150)	lr 0.0002	loss 0.150 (0.133)
Train: [69][40/589]	BT 0.377 (0.479)	DT 0.000 (0.121)	lr 0.0002	loss 0.122 (0.132)
Train: [69][50/589]	BT 0.355 (0.458)	DT 0.000 (0.100)	lr 0.0002	loss 0.134 (0.131)
Train: [69][60/589]	BT 0.356 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.141 (0.131)
Train: [69][70/589]	BT 0.374 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.137 (0.132)
Train: [69][80/589]	BT 0.361 (0.430)	DT 0.000 (0.073)	lr 0.0002	loss 0.131 (0.133)
Train: [69][90/589]	BT 0.381 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.125 (0.132)
Train: [69][100/589]	BT 0.391 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.112 (0.131)
Train: [69][110/589]	BT 0.358 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.124 (0.131)
Train: [69][120/589]	BT 0.360 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.141 (0.131)
Train: [69][130/589]	BT 0.359 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.136 (0.131)
Train: [69][140/589]	BT 0.381 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.116 (0.132)
Train: [69][150/589]	BT 0.368 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.113 (0.131)
Train: [69][160/589]	BT 0.357 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.117 (0.131)
Train: [69][170/589]	BT 0.362 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.120 (0.131)
Train: [69][180/589]	BT 0.380 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.126 (0.131)
Train: [69][190/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.125 (0.131)
Train: [69][200/589]	BT 0.361 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.113 (0.131)
Train: [69][210/589]	BT 0.355 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.128 (0.131)
Train: [69][220/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.124 (0.131)
Train: [69][230/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.155 (0.131)
Train: [69][240/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.155 (0.131)
Train: [69][250/589]	BT 0.358 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.125 (0.131)
Train: [69][260/589]	BT 0.367 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.127 (0.131)
Train: [69][270/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.134 (0.131)
Train: [69][280/589]	BT 0.383 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.132 (0.131)
Train: [69][290/589]	BT 0.363 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.128 (0.131)
Train: [69][300/589]	BT 0.359 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.153 (0.131)
Train: [69][310/589]	BT 0.366 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.112 (0.131)
Train: [69][320/589]	BT 0.370 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.128 (0.131)
Train: [69][330/589]	BT 0.356 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.131 (0.131)
Train: [69][340/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.139 (0.131)
Train: [69][350/589]	BT 0.361 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.132)
Train: [69][360/589]	BT 0.356 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.111 (0.131)
Train: [69][370/589]	BT 0.356 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.123 (0.131)
Train: [69][380/589]	BT 0.354 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.149 (0.131)
Train: [69][390/589]	BT 0.368 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.132 (0.131)
Train: [69][400/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.131)
Train: [69][410/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.123 (0.131)
Train: [69][420/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.119 (0.131)
Train: [69][430/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.142 (0.131)
Train: [69][440/589]	BT 0.366 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.131)
Train: [69][450/589]	BT 0.370 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.132 (0.131)
Train: [69][460/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.143 (0.131)
Train: [69][470/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.129 (0.131)
Train: [69][480/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.131)
Train: [69][490/589]	BT 0.370 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.131)
Train: [69][500/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.111 (0.131)
Train: [69][510/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.131)
Train: [69][520/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.131)
Train: [69][530/589]	BT 0.385 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.147 (0.131)
Train: [69][540/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.131)
Train: [69][550/589]	BT 0.362 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.146 (0.131)
Train: [69][560/589]	BT 0.378 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.131)
Train: [69][570/589]	BT 0.381 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.115 (0.131)
Train: [69][580/589]	BT 0.355 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.121 (0.131)
epoch 69, total time 226.54
loss: 0.13050027573744355@Epoch: 69
learning_rate: 0.0002,69
Valid: [69][10/88]	BT 0.109 (0.575)	DT 0.000 (0.463)	loss 0.130 (0.136)
Valid: [69][20/88]	BT 0.109 (0.503)	DT 0.000 (0.393)	loss 0.111 (0.138)
Valid: [69][30/88]	BT 0.109 (0.476)	DT 0.000 (0.365)	loss 0.127 (0.138)
Valid: [69][40/88]	BT 0.110 (0.461)	DT 0.000 (0.350)	loss 0.114 (0.136)
Valid: [69][50/88]	BT 0.109 (0.449)	DT 0.000 (0.338)	loss 0.125 (0.135)
Valid: [69][60/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.127 (0.134)
Valid: [69][70/88]	BT 0.109 (0.445)	DT 0.000 (0.334)	loss 0.123 (0.134)
Valid: [69][80/88]	BT 0.109 (0.442)	DT 0.000 (0.331)	loss 0.122 (0.135)
Train: [70][10/589]	BT 0.353 (0.761)	DT 0.000 (0.403)	lr 0.0002	loss 0.126 (0.130)
Train: [70][20/589]	BT 0.356 (0.579)	DT 0.000 (0.221)	lr 0.0002	loss 0.123 (0.130)
Train: [70][30/589]	BT 0.355 (0.518)	DT 0.000 (0.161)	lr 0.0002	loss 0.115 (0.129)
Train: [70][40/589]	BT 0.358 (0.486)	DT 0.000 (0.129)	lr 0.0002	loss 0.155 (0.130)
Train: [70][50/589]	BT 0.380 (0.466)	DT 0.000 (0.108)	lr 0.0002	loss 0.121 (0.129)
Train: [70][60/589]	BT 0.357 (0.448)	DT 0.000 (0.091)	lr 0.0002	loss 0.137 (0.129)
Train: [70][70/589]	BT 0.360 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.145 (0.130)
Train: [70][80/589]	BT 0.358 (0.434)	DT 0.000 (0.076)	lr 0.0002	loss 0.154 (0.130)
Train: [70][90/589]	BT 0.376 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.106 (0.130)
Train: [70][100/589]	BT 0.423 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.126 (0.130)
Train: [70][110/589]	BT 0.361 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.134 (0.130)
Train: [70][120/589]	BT 0.362 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.118 (0.130)
Train: [70][130/589]	BT 0.367 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.125 (0.130)
Train: [70][140/589]	BT 0.357 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.109 (0.130)
Train: [70][150/589]	BT 0.359 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.124 (0.130)
Train: [70][160/589]	BT 0.382 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.121 (0.130)
Train: [70][170/589]	BT 0.359 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.114 (0.130)
Train: [70][180/589]	BT 0.385 (0.405)	DT 0.002 (0.045)	lr 0.0002	loss 0.140 (0.130)
Train: [70][190/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.127 (0.130)
Train: [70][200/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.144 (0.130)
Train: [70][210/589]	BT 0.357 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.140 (0.130)
Train: [70][220/589]	BT 0.365 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.100 (0.130)
Train: [70][230/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.128 (0.130)
Train: [70][240/589]	BT 0.379 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.149 (0.130)
Train: [70][250/589]	BT 0.355 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.128 (0.130)
Train: [70][260/589]	BT 0.362 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.151 (0.130)
Train: [70][270/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.113 (0.130)
Train: [70][280/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.120 (0.130)
Train: [70][290/589]	BT 0.357 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.110 (0.130)
Train: [70][300/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.156 (0.130)
Train: [70][310/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.133 (0.131)
Train: [70][320/589]	BT 0.357 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.134 (0.131)
Train: [70][330/589]	BT 0.359 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.163 (0.131)
Train: [70][340/589]	BT 0.360 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.141 (0.131)
Train: [70][350/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.156 (0.131)
Train: [70][360/589]	BT 0.357 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.121 (0.130)
Train: [70][370/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.141 (0.130)
Train: [70][380/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.129 (0.130)
Train: [70][390/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.117 (0.130)
Train: [70][400/589]	BT 0.358 (0.395)	DT 0.001 (0.035)	lr 0.0002	loss 0.128 (0.130)
Train: [70][410/589]	BT 0.356 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.138 (0.130)
Train: [70][420/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.126 (0.130)
Train: [70][430/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.115 (0.130)
Train: [70][440/589]	BT 0.371 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.163 (0.130)
Train: [70][450/589]	BT 0.357 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.147 (0.130)
Train: [70][460/589]	BT 0.391 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.143 (0.130)
Train: [70][470/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.127 (0.130)
Train: [70][480/589]	BT 0.375 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.135 (0.130)
Train: [70][490/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.104 (0.130)
Train: [70][500/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.121 (0.130)
Train: [70][510/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.130)
Train: [70][520/589]	BT 0.363 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.130)
Train: [70][530/589]	BT 0.376 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.130)
Train: [70][540/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.150 (0.130)
Train: [70][550/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.130)
Train: [70][560/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.130)
Train: [70][570/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.130)
Train: [70][580/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.126 (0.130)
epoch 70, total time 228.17
loss: 0.13030023516072878@Epoch: 70
learning_rate: 0.0002,70
Valid: [70][10/88]	BT 0.109 (0.541)	DT 0.000 (0.427)	loss 0.137 (0.132)
Valid: [70][20/88]	BT 0.109 (0.480)	DT 0.000 (0.368)	loss 0.119 (0.134)
Valid: [70][30/88]	BT 0.109 (0.454)	DT 0.000 (0.343)	loss 0.131 (0.139)
Valid: [70][40/88]	BT 0.110 (0.443)	DT 0.000 (0.331)	loss 0.156 (0.136)
Valid: [70][50/88]	BT 0.109 (0.440)	DT 0.000 (0.328)	loss 0.128 (0.137)
Valid: [70][60/88]	BT 0.109 (0.432)	DT 0.000 (0.320)	loss 0.138 (0.136)
Valid: [70][70/88]	BT 0.109 (0.433)	DT 0.000 (0.322)	loss 0.135 (0.135)
Valid: [70][80/88]	BT 0.109 (0.428)	DT 0.000 (0.317)	loss 0.144 (0.134)
Train: [71][10/589]	BT 0.367 (0.737)	DT 0.000 (0.379)	lr 0.0002	loss 0.127 (0.129)
Train: [71][20/589]	BT 0.356 (0.551)	DT 0.000 (0.193)	lr 0.0002	loss 0.116 (0.127)
Train: [71][30/589]	BT 0.357 (0.489)	DT 0.000 (0.132)	lr 0.0002	loss 0.150 (0.128)
Train: [71][40/589]	BT 0.355 (0.459)	DT 0.000 (0.102)	lr 0.0002	loss 0.151 (0.128)
Train: [71][50/589]	BT 0.358 (0.441)	DT 0.000 (0.084)	lr 0.0002	loss 0.120 (0.127)
Train: [71][60/589]	BT 0.357 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.120 (0.128)
Train: [71][70/589]	BT 0.366 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.149 (0.129)
Train: [71][80/589]	BT 0.384 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.133 (0.128)
Train: [71][90/589]	BT 0.356 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.119 (0.128)
Train: [71][100/589]	BT 0.354 (0.407)	DT 0.001 (0.049)	lr 0.0002	loss 0.110 (0.129)
Train: [71][110/589]	BT 0.383 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.132 (0.129)
Train: [71][120/589]	BT 0.407 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.115 (0.129)
Train: [71][130/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.135 (0.129)
Train: [71][140/589]	BT 0.362 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.118 (0.129)
Train: [71][150/589]	BT 0.375 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.153 (0.129)
Train: [71][160/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.129)
Train: [71][170/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.139 (0.130)
Train: [71][180/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.117 (0.129)
Train: [71][190/589]	BT 0.374 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.130)
Train: [71][200/589]	BT 0.369 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.111 (0.129)
Train: [71][210/589]	BT 0.393 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.137 (0.130)
Train: [71][220/589]	BT 0.362 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.130 (0.130)
Train: [71][230/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.130)
Train: [71][240/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.130 (0.130)
Train: [71][250/589]	BT 0.369 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.130)
Train: [71][260/589]	BT 0.360 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.137 (0.130)
Train: [71][270/589]	BT 0.380 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.130)
Train: [71][280/589]	BT 0.360 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.130)
Train: [71][290/589]	BT 0.379 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.130)
Train: [71][300/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.130)
Train: [71][310/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.130)
Train: [71][320/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.128 (0.130)
Train: [71][330/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.130)
Train: [71][340/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.125 (0.130)
Train: [71][350/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.122 (0.130)
Train: [71][360/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.131 (0.130)
Train: [71][370/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.128 (0.130)
Train: [71][380/589]	BT 0.371 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.130)
Train: [71][390/589]	BT 0.375 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.118 (0.129)
Train: [71][400/589]	BT 0.388 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.129)
Train: [71][410/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.107 (0.129)
Train: [71][420/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.127 (0.129)
Train: [71][430/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.097 (0.129)
Train: [71][440/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.129)
Train: [71][450/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.107 (0.129)
Train: [71][460/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.112 (0.129)
Train: [71][470/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.126 (0.130)
Train: [71][480/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.119 (0.130)
Train: [71][490/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.111 (0.130)
Train: [71][500/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.116 (0.130)
Train: [71][510/589]	BT 0.360 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.130)
Train: [71][520/589]	BT 0.360 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.116 (0.130)
Train: [71][530/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.130)
Train: [71][540/589]	BT 0.389 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.130)
Train: [71][550/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.130)
Train: [71][560/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.130)
Train: [71][570/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.122 (0.130)
Train: [71][580/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.163 (0.130)
epoch 71, total time 223.84
loss: 0.129960287233333@Epoch: 71
learning_rate: 0.0002,71
Valid: [71][10/88]	BT 0.109 (0.562)	DT 0.000 (0.451)	loss 0.135 (0.140)
Valid: [71][20/88]	BT 0.109 (0.506)	DT 0.000 (0.396)	loss 0.135 (0.137)
Valid: [71][30/88]	BT 0.110 (0.482)	DT 0.000 (0.372)	loss 0.127 (0.135)
Valid: [71][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.127 (0.137)
Valid: [71][50/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.124 (0.136)
Valid: [71][60/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.135 (0.136)
Valid: [71][70/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.120 (0.136)
Valid: [71][80/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.119 (0.136)
Train: [72][10/589]	BT 0.360 (0.776)	DT 0.000 (0.420)	lr 0.0002	loss 0.128 (0.125)
Train: [72][20/589]	BT 0.357 (0.576)	DT 0.000 (0.220)	lr 0.0002	loss 0.165 (0.128)
Train: [72][30/589]	BT 0.357 (0.512)	DT 0.000 (0.156)	lr 0.0002	loss 0.124 (0.129)
Train: [72][40/589]	BT 0.377 (0.477)	DT 0.000 (0.120)	lr 0.0002	loss 0.121 (0.129)
Train: [72][50/589]	BT 0.373 (0.455)	DT 0.000 (0.098)	lr 0.0002	loss 0.106 (0.128)
Train: [72][60/589]	BT 0.367 (0.439)	DT 0.000 (0.082)	lr 0.0002	loss 0.126 (0.128)
Train: [72][70/589]	BT 0.368 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.117 (0.128)
Train: [72][80/589]	BT 0.357 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.145 (0.128)
Train: [72][90/589]	BT 0.358 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.148 (0.128)
Train: [72][100/589]	BT 0.367 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.132 (0.128)
Train: [72][110/589]	BT 0.365 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.122 (0.128)
Train: [72][120/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.114 (0.128)
Train: [72][130/589]	BT 0.380 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.104 (0.128)
Train: [72][140/589]	BT 0.354 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.123 (0.128)
Train: [72][150/589]	BT 0.404 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.120 (0.128)
Train: [72][160/589]	BT 0.380 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.155 (0.129)
Train: [72][170/589]	BT 0.363 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.127 (0.129)
Train: [72][180/589]	BT 0.355 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.149 (0.129)
Train: [72][190/589]	BT 0.388 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.115 (0.129)
Train: [72][200/589]	BT 0.376 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.129)
Train: [72][210/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.137 (0.129)
Train: [72][220/589]	BT 0.373 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.136 (0.129)
Train: [72][230/589]	BT 0.360 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.157 (0.129)
Train: [72][240/589]	BT 0.371 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.136 (0.129)
Train: [72][250/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.130)
Train: [72][260/589]	BT 0.366 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.156 (0.130)
Train: [72][270/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.130)
Train: [72][280/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.159 (0.130)
Train: [72][290/589]	BT 0.356 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.130)
Train: [72][300/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.130)
Train: [72][310/589]	BT 0.356 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.130)
Train: [72][320/589]	BT 0.360 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.130)
Train: [72][330/589]	BT 0.378 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.133 (0.130)
Train: [72][340/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.118 (0.129)
Train: [72][350/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.130)
Train: [72][360/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.138 (0.130)
Train: [72][370/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.116 (0.130)
Train: [72][380/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.151 (0.130)
Train: [72][390/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.119 (0.130)
Train: [72][400/589]	BT 0.360 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.130)
Train: [72][410/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.105 (0.130)
Train: [72][420/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.130)
Train: [72][430/589]	BT 0.367 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.130)
Train: [72][440/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.130)
Train: [72][450/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.130)
Train: [72][460/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.115 (0.130)
Train: [72][470/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.130)
Train: [72][480/589]	BT 0.381 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.130)
Train: [72][490/589]	BT 0.355 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.130)
Train: [72][500/589]	BT 0.356 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.126 (0.130)
Train: [72][510/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.118 (0.130)
Train: [72][520/589]	BT 0.355 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.114 (0.130)
Train: [72][530/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.130)
Train: [72][540/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.115 (0.130)
Train: [72][550/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.130)
Train: [72][560/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.097 (0.130)
Train: [72][570/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.105 (0.129)
Train: [72][580/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.130)
epoch 72, total time 225.04
loss: 0.1296786862255941@Epoch: 72
learning_rate: 0.0002,72
Valid: [72][10/88]	BT 0.109 (0.565)	DT 0.000 (0.455)	loss 0.145 (0.143)
Valid: [72][20/88]	BT 0.109 (0.495)	DT 0.000 (0.385)	loss 0.163 (0.142)
Valid: [72][30/88]	BT 0.110 (0.470)	DT 0.000 (0.360)	loss 0.112 (0.138)
Valid: [72][40/88]	BT 0.109 (0.454)	DT 0.000 (0.345)	loss 0.125 (0.138)
Valid: [72][50/88]	BT 0.109 (0.448)	DT 0.000 (0.337)	loss 0.148 (0.138)
Valid: [72][60/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.148 (0.137)
Valid: [72][70/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.136 (0.137)
Valid: [72][80/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.120 (0.137)
Train: [73][10/589]	BT 0.385 (0.760)	DT 0.000 (0.401)	lr 0.0002	loss 0.129 (0.130)
Train: [73][20/589]	BT 0.376 (0.572)	DT 0.000 (0.213)	lr 0.0002	loss 0.131 (0.128)
Train: [73][30/589]	BT 0.384 (0.505)	DT 0.000 (0.146)	lr 0.0002	loss 0.144 (0.128)
Train: [73][40/589]	BT 0.370 (0.472)	DT 0.000 (0.113)	lr 0.0002	loss 0.134 (0.130)
Train: [73][50/589]	BT 0.366 (0.452)	DT 0.000 (0.093)	lr 0.0002	loss 0.128 (0.129)
Train: [73][60/589]	BT 0.358 (0.439)	DT 0.000 (0.080)	lr 0.0002	loss 0.108 (0.128)
Train: [73][70/589]	BT 0.381 (0.431)	DT 0.000 (0.072)	lr 0.0002	loss 0.131 (0.129)
Train: [73][80/589]	BT 0.356 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.166 (0.130)
Train: [73][90/589]	BT 0.358 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.120 (0.130)
Train: [73][100/589]	BT 0.382 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.106 (0.130)
Train: [73][110/589]	BT 0.367 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.133 (0.131)
Train: [73][120/589]	BT 0.357 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.143 (0.130)
Train: [73][130/589]	BT 0.360 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.126 (0.130)
Train: [73][140/589]	BT 0.375 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.155 (0.130)
Train: [73][150/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.128 (0.130)
Train: [73][160/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.135 (0.130)
Train: [73][170/589]	BT 0.373 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.114 (0.130)
Train: [73][180/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.120 (0.130)
Train: [73][190/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.130)
Train: [73][200/589]	BT 0.398 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.130)
Train: [73][210/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.148 (0.130)
Train: [73][220/589]	BT 0.360 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.141 (0.131)
Train: [73][230/589]	BT 0.376 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.131)
Train: [73][240/589]	BT 0.363 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.113 (0.131)
Train: [73][250/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.117 (0.131)
Train: [73][260/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.111 (0.131)
Train: [73][270/589]	BT 0.371 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.101 (0.131)
Train: [73][280/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.123 (0.131)
Train: [73][290/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.130)
Train: [73][300/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.135 (0.130)
Train: [73][310/589]	BT 0.355 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.142 (0.130)
Train: [73][320/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.130)
Train: [73][330/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.130)
Train: [73][340/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.150 (0.130)
Train: [73][350/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.118 (0.130)
Train: [73][360/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.117 (0.130)
Train: [73][370/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.154 (0.130)
Train: [73][380/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.137 (0.130)
Train: [73][390/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.129)
Train: [73][400/589]	BT 0.369 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.130)
Train: [73][410/589]	BT 0.355 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.129)
Train: [73][420/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.160 (0.129)
Train: [73][430/589]	BT 0.377 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.130)
Train: [73][440/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.130)
Train: [73][450/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.130)
Train: [73][460/589]	BT 0.387 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.130)
Train: [73][470/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.130)
Train: [73][480/589]	BT 0.355 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.130)
Train: [73][490/589]	BT 0.359 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.129)
Train: [73][500/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.119 (0.129)
Train: [73][510/589]	BT 0.355 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.141 (0.129)
Train: [73][520/589]	BT 0.372 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.117 (0.129)
Train: [73][530/589]	BT 0.360 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.122 (0.129)
Train: [73][540/589]	BT 0.358 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.129)
Train: [73][550/589]	BT 0.358 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.129)
Train: [73][560/589]	BT 0.360 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.130)
Train: [73][570/589]	BT 0.373 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.146 (0.130)
Train: [73][580/589]	BT 0.356 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.110 (0.130)
epoch 73, total time 224.26
loss: 0.12956416882639457@Epoch: 73
learning_rate: 0.0002,73
Valid: [73][10/88]	BT 0.110 (0.559)	DT 0.000 (0.448)	loss 0.146 (0.138)
Valid: [73][20/88]	BT 0.110 (0.489)	DT 0.000 (0.378)	loss 0.127 (0.139)
Valid: [73][30/88]	BT 0.109 (0.469)	DT 0.000 (0.358)	loss 0.156 (0.138)
Valid: [73][40/88]	BT 0.109 (0.458)	DT 0.000 (0.348)	loss 0.129 (0.137)
Valid: [73][50/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.133 (0.137)
Valid: [73][60/88]	BT 0.110 (0.443)	DT 0.000 (0.333)	loss 0.122 (0.137)
Valid: [73][70/88]	BT 0.109 (0.437)	DT 0.000 (0.328)	loss 0.141 (0.136)
Valid: [73][80/88]	BT 0.109 (0.433)	DT 0.000 (0.323)	loss 0.122 (0.136)
Train: [74][10/589]	BT 0.371 (0.767)	DT 0.000 (0.409)	lr 0.0002	loss 0.118 (0.131)
Train: [74][20/589]	BT 0.387 (0.570)	DT 0.000 (0.212)	lr 0.0002	loss 0.150 (0.133)
Train: [74][30/589]	BT 0.371 (0.499)	DT 0.000 (0.142)	lr 0.0002	loss 0.135 (0.131)
Train: [74][40/589]	BT 0.366 (0.466)	DT 0.000 (0.108)	lr 0.0002	loss 0.107 (0.129)
Train: [74][50/589]	BT 0.402 (0.448)	DT 0.000 (0.089)	lr 0.0002	loss 0.131 (0.129)
Train: [74][60/589]	BT 0.359 (0.433)	DT 0.000 (0.074)	lr 0.0002	loss 0.123 (0.130)
Train: [74][70/589]	BT 0.368 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.127 (0.129)
Train: [74][80/589]	BT 0.357 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.107 (0.129)
Train: [74][90/589]	BT 0.360 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.130 (0.129)
Train: [74][100/589]	BT 0.367 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.162 (0.129)
Train: [74][110/589]	BT 0.358 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.143 (0.129)
Train: [74][120/589]	BT 0.357 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.107 (0.130)
Train: [74][130/589]	BT 0.355 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.145 (0.129)
Train: [74][140/589]	BT 0.357 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.116 (0.129)
Train: [74][150/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.120 (0.129)
Train: [74][160/589]	BT 0.357 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.137 (0.129)
Train: [74][170/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.124 (0.129)
Train: [74][180/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.111 (0.129)
Train: [74][190/589]	BT 0.359 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.134 (0.129)
Train: [74][200/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.127 (0.129)
Train: [74][210/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.125 (0.129)
Train: [74][220/589]	BT 0.358 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.137 (0.129)
Train: [74][230/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.107 (0.129)
Train: [74][240/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.129)
Train: [74][250/589]	BT 0.358 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.111 (0.128)
Train: [74][260/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.155 (0.128)
Train: [74][270/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.113 (0.128)
Train: [74][280/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.128)
Train: [74][290/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.128)
Train: [74][300/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.107 (0.129)
Train: [74][310/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.115 (0.128)
Train: [74][320/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.133 (0.129)
Train: [74][330/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.127 (0.129)
Train: [74][340/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.129)
Train: [74][350/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.129)
Train: [74][360/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.114 (0.129)
Train: [74][370/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.129)
Train: [74][380/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.135 (0.129)
Train: [74][390/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.129)
Train: [74][400/589]	BT 0.357 (0.385)	DT 0.000 (0.024)	lr 0.0002	loss 0.111 (0.129)
Train: [74][410/589]	BT 0.357 (0.385)	DT 0.000 (0.024)	lr 0.0002	loss 0.120 (0.129)
Train: [74][420/589]	BT 0.358 (0.385)	DT 0.000 (0.024)	lr 0.0002	loss 0.119 (0.129)
Train: [74][430/589]	BT 0.359 (0.385)	DT 0.000 (0.024)	lr 0.0002	loss 0.118 (0.129)
Train: [74][440/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.142 (0.129)
Train: [74][450/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.129)
Train: [74][460/589]	BT 0.359 (0.384)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.129)
Train: [74][470/589]	BT 0.357 (0.384)	DT 0.000 (0.023)	lr 0.0002	loss 0.128 (0.129)
Train: [74][480/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.147 (0.129)
Train: [74][490/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.129)
Train: [74][500/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.109 (0.129)
Train: [74][510/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.118 (0.129)
Train: [74][520/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.129)
Train: [74][530/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.116 (0.129)
Train: [74][540/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.129)
Train: [74][550/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.129)
Train: [74][560/589]	BT 0.359 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.129)
Train: [74][570/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.129)
Train: [74][580/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.128 (0.129)
epoch 74, total time 226.18
loss: 0.12934179946903668@Epoch: 74
learning_rate: 0.0002,74
Valid: [74][10/88]	BT 0.110 (0.583)	DT 0.000 (0.472)	loss 0.138 (0.139)
Valid: [74][20/88]	BT 0.109 (0.509)	DT 0.000 (0.399)	loss 0.135 (0.139)
Valid: [74][30/88]	BT 0.110 (0.472)	DT 0.000 (0.362)	loss 0.138 (0.137)
Valid: [74][40/88]	BT 0.110 (0.461)	DT 0.000 (0.351)	loss 0.143 (0.135)
Valid: [74][50/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.147 (0.134)
Valid: [74][60/88]	BT 0.109 (0.447)	DT 0.000 (0.338)	loss 0.143 (0.135)
Valid: [74][70/88]	BT 0.109 (0.445)	DT 0.000 (0.336)	loss 0.128 (0.135)
Valid: [74][80/88]	BT 0.109 (0.442)	DT 0.000 (0.332)	loss 0.146 (0.136)
Train: [75][10/589]	BT 0.356 (0.743)	DT 0.000 (0.384)	lr 0.0002	loss 0.123 (0.126)
Train: [75][20/589]	BT 0.354 (0.570)	DT 0.000 (0.213)	lr 0.0002	loss 0.130 (0.126)
Train: [75][30/589]	BT 0.356 (0.503)	DT 0.000 (0.145)	lr 0.0002	loss 0.151 (0.128)
Train: [75][40/589]	BT 0.357 (0.472)	DT 0.000 (0.114)	lr 0.0002	loss 0.122 (0.128)
Train: [75][50/589]	BT 0.368 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.129 (0.129)
Train: [75][60/589]	BT 0.368 (0.436)	DT 0.000 (0.077)	lr 0.0002	loss 0.149 (0.131)
Train: [75][70/589]	BT 0.368 (0.427)	DT 0.000 (0.068)	lr 0.0002	loss 0.125 (0.131)
Train: [75][80/589]	BT 0.367 (0.419)	DT 0.000 (0.060)	lr 0.0002	loss 0.113 (0.130)
Train: [75][90/589]	BT 0.372 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.117 (0.129)
Train: [75][100/589]	BT 0.358 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.121 (0.129)
Train: [75][110/589]	BT 0.379 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.112 (0.129)
Train: [75][120/589]	BT 0.376 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.125 (0.128)
Train: [75][130/589]	BT 0.375 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.119 (0.128)
Train: [75][140/589]	BT 0.360 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.142 (0.128)
Train: [75][150/589]	BT 0.376 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.143 (0.128)
Train: [75][160/589]	BT 0.388 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.119 (0.128)
Train: [75][170/589]	BT 0.381 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.128)
Train: [75][180/589]	BT 0.388 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.135 (0.128)
Train: [75][190/589]	BT 0.386 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.135 (0.128)
Train: [75][200/589]	BT 0.369 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.128)
Train: [75][210/589]	BT 0.356 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.108 (0.128)
Train: [75][220/589]	BT 0.371 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.145 (0.128)
Train: [75][230/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.131 (0.128)
Train: [75][240/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.157 (0.128)
Train: [75][250/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.128)
Train: [75][260/589]	BT 0.381 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.156 (0.128)
Train: [75][270/589]	BT 0.370 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.129)
Train: [75][280/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.143 (0.129)
Train: [75][290/589]	BT 0.382 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.112 (0.129)
Train: [75][300/589]	BT 0.388 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.129)
Train: [75][310/589]	BT 0.382 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.129)
Train: [75][320/589]	BT 0.361 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.150 (0.129)
Train: [75][330/589]	BT 0.387 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.125 (0.129)
Train: [75][340/589]	BT 0.360 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.137 (0.129)
Train: [75][350/589]	BT 0.379 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.123 (0.129)
Train: [75][360/589]	BT 0.356 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.146 (0.129)
Train: [75][370/589]	BT 0.361 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.103 (0.129)
Train: [75][380/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.124 (0.129)
Train: [75][390/589]	BT 0.383 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.116 (0.129)
Train: [75][400/589]	BT 0.356 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.129)
Train: [75][410/589]	BT 0.364 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.148 (0.129)
Train: [75][420/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.113 (0.129)
Train: [75][430/589]	BT 0.381 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.141 (0.129)
Train: [75][440/589]	BT 0.385 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.114 (0.129)
Train: [75][450/589]	BT 0.384 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.120 (0.129)
Train: [75][460/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.125 (0.129)
Train: [75][470/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.111 (0.129)
Train: [75][480/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.114 (0.129)
Train: [75][490/589]	BT 0.357 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.129)
Train: [75][500/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.138 (0.129)
Train: [75][510/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.121 (0.129)
Train: [75][520/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.131 (0.129)
Train: [75][530/589]	BT 0.358 (0.379)	DT 0.000 (0.018)	lr 0.0002	loss 0.130 (0.129)
Train: [75][540/589]	BT 0.370 (0.378)	DT 0.000 (0.018)	lr 0.0002	loss 0.126 (0.129)
Train: [75][550/589]	BT 0.360 (0.378)	DT 0.000 (0.018)	lr 0.0002	loss 0.153 (0.129)
Train: [75][560/589]	BT 0.359 (0.378)	DT 0.000 (0.018)	lr 0.0002	loss 0.157 (0.129)
Train: [75][570/589]	BT 0.357 (0.378)	DT 0.000 (0.018)	lr 0.0002	loss 0.144 (0.129)
Train: [75][580/589]	BT 0.358 (0.378)	DT 0.000 (0.018)	lr 0.0002	loss 0.113 (0.129)
epoch 75, total time 222.25
loss: 0.12910037363806373@Epoch: 75
learning_rate: 0.0002,75
Valid: [75][10/88]	BT 0.109 (0.558)	DT 0.000 (0.442)	loss 0.143 (0.132)
Valid: [75][20/88]	BT 0.109 (0.482)	DT 0.000 (0.369)	loss 0.122 (0.133)
Valid: [75][30/88]	BT 0.109 (0.464)	DT 0.000 (0.352)	loss 0.137 (0.133)
Valid: [75][40/88]	BT 0.110 (0.455)	DT 0.000 (0.344)	loss 0.166 (0.134)
Valid: [75][50/88]	BT 0.109 (0.451)	DT 0.000 (0.341)	loss 0.162 (0.134)
Valid: [75][60/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.126 (0.133)
Valid: [75][70/88]	BT 0.109 (0.439)	DT 0.000 (0.329)	loss 0.147 (0.134)
Valid: [75][80/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.130 (0.134)
Train: [76][10/589]	BT 0.356 (0.742)	DT 0.000 (0.386)	lr 0.0002	loss 0.117 (0.124)
Train: [76][20/589]	BT 0.367 (0.558)	DT 0.000 (0.202)	lr 0.0002	loss 0.137 (0.127)
Train: [76][30/589]	BT 0.357 (0.498)	DT 0.000 (0.142)	lr 0.0002	loss 0.134 (0.128)
Train: [76][40/589]	BT 0.401 (0.470)	DT 0.000 (0.112)	lr 0.0002	loss 0.115 (0.127)
Train: [76][50/589]	BT 0.364 (0.449)	DT 0.000 (0.091)	lr 0.0002	loss 0.114 (0.128)
Train: [76][60/589]	BT 0.356 (0.433)	DT 0.000 (0.076)	lr 0.0002	loss 0.117 (0.129)
Train: [76][70/589]	BT 0.383 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.119 (0.129)
Train: [76][80/589]	BT 0.355 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.128 (0.129)
Train: [76][90/589]	BT 0.373 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.129 (0.128)
Train: [76][100/589]	BT 0.389 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.144 (0.129)
Train: [76][110/589]	BT 0.378 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.124 (0.128)
Train: [76][120/589]	BT 0.371 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.125 (0.128)
Train: [76][130/589]	BT 0.359 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.120 (0.128)
Train: [76][140/589]	BT 0.360 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.110 (0.128)
Train: [76][150/589]	BT 0.360 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.118 (0.128)
Train: [76][160/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.120 (0.128)
Train: [76][170/589]	BT 0.356 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.137 (0.128)
Train: [76][180/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.132 (0.128)
Train: [76][190/589]	BT 0.356 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.145 (0.128)
Train: [76][200/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.128)
Train: [76][210/589]	BT 0.383 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.127)
Train: [76][220/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.127)
Train: [76][230/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.149 (0.127)
Train: [76][240/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.147 (0.127)
Train: [76][250/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.148 (0.128)
Train: [76][260/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.123 (0.128)
Train: [76][270/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.128)
Train: [76][280/589]	BT 0.356 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.119 (0.128)
Train: [76][290/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.137 (0.128)
Train: [76][300/589]	BT 0.355 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.147 (0.128)
Train: [76][310/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.128)
Train: [76][320/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.135 (0.128)
Train: [76][330/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.117 (0.128)
Train: [76][340/589]	BT 0.384 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.135 (0.128)
Train: [76][350/589]	BT 0.378 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.128)
Train: [76][360/589]	BT 0.362 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.125 (0.129)
Train: [76][370/589]	BT 0.354 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.129)
Train: [76][380/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.129)
Train: [76][390/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.129)
Train: [76][400/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.129)
Train: [76][410/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.114 (0.129)
Train: [76][420/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.129 (0.129)
Train: [76][430/589]	BT 0.376 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.163 (0.129)
Train: [76][440/589]	BT 0.361 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.129)
Train: [76][450/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.129)
Train: [76][460/589]	BT 0.364 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.129)
Train: [76][470/589]	BT 0.360 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.129)
Train: [76][480/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.129)
Train: [76][490/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.153 (0.129)
Train: [76][500/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.121 (0.129)
Train: [76][510/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.127 (0.129)
Train: [76][520/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.160 (0.129)
Train: [76][530/589]	BT 0.359 (0.381)	DT 0.001 (0.022)	lr 0.0002	loss 0.119 (0.129)
Train: [76][540/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.125 (0.129)
Train: [76][550/589]	BT 0.367 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.142 (0.129)
Train: [76][560/589]	BT 0.359 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.144 (0.129)
Train: [76][570/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.129)
Train: [76][580/589]	BT 0.379 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.129)
epoch 76, total time 223.68
loss: 0.1289665149162726@Epoch: 76
learning_rate: 0.0002,76
Valid: [76][10/88]	BT 0.110 (0.573)	DT 0.000 (0.462)	loss 0.146 (0.136)
Valid: [76][20/88]	BT 0.109 (0.497)	DT 0.000 (0.386)	loss 0.137 (0.139)
Valid: [76][30/88]	BT 0.110 (0.471)	DT 0.000 (0.361)	loss 0.121 (0.138)
Valid: [76][40/88]	BT 0.110 (0.459)	DT 0.000 (0.348)	loss 0.137 (0.137)
Valid: [76][50/88]	BT 0.109 (0.455)	DT 0.000 (0.345)	loss 0.129 (0.135)
Valid: [76][60/88]	BT 0.110 (0.456)	DT 0.000 (0.346)	loss 0.108 (0.135)
Valid: [76][70/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.138 (0.136)
Valid: [76][80/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.138 (0.135)
Train: [77][10/589]	BT 0.357 (0.768)	DT 0.000 (0.413)	lr 0.0002	loss 0.131 (0.133)
Train: [77][20/589]	BT 0.398 (0.578)	DT 0.000 (0.221)	lr 0.0002	loss 0.135 (0.133)
Train: [77][30/589]	BT 0.382 (0.514)	DT 0.000 (0.156)	lr 0.0002	loss 0.124 (0.131)
Train: [77][40/589]	BT 0.376 (0.483)	DT 0.000 (0.125)	lr 0.0002	loss 0.131 (0.129)
Train: [77][50/589]	BT 0.408 (0.460)	DT 0.000 (0.101)	lr 0.0002	loss 0.114 (0.129)
Train: [77][60/589]	BT 0.358 (0.446)	DT 0.000 (0.087)	lr 0.0002	loss 0.132 (0.129)
Train: [77][70/589]	BT 0.358 (0.437)	DT 0.000 (0.078)	lr 0.0002	loss 0.146 (0.129)
Train: [77][80/589]	BT 0.361 (0.430)	DT 0.000 (0.071)	lr 0.0002	loss 0.116 (0.129)
Train: [77][90/589]	BT 0.369 (0.424)	DT 0.000 (0.064)	lr 0.0002	loss 0.137 (0.128)
Train: [77][100/589]	BT 0.407 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.154 (0.128)
Train: [77][110/589]	BT 0.375 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.130 (0.128)
Train: [77][120/589]	BT 0.356 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.089 (0.128)
Train: [77][130/589]	BT 0.378 (0.407)	DT 0.000 (0.047)	lr 0.0002	loss 0.133 (0.128)
Train: [77][140/589]	BT 0.355 (0.404)	DT 0.000 (0.044)	lr 0.0002	loss 0.138 (0.127)
Train: [77][150/589]	BT 0.374 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.161 (0.128)
Train: [77][160/589]	BT 0.360 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.149 (0.128)
Train: [77][170/589]	BT 0.364 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.130 (0.128)
Train: [77][180/589]	BT 0.376 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.140 (0.128)
Train: [77][190/589]	BT 0.357 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.126 (0.128)
Train: [77][200/589]	BT 0.356 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.159 (0.128)
Train: [77][210/589]	BT 0.380 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.116 (0.128)
Train: [77][220/589]	BT 0.356 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.135 (0.128)
Train: [77][230/589]	BT 0.368 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.139 (0.128)
Train: [77][240/589]	BT 0.358 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.141 (0.128)
Train: [77][250/589]	BT 0.357 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.091 (0.128)
Train: [77][260/589]	BT 0.358 (0.393)	DT 0.000 (0.032)	lr 0.0002	loss 0.151 (0.128)
Train: [77][270/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.128)
Train: [77][280/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.113 (0.128)
Train: [77][290/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.119 (0.128)
Train: [77][300/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.153 (0.128)
Train: [77][310/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.152 (0.129)
Train: [77][320/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.110 (0.128)
Train: [77][330/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.128)
Train: [77][340/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.123 (0.128)
Train: [77][350/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.118 (0.128)
Train: [77][360/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.128)
Train: [77][370/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.118 (0.128)
Train: [77][380/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.128)
Train: [77][390/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.148 (0.128)
Train: [77][400/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.128)
Train: [77][410/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.154 (0.128)
Train: [77][420/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.123 (0.128)
Train: [77][430/589]	BT 0.360 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.106 (0.128)
Train: [77][440/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.128)
Train: [77][450/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.118 (0.128)
Train: [77][460/589]	BT 0.360 (0.385)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.128)
Train: [77][470/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.128)
Train: [77][480/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.119 (0.128)
Train: [77][490/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.128)
Train: [77][500/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.134 (0.128)
Train: [77][510/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.140 (0.128)
Train: [77][520/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.147 (0.128)
Train: [77][530/589]	BT 0.374 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.117 (0.128)
Train: [77][540/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.144 (0.128)
Train: [77][550/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.128)
Train: [77][560/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.129)
Train: [77][570/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.129)
Train: [77][580/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.129)
epoch 77, total time 225.81
loss: 0.12864980638812296@Epoch: 77
learning_rate: 0.0002,77
Valid: [77][10/88]	BT 0.109 (0.554)	DT 0.000 (0.441)	loss 0.151 (0.132)
Valid: [77][20/88]	BT 0.109 (0.476)	DT 0.000 (0.362)	loss 0.142 (0.133)
Valid: [77][30/88]	BT 0.109 (0.454)	DT 0.000 (0.341)	loss 0.103 (0.133)
Valid: [77][40/88]	BT 0.109 (0.447)	DT 0.000 (0.334)	loss 0.145 (0.134)
Valid: [77][50/88]	BT 0.110 (0.440)	DT 0.000 (0.328)	loss 0.129 (0.136)
Valid: [77][60/88]	BT 0.110 (0.434)	DT 0.000 (0.322)	loss 0.138 (0.136)
Valid: [77][70/88]	BT 0.109 (0.429)	DT 0.000 (0.317)	loss 0.130 (0.136)
Valid: [77][80/88]	BT 0.109 (0.428)	DT 0.000 (0.317)	loss 0.128 (0.136)
Train: [78][10/589]	BT 0.357 (0.755)	DT 0.000 (0.398)	lr 0.0002	loss 0.121 (0.128)
Train: [78][20/589]	BT 0.358 (0.564)	DT 0.000 (0.208)	lr 0.0002	loss 0.125 (0.130)
Train: [78][30/589]	BT 0.356 (0.500)	DT 0.000 (0.144)	lr 0.0002	loss 0.122 (0.127)
Train: [78][40/589]	BT 0.397 (0.474)	DT 0.000 (0.116)	lr 0.0002	loss 0.121 (0.127)
Train: [78][50/589]	BT 0.377 (0.451)	DT 0.000 (0.094)	lr 0.0002	loss 0.133 (0.126)
Train: [78][60/589]	BT 0.373 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.147 (0.126)
Train: [78][70/589]	BT 0.380 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.124 (0.126)
Train: [78][80/589]	BT 0.380 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.119 (0.127)
Train: [78][90/589]	BT 0.379 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.138 (0.127)
Train: [78][100/589]	BT 0.367 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.140 (0.127)
Train: [78][110/589]	BT 0.371 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.127 (0.126)
Train: [78][120/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.121 (0.126)
Train: [78][130/589]	BT 0.359 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.142 (0.126)
Train: [78][140/589]	BT 0.381 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.119 (0.126)
Train: [78][150/589]	BT 0.367 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.144 (0.126)
Train: [78][160/589]	BT 0.382 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.121 (0.127)
Train: [78][170/589]	BT 0.377 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.134 (0.127)
Train: [78][180/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.143 (0.128)
Train: [78][190/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.138 (0.128)
Train: [78][200/589]	BT 0.359 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.151 (0.128)
Train: [78][210/589]	BT 0.360 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.141 (0.128)
Train: [78][220/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.127 (0.128)
Train: [78][230/589]	BT 0.356 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.128)
Train: [78][240/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.154 (0.128)
Train: [78][250/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.128)
Train: [78][260/589]	BT 0.355 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.118 (0.128)
Train: [78][270/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.128)
Train: [78][280/589]	BT 0.376 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.128)
Train: [78][290/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.121 (0.128)
Train: [78][300/589]	BT 0.380 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.128)
Train: [78][310/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.128)
Train: [78][320/589]	BT 0.355 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.114 (0.128)
Train: [78][330/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.128)
Train: [78][340/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.116 (0.128)
Train: [78][350/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.128)
Train: [78][360/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.128)
Train: [78][370/589]	BT 0.373 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.128)
Train: [78][380/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.103 (0.128)
Train: [78][390/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.128)
Train: [78][400/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.155 (0.128)
Train: [78][410/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.117 (0.128)
Train: [78][420/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.128)
Train: [78][430/589]	BT 0.363 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.146 (0.129)
Train: [78][440/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.145 (0.129)
Train: [78][450/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.106 (0.128)
Train: [78][460/589]	BT 0.366 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.129)
Train: [78][470/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.126 (0.129)
Train: [78][480/589]	BT 0.356 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.129)
Train: [78][490/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.117 (0.129)
Train: [78][500/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.108 (0.129)
Train: [78][510/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.129)
Train: [78][520/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.129)
Train: [78][530/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.129 (0.129)
Train: [78][540/589]	BT 0.361 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.129)
Train: [78][550/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.139 (0.129)
Train: [78][560/589]	BT 0.364 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.148 (0.129)
Train: [78][570/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.118 (0.129)
Train: [78][580/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.129)
epoch 78, total time 224.22
loss: 0.12879683379030846@Epoch: 78
learning_rate: 0.0002,78
Valid: [78][10/88]	BT 0.110 (0.547)	DT 0.000 (0.435)	loss 0.136 (0.138)
Valid: [78][20/88]	BT 0.110 (0.477)	DT 0.000 (0.366)	loss 0.138 (0.135)
Valid: [78][30/88]	BT 0.109 (0.464)	DT 0.000 (0.354)	loss 0.146 (0.138)
Valid: [78][40/88]	BT 0.110 (0.448)	DT 0.000 (0.338)	loss 0.154 (0.136)
Valid: [78][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.145 (0.135)
Valid: [78][60/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.130 (0.137)
Valid: [78][70/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.143 (0.138)
Valid: [78][80/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.149 (0.138)
Train: [79][10/589]	BT 0.356 (0.734)	DT 0.000 (0.377)	lr 0.0002	loss 0.152 (0.132)
Train: [79][20/589]	BT 0.354 (0.550)	DT 0.000 (0.192)	lr 0.0002	loss 0.129 (0.129)
Train: [79][30/589]	BT 0.356 (0.495)	DT 0.000 (0.138)	lr 0.0002	loss 0.124 (0.130)
Train: [79][40/589]	BT 0.356 (0.465)	DT 0.000 (0.108)	lr 0.0002	loss 0.126 (0.131)
Train: [79][50/589]	BT 0.357 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.134 (0.131)
Train: [79][60/589]	BT 0.357 (0.434)	DT 0.000 (0.077)	lr 0.0002	loss 0.124 (0.129)
Train: [79][70/589]	BT 0.357 (0.425)	DT 0.000 (0.068)	lr 0.0002	loss 0.106 (0.128)
Train: [79][80/589]	BT 0.358 (0.422)	DT 0.000 (0.065)	lr 0.0002	loss 0.113 (0.128)
Train: [79][90/589]	BT 0.357 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.139 (0.128)
Train: [79][100/589]	BT 0.358 (0.413)	DT 0.000 (0.056)	lr 0.0002	loss 0.140 (0.128)
Train: [79][110/589]	BT 0.357 (0.410)	DT 0.000 (0.053)	lr 0.0002	loss 0.136 (0.129)
Train: [79][120/589]	BT 0.357 (0.407)	DT 0.000 (0.050)	lr 0.0002	loss 0.151 (0.128)
Train: [79][130/589]	BT 0.357 (0.405)	DT 0.000 (0.048)	lr 0.0002	loss 0.148 (0.129)
Train: [79][140/589]	BT 0.358 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.117 (0.129)
Train: [79][150/589]	BT 0.371 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.113 (0.128)
Train: [79][160/589]	BT 0.356 (0.401)	DT 0.000 (0.044)	lr 0.0002	loss 0.119 (0.128)
Train: [79][170/589]	BT 0.372 (0.400)	DT 0.000 (0.043)	lr 0.0002	loss 0.146 (0.128)
Train: [79][180/589]	BT 0.359 (0.399)	DT 0.000 (0.042)	lr 0.0002	loss 0.135 (0.128)
Train: [79][190/589]	BT 0.356 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.141 (0.128)
Train: [79][200/589]	BT 0.357 (0.397)	DT 0.000 (0.040)	lr 0.0002	loss 0.117 (0.128)
Train: [79][210/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.135 (0.128)
Train: [79][220/589]	BT 0.359 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.135 (0.129)
Train: [79][230/589]	BT 0.356 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.148 (0.129)
Train: [79][240/589]	BT 0.357 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.110 (0.128)
Train: [79][250/589]	BT 0.388 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.107 (0.128)
Train: [79][260/589]	BT 0.358 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.142 (0.128)
Train: [79][270/589]	BT 0.357 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.124 (0.128)
Train: [79][280/589]	BT 0.370 (0.393)	DT 0.000 (0.036)	lr 0.0002	loss 0.115 (0.128)
Train: [79][290/589]	BT 0.368 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.128)
Train: [79][300/589]	BT 0.377 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.132 (0.128)
Train: [79][310/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.128)
Train: [79][320/589]	BT 0.360 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.141 (0.128)
Train: [79][330/589]	BT 0.365 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.130 (0.128)
Train: [79][340/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.128)
Train: [79][350/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.118 (0.128)
Train: [79][360/589]	BT 0.358 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.136 (0.128)
Train: [79][370/589]	BT 0.383 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.119 (0.128)
Train: [79][380/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.105 (0.128)
Train: [79][390/589]	BT 0.360 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.132 (0.128)
Train: [79][400/589]	BT 0.360 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.149 (0.128)
Train: [79][410/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.111 (0.128)
Train: [79][420/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.124 (0.128)
Train: [79][430/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.124 (0.128)
Train: [79][440/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.125 (0.128)
Train: [79][450/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.126 (0.128)
Train: [79][460/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.140 (0.128)
Train: [79][470/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.128)
Train: [79][480/589]	BT 0.368 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.116 (0.128)
Train: [79][490/589]	BT 0.357 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.118 (0.128)
Train: [79][500/589]	BT 0.371 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.119 (0.128)
Train: [79][510/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.132 (0.128)
Train: [79][520/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.146 (0.128)
Train: [79][530/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.128 (0.128)
Train: [79][540/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.128)
Train: [79][550/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.128)
Train: [79][560/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.125 (0.128)
Train: [79][570/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.128)
Train: [79][580/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.116 (0.128)
epoch 79, total time 229.34
loss: 0.1282474668777645@Epoch: 79
learning_rate: 0.0002,79
Valid: [79][10/88]	BT 0.109 (0.588)	DT 0.000 (0.476)	loss 0.183 (0.143)
Valid: [79][20/88]	BT 0.109 (0.506)	DT 0.000 (0.395)	loss 0.120 (0.140)
Valid: [79][30/88]	BT 0.109 (0.481)	DT 0.000 (0.371)	loss 0.164 (0.139)
Valid: [79][40/88]	BT 0.109 (0.472)	DT 0.000 (0.362)	loss 0.165 (0.137)
Valid: [79][50/88]	BT 0.109 (0.462)	DT 0.000 (0.352)	loss 0.158 (0.138)
Valid: [79][60/88]	BT 0.109 (0.457)	DT 0.000 (0.347)	loss 0.139 (0.137)
Valid: [79][70/88]	BT 0.109 (0.453)	DT 0.000 (0.343)	loss 0.154 (0.136)
Valid: [79][80/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.135 (0.135)
Train: [80][10/589]	BT 0.356 (0.777)	DT 0.000 (0.422)	lr 0.0002	loss 0.147 (0.128)
Train: [80][20/589]	BT 0.354 (0.574)	DT 0.000 (0.218)	lr 0.0002	loss 0.095 (0.125)
Train: [80][30/589]	BT 0.356 (0.507)	DT 0.000 (0.151)	lr 0.0002	loss 0.141 (0.129)
Train: [80][40/589]	BT 0.356 (0.475)	DT 0.000 (0.119)	lr 0.0002	loss 0.150 (0.129)
Train: [80][50/589]	BT 0.359 (0.460)	DT 0.000 (0.103)	lr 0.0002	loss 0.129 (0.129)
Train: [80][60/589]	BT 0.357 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.140 (0.129)
Train: [80][70/589]	BT 0.372 (0.444)	DT 0.000 (0.086)	lr 0.0002	loss 0.126 (0.128)
Train: [80][80/589]	BT 0.356 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.133 (0.128)
Train: [80][90/589]	BT 0.358 (0.431)	DT 0.000 (0.074)	lr 0.0002	loss 0.124 (0.128)
Train: [80][100/589]	BT 0.377 (0.428)	DT 0.000 (0.071)	lr 0.0002	loss 0.145 (0.128)
Train: [80][110/589]	BT 0.357 (0.424)	DT 0.000 (0.067)	lr 0.0002	loss 0.116 (0.128)
Train: [80][120/589]	BT 0.359 (0.423)	DT 0.000 (0.066)	lr 0.0002	loss 0.123 (0.127)
Train: [80][130/589]	BT 0.358 (0.421)	DT 0.000 (0.064)	lr 0.0002	loss 0.138 (0.127)
Train: [80][140/589]	BT 0.364 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.110 (0.126)
Train: [80][150/589]	BT 0.363 (0.416)	DT 0.000 (0.059)	lr 0.0002	loss 0.143 (0.127)
Train: [80][160/589]	BT 0.354 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.127 (0.127)
Train: [80][170/589]	BT 0.381 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.143 (0.127)
Train: [80][180/589]	BT 0.355 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.139 (0.128)
Train: [80][190/589]	BT 0.382 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.114 (0.128)
Train: [80][200/589]	BT 0.357 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.116 (0.128)
Train: [80][210/589]	BT 0.363 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.139 (0.128)
Train: [80][220/589]	BT 0.355 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.157 (0.128)
Train: [80][230/589]	BT 0.355 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.109 (0.128)
Train: [80][240/589]	BT 0.360 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.120 (0.128)
Train: [80][250/589]	BT 0.359 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.104 (0.128)
Train: [80][260/589]	BT 0.359 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.114 (0.128)
Train: [80][270/589]	BT 0.358 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.127 (0.128)
Train: [80][280/589]	BT 0.361 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.125 (0.128)
Train: [80][290/589]	BT 0.358 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.145 (0.128)
Train: [80][300/589]	BT 0.359 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.109 (0.128)
Train: [80][310/589]	BT 0.359 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.132 (0.127)
Train: [80][320/589]	BT 0.357 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.115 (0.127)
Train: [80][330/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.148 (0.128)
Train: [80][340/589]	BT 0.358 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.113 (0.127)
Train: [80][350/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.117 (0.127)
Train: [80][360/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.126 (0.127)
Train: [80][370/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.124 (0.127)
Train: [80][380/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.133 (0.127)
Train: [80][390/589]	BT 0.356 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.107 (0.127)
Train: [80][400/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.125 (0.127)
Train: [80][410/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.134 (0.127)
Train: [80][420/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.103 (0.127)
Train: [80][430/589]	BT 0.357 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.117 (0.128)
Train: [80][440/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.128)
Train: [80][450/589]	BT 0.386 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.118 (0.128)
Train: [80][460/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.141 (0.128)
Train: [80][470/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.152 (0.128)
Train: [80][480/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.150 (0.128)
Train: [80][490/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.104 (0.128)
Train: [80][500/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.128)
Train: [80][510/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.142 (0.128)
Train: [80][520/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.122 (0.128)
Train: [80][530/589]	BT 0.360 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.130 (0.128)
Train: [80][540/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.123 (0.128)
Train: [80][550/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.108 (0.128)
Train: [80][560/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.128)
Train: [80][570/589]	BT 0.360 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.123 (0.128)
Train: [80][580/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.106 (0.128)
epoch 80, total time 229.08
loss: 0.12818143993698414@Epoch: 80
learning_rate: 0.0002,80
Valid: [80][10/88]	BT 0.110 (0.593)	DT 0.000 (0.481)	loss 0.141 (0.146)
Valid: [80][20/88]	BT 0.110 (0.503)	DT 0.000 (0.393)	loss 0.117 (0.141)
Valid: [80][30/88]	BT 0.110 (0.479)	DT 0.000 (0.369)	loss 0.141 (0.139)
Valid: [80][40/88]	BT 0.109 (0.465)	DT 0.000 (0.355)	loss 0.128 (0.138)
Valid: [80][50/88]	BT 0.109 (0.457)	DT 0.000 (0.347)	loss 0.144 (0.137)
Valid: [80][60/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.135 (0.137)
Valid: [80][70/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.117 (0.136)
Valid: [80][80/88]	BT 0.109 (0.438)	DT 0.000 (0.328)	loss 0.143 (0.137)
Train: [81][10/589]	BT 0.357 (0.770)	DT 0.000 (0.413)	lr 0.0002	loss 0.111 (0.125)
Train: [81][20/589]	BT 0.355 (0.575)	DT 0.000 (0.218)	lr 0.0002	loss 0.118 (0.124)
Train: [81][30/589]	BT 0.377 (0.521)	DT 0.000 (0.164)	lr 0.0002	loss 0.138 (0.125)
Train: [81][40/589]	BT 0.369 (0.485)	DT 0.000 (0.127)	lr 0.0002	loss 0.130 (0.126)
Train: [81][50/589]	BT 0.367 (0.462)	DT 0.000 (0.104)	lr 0.0002	loss 0.133 (0.127)
Train: [81][60/589]	BT 0.362 (0.451)	DT 0.000 (0.094)	lr 0.0002	loss 0.137 (0.127)
Train: [81][70/589]	BT 0.353 (0.441)	DT 0.000 (0.083)	lr 0.0002	loss 0.133 (0.126)
Train: [81][80/589]	BT 0.356 (0.431)	DT 0.000 (0.074)	lr 0.0002	loss 0.121 (0.126)
Train: [81][90/589]	BT 0.362 (0.426)	DT 0.000 (0.069)	lr 0.0002	loss 0.145 (0.127)
Train: [81][100/589]	BT 0.367 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.123 (0.127)
Train: [81][110/589]	BT 0.358 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.107 (0.127)
Train: [81][120/589]	BT 0.358 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.123 (0.127)
Train: [81][130/589]	BT 0.359 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.135 (0.127)
Train: [81][140/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.115 (0.127)
Train: [81][150/589]	BT 0.387 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.131 (0.127)
Train: [81][160/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.121 (0.128)
Train: [81][170/589]	BT 0.366 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.115 (0.128)
Train: [81][180/589]	BT 0.357 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.147 (0.127)
Train: [81][190/589]	BT 0.359 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.129 (0.127)
Train: [81][200/589]	BT 0.372 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.115 (0.127)
Train: [81][210/589]	BT 0.358 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.136 (0.128)
Train: [81][220/589]	BT 0.356 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.122 (0.128)
Train: [81][230/589]	BT 0.357 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.129 (0.127)
Train: [81][240/589]	BT 0.361 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.145 (0.128)
Train: [81][250/589]	BT 0.358 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.124 (0.128)
Train: [81][260/589]	BT 0.374 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.101 (0.127)
Train: [81][270/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.118 (0.127)
Train: [81][280/589]	BT 0.366 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.138 (0.127)
Train: [81][290/589]	BT 0.363 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.118 (0.127)
Train: [81][300/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.112 (0.127)
Train: [81][310/589]	BT 0.355 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.125 (0.127)
Train: [81][320/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.143 (0.127)
Train: [81][330/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.158 (0.128)
Train: [81][340/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.125 (0.128)
Train: [81][350/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.124 (0.128)
Train: [81][360/589]	BT 0.359 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.154 (0.128)
Train: [81][370/589]	BT 0.358 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.128)
Train: [81][380/589]	BT 0.357 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.148 (0.128)
Train: [81][390/589]	BT 0.383 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.114 (0.128)
Train: [81][400/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.133 (0.128)
Train: [81][410/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.128)
Train: [81][420/589]	BT 0.360 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.148 (0.128)
Train: [81][430/589]	BT 0.356 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.157 (0.128)
Train: [81][440/589]	BT 0.357 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.120 (0.128)
Train: [81][450/589]	BT 0.358 (0.392)	DT 0.001 (0.033)	lr 0.0002	loss 0.113 (0.128)
Train: [81][460/589]	BT 0.378 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.142 (0.128)
Train: [81][470/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.137 (0.128)
Train: [81][480/589]	BT 0.354 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.126 (0.128)
Train: [81][490/589]	BT 0.374 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.151 (0.128)
Train: [81][500/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.134 (0.128)
Train: [81][510/589]	BT 0.357 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.116 (0.128)
Train: [81][520/589]	BT 0.356 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.146 (0.128)
Train: [81][530/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.116 (0.128)
Train: [81][540/589]	BT 0.363 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.113 (0.128)
Train: [81][550/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.143 (0.128)
Train: [81][560/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.146 (0.128)
Train: [81][570/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.124 (0.128)
Train: [81][580/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.139 (0.128)
epoch 81, total time 229.65
loss: 0.12805670877633288@Epoch: 81
learning_rate: 0.0002,81
Valid: [81][10/88]	BT 0.110 (0.585)	DT 0.000 (0.475)	loss 0.147 (0.135)
Valid: [81][20/88]	BT 0.110 (0.504)	DT 0.000 (0.393)	loss 0.147 (0.132)
Valid: [81][30/88]	BT 0.110 (0.482)	DT 0.000 (0.372)	loss 0.149 (0.137)
Valid: [81][40/88]	BT 0.109 (0.466)	DT 0.000 (0.355)	loss 0.150 (0.136)
Valid: [81][50/88]	BT 0.109 (0.459)	DT 0.000 (0.348)	loss 0.141 (0.135)
Valid: [81][60/88]	BT 0.109 (0.454)	DT 0.000 (0.344)	loss 0.108 (0.134)
Valid: [81][70/88]	BT 0.110 (0.451)	DT 0.000 (0.340)	loss 0.130 (0.134)
Valid: [81][80/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.131 (0.134)
Train: [82][10/589]	BT 0.362 (0.768)	DT 0.000 (0.411)	lr 0.0002	loss 0.110 (0.126)
Train: [82][20/589]	BT 0.362 (0.578)	DT 0.000 (0.221)	lr 0.0002	loss 0.121 (0.124)
Train: [82][30/589]	BT 0.357 (0.513)	DT 0.000 (0.156)	lr 0.0002	loss 0.124 (0.124)
Train: [82][40/589]	BT 0.392 (0.482)	DT 0.000 (0.124)	lr 0.0002	loss 0.137 (0.126)
Train: [82][50/589]	BT 0.356 (0.461)	DT 0.000 (0.103)	lr 0.0002	loss 0.111 (0.126)
Train: [82][60/589]	BT 0.361 (0.448)	DT 0.000 (0.090)	lr 0.0002	loss 0.142 (0.125)
Train: [82][70/589]	BT 0.360 (0.440)	DT 0.000 (0.082)	lr 0.0002	loss 0.114 (0.126)
Train: [82][80/589]	BT 0.364 (0.432)	DT 0.000 (0.074)	lr 0.0002	loss 0.121 (0.126)
Train: [82][90/589]	BT 0.357 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.157 (0.127)
Train: [82][100/589]	BT 0.367 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.135 (0.128)
Train: [82][110/589]	BT 0.357 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.146 (0.128)
Train: [82][120/589]	BT 0.382 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.121 (0.128)
Train: [82][130/589]	BT 0.358 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.125 (0.128)
Train: [82][140/589]	BT 0.384 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.138 (0.128)
Train: [82][150/589]	BT 0.392 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.130 (0.128)
Train: [82][160/589]	BT 0.360 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.105 (0.128)
Train: [82][170/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.126 (0.128)
Train: [82][180/589]	BT 0.377 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.129 (0.127)
Train: [82][190/589]	BT 0.359 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.134 (0.128)
Train: [82][200/589]	BT 0.396 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.124 (0.128)
Train: [82][210/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.117 (0.128)
Train: [82][220/589]	BT 0.371 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.118 (0.128)
Train: [82][230/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.127)
Train: [82][240/589]	BT 0.378 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.155 (0.127)
Train: [82][250/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.127)
Train: [82][260/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.117 (0.127)
Train: [82][270/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.128)
Train: [82][280/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.157 (0.128)
Train: [82][290/589]	BT 0.384 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.110 (0.128)
Train: [82][300/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.128)
Train: [82][310/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.112 (0.128)
Train: [82][320/589]	BT 0.356 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.128)
Train: [82][330/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.128)
Train: [82][340/589]	BT 0.361 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.123 (0.128)
Train: [82][350/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.129 (0.128)
Train: [82][360/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.128)
Train: [82][370/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.128)
Train: [82][380/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.139 (0.127)
Train: [82][390/589]	BT 0.358 (0.388)	DT 0.001 (0.028)	lr 0.0002	loss 0.119 (0.127)
Train: [82][400/589]	BT 0.360 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.127)
Train: [82][410/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.127)
Train: [82][420/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.114 (0.127)
Train: [82][430/589]	BT 0.361 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.144 (0.127)
Train: [82][440/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.146 (0.127)
Train: [82][450/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.127)
Train: [82][460/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.127)
Train: [82][470/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.128)
Train: [82][480/589]	BT 0.360 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.161 (0.128)
Train: [82][490/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.128)
Train: [82][500/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.112 (0.128)
Train: [82][510/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.129 (0.127)
Train: [82][520/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.128)
Train: [82][530/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.131 (0.128)
Train: [82][540/589]	BT 0.387 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.109 (0.128)
Train: [82][550/589]	BT 0.375 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.104 (0.128)
Train: [82][560/589]	BT 0.358 (0.388)	DT 0.000 (0.027)	lr 0.0002	loss 0.140 (0.128)
Train: [82][570/589]	BT 0.360 (0.388)	DT 0.000 (0.027)	lr 0.0002	loss 0.127 (0.128)
Train: [82][580/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.149 (0.128)
epoch 82, total time 227.97
loss: 0.12767827886607658@Epoch: 82
learning_rate: 0.0002,82
Valid: [82][10/88]	BT 0.110 (0.572)	DT 0.000 (0.459)	loss 0.135 (0.138)
Valid: [82][20/88]	BT 0.109 (0.508)	DT 0.000 (0.397)	loss 0.156 (0.137)
Valid: [82][30/88]	BT 0.109 (0.475)	DT 0.000 (0.363)	loss 0.138 (0.137)
Valid: [82][40/88]	BT 0.109 (0.470)	DT 0.000 (0.359)	loss 0.116 (0.136)
Valid: [82][50/88]	BT 0.109 (0.459)	DT 0.000 (0.349)	loss 0.146 (0.137)
Valid: [82][60/88]	BT 0.109 (0.455)	DT 0.000 (0.344)	loss 0.136 (0.136)
Valid: [82][70/88]	BT 0.110 (0.451)	DT 0.000 (0.341)	loss 0.138 (0.136)
Valid: [82][80/88]	BT 0.109 (0.447)	DT 0.000 (0.337)	loss 0.131 (0.136)
Train: [83][10/589]	BT 0.353 (0.762)	DT 0.000 (0.404)	lr 0.0002	loss 0.125 (0.136)
Train: [83][20/589]	BT 0.367 (0.571)	DT 0.000 (0.214)	lr 0.0002	loss 0.146 (0.132)
Train: [83][30/589]	BT 0.369 (0.511)	DT 0.000 (0.153)	lr 0.0002	loss 0.105 (0.129)
Train: [83][40/589]	BT 0.388 (0.475)	DT 0.000 (0.117)	lr 0.0002	loss 0.132 (0.128)
Train: [83][50/589]	BT 0.361 (0.457)	DT 0.000 (0.099)	lr 0.0002	loss 0.114 (0.128)
Train: [83][60/589]	BT 0.359 (0.445)	DT 0.000 (0.088)	lr 0.0002	loss 0.128 (0.127)
Train: [83][70/589]	BT 0.357 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.108 (0.127)
Train: [83][80/589]	BT 0.376 (0.431)	DT 0.000 (0.073)	lr 0.0002	loss 0.119 (0.128)
Train: [83][90/589]	BT 0.374 (0.426)	DT 0.000 (0.068)	lr 0.0002	loss 0.112 (0.127)
Train: [83][100/589]	BT 0.367 (0.422)	DT 0.000 (0.064)	lr 0.0002	loss 0.124 (0.127)
Train: [83][110/589]	BT 0.413 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.121 (0.126)
Train: [83][120/589]	BT 0.357 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.146 (0.126)
Train: [83][130/589]	BT 0.359 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.130 (0.125)
Train: [83][140/589]	BT 0.362 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.134 (0.125)
Train: [83][150/589]	BT 0.361 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.153 (0.126)
Train: [83][160/589]	BT 0.358 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.122 (0.126)
Train: [83][170/589]	BT 0.358 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.118 (0.125)
Train: [83][180/589]	BT 0.357 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.125 (0.126)
Train: [83][190/589]	BT 0.370 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.145 (0.126)
Train: [83][200/589]	BT 0.359 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.096 (0.126)
Train: [83][210/589]	BT 0.356 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.132 (0.126)
Train: [83][220/589]	BT 0.362 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.158 (0.126)
Train: [83][230/589]	BT 0.367 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.109 (0.126)
Train: [83][240/589]	BT 0.379 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.136 (0.126)
Train: [83][250/589]	BT 0.372 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.137 (0.126)
Train: [83][260/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.110 (0.126)
Train: [83][270/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.118 (0.126)
Train: [83][280/589]	BT 0.395 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.134 (0.126)
Train: [83][290/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.149 (0.126)
Train: [83][300/589]	BT 0.358 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.100 (0.126)
Train: [83][310/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.132 (0.126)
Train: [83][320/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.114 (0.126)
Train: [83][330/589]	BT 0.361 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.137 (0.127)
Train: [83][340/589]	BT 0.359 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.122 (0.127)
Train: [83][350/589]	BT 0.373 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.127)
Train: [83][360/589]	BT 0.355 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.119 (0.127)
Train: [83][370/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.143 (0.127)
Train: [83][380/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.111 (0.127)
Train: [83][390/589]	BT 0.373 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.134 (0.127)
Train: [83][400/589]	BT 0.369 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.127)
Train: [83][410/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.126 (0.127)
Train: [83][420/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.143 (0.127)
Train: [83][430/589]	BT 0.369 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.113 (0.127)
Train: [83][440/589]	BT 0.376 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.127)
Train: [83][450/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.110 (0.127)
Train: [83][460/589]	BT 0.380 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.137 (0.127)
Train: [83][470/589]	BT 0.377 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.127)
Train: [83][480/589]	BT 0.361 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.148 (0.127)
Train: [83][490/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.127)
Train: [83][500/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.127)
Train: [83][510/589]	BT 0.368 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.147 (0.128)
Train: [83][520/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.108 (0.127)
Train: [83][530/589]	BT 0.388 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.118 (0.127)
Train: [83][540/589]	BT 0.368 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.121 (0.127)
Train: [83][550/589]	BT 0.385 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.127)
Train: [83][560/589]	BT 0.360 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.116 (0.128)
Train: [83][570/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.128)
Train: [83][580/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.113 (0.128)
epoch 83, total time 227.84
loss: 0.1275959897739684@Epoch: 83
learning_rate: 0.0002,83
Valid: [83][10/88]	BT 0.110 (0.577)	DT 0.000 (0.466)	loss 0.128 (0.138)
Valid: [83][20/88]	BT 0.110 (0.497)	DT 0.000 (0.386)	loss 0.170 (0.139)
Valid: [83][30/88]	BT 0.110 (0.472)	DT 0.000 (0.361)	loss 0.118 (0.138)
Valid: [83][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.128 (0.137)
Valid: [83][50/88]	BT 0.110 (0.456)	DT 0.000 (0.346)	loss 0.175 (0.137)
Valid: [83][60/88]	BT 0.109 (0.445)	DT 0.000 (0.336)	loss 0.121 (0.136)
Valid: [83][70/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.149 (0.136)
Valid: [83][80/88]	BT 0.109 (0.439)	DT 0.000 (0.330)	loss 0.148 (0.136)
Train: [84][10/589]	BT 0.357 (0.735)	DT 0.000 (0.380)	lr 0.0002	loss 0.148 (0.124)
Train: [84][20/589]	BT 0.356 (0.562)	DT 0.000 (0.206)	lr 0.0002	loss 0.134 (0.126)
Train: [84][30/589]	BT 0.355 (0.502)	DT 0.000 (0.146)	lr 0.0002	loss 0.120 (0.125)
Train: [84][40/589]	BT 0.356 (0.472)	DT 0.000 (0.116)	lr 0.0002	loss 0.126 (0.126)
Train: [84][50/589]	BT 0.357 (0.450)	DT 0.000 (0.093)	lr 0.0002	loss 0.146 (0.128)
Train: [84][60/589]	BT 0.357 (0.437)	DT 0.000 (0.079)	lr 0.0002	loss 0.130 (0.128)
Train: [84][70/589]	BT 0.357 (0.430)	DT 0.000 (0.072)	lr 0.0002	loss 0.137 (0.127)
Train: [84][80/589]	BT 0.358 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.121 (0.127)
Train: [84][90/589]	BT 0.359 (0.419)	DT 0.000 (0.062)	lr 0.0002	loss 0.134 (0.127)
Train: [84][100/589]	BT 0.357 (0.415)	DT 0.000 (0.058)	lr 0.0002	loss 0.122 (0.127)
Train: [84][110/589]	BT 0.396 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.149 (0.127)
Train: [84][120/589]	BT 0.357 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.112 (0.127)
Train: [84][130/589]	BT 0.356 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.127 (0.127)
Train: [84][140/589]	BT 0.363 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.132 (0.127)
Train: [84][150/589]	BT 0.383 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.140 (0.127)
Train: [84][160/589]	BT 0.359 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.137 (0.127)
Train: [84][170/589]	BT 0.362 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.148 (0.127)
Train: [84][180/589]	BT 0.383 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.137 (0.127)
Train: [84][190/589]	BT 0.393 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.134 (0.128)
Train: [84][200/589]	BT 0.380 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.131 (0.128)
Train: [84][210/589]	BT 0.355 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.107 (0.128)
Train: [84][220/589]	BT 0.377 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.139 (0.128)
Train: [84][230/589]	BT 0.358 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.120 (0.128)
Train: [84][240/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.124 (0.128)
Train: [84][250/589]	BT 0.368 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.118 (0.128)
Train: [84][260/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.112 (0.127)
Train: [84][270/589]	BT 0.366 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.127)
Train: [84][280/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.142 (0.127)
Train: [84][290/589]	BT 0.379 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.113 (0.127)
Train: [84][300/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.135 (0.127)
Train: [84][310/589]	BT 0.360 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.138 (0.128)
Train: [84][320/589]	BT 0.364 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.128 (0.128)
Train: [84][330/589]	BT 0.363 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.146 (0.127)
Train: [84][340/589]	BT 0.377 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.146 (0.128)
Train: [84][350/589]	BT 0.354 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.139 (0.128)
Train: [84][360/589]	BT 0.356 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.121 (0.128)
Train: [84][370/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.102 (0.128)
Train: [84][380/589]	BT 0.389 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.150 (0.128)
Train: [84][390/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.147 (0.128)
Train: [84][400/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.124 (0.128)
Train: [84][410/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.144 (0.128)
Train: [84][420/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.135 (0.128)
Train: [84][430/589]	BT 0.370 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.096 (0.128)
Train: [84][440/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.098 (0.128)
Train: [84][450/589]	BT 0.360 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.128)
Train: [84][460/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.111 (0.128)
Train: [84][470/589]	BT 0.361 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.128)
Train: [84][480/589]	BT 0.355 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.128)
Train: [84][490/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.126 (0.128)
Train: [84][500/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.111 (0.128)
Train: [84][510/589]	BT 0.360 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.113 (0.128)
Train: [84][520/589]	BT 0.360 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.118 (0.128)
Train: [84][530/589]	BT 0.369 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.131 (0.128)
Train: [84][540/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.101 (0.128)
Train: [84][550/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.121 (0.128)
Train: [84][560/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.128)
Train: [84][570/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.142 (0.128)
Train: [84][580/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.127 (0.128)
epoch 84, total time 228.17
loss: 0.1276176192447312@Epoch: 84
learning_rate: 0.0002,84
Valid: [84][10/88]	BT 0.110 (0.565)	DT 0.000 (0.451)	loss 0.149 (0.140)
Valid: [84][20/88]	BT 0.110 (0.505)	DT 0.000 (0.393)	loss 0.111 (0.140)
Valid: [84][30/88]	BT 0.109 (0.471)	DT 0.000 (0.360)	loss 0.145 (0.140)
Valid: [84][40/88]	BT 0.109 (0.460)	DT 0.000 (0.349)	loss 0.142 (0.139)
Valid: [84][50/88]	BT 0.110 (0.457)	DT 0.000 (0.345)	loss 0.117 (0.138)
Valid: [84][60/88]	BT 0.109 (0.448)	DT 0.000 (0.337)	loss 0.138 (0.139)
Valid: [84][70/88]	BT 0.109 (0.447)	DT 0.000 (0.336)	loss 0.130 (0.139)
Valid: [84][80/88]	BT 0.109 (0.444)	DT 0.000 (0.333)	loss 0.137 (0.137)
Train: [85][10/589]	BT 0.356 (0.751)	DT 0.000 (0.394)	lr 0.0002	loss 0.111 (0.121)
Train: [85][20/589]	BT 0.357 (0.569)	DT 0.000 (0.212)	lr 0.0002	loss 0.121 (0.120)
Train: [85][30/589]	BT 0.371 (0.508)	DT 0.000 (0.151)	lr 0.0002	loss 0.145 (0.122)
Train: [85][40/589]	BT 0.388 (0.483)	DT 0.000 (0.125)	lr 0.0002	loss 0.141 (0.125)
Train: [85][50/589]	BT 0.361 (0.463)	DT 0.000 (0.105)	lr 0.0002	loss 0.130 (0.125)
Train: [85][60/589]	BT 0.381 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.131 (0.125)
Train: [85][70/589]	BT 0.357 (0.441)	DT 0.000 (0.083)	lr 0.0002	loss 0.152 (0.125)
Train: [85][80/589]	BT 0.358 (0.435)	DT 0.000 (0.076)	lr 0.0002	loss 0.129 (0.125)
Train: [85][90/589]	BT 0.369 (0.429)	DT 0.000 (0.070)	lr 0.0002	loss 0.155 (0.125)
Train: [85][100/589]	BT 0.356 (0.426)	DT 0.000 (0.067)	lr 0.0002	loss 0.126 (0.125)
Train: [85][110/589]	BT 0.395 (0.421)	DT 0.000 (0.063)	lr 0.0002	loss 0.139 (0.126)
Train: [85][120/589]	BT 0.360 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.140 (0.127)
Train: [85][130/589]	BT 0.355 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.139 (0.127)
Train: [85][140/589]	BT 0.358 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.148 (0.127)
Train: [85][150/589]	BT 0.373 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.133 (0.127)
Train: [85][160/589]	BT 0.368 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.118 (0.127)
Train: [85][170/589]	BT 0.357 (0.404)	DT 0.001 (0.045)	lr 0.0002	loss 0.126 (0.127)
Train: [85][180/589]	BT 0.368 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.122 (0.127)
Train: [85][190/589]	BT 0.356 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.140 (0.127)
Train: [85][200/589]	BT 0.361 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.117 (0.127)
Train: [85][210/589]	BT 0.374 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.124 (0.127)
Train: [85][220/589]	BT 0.366 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.127)
Train: [85][230/589]	BT 0.368 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.115 (0.127)
Train: [85][240/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.129 (0.127)
Train: [85][250/589]	BT 0.358 (0.399)	DT 0.000 (0.039)	lr 0.0002	loss 0.121 (0.127)
Train: [85][260/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.151 (0.127)
Train: [85][270/589]	BT 0.362 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.119 (0.127)
Train: [85][280/589]	BT 0.387 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.108 (0.127)
Train: [85][290/589]	BT 0.365 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.115 (0.127)
Train: [85][300/589]	BT 0.360 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.126 (0.127)
Train: [85][310/589]	BT 0.356 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.120 (0.127)
Train: [85][320/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.135 (0.127)
Train: [85][330/589]	BT 0.364 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.137 (0.127)
Train: [85][340/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.100 (0.127)
Train: [85][350/589]	BT 0.387 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.116 (0.127)
Train: [85][360/589]	BT 0.372 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.142 (0.127)
Train: [85][370/589]	BT 0.359 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.121 (0.127)
Train: [85][380/589]	BT 0.357 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.126 (0.127)
Train: [85][390/589]	BT 0.361 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.112 (0.127)
Train: [85][400/589]	BT 0.356 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.130 (0.127)
Train: [85][410/589]	BT 0.354 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.099 (0.127)
Train: [85][420/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.140 (0.127)
Train: [85][430/589]	BT 0.358 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.129 (0.127)
Train: [85][440/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.121 (0.127)
Train: [85][450/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.124 (0.127)
Train: [85][460/589]	BT 0.360 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.127)
Train: [85][470/589]	BT 0.410 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.125 (0.127)
Train: [85][480/589]	BT 0.355 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.128 (0.127)
Train: [85][490/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.126 (0.127)
Train: [85][500/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.137 (0.127)
Train: [85][510/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.126 (0.127)
Train: [85][520/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.108 (0.127)
Train: [85][530/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.135 (0.127)
Train: [85][540/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.118 (0.127)
Train: [85][550/589]	BT 0.381 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.138 (0.127)
Train: [85][560/589]	BT 0.358 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.131 (0.127)
Train: [85][570/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.123 (0.127)
Train: [85][580/589]	BT 0.372 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.142 (0.127)
epoch 85, total time 229.94
loss: 0.12697262242705498@Epoch: 85
learning_rate: 0.0002,85
Valid: [85][10/88]	BT 0.109 (0.572)	DT 0.000 (0.461)	loss 0.121 (0.138)
Valid: [85][20/88]	BT 0.110 (0.503)	DT 0.000 (0.393)	loss 0.135 (0.140)
Valid: [85][30/88]	BT 0.110 (0.483)	DT 0.000 (0.373)	loss 0.110 (0.138)
Valid: [85][40/88]	BT 0.109 (0.472)	DT 0.000 (0.363)	loss 0.128 (0.139)
Valid: [85][50/88]	BT 0.109 (0.463)	DT 0.000 (0.354)	loss 0.162 (0.138)
Valid: [85][60/88]	BT 0.110 (0.458)	DT 0.000 (0.349)	loss 0.122 (0.137)
Valid: [85][70/88]	BT 0.109 (0.455)	DT 0.000 (0.345)	loss 0.122 (0.136)
Valid: [85][80/88]	BT 0.109 (0.449)	DT 0.000 (0.340)	loss 0.162 (0.136)
Train: [86][10/589]	BT 0.374 (0.764)	DT 0.000 (0.405)	lr 0.0002	loss 0.120 (0.137)
Train: [86][20/589]	BT 0.394 (0.577)	DT 0.000 (0.218)	lr 0.0002	loss 0.139 (0.134)
Train: [86][30/589]	BT 0.379 (0.505)	DT 0.000 (0.145)	lr 0.0002	loss 0.123 (0.130)
Train: [86][40/589]	BT 0.365 (0.474)	DT 0.000 (0.115)	lr 0.0002	loss 0.129 (0.129)
Train: [86][50/589]	BT 0.376 (0.454)	DT 0.000 (0.094)	lr 0.0002	loss 0.129 (0.128)
Train: [86][60/589]	BT 0.374 (0.444)	DT 0.000 (0.085)	lr 0.0002	loss 0.139 (0.129)
Train: [86][70/589]	BT 0.400 (0.434)	DT 0.000 (0.075)	lr 0.0002	loss 0.120 (0.128)
Train: [86][80/589]	BT 0.358 (0.425)	DT 0.000 (0.066)	lr 0.0002	loss 0.147 (0.129)
Train: [86][90/589]	BT 0.374 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.132 (0.128)
Train: [86][100/589]	BT 0.357 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.143 (0.128)
Train: [86][110/589]	BT 0.391 (0.415)	DT 0.000 (0.055)	lr 0.0002	loss 0.150 (0.128)
Train: [86][120/589]	BT 0.357 (0.412)	DT 0.000 (0.052)	lr 0.0002	loss 0.106 (0.128)
Train: [86][130/589]	BT 0.376 (0.410)	DT 0.000 (0.050)	lr 0.0002	loss 0.118 (0.128)
Train: [86][140/589]	BT 0.411 (0.408)	DT 0.000 (0.048)	lr 0.0002	loss 0.119 (0.128)
Train: [86][150/589]	BT 0.368 (0.407)	DT 0.000 (0.047)	lr 0.0002	loss 0.107 (0.128)
Train: [86][160/589]	BT 0.359 (0.405)	DT 0.000 (0.045)	lr 0.0002	loss 0.144 (0.128)
Train: [86][170/589]	BT 0.391 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.108 (0.128)
Train: [86][180/589]	BT 0.399 (0.403)	DT 0.000 (0.043)	lr 0.0002	loss 0.106 (0.127)
Train: [86][190/589]	BT 0.379 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.121 (0.128)
Train: [86][200/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.125 (0.128)
Train: [86][210/589]	BT 0.398 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.135 (0.128)
Train: [86][220/589]	BT 0.357 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.126 (0.128)
Train: [86][230/589]	BT 0.362 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.133 (0.128)
Train: [86][240/589]	BT 0.375 (0.395)	DT 0.001 (0.035)	lr 0.0002	loss 0.136 (0.128)
Train: [86][250/589]	BT 0.357 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.122 (0.128)
Train: [86][260/589]	BT 0.404 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.110 (0.127)
Train: [86][270/589]	BT 0.384 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.131 (0.127)
Train: [86][280/589]	BT 0.358 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.148 (0.127)
Train: [86][290/589]	BT 0.361 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.127)
Train: [86][300/589]	BT 0.359 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.114 (0.127)
Train: [86][310/589]	BT 0.358 (0.392)	DT 0.000 (0.031)	lr 0.0002	loss 0.132 (0.127)
Train: [86][320/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.127)
Train: [86][330/589]	BT 0.359 (0.391)	DT 0.000 (0.030)	lr 0.0002	loss 0.118 (0.127)
Train: [86][340/589]	BT 0.356 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.128 (0.127)
Train: [86][350/589]	BT 0.360 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.134 (0.127)
Train: [86][360/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.127)
Train: [86][370/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.117 (0.127)
Train: [86][380/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.127 (0.127)
Train: [86][390/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.142 (0.127)
Train: [86][400/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.106 (0.127)
Train: [86][410/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.133 (0.127)
Train: [86][420/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.116 (0.127)
Train: [86][430/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.133 (0.127)
Train: [86][440/589]	BT 0.373 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.117 (0.127)
Train: [86][450/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.127)
Train: [86][460/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.127)
Train: [86][470/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.127)
Train: [86][480/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.127)
Train: [86][490/589]	BT 0.355 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.115 (0.127)
Train: [86][500/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.127)
Train: [86][510/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.103 (0.127)
Train: [86][520/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.111 (0.127)
Train: [86][530/589]	BT 0.384 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.127)
Train: [86][540/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.132 (0.127)
Train: [86][550/589]	BT 0.362 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.113 (0.127)
Train: [86][560/589]	BT 0.389 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.127)
Train: [86][570/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.143 (0.127)
Train: [86][580/589]	BT 0.366 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.122 (0.127)
epoch 86, total time 225.24
loss: 0.1266288596694323@Epoch: 86
learning_rate: 0.0002,86
Valid: [86][10/88]	BT 0.109 (0.555)	DT 0.000 (0.445)	loss 0.143 (0.133)
Valid: [86][20/88]	BT 0.110 (0.488)	DT 0.000 (0.378)	loss 0.115 (0.135)
Valid: [86][30/88]	BT 0.110 (0.460)	DT 0.000 (0.351)	loss 0.141 (0.136)
Valid: [86][40/88]	BT 0.109 (0.447)	DT 0.000 (0.338)	loss 0.153 (0.138)
Valid: [86][50/88]	BT 0.110 (0.440)	DT 0.000 (0.330)	loss 0.135 (0.139)
Valid: [86][60/88]	BT 0.110 (0.435)	DT 0.000 (0.326)	loss 0.124 (0.138)
Valid: [86][70/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.127 (0.139)
Valid: [86][80/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.139 (0.138)
Train: [87][10/589]	BT 0.374 (0.768)	DT 0.000 (0.411)	lr 0.0002	loss 0.135 (0.125)
Train: [87][20/589]	BT 0.386 (0.574)	DT 0.000 (0.216)	lr 0.0002	loss 0.141 (0.124)
Train: [87][30/589]	BT 0.369 (0.507)	DT 0.000 (0.149)	lr 0.0002	loss 0.125 (0.126)
Train: [87][40/589]	BT 0.373 (0.475)	DT 0.000 (0.117)	lr 0.0002	loss 0.119 (0.127)
Train: [87][50/589]	BT 0.372 (0.458)	DT 0.000 (0.099)	lr 0.0002	loss 0.139 (0.127)
Train: [87][60/589]	BT 0.374 (0.444)	DT 0.000 (0.085)	lr 0.0002	loss 0.140 (0.127)
Train: [87][70/589]	BT 0.356 (0.432)	DT 0.000 (0.073)	lr 0.0002	loss 0.130 (0.126)
Train: [87][80/589]	BT 0.389 (0.423)	DT 0.000 (0.064)	lr 0.0002	loss 0.127 (0.126)
Train: [87][90/589]	BT 0.365 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.122 (0.126)
Train: [87][100/589]	BT 0.360 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.106 (0.126)
Train: [87][110/589]	BT 0.355 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.128 (0.126)
Train: [87][120/589]	BT 0.400 (0.411)	DT 0.000 (0.051)	lr 0.0002	loss 0.128 (0.125)
Train: [87][130/589]	BT 0.360 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.145 (0.125)
Train: [87][140/589]	BT 0.370 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.142 (0.125)
Train: [87][150/589]	BT 0.356 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.134 (0.126)
Train: [87][160/589]	BT 0.388 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.127 (0.126)
Train: [87][170/589]	BT 0.364 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.139 (0.126)
Train: [87][180/589]	BT 0.361 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.133 (0.126)
Train: [87][190/589]	BT 0.384 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.123 (0.126)
Train: [87][200/589]	BT 0.373 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.126)
Train: [87][210/589]	BT 0.359 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.116 (0.126)
Train: [87][220/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.115 (0.126)
Train: [87][230/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.120 (0.126)
Train: [87][240/589]	BT 0.369 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.124 (0.126)
Train: [87][250/589]	BT 0.360 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.126)
Train: [87][260/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.111 (0.126)
Train: [87][270/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.158 (0.126)
Train: [87][280/589]	BT 0.354 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.114 (0.126)
Train: [87][290/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.112 (0.126)
Train: [87][300/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.150 (0.126)
Train: [87][310/589]	BT 0.364 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.114 (0.126)
Train: [87][320/589]	BT 0.371 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.138 (0.126)
Train: [87][330/589]	BT 0.619 (0.388)	DT 0.263 (0.028)	lr 0.0002	loss 0.128 (0.126)
Train: [87][340/589]	BT 0.688 (0.388)	DT 0.330 (0.028)	lr 0.0002	loss 0.150 (0.126)
Train: [87][350/589]	BT 0.573 (0.388)	DT 0.216 (0.028)	lr 0.0002	loss 0.131 (0.126)
Train: [87][360/589]	BT 0.628 (0.388)	DT 0.269 (0.028)	lr 0.0002	loss 0.129 (0.126)
Train: [87][370/589]	BT 0.610 (0.388)	DT 0.253 (0.028)	lr 0.0002	loss 0.114 (0.126)
Train: [87][380/589]	BT 0.570 (0.388)	DT 0.213 (0.028)	lr 0.0002	loss 0.133 (0.126)
Train: [87][390/589]	BT 0.579 (0.388)	DT 0.225 (0.028)	lr 0.0002	loss 0.115 (0.126)
Train: [87][400/589]	BT 0.575 (0.387)	DT 0.219 (0.027)	lr 0.0002	loss 0.141 (0.126)
Train: [87][410/589]	BT 0.660 (0.388)	DT 0.307 (0.028)	lr 0.0002	loss 0.133 (0.126)
Train: [87][420/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.108 (0.126)
Train: [87][430/589]	BT 0.518 (0.387)	DT 0.162 (0.027)	lr 0.0002	loss 0.129 (0.126)
Train: [87][440/589]	BT 0.467 (0.386)	DT 0.112 (0.026)	lr 0.0002	loss 0.127 (0.126)
Train: [87][450/589]	BT 0.532 (0.386)	DT 0.166 (0.026)	lr 0.0002	loss 0.130 (0.126)
Train: [87][460/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.126)
Train: [87][470/589]	BT 0.469 (0.386)	DT 0.114 (0.026)	lr 0.0002	loss 0.154 (0.126)
Train: [87][480/589]	BT 0.555 (0.386)	DT 0.199 (0.025)	lr 0.0002	loss 0.127 (0.126)
Train: [87][490/589]	BT 0.526 (0.385)	DT 0.171 (0.025)	lr 0.0002	loss 0.151 (0.126)
Train: [87][500/589]	BT 0.559 (0.385)	DT 0.203 (0.025)	lr 0.0002	loss 0.152 (0.126)
Train: [87][510/589]	BT 0.607 (0.385)	DT 0.251 (0.025)	lr 0.0002	loss 0.110 (0.126)
Train: [87][520/589]	BT 0.785 (0.386)	DT 0.429 (0.026)	lr 0.0002	loss 0.131 (0.126)
Train: [87][530/589]	BT 0.643 (0.386)	DT 0.289 (0.026)	lr 0.0002	loss 0.094 (0.126)
Train: [87][540/589]	BT 0.501 (0.385)	DT 0.145 (0.025)	lr 0.0002	loss 0.129 (0.127)
Train: [87][550/589]	BT 0.749 (0.386)	DT 0.393 (0.026)	lr 0.0002	loss 0.133 (0.127)
Train: [87][560/589]	BT 0.411 (0.385)	DT 0.055 (0.025)	lr 0.0002	loss 0.126 (0.127)
Train: [87][570/589]	BT 0.507 (0.385)	DT 0.153 (0.025)	lr 0.0002	loss 0.119 (0.127)
Train: [87][580/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.127)
epoch 87, total time 226.26
loss: 0.1266823275367343@Epoch: 87
learning_rate: 0.0002,87
Valid: [87][10/88]	BT 0.109 (0.561)	DT 0.000 (0.450)	loss 0.133 (0.135)
Valid: [87][20/88]	BT 0.110 (0.483)	DT 0.000 (0.370)	loss 0.153 (0.137)
Valid: [87][30/88]	BT 0.110 (0.463)	DT 0.000 (0.351)	loss 0.159 (0.135)
Valid: [87][40/88]	BT 0.110 (0.448)	DT 0.000 (0.337)	loss 0.120 (0.136)
Valid: [87][50/88]	BT 0.109 (0.441)	DT 0.000 (0.330)	loss 0.156 (0.135)
Valid: [87][60/88]	BT 0.109 (0.436)	DT 0.000 (0.325)	loss 0.122 (0.136)
Valid: [87][70/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.141 (0.137)
Valid: [87][80/88]	BT 0.109 (0.432)	DT 0.000 (0.321)	loss 0.119 (0.137)
Train: [88][10/589]	BT 0.354 (0.729)	DT 0.000 (0.372)	lr 0.0002	loss 0.115 (0.131)
Train: [88][20/589]	BT 0.356 (0.548)	DT 0.000 (0.190)	lr 0.0002	loss 0.138 (0.128)
Train: [88][30/589]	BT 0.357 (0.494)	DT 0.000 (0.136)	lr 0.0002	loss 0.130 (0.126)
Train: [88][40/589]	BT 0.358 (0.464)	DT 0.000 (0.105)	lr 0.0002	loss 0.163 (0.128)
Train: [88][50/589]	BT 0.358 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.092 (0.127)
Train: [88][60/589]	BT 0.356 (0.437)	DT 0.000 (0.078)	lr 0.0002	loss 0.114 (0.127)
Train: [88][70/589]	BT 0.358 (0.432)	DT 0.000 (0.074)	lr 0.0002	loss 0.131 (0.126)
Train: [88][80/589]	BT 0.380 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.126 (0.127)
Train: [88][90/589]	BT 0.390 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.104 (0.127)
Train: [88][100/589]	BT 0.364 (0.416)	DT 0.000 (0.057)	lr 0.0002	loss 0.127 (0.126)
Train: [88][110/589]	BT 0.361 (0.412)	DT 0.000 (0.054)	lr 0.0002	loss 0.117 (0.126)
Train: [88][120/589]	BT 0.358 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.107 (0.126)
Train: [88][130/589]	BT 0.354 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.131 (0.126)
Train: [88][140/589]	BT 0.358 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.147 (0.126)
Train: [88][150/589]	BT 0.359 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.105 (0.126)
Train: [88][160/589]	BT 0.378 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.117 (0.126)
Train: [88][170/589]	BT 0.359 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.129 (0.126)
Train: [88][180/589]	BT 0.363 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.113 (0.126)
Train: [88][190/589]	BT 0.355 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.126)
Train: [88][200/589]	BT 0.378 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.122 (0.126)
Train: [88][210/589]	BT 0.387 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.128 (0.126)
Train: [88][220/589]	BT 0.377 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.120 (0.126)
Train: [88][230/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.113 (0.126)
Train: [88][240/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.117 (0.126)
Train: [88][250/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.115 (0.126)
Train: [88][260/589]	BT 0.358 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.124 (0.126)
Train: [88][270/589]	BT 0.361 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.135 (0.126)
Train: [88][280/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.132 (0.126)
Train: [88][290/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.137 (0.126)
Train: [88][300/589]	BT 0.357 (0.394)	DT 0.000 (0.033)	lr 0.0002	loss 0.139 (0.127)
Train: [88][310/589]	BT 0.384 (0.393)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.126)
Train: [88][320/589]	BT 0.358 (0.393)	DT 0.000 (0.032)	lr 0.0002	loss 0.112 (0.126)
Train: [88][330/589]	BT 0.360 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.125 (0.127)
Train: [88][340/589]	BT 0.358 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.140 (0.127)
Train: [88][350/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.145 (0.127)
Train: [88][360/589]	BT 0.359 (0.392)	DT 0.000 (0.031)	lr 0.0002	loss 0.142 (0.127)
Train: [88][370/589]	BT 0.359 (0.392)	DT 0.000 (0.031)	lr 0.0002	loss 0.143 (0.127)
Train: [88][380/589]	BT 0.358 (0.391)	DT 0.000 (0.030)	lr 0.0002	loss 0.115 (0.126)
Train: [88][390/589]	BT 0.361 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.104 (0.126)
Train: [88][400/589]	BT 0.358 (0.391)	DT 0.000 (0.030)	lr 0.0002	loss 0.131 (0.126)
Train: [88][410/589]	BT 0.360 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.126)
Train: [88][420/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.126)
Train: [88][430/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.126)
Train: [88][440/589]	BT 0.379 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.132 (0.126)
Train: [88][450/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.126)
Train: [88][460/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.126)
Train: [88][470/589]	BT 0.379 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.128 (0.126)
Train: [88][480/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.118 (0.126)
Train: [88][490/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.129 (0.126)
Train: [88][500/589]	BT 0.359 (0.388)	DT 0.000 (0.027)	lr 0.0002	loss 0.115 (0.126)
Train: [88][510/589]	BT 0.356 (0.388)	DT 0.000 (0.027)	lr 0.0002	loss 0.113 (0.126)
Train: [88][520/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.109 (0.126)
Train: [88][530/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.142 (0.127)
Train: [88][540/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.138 (0.127)
Train: [88][550/589]	BT 0.360 (0.387)	DT 0.000 (0.026)	lr 0.0002	loss 0.159 (0.127)
Train: [88][560/589]	BT 0.357 (0.387)	DT 0.000 (0.026)	lr 0.0002	loss 0.143 (0.127)
Train: [88][570/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.112 (0.127)
Train: [88][580/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.143 (0.126)
epoch 88, total time 227.53
loss: 0.12643025593726478@Epoch: 88
learning_rate: 0.0002,88
Valid: [88][10/88]	BT 0.110 (0.556)	DT 0.000 (0.443)	loss 0.129 (0.139)
Valid: [88][20/88]	BT 0.109 (0.492)	DT 0.000 (0.380)	loss 0.120 (0.133)
Valid: [88][30/88]	BT 0.109 (0.467)	DT 0.000 (0.356)	loss 0.135 (0.135)
Valid: [88][40/88]	BT 0.113 (0.455)	DT 0.000 (0.344)	loss 0.123 (0.137)
Valid: [88][50/88]	BT 0.110 (0.445)	DT 0.000 (0.335)	loss 0.113 (0.137)
Valid: [88][60/88]	BT 0.110 (0.439)	DT 0.000 (0.329)	loss 0.135 (0.137)
Valid: [88][70/88]	BT 0.109 (0.436)	DT 0.000 (0.325)	loss 0.140 (0.137)
Valid: [88][80/88]	BT 0.109 (0.429)	DT 0.000 (0.319)	loss 0.119 (0.137)
Train: [89][10/589]	BT 0.357 (0.769)	DT 0.000 (0.414)	lr 0.0002	loss 0.126 (0.127)
Train: [89][20/589]	BT 0.377 (0.565)	DT 0.000 (0.207)	lr 0.0002	loss 0.137 (0.129)
Train: [89][30/589]	BT 0.360 (0.504)	DT 0.000 (0.147)	lr 0.0002	loss 0.142 (0.129)
Train: [89][40/589]	BT 0.365 (0.474)	DT 0.000 (0.116)	lr 0.0002	loss 0.129 (0.128)
Train: [89][50/589]	BT 0.354 (0.451)	DT 0.000 (0.093)	lr 0.0002	loss 0.145 (0.129)
Train: [89][60/589]	BT 0.371 (0.438)	DT 0.000 (0.080)	lr 0.0002	loss 0.125 (0.129)
Train: [89][70/589]	BT 0.358 (0.430)	DT 0.000 (0.071)	lr 0.0002	loss 0.100 (0.128)
Train: [89][80/589]	BT 0.358 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.120 (0.127)
Train: [89][90/589]	BT 0.368 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.127 (0.127)
Train: [89][100/589]	BT 0.356 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.107 (0.127)
Train: [89][110/589]	BT 0.386 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.137 (0.127)
Train: [89][120/589]	BT 0.373 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.132 (0.127)
Train: [89][130/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.139 (0.126)
Train: [89][140/589]	BT 0.355 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.117 (0.126)
Train: [89][150/589]	BT 0.381 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.114 (0.127)
Train: [89][160/589]	BT 0.357 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.112 (0.126)
Train: [89][170/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.120 (0.126)
Train: [89][180/589]	BT 0.410 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.126 (0.126)
Train: [89][190/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.117 (0.126)
Train: [89][200/589]	BT 0.405 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.152 (0.126)
Train: [89][210/589]	BT 0.367 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.127 (0.126)
Train: [89][220/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.118 (0.126)
Train: [89][230/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.119 (0.126)
Train: [89][240/589]	BT 0.357 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.122 (0.126)
Train: [89][250/589]	BT 0.360 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.108 (0.126)
Train: [89][260/589]	BT 0.366 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.150 (0.126)
Train: [89][270/589]	BT 0.355 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.126)
Train: [89][280/589]	BT 0.372 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.109 (0.126)
Train: [89][290/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.120 (0.126)
Train: [89][300/589]	BT 0.372 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.128 (0.126)
Train: [89][310/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.126)
Train: [89][320/589]	BT 0.388 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.129 (0.126)
Train: [89][330/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.126)
Train: [89][340/589]	BT 0.381 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.105 (0.126)
Train: [89][350/589]	BT 0.377 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.118 (0.126)
Train: [89][360/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.128 (0.126)
Train: [89][370/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.126)
Train: [89][380/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.120 (0.126)
Train: [89][390/589]	BT 0.389 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.114 (0.126)
Train: [89][400/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.120 (0.126)
Train: [89][410/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.127 (0.126)
Train: [89][420/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.154 (0.126)
Train: [89][430/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.111 (0.126)
Train: [89][440/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.110 (0.126)
Train: [89][450/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.126)
Train: [89][460/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.126)
Train: [89][470/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.126)
Train: [89][480/589]	BT 0.355 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.110 (0.126)
Train: [89][490/589]	BT 0.404 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.121 (0.126)
Train: [89][500/589]	BT 0.356 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.112 (0.126)
Train: [89][510/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.113 (0.126)
Train: [89][520/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.126)
Train: [89][530/589]	BT 0.378 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.126)
Train: [89][540/589]	BT 0.358 (0.382)	DT 0.000 (0.021)	lr 0.0002	loss 0.125 (0.126)
Train: [89][550/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.135 (0.126)
Train: [89][560/589]	BT 0.361 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.130 (0.126)
Train: [89][570/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.120 (0.126)
Train: [89][580/589]	BT 0.354 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.114 (0.126)
epoch 89, total time 224.23
loss: 0.126070022617831@Epoch: 89
learning_rate: 0.0002,89
Valid: [89][10/88]	BT 0.110 (0.567)	DT 0.000 (0.456)	loss 0.166 (0.149)
Valid: [89][20/88]	BT 0.109 (0.488)	DT 0.000 (0.377)	loss 0.120 (0.140)
Valid: [89][30/88]	BT 0.110 (0.462)	DT 0.000 (0.352)	loss 0.152 (0.142)
Valid: [89][40/88]	BT 0.109 (0.453)	DT 0.000 (0.343)	loss 0.126 (0.141)
Valid: [89][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.133 (0.140)
Valid: [89][60/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.130 (0.138)
Valid: [89][70/88]	BT 0.109 (0.433)	DT 0.000 (0.324)	loss 0.148 (0.138)
Valid: [89][80/88]	BT 0.110 (0.429)	DT 0.000 (0.320)	loss 0.149 (0.138)
Train: [90][10/589]	BT 0.357 (0.727)	DT 0.000 (0.368)	lr 0.0002	loss 0.126 (0.128)
Train: [90][20/589]	BT 0.355 (0.553)	DT 0.000 (0.196)	lr 0.0002	loss 0.112 (0.126)
Train: [90][30/589]	BT 0.356 (0.496)	DT 0.000 (0.138)	lr 0.0002	loss 0.114 (0.125)
Train: [90][40/589]	BT 0.356 (0.466)	DT 0.000 (0.108)	lr 0.0002	loss 0.153 (0.128)
Train: [90][50/589]	BT 0.356 (0.445)	DT 0.000 (0.087)	lr 0.0002	loss 0.124 (0.128)
Train: [90][60/589]	BT 0.387 (0.435)	DT 0.000 (0.076)	lr 0.0002	loss 0.132 (0.128)
Train: [90][70/589]	BT 0.358 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.113 (0.128)
Train: [90][80/589]	BT 0.358 (0.417)	DT 0.000 (0.058)	lr 0.0002	loss 0.115 (0.127)
Train: [90][90/589]	BT 0.361 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.120 (0.127)
Train: [90][100/589]	BT 0.357 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.124 (0.127)
Train: [90][110/589]	BT 0.359 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.138 (0.127)
Train: [90][120/589]	BT 0.361 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.106 (0.127)
Train: [90][130/589]	BT 0.359 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.120 (0.126)
Train: [90][140/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.122 (0.126)
Train: [90][150/589]	BT 0.358 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.142 (0.126)
Train: [90][160/589]	BT 0.357 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.120 (0.126)
Train: [90][170/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.143 (0.126)
Train: [90][180/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.125 (0.126)
Train: [90][190/589]	BT 0.358 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.126 (0.125)
Train: [90][200/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.144 (0.125)
Train: [90][210/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.118 (0.125)
Train: [90][220/589]	BT 0.371 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.123 (0.125)
Train: [90][230/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.125)
Train: [90][240/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.122 (0.125)
Train: [90][250/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.128 (0.125)
Train: [90][260/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.106 (0.125)
Train: [90][270/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.103 (0.125)
Train: [90][280/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.125)
Train: [90][290/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.125)
Train: [90][300/589]	BT 0.360 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.115 (0.125)
Train: [90][310/589]	BT 0.366 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.117 (0.126)
Train: [90][320/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.136 (0.126)
Train: [90][330/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.126)
Train: [90][340/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.107 (0.126)
Train: [90][350/589]	BT 0.370 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.134 (0.126)
Train: [90][360/589]	BT 0.377 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.104 (0.126)
Train: [90][370/589]	BT 0.355 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.126)
Train: [90][380/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.126)
Train: [90][390/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.110 (0.126)
Train: [90][400/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.126)
Train: [90][410/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.126)
Train: [90][420/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.111 (0.126)
Train: [90][430/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.114 (0.126)
Train: [90][440/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.126)
Train: [90][450/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.121 (0.126)
Train: [90][460/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.126)
Train: [90][470/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.120 (0.126)
Train: [90][480/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.126)
Train: [90][490/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.126)
Train: [90][500/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.100 (0.126)
Train: [90][510/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.131 (0.126)
Train: [90][520/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.126)
Train: [90][530/589]	BT 0.357 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.121 (0.126)
Train: [90][540/589]	BT 0.362 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.105 (0.126)
Train: [90][550/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.128 (0.126)
Train: [90][560/589]	BT 0.360 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.142 (0.126)
Train: [90][570/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.122 (0.126)
Train: [90][580/589]	BT 0.359 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.149 (0.126)
epoch 90, total time 224.04
loss: 0.12587880273710675@Epoch: 90
learning_rate: 0.0002,90
Valid: [90][10/88]	BT 0.110 (0.560)	DT 0.000 (0.450)	loss 0.149 (0.140)
Valid: [90][20/88]	BT 0.109 (0.494)	DT 0.000 (0.384)	loss 0.147 (0.144)
Valid: [90][30/88]	BT 0.109 (0.466)	DT 0.000 (0.356)	loss 0.170 (0.146)
Valid: [90][40/88]	BT 0.110 (0.459)	DT 0.000 (0.349)	loss 0.141 (0.144)
Valid: [90][50/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.151 (0.144)
Valid: [90][60/88]	BT 0.109 (0.442)	DT 0.000 (0.332)	loss 0.139 (0.143)
Valid: [90][70/88]	BT 0.109 (0.436)	DT 0.000 (0.327)	loss 0.113 (0.142)
Valid: [90][80/88]	BT 0.109 (0.434)	DT 0.000 (0.324)	loss 0.127 (0.142)
Train: [91][10/589]	BT 0.390 (0.759)	DT 0.000 (0.400)	lr 0.0002	loss 0.115 (0.122)
Train: [91][20/589]	BT 0.356 (0.559)	DT 0.000 (0.200)	lr 0.0002	loss 0.102 (0.124)
Train: [91][30/589]	BT 0.357 (0.500)	DT 0.000 (0.142)	lr 0.0002	loss 0.129 (0.125)
Train: [91][40/589]	BT 0.357 (0.470)	DT 0.000 (0.112)	lr 0.0002	loss 0.125 (0.125)
Train: [91][50/589]	BT 0.357 (0.452)	DT 0.000 (0.094)	lr 0.0002	loss 0.113 (0.124)
Train: [91][60/589]	BT 0.371 (0.440)	DT 0.000 (0.082)	lr 0.0002	loss 0.129 (0.124)
Train: [91][70/589]	BT 0.371 (0.429)	DT 0.000 (0.071)	lr 0.0002	loss 0.119 (0.123)
Train: [91][80/589]	BT 0.374 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.130 (0.124)
Train: [91][90/589]	BT 0.377 (0.418)	DT 0.000 (0.059)	lr 0.0002	loss 0.130 (0.124)
Train: [91][100/589]	BT 0.357 (0.413)	DT 0.000 (0.054)	lr 0.0002	loss 0.115 (0.124)
Train: [91][110/589]	BT 0.371 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.137 (0.125)
Train: [91][120/589]	BT 0.355 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.122 (0.125)
Train: [91][130/589]	BT 0.389 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.126 (0.125)
Train: [91][140/589]	BT 0.362 (0.405)	DT 0.000 (0.045)	lr 0.0002	loss 0.122 (0.125)
Train: [91][150/589]	BT 0.360 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.133 (0.125)
Train: [91][160/589]	BT 0.357 (0.402)	DT 0.000 (0.042)	lr 0.0002	loss 0.101 (0.125)
Train: [91][170/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.120 (0.125)
Train: [91][180/589]	BT 0.362 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.119 (0.125)
Train: [91][190/589]	BT 0.357 (0.397)	DT 0.000 (0.037)	lr 0.0002	loss 0.110 (0.125)
Train: [91][200/589]	BT 0.359 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.122 (0.125)
Train: [91][210/589]	BT 0.360 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.098 (0.125)
Train: [91][220/589]	BT 0.389 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.134 (0.125)
Train: [91][230/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.144 (0.126)
Train: [91][240/589]	BT 0.385 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.130 (0.125)
Train: [91][250/589]	BT 0.378 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.126 (0.125)
Train: [91][260/589]	BT 0.380 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.131 (0.126)
Train: [91][270/589]	BT 0.392 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.136 (0.126)
Train: [91][280/589]	BT 0.389 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.111 (0.126)
Train: [91][290/589]	BT 0.384 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.156 (0.126)
Train: [91][300/589]	BT 0.364 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.101 (0.126)
Train: [91][310/589]	BT 0.359 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.124 (0.126)
Train: [91][320/589]	BT 0.358 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.143 (0.126)
Train: [91][330/589]	BT 0.361 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.109 (0.126)
Train: [91][340/589]	BT 0.357 (0.391)	DT 0.000 (0.030)	lr 0.0002	loss 0.160 (0.126)
Train: [91][350/589]	BT 0.402 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.106 (0.126)
Train: [91][360/589]	BT 0.359 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.133 (0.126)
Train: [91][370/589]	BT 0.357 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.124 (0.126)
Train: [91][380/589]	BT 0.355 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.139 (0.126)
Train: [91][390/589]	BT 0.358 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.117 (0.126)
Train: [91][400/589]	BT 0.360 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.126)
Train: [91][410/589]	BT 0.360 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.123 (0.126)
Train: [91][420/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.126)
Train: [91][430/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.114 (0.126)
Train: [91][440/589]	BT 0.358 (0.390)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.126)
Train: [91][450/589]	BT 0.377 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.126)
Train: [91][460/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.126)
Train: [91][470/589]	BT 0.386 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.110 (0.126)
Train: [91][480/589]	BT 0.374 (0.389)	DT 0.000 (0.028)	lr 0.0002	loss 0.123 (0.126)
Train: [91][490/589]	BT 0.360 (0.389)	DT 0.000 (0.028)	lr 0.0002	loss 0.147 (0.126)
Train: [91][500/589]	BT 0.354 (0.389)	DT 0.000 (0.028)	lr 0.0002	loss 0.118 (0.126)
Train: [91][510/589]	BT 0.359 (0.389)	DT 0.000 (0.028)	lr 0.0002	loss 0.150 (0.126)
Train: [91][520/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.126)
Train: [91][530/589]	BT 0.360 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.120 (0.126)
Train: [91][540/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.106 (0.126)
Train: [91][550/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.097 (0.126)
Train: [91][560/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.116 (0.126)
Train: [91][570/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.126)
Train: [91][580/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.120 (0.126)
epoch 91, total time 228.19
loss: 0.12565996177496108@Epoch: 91
learning_rate: 0.0002,91
Valid: [91][10/88]	BT 0.110 (0.590)	DT 0.000 (0.479)	loss 0.156 (0.139)
Valid: [91][20/88]	BT 0.110 (0.503)	DT 0.000 (0.391)	loss 0.152 (0.138)
Valid: [91][30/88]	BT 0.109 (0.480)	DT 0.000 (0.368)	loss 0.152 (0.140)
Valid: [91][40/88]	BT 0.109 (0.463)	DT 0.000 (0.353)	loss 0.139 (0.139)
Valid: [91][50/88]	BT 0.110 (0.456)	DT 0.000 (0.345)	loss 0.121 (0.138)
Valid: [91][60/88]	BT 0.109 (0.450)	DT 0.000 (0.339)	loss 0.156 (0.140)
Valid: [91][70/88]	BT 0.109 (0.447)	DT 0.000 (0.336)	loss 0.139 (0.140)
Valid: [91][80/88]	BT 0.109 (0.440)	DT 0.000 (0.330)	loss 0.115 (0.138)
Train: [92][10/589]	BT 0.358 (0.755)	DT 0.000 (0.399)	lr 0.0002	loss 0.133 (0.131)
Train: [92][20/589]	BT 0.360 (0.556)	DT 0.000 (0.199)	lr 0.0002	loss 0.102 (0.124)
Train: [92][30/589]	BT 0.357 (0.495)	DT 0.000 (0.138)	lr 0.0002	loss 0.112 (0.122)
Train: [92][40/589]	BT 0.357 (0.468)	DT 0.000 (0.111)	lr 0.0002	loss 0.117 (0.123)
Train: [92][50/589]	BT 0.358 (0.446)	DT 0.000 (0.089)	lr 0.0002	loss 0.139 (0.124)
Train: [92][60/589]	BT 0.358 (0.433)	DT 0.000 (0.075)	lr 0.0002	loss 0.126 (0.125)
Train: [92][70/589]	BT 0.359 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.124 (0.125)
Train: [92][80/589]	BT 0.357 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.122 (0.125)
Train: [92][90/589]	BT 0.357 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.121 (0.125)
Train: [92][100/589]	BT 0.356 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.145 (0.125)
Train: [92][110/589]	BT 0.358 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.111 (0.125)
Train: [92][120/589]	BT 0.358 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.130 (0.125)
Train: [92][130/589]	BT 0.360 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.136 (0.125)
Train: [92][140/589]	BT 0.360 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.129 (0.126)
Train: [92][150/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.108 (0.125)
Train: [92][160/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.119 (0.125)
Train: [92][170/589]	BT 0.360 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.111 (0.125)
Train: [92][180/589]	BT 0.358 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.155 (0.126)
Train: [92][190/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.126)
Train: [92][200/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.102 (0.125)
Train: [92][210/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.136 (0.125)
Train: [92][220/589]	BT 0.372 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.121 (0.125)
Train: [92][230/589]	BT 0.360 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.112 (0.125)
Train: [92][240/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.109 (0.125)
Train: [92][250/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.135 (0.126)
Train: [92][260/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.159 (0.126)
Train: [92][270/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.133 (0.126)
Train: [92][280/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.128 (0.126)
Train: [92][290/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.144 (0.126)
Train: [92][300/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.108 (0.125)
Train: [92][310/589]	BT 0.355 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.125)
Train: [92][320/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.148 (0.126)
Train: [92][330/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.125)
Train: [92][340/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.128 (0.126)
Train: [92][350/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.125)
Train: [92][360/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.125 (0.126)
Train: [92][370/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.126 (0.126)
Train: [92][380/589]	BT 0.375 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.126)
Train: [92][390/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.126)
Train: [92][400/589]	BT 0.353 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.125)
Train: [92][410/589]	BT 0.356 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.126)
Train: [92][420/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.137 (0.126)
Train: [92][430/589]	BT 0.361 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.115 (0.126)
Train: [92][440/589]	BT 0.366 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.125)
Train: [92][450/589]	BT 0.369 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.140 (0.125)
Train: [92][460/589]	BT 0.368 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.109 (0.125)
Train: [92][470/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.111 (0.125)
Train: [92][480/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.113 (0.125)
Train: [92][490/589]	BT 0.361 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.125)
Train: [92][500/589]	BT 0.356 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.125)
Train: [92][510/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.141 (0.125)
Train: [92][520/589]	BT 0.380 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.113 (0.125)
Train: [92][530/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.105 (0.125)
Train: [92][540/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.147 (0.125)
Train: [92][550/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.150 (0.125)
Train: [92][560/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.144 (0.125)
Train: [92][570/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.147 (0.125)
Train: [92][580/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.154 (0.125)
epoch 92, total time 227.32
loss: 0.12522913140901873@Epoch: 92
learning_rate: 0.0002,92
Valid: [92][10/88]	BT 0.110 (0.565)	DT 0.000 (0.453)	loss 0.149 (0.141)
Valid: [92][20/88]	BT 0.110 (0.496)	DT 0.000 (0.384)	loss 0.150 (0.138)
Valid: [92][30/88]	BT 0.109 (0.492)	DT 0.000 (0.381)	loss 0.125 (0.139)
Valid: [92][40/88]	BT 0.109 (0.473)	DT 0.000 (0.362)	loss 0.157 (0.141)
Valid: [92][50/88]	BT 0.109 (0.459)	DT 0.000 (0.348)	loss 0.143 (0.142)
Valid: [92][60/88]	BT 0.109 (0.447)	DT 0.000 (0.337)	loss 0.124 (0.141)
Valid: [92][70/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.149 (0.142)
Valid: [92][80/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.136 (0.141)
Train: [93][10/589]	BT 0.357 (0.768)	DT 0.000 (0.412)	lr 0.0002	loss 0.119 (0.126)
Train: [93][20/589]	BT 0.357 (0.564)	DT 0.000 (0.208)	lr 0.0002	loss 0.125 (0.124)
Train: [93][30/589]	BT 0.358 (0.508)	DT 0.000 (0.151)	lr 0.0002	loss 0.123 (0.122)
Train: [93][40/589]	BT 0.357 (0.475)	DT 0.000 (0.118)	lr 0.0002	loss 0.143 (0.124)
Train: [93][50/589]	BT 0.356 (0.455)	DT 0.000 (0.098)	lr 0.0002	loss 0.132 (0.124)
Train: [93][60/589]	BT 0.369 (0.443)	DT 0.000 (0.085)	lr 0.0002	loss 0.135 (0.125)
Train: [93][70/589]	BT 0.358 (0.431)	DT 0.000 (0.074)	lr 0.0002	loss 0.109 (0.125)
Train: [93][80/589]	BT 0.364 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.141 (0.125)
Train: [93][90/589]	BT 0.358 (0.422)	DT 0.000 (0.064)	lr 0.0002	loss 0.135 (0.124)
Train: [93][100/589]	BT 0.357 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.097 (0.124)
Train: [93][110/589]	BT 0.358 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.128 (0.124)
Train: [93][120/589]	BT 0.365 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.133 (0.124)
Train: [93][130/589]	BT 0.360 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.143 (0.125)
Train: [93][140/589]	BT 0.355 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.142 (0.125)
Train: [93][150/589]	BT 0.355 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.133 (0.125)
Train: [93][160/589]	BT 0.357 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.118 (0.125)
Train: [93][170/589]	BT 0.357 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.131 (0.125)
Train: [93][180/589]	BT 0.404 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.128 (0.125)
Train: [93][190/589]	BT 0.372 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.105 (0.125)
Train: [93][200/589]	BT 0.379 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.123 (0.125)
Train: [93][210/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.117 (0.125)
Train: [93][220/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.124 (0.125)
Train: [93][230/589]	BT 0.356 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.122 (0.125)
Train: [93][240/589]	BT 0.357 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.124 (0.125)
Train: [93][250/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.120 (0.125)
Train: [93][260/589]	BT 0.358 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.132 (0.125)
Train: [93][270/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.128 (0.125)
Train: [93][280/589]	BT 0.375 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.118 (0.125)
Train: [93][290/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.096 (0.125)
Train: [93][300/589]	BT 0.366 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.106 (0.125)
Train: [93][310/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.108 (0.125)
Train: [93][320/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.125)
Train: [93][330/589]	BT 0.390 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.131 (0.125)
Train: [93][340/589]	BT 0.360 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.125)
Train: [93][350/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.099 (0.125)
Train: [93][360/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.140 (0.125)
Train: [93][370/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.122 (0.125)
Train: [93][380/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.137 (0.125)
Train: [93][390/589]	BT 0.361 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.125)
Train: [93][400/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.125)
Train: [93][410/589]	BT 0.360 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.107 (0.125)
Train: [93][420/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.119 (0.125)
Train: [93][430/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.125)
Train: [93][440/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.125)
Train: [93][450/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.121 (0.125)
Train: [93][460/589]	BT 0.367 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.143 (0.125)
Train: [93][470/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.128 (0.125)
Train: [93][480/589]	BT 0.369 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.125)
Train: [93][490/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.106 (0.125)
Train: [93][500/589]	BT 0.364 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.107 (0.125)
Train: [93][510/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.111 (0.125)
Train: [93][520/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.134 (0.125)
Train: [93][530/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.140 (0.125)
Train: [93][540/589]	BT 0.363 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.125)
Train: [93][550/589]	BT 0.383 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.141 (0.125)
Train: [93][560/589]	BT 0.360 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.125)
Train: [93][570/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.104 (0.125)
Train: [93][580/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.105 (0.125)
epoch 93, total time 224.39
loss: 0.1249966563544938@Epoch: 93
learning_rate: 0.0002,93
Valid: [93][10/88]	BT 0.110 (0.529)	DT 0.000 (0.415)	loss 0.143 (0.135)
Valid: [93][20/88]	BT 0.109 (0.469)	DT 0.000 (0.357)	loss 0.154 (0.138)
Valid: [93][30/88]	BT 0.110 (0.448)	DT 0.000 (0.336)	loss 0.132 (0.139)
Valid: [93][40/88]	BT 0.110 (0.437)	DT 0.000 (0.325)	loss 0.153 (0.139)
Valid: [93][50/88]	BT 0.109 (0.437)	DT 0.000 (0.325)	loss 0.142 (0.138)
Valid: [93][60/88]	BT 0.109 (0.432)	DT 0.000 (0.320)	loss 0.120 (0.138)
Valid: [93][70/88]	BT 0.109 (0.429)	DT 0.000 (0.317)	loss 0.164 (0.137)
Valid: [93][80/88]	BT 0.109 (0.426)	DT 0.000 (0.314)	loss 0.138 (0.138)
Train: [94][10/589]	BT 0.370 (0.759)	DT 0.000 (0.403)	lr 0.0002	loss 0.127 (0.125)
Train: [94][20/589]	BT 0.394 (0.567)	DT 0.000 (0.209)	lr 0.0002	loss 0.146 (0.126)
Train: [94][30/589]	BT 0.356 (0.507)	DT 0.000 (0.150)	lr 0.0002	loss 0.140 (0.124)
Train: [94][40/589]	BT 0.388 (0.475)	DT 0.000 (0.117)	lr 0.0002	loss 0.126 (0.124)
Train: [94][50/589]	BT 0.369 (0.452)	DT 0.000 (0.094)	lr 0.0002	loss 0.125 (0.123)
Train: [94][60/589]	BT 0.359 (0.437)	DT 0.000 (0.078)	lr 0.0002	loss 0.114 (0.123)
Train: [94][70/589]	BT 0.357 (0.428)	DT 0.000 (0.069)	lr 0.0002	loss 0.130 (0.124)
Train: [94][80/589]	BT 0.359 (0.422)	DT 0.000 (0.064)	lr 0.0002	loss 0.114 (0.123)
Train: [94][90/589]	BT 0.381 (0.417)	DT 0.000 (0.059)	lr 0.0002	loss 0.147 (0.124)
Train: [94][100/589]	BT 0.357 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.111 (0.125)
Train: [94][110/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.114 (0.124)
Train: [94][120/589]	BT 0.363 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.110 (0.124)
Train: [94][130/589]	BT 0.358 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.127 (0.124)
Train: [94][140/589]	BT 0.356 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.132 (0.123)
Train: [94][150/589]	BT 0.358 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.129 (0.123)
Train: [94][160/589]	BT 0.361 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.129 (0.123)
Train: [94][170/589]	BT 0.361 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.122 (0.123)
Train: [94][180/589]	BT 0.359 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.121 (0.123)
Train: [94][190/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.141 (0.124)
Train: [94][200/589]	BT 0.385 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.140 (0.124)
Train: [94][210/589]	BT 0.362 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.118 (0.124)
Train: [94][220/589]	BT 0.370 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.122 (0.124)
Train: [94][230/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.107 (0.124)
Train: [94][240/589]	BT 0.386 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.124)
Train: [94][250/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.137 (0.124)
Train: [94][260/589]	BT 0.385 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.110 (0.124)
Train: [94][270/589]	BT 0.363 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.115 (0.124)
Train: [94][280/589]	BT 0.374 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.111 (0.124)
Train: [94][290/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.122 (0.124)
Train: [94][300/589]	BT 0.361 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.126 (0.124)
Train: [94][310/589]	BT 0.371 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.113 (0.124)
Train: [94][320/589]	BT 0.382 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.142 (0.124)
Train: [94][330/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.143 (0.125)
Train: [94][340/589]	BT 0.355 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.126 (0.125)
Train: [94][350/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.121 (0.125)
Train: [94][360/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.125)
Train: [94][370/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.144 (0.125)
Train: [94][380/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.114 (0.125)
Train: [94][390/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.133 (0.125)
Train: [94][400/589]	BT 0.364 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.125)
Train: [94][410/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.118 (0.125)
Train: [94][420/589]	BT 0.379 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.126 (0.125)
Train: [94][430/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.126 (0.125)
Train: [94][440/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.130 (0.125)
Train: [94][450/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.111 (0.125)
Train: [94][460/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.142 (0.125)
Train: [94][470/589]	BT 0.356 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.125)
Train: [94][480/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.139 (0.125)
Train: [94][490/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.125)
Train: [94][500/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.134 (0.125)
Train: [94][510/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.148 (0.125)
Train: [94][520/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.117 (0.125)
Train: [94][530/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.116 (0.125)
Train: [94][540/589]	BT 0.359 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.144 (0.125)
Train: [94][550/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.115 (0.125)
Train: [94][560/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.108 (0.125)
Train: [94][570/589]	BT 0.356 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.121 (0.125)
Train: [94][580/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.123 (0.125)
epoch 94, total time 225.78
loss: 0.12489490305982326@Epoch: 94
learning_rate: 0.0002,94
Valid: [94][10/88]	BT 0.110 (0.559)	DT 0.000 (0.448)	loss 0.136 (0.137)
Valid: [94][20/88]	BT 0.109 (0.482)	DT 0.000 (0.371)	loss 0.119 (0.137)
Valid: [94][30/88]	BT 0.110 (0.455)	DT 0.000 (0.344)	loss 0.134 (0.135)
Valid: [94][40/88]	BT 0.109 (0.444)	DT 0.000 (0.333)	loss 0.158 (0.136)
Valid: [94][50/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.135 (0.137)
Valid: [94][60/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.132 (0.136)
Valid: [94][70/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.157 (0.137)
Valid: [94][80/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.159 (0.137)
Train: [95][10/589]	BT 0.366 (0.761)	DT 0.000 (0.404)	lr 0.0002	loss 0.143 (0.133)
Train: [95][20/589]	BT 0.362 (0.568)	DT 0.000 (0.211)	lr 0.0002	loss 0.135 (0.127)
Train: [95][30/589]	BT 0.358 (0.498)	DT 0.000 (0.141)	lr 0.0002	loss 0.136 (0.126)
Train: [95][40/589]	BT 0.358 (0.467)	DT 0.000 (0.110)	lr 0.0002	loss 0.113 (0.125)
Train: [95][50/589]	BT 0.356 (0.447)	DT 0.000 (0.089)	lr 0.0002	loss 0.132 (0.124)
Train: [95][60/589]	BT 0.360 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.108 (0.124)
Train: [95][70/589]	BT 0.358 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.135 (0.124)
Train: [95][80/589]	BT 0.376 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.129 (0.124)
Train: [95][90/589]	BT 0.363 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.125 (0.124)
Train: [95][100/589]	BT 0.360 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.137 (0.125)
Train: [95][110/589]	BT 0.358 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.124 (0.125)
Train: [95][120/589]	BT 0.388 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.138 (0.125)
Train: [95][130/589]	BT 0.356 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.101 (0.124)
Train: [95][140/589]	BT 0.357 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.126 (0.124)
Train: [95][150/589]	BT 0.369 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.113 (0.124)
Train: [95][160/589]	BT 0.357 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.149 (0.124)
Train: [95][170/589]	BT 0.358 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.115 (0.124)
Train: [95][180/589]	BT 0.396 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.137 (0.124)
Train: [95][190/589]	BT 0.367 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.134 (0.125)
Train: [95][200/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.121 (0.124)
Train: [95][210/589]	BT 0.361 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.090 (0.124)
Train: [95][220/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.110 (0.124)
Train: [95][230/589]	BT 0.371 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.130 (0.124)
Train: [95][240/589]	BT 0.370 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.114 (0.124)
Train: [95][250/589]	BT 0.362 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.124 (0.124)
Train: [95][260/589]	BT 0.381 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.124)
Train: [95][270/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.145 (0.125)
Train: [95][280/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.125)
Train: [95][290/589]	BT 0.362 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.119 (0.125)
Train: [95][300/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.124)
Train: [95][310/589]	BT 0.355 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.143 (0.124)
Train: [95][320/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.124)
Train: [95][330/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.124 (0.125)
Train: [95][340/589]	BT 0.364 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.112 (0.125)
Train: [95][350/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.123 (0.125)
Train: [95][360/589]	BT 0.379 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.135 (0.124)
Train: [95][370/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.108 (0.124)
Train: [95][380/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.129 (0.125)
Train: [95][390/589]	BT 0.369 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.112 (0.124)
Train: [95][400/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.124)
Train: [95][410/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.119 (0.124)
Train: [95][420/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.132 (0.124)
Train: [95][430/589]	BT 0.357 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.112 (0.124)
Train: [95][440/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.120 (0.124)
Train: [95][450/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.138 (0.124)
Train: [95][460/589]	BT 0.363 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.158 (0.124)
Train: [95][470/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.124)
Train: [95][480/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.107 (0.124)
Train: [95][490/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.145 (0.124)
Train: [95][500/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.137 (0.124)
Train: [95][510/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.111 (0.124)
Train: [95][520/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.113 (0.124)
Train: [95][530/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.121 (0.124)
Train: [95][540/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.158 (0.124)
Train: [95][550/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.115 (0.124)
Train: [95][560/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.101 (0.124)
Train: [95][570/589]	BT 0.356 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.139 (0.124)
Train: [95][580/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.125)
epoch 95, total time 224.89
loss: 0.12451526544954915@Epoch: 95
learning_rate: 0.0002,95
Valid: [95][10/88]	BT 0.110 (0.546)	DT 0.000 (0.434)	loss 0.115 (0.131)
Valid: [95][20/88]	BT 0.110 (0.484)	DT 0.000 (0.373)	loss 0.163 (0.137)
Valid: [95][30/88]	BT 0.109 (0.460)	DT 0.000 (0.349)	loss 0.116 (0.137)
Valid: [95][40/88]	BT 0.109 (0.444)	DT 0.000 (0.333)	loss 0.126 (0.136)
Valid: [95][50/88]	BT 0.110 (0.436)	DT 0.000 (0.326)	loss 0.127 (0.135)
Valid: [95][60/88]	BT 0.113 (0.430)	DT 0.000 (0.320)	loss 0.150 (0.136)
Valid: [95][70/88]	BT 0.109 (0.428)	DT 0.000 (0.317)	loss 0.144 (0.137)
Valid: [95][80/88]	BT 0.109 (0.427)	DT 0.000 (0.316)	loss 0.136 (0.137)
Train: [96][10/589]	BT 0.357 (0.757)	DT 0.000 (0.402)	lr 0.0002	loss 0.134 (0.113)
Train: [96][20/589]	BT 0.356 (0.564)	DT 0.000 (0.207)	lr 0.0002	loss 0.122 (0.116)
Train: [96][30/589]	BT 0.378 (0.498)	DT 0.000 (0.141)	lr 0.0002	loss 0.141 (0.120)
Train: [96][40/589]	BT 0.377 (0.466)	DT 0.000 (0.108)	lr 0.0002	loss 0.124 (0.120)
Train: [96][50/589]	BT 0.389 (0.447)	DT 0.000 (0.088)	lr 0.0002	loss 0.141 (0.121)
Train: [96][60/589]	BT 0.357 (0.436)	DT 0.000 (0.077)	lr 0.0002	loss 0.150 (0.122)
Train: [96][70/589]	BT 0.366 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.136 (0.122)
Train: [96][80/589]	BT 0.378 (0.421)	DT 0.000 (0.062)	lr 0.0002	loss 0.132 (0.122)
Train: [96][90/589]	BT 0.371 (0.415)	DT 0.000 (0.055)	lr 0.0002	loss 0.114 (0.122)
Train: [96][100/589]	BT 0.361 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.111 (0.122)
Train: [96][110/589]	BT 0.377 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.117 (0.122)
Train: [96][120/589]	BT 0.355 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.124 (0.122)
Train: [96][130/589]	BT 0.355 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.120 (0.122)
Train: [96][140/589]	BT 0.372 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.115 (0.123)
Train: [96][150/589]	BT 0.362 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.102 (0.123)
Train: [96][160/589]	BT 0.364 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.145 (0.123)
Train: [96][170/589]	BT 0.369 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.154 (0.123)
Train: [96][180/589]	BT 0.360 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.124 (0.123)
Train: [96][190/589]	BT 0.361 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.125 (0.123)
Train: [96][200/589]	BT 0.381 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.110 (0.123)
Train: [96][210/589]	BT 0.356 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.107 (0.123)
Train: [96][220/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.107 (0.123)
Train: [96][230/589]	BT 0.355 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.108 (0.123)
Train: [96][240/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.092 (0.123)
Train: [96][250/589]	BT 0.374 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.106 (0.123)
Train: [96][260/589]	BT 0.369 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.117 (0.123)
Train: [96][270/589]	BT 0.389 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.118 (0.123)
Train: [96][280/589]	BT 0.363 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.139 (0.123)
Train: [96][290/589]	BT 0.387 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.123)
Train: [96][300/589]	BT 0.375 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.134 (0.123)
Train: [96][310/589]	BT 0.369 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.123)
Train: [96][320/589]	BT 0.357 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.135 (0.123)
Train: [96][330/589]	BT 0.394 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.123)
Train: [96][340/589]	BT 0.361 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.123)
Train: [96][350/589]	BT 0.368 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.124)
Train: [96][360/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.122 (0.124)
Train: [96][370/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.139 (0.123)
Train: [96][380/589]	BT 0.402 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.124)
Train: [96][390/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.123)
Train: [96][400/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.113 (0.123)
Train: [96][410/589]	BT 0.381 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.099 (0.123)
Train: [96][420/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.110 (0.123)
Train: [96][430/589]	BT 0.382 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.124)
Train: [96][440/589]	BT 0.382 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.105 (0.124)
Train: [96][450/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.124)
Train: [96][460/589]	BT 0.357 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.105 (0.124)
Train: [96][470/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.113 (0.124)
Train: [96][480/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.124)
Train: [96][490/589]	BT 0.356 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.128 (0.124)
Train: [96][500/589]	BT 0.355 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.124)
Train: [96][510/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.124)
Train: [96][520/589]	BT 0.385 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.144 (0.124)
Train: [96][530/589]	BT 0.357 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.124)
Train: [96][540/589]	BT 0.358 (0.383)	DT 0.000 (0.022)	lr 0.0002	loss 0.130 (0.124)
Train: [96][550/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.107 (0.124)
Train: [96][560/589]	BT 0.354 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.114 (0.124)
Train: [96][570/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.109 (0.124)
Train: [96][580/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.124)
epoch 96, total time 225.22
loss: 0.12387227051597961@Epoch: 96
learning_rate: 0.0002,96
Valid: [96][10/88]	BT 0.110 (0.563)	DT 0.000 (0.452)	loss 0.144 (0.146)
Valid: [96][20/88]	BT 0.109 (0.490)	DT 0.000 (0.380)	loss 0.120 (0.144)
Valid: [96][30/88]	BT 0.109 (0.462)	DT 0.000 (0.352)	loss 0.166 (0.143)
Valid: [96][40/88]	BT 0.109 (0.456)	DT 0.000 (0.346)	loss 0.123 (0.143)
Valid: [96][50/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.148 (0.144)
Valid: [96][60/88]	BT 0.109 (0.445)	DT 0.000 (0.335)	loss 0.138 (0.143)
Valid: [96][70/88]	BT 0.109 (0.440)	DT 0.000 (0.330)	loss 0.140 (0.144)
Valid: [96][80/88]	BT 0.109 (0.436)	DT 0.000 (0.326)	loss 0.128 (0.142)
Train: [97][10/589]	BT 0.356 (0.765)	DT 0.000 (0.410)	lr 0.0002	loss 0.130 (0.115)
Train: [97][20/589]	BT 0.377 (0.574)	DT 0.000 (0.217)	lr 0.0002	loss 0.134 (0.119)
Train: [97][30/589]	BT 0.381 (0.507)	DT 0.000 (0.150)	lr 0.0002	loss 0.119 (0.119)
Train: [97][40/589]	BT 0.378 (0.473)	DT 0.000 (0.116)	lr 0.0002	loss 0.125 (0.121)
Train: [97][50/589]	BT 0.355 (0.456)	DT 0.000 (0.098)	lr 0.0002	loss 0.110 (0.121)
Train: [97][60/589]	BT 0.356 (0.444)	DT 0.001 (0.086)	lr 0.0002	loss 0.100 (0.122)
Train: [97][70/589]	BT 0.355 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.119 (0.122)
Train: [97][80/589]	BT 0.355 (0.426)	DT 0.000 (0.069)	lr 0.0002	loss 0.114 (0.122)
Train: [97][90/589]	BT 0.354 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.112 (0.122)
Train: [97][100/589]	BT 0.355 (0.415)	DT 0.000 (0.057)	lr 0.0002	loss 0.133 (0.122)
Train: [97][110/589]	BT 0.354 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.130 (0.122)
Train: [97][120/589]	BT 0.421 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.140 (0.122)
Train: [97][130/589]	BT 0.369 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.108 (0.122)
Train: [97][140/589]	BT 0.358 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.132 (0.122)
Train: [97][150/589]	BT 0.375 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.140 (0.123)
Train: [97][160/589]	BT 0.376 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.124 (0.123)
Train: [97][170/589]	BT 0.366 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.137 (0.123)
Train: [97][180/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.127 (0.123)
Train: [97][190/589]	BT 0.359 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.123)
Train: [97][200/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.123)
Train: [97][210/589]	BT 0.363 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.123)
Train: [97][220/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.143 (0.122)
Train: [97][230/589]	BT 0.361 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.130 (0.122)
Train: [97][240/589]	BT 0.359 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.116 (0.122)
Train: [97][250/589]	BT 0.366 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.104 (0.122)
Train: [97][260/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.152 (0.123)
Train: [97][270/589]	BT 0.366 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.117 (0.123)
Train: [97][280/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.142 (0.123)
Train: [97][290/589]	BT 0.377 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.121 (0.123)
Train: [97][300/589]	BT 0.356 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.143 (0.123)
Train: [97][310/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.147 (0.123)
Train: [97][320/589]	BT 0.361 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.124)
Train: [97][330/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.136 (0.124)
Train: [97][340/589]	BT 0.358 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.110 (0.124)
Train: [97][350/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.121 (0.124)
Train: [97][360/589]	BT 0.359 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.138 (0.124)
Train: [97][370/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.115 (0.124)
Train: [97][380/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.124)
Train: [97][390/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.126 (0.124)
Train: [97][400/589]	BT 0.358 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.135 (0.124)
Train: [97][410/589]	BT 0.362 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.143 (0.124)
Train: [97][420/589]	BT 0.358 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.141 (0.124)
Train: [97][430/589]	BT 0.379 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.113 (0.124)
Train: [97][440/589]	BT 0.360 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.119 (0.124)
Train: [97][450/589]	BT 0.374 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.137 (0.124)
Train: [97][460/589]	BT 0.382 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.111 (0.124)
Train: [97][470/589]	BT 0.377 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.127 (0.124)
Train: [97][480/589]	BT 0.367 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.124)
Train: [97][490/589]	BT 0.379 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.094 (0.124)
Train: [97][500/589]	BT 0.377 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.122 (0.124)
Train: [97][510/589]	BT 0.363 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.114 (0.124)
Train: [97][520/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.124)
Train: [97][530/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.126 (0.124)
Train: [97][540/589]	BT 0.360 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.092 (0.124)
Train: [97][550/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.129 (0.124)
Train: [97][560/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.125 (0.124)
Train: [97][570/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.122 (0.124)
Train: [97][580/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.120 (0.124)
epoch 97, total time 222.56
loss: 0.123963950378755@Epoch: 97
learning_rate: 0.0002,97
Valid: [97][10/88]	BT 0.109 (0.570)	DT 0.000 (0.457)	loss 0.136 (0.139)
Valid: [97][20/88]	BT 0.109 (0.494)	DT 0.000 (0.383)	loss 0.148 (0.138)
Valid: [97][30/88]	BT 0.109 (0.471)	DT 0.000 (0.361)	loss 0.176 (0.140)
Valid: [97][40/88]	BT 0.109 (0.459)	DT 0.000 (0.348)	loss 0.138 (0.139)
Valid: [97][50/88]	BT 0.110 (0.449)	DT 0.000 (0.339)	loss 0.126 (0.140)
Valid: [97][60/88]	BT 0.109 (0.444)	DT 0.000 (0.335)	loss 0.145 (0.141)
Valid: [97][70/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.131 (0.140)
Valid: [97][80/88]	BT 0.109 (0.435)	DT 0.000 (0.325)	loss 0.134 (0.138)
Train: [98][10/589]	BT 0.377 (0.745)	DT 0.000 (0.384)	lr 0.0002	loss 0.107 (0.127)
Train: [98][20/589]	BT 0.356 (0.555)	DT 0.000 (0.196)	lr 0.0002	loss 0.120 (0.129)
Train: [98][30/589]	BT 0.366 (0.493)	DT 0.000 (0.135)	lr 0.0002	loss 0.115 (0.126)
Train: [98][40/589]	BT 0.358 (0.461)	DT 0.000 (0.103)	lr 0.0002	loss 0.138 (0.126)
Train: [98][50/589]	BT 0.358 (0.442)	DT 0.000 (0.084)	lr 0.0002	loss 0.134 (0.125)
Train: [98][60/589]	BT 0.355 (0.431)	DT 0.000 (0.073)	lr 0.0002	loss 0.119 (0.125)
Train: [98][70/589]	BT 0.358 (0.425)	DT 0.000 (0.067)	lr 0.0002	loss 0.118 (0.125)
Train: [98][80/589]	BT 0.356 (0.419)	DT 0.000 (0.062)	lr 0.0002	loss 0.126 (0.124)
Train: [98][90/589]	BT 0.355 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.099 (0.123)
Train: [98][100/589]	BT 0.383 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.121 (0.124)
Train: [98][110/589]	BT 0.372 (0.407)	DT 0.000 (0.048)	lr 0.0002	loss 0.120 (0.123)
Train: [98][120/589]	BT 0.357 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.117 (0.123)
Train: [98][130/589]	BT 0.395 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.124 (0.124)
Train: [98][140/589]	BT 0.379 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.128 (0.123)
Train: [98][150/589]	BT 0.384 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.122 (0.124)
Train: [98][160/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.135 (0.124)
Train: [98][170/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.133 (0.124)
Train: [98][180/589]	BT 0.375 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.144 (0.124)
Train: [98][190/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.124)
Train: [98][200/589]	BT 0.358 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.127 (0.124)
Train: [98][210/589]	BT 0.378 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.114 (0.124)
Train: [98][220/589]	BT 0.358 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.095 (0.124)
Train: [98][230/589]	BT 0.357 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.153 (0.124)
Train: [98][240/589]	BT 0.390 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.135 (0.124)
Train: [98][250/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.124)
Train: [98][260/589]	BT 0.373 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.098 (0.124)
Train: [98][270/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.140 (0.124)
Train: [98][280/589]	BT 0.366 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.105 (0.124)
Train: [98][290/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.137 (0.124)
Train: [98][300/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.135 (0.124)
Train: [98][310/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.136 (0.124)
Train: [98][320/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.152 (0.124)
Train: [98][330/589]	BT 0.366 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.147 (0.124)
Train: [98][340/589]	BT 0.358 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.124)
Train: [98][350/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.127 (0.124)
Train: [98][360/589]	BT 0.363 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.126 (0.124)
Train: [98][370/589]	BT 0.385 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.122 (0.124)
Train: [98][380/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.154 (0.124)
Train: [98][390/589]	BT 0.360 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.124)
Train: [98][400/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.124)
Train: [98][410/589]	BT 0.361 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.124)
Train: [98][420/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.122 (0.124)
Train: [98][430/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.137 (0.124)
Train: [98][440/589]	BT 0.376 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.108 (0.124)
Train: [98][450/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.128 (0.124)
Train: [98][460/589]	BT 0.357 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.110 (0.124)
Train: [98][470/589]	BT 0.360 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.116 (0.124)
Train: [98][480/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.124)
Train: [98][490/589]	BT 0.357 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.124)
Train: [98][500/589]	BT 0.355 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.124)
Train: [98][510/589]	BT 0.363 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.110 (0.124)
Train: [98][520/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.116 (0.124)
Train: [98][530/589]	BT 0.380 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.124)
Train: [98][540/589]	BT 0.362 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.135 (0.124)
Train: [98][550/589]	BT 0.361 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.124)
Train: [98][560/589]	BT 0.359 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.103 (0.124)
Train: [98][570/589]	BT 0.367 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.138 (0.124)
Train: [98][580/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.118 (0.124)
epoch 98, total time 224.55
loss: 0.12374675098987858@Epoch: 98
learning_rate: 0.0002,98
Valid: [98][10/88]	BT 0.110 (0.575)	DT 0.000 (0.465)	loss 0.118 (0.140)
Valid: [98][20/88]	BT 0.110 (0.491)	DT 0.000 (0.380)	loss 0.130 (0.142)
Valid: [98][30/88]	BT 0.109 (0.480)	DT 0.000 (0.369)	loss 0.120 (0.140)
Valid: [98][40/88]	BT 0.109 (0.462)	DT 0.000 (0.352)	loss 0.190 (0.140)
Valid: [98][50/88]	BT 0.110 (0.456)	DT 0.000 (0.346)	loss 0.118 (0.140)
Valid: [98][60/88]	BT 0.109 (0.449)	DT 0.000 (0.339)	loss 0.142 (0.140)
Valid: [98][70/88]	BT 0.109 (0.448)	DT 0.000 (0.338)	loss 0.155 (0.140)
Valid: [98][80/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.132 (0.141)
Train: [99][10/589]	BT 0.358 (0.745)	DT 0.000 (0.390)	lr 0.0002	loss 0.121 (0.120)
Train: [99][20/589]	BT 0.380 (0.567)	DT 0.000 (0.211)	lr 0.0002	loss 0.115 (0.122)
Train: [99][30/589]	BT 0.353 (0.505)	DT 0.000 (0.148)	lr 0.0002	loss 0.123 (0.122)
Train: [99][40/589]	BT 0.360 (0.472)	DT 0.000 (0.114)	lr 0.0002	loss 0.132 (0.122)
Train: [99][50/589]	BT 0.366 (0.453)	DT 0.000 (0.096)	lr 0.0002	loss 0.137 (0.123)
Train: [99][60/589]	BT 0.357 (0.444)	DT 0.000 (0.087)	lr 0.0002	loss 0.105 (0.123)
Train: [99][70/589]	BT 0.389 (0.432)	DT 0.000 (0.074)	lr 0.0002	loss 0.109 (0.124)
Train: [99][80/589]	BT 0.360 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.135 (0.124)
Train: [99][90/589]	BT 0.357 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.125 (0.123)
Train: [99][100/589]	BT 0.358 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.112 (0.123)
Train: [99][110/589]	BT 0.356 (0.411)	DT 0.000 (0.053)	lr 0.0002	loss 0.111 (0.124)
Train: [99][120/589]	BT 0.357 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.121 (0.124)
Train: [99][130/589]	BT 0.356 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.125 (0.124)
Train: [99][140/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.115 (0.123)
Train: [99][150/589]	BT 0.357 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.124 (0.123)
Train: [99][160/589]	BT 0.357 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.150 (0.123)
Train: [99][170/589]	BT 0.359 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.117 (0.123)
Train: [99][180/589]	BT 0.381 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.115 (0.124)
Train: [99][190/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.127 (0.124)
Train: [99][200/589]	BT 0.357 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.128 (0.124)
Train: [99][210/589]	BT 0.389 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.156 (0.124)
Train: [99][220/589]	BT 0.383 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.129 (0.124)
Train: [99][230/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.130 (0.124)
Train: [99][240/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.126 (0.124)
Train: [99][250/589]	BT 0.375 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.136 (0.124)
Train: [99][260/589]	BT 0.358 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.141 (0.124)
Train: [99][270/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.104 (0.124)
Train: [99][280/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.146 (0.124)
Train: [99][290/589]	BT 0.356 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.115 (0.124)
Train: [99][300/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.127 (0.124)
Train: [99][310/589]	BT 0.354 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.125 (0.124)
Train: [99][320/589]	BT 0.375 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.124 (0.124)
Train: [99][330/589]	BT 0.357 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.124 (0.124)
Train: [99][340/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.124)
Train: [99][350/589]	BT 0.385 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.126 (0.124)
Train: [99][360/589]	BT 0.379 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.128 (0.124)
Train: [99][370/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.136 (0.124)
Train: [99][380/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.140 (0.124)
Train: [99][390/589]	BT 0.355 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.129 (0.124)
Train: [99][400/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.121 (0.124)
Train: [99][410/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.124)
Train: [99][420/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.141 (0.124)
Train: [99][430/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.111 (0.124)
Train: [99][440/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.124)
Train: [99][450/589]	BT 0.356 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.119 (0.124)
Train: [99][460/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.128 (0.124)
Train: [99][470/589]	BT 0.357 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.144 (0.124)
Train: [99][480/589]	BT 0.369 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.138 (0.124)
Train: [99][490/589]	BT 0.362 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.124)
Train: [99][500/589]	BT 0.383 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.120 (0.124)
Train: [99][510/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.142 (0.124)
Train: [99][520/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.133 (0.124)
Train: [99][530/589]	BT 0.358 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.146 (0.124)
Train: [99][540/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.120 (0.124)
Train: [99][550/589]	BT 0.357 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.106 (0.123)
Train: [99][560/589]	BT 0.359 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.150 (0.123)
Train: [99][570/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.149 (0.124)
Train: [99][580/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.130 (0.124)
epoch 99, total time 227.78
loss: 0.1235083153569093@Epoch: 99
learning_rate: 0.0002,99
Valid: [99][10/88]	BT 0.109 (0.580)	DT 0.000 (0.468)	loss 0.149 (0.144)
Valid: [99][20/88]	BT 0.109 (0.492)	DT 0.000 (0.381)	loss 0.168 (0.144)
Valid: [99][30/88]	BT 0.109 (0.470)	DT 0.000 (0.360)	loss 0.157 (0.141)
Valid: [99][40/88]	BT 0.109 (0.451)	DT 0.000 (0.341)	loss 0.137 (0.140)
Valid: [99][50/88]	BT 0.109 (0.444)	DT 0.000 (0.334)	loss 0.125 (0.139)
Valid: [99][60/88]	BT 0.109 (0.437)	DT 0.000 (0.327)	loss 0.150 (0.140)
Valid: [99][70/88]	BT 0.109 (0.432)	DT 0.000 (0.323)	loss 0.131 (0.139)
Valid: [99][80/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.151 (0.139)
Train: [100][10/589]	BT 0.355 (0.764)	DT 0.000 (0.407)	lr 0.0002	loss 0.138 (0.120)
Train: [100][20/589]	BT 0.370 (0.584)	DT 0.000 (0.227)	lr 0.0002	loss 0.116 (0.121)
Train: [100][30/589]	BT 0.392 (0.510)	DT 0.000 (0.151)	lr 0.0002	loss 0.113 (0.120)
Train: [100][40/589]	BT 0.358 (0.471)	DT 0.000 (0.114)	lr 0.0002	loss 0.117 (0.121)
Train: [100][50/589]	BT 0.356 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.151 (0.123)
Train: [100][60/589]	BT 0.379 (0.440)	DT 0.000 (0.081)	lr 0.0002	loss 0.119 (0.123)
Train: [100][70/589]	BT 0.359 (0.428)	DT 0.000 (0.070)	lr 0.0002	loss 0.132 (0.123)
Train: [100][80/589]	BT 0.357 (0.423)	DT 0.000 (0.065)	lr 0.0002	loss 0.134 (0.123)
Train: [100][90/589]	BT 0.355 (0.418)	DT 0.000 (0.060)	lr 0.0002	loss 0.122 (0.123)
Train: [100][100/589]	BT 0.358 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.116 (0.122)
Train: [100][110/589]	BT 0.371 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.117 (0.123)
Train: [100][120/589]	BT 0.358 (0.405)	DT 0.000 (0.047)	lr 0.0002	loss 0.150 (0.123)
Train: [100][130/589]	BT 0.382 (0.404)	DT 0.000 (0.046)	lr 0.0002	loss 0.110 (0.123)
Train: [100][140/589]	BT 0.365 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.099 (0.123)
Train: [100][150/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.147 (0.123)
Train: [100][160/589]	BT 0.358 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.159 (0.123)
Train: [100][170/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.128 (0.123)
Train: [100][180/589]	BT 0.380 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.113 (0.124)
Train: [100][190/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.140 (0.124)
Train: [100][200/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.123 (0.124)
Train: [100][210/589]	BT 0.369 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.130 (0.124)
Train: [100][220/589]	BT 0.358 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.141 (0.124)
Train: [100][230/589]	BT 0.368 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.103 (0.123)
Train: [100][240/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.124 (0.123)
Train: [100][250/589]	BT 0.365 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.121 (0.123)
Train: [100][260/589]	BT 0.372 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.095 (0.123)
Train: [100][270/589]	BT 0.384 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.103 (0.123)
Train: [100][280/589]	BT 0.366 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.115 (0.123)
Train: [100][290/589]	BT 0.357 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.146 (0.123)
Train: [100][300/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.113 (0.123)
Train: [100][310/589]	BT 0.364 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.140 (0.123)
Train: [100][320/589]	BT 0.366 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.115 (0.123)
Train: [100][330/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.141 (0.123)
Train: [100][340/589]	BT 0.360 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.124)
Train: [100][350/589]	BT 0.373 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.157 (0.123)
Train: [100][360/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.132 (0.124)
Train: [100][370/589]	BT 0.370 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.108 (0.124)
Train: [100][380/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.124 (0.124)
Train: [100][390/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.109 (0.123)
Train: [100][400/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.117 (0.124)
Train: [100][410/589]	BT 0.357 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.133 (0.124)
Train: [100][420/589]	BT 0.360 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.134 (0.124)
Train: [100][430/589]	BT 0.358 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.129 (0.124)
Train: [100][440/589]	BT 0.363 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.118 (0.124)
Train: [100][450/589]	BT 0.369 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.133 (0.123)
Train: [100][460/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.151 (0.123)
Train: [100][470/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.116 (0.123)
Train: [100][480/589]	BT 0.360 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.093 (0.123)
Train: [100][490/589]	BT 0.357 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.124 (0.123)
Train: [100][500/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.131 (0.123)
Train: [100][510/589]	BT 0.360 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.112 (0.123)
Train: [100][520/589]	BT 0.357 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.126 (0.123)
Train: [100][530/589]	BT 0.358 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.151 (0.123)
Train: [100][540/589]	BT 0.369 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.128 (0.123)
Train: [100][550/589]	BT 0.357 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.136 (0.123)
Train: [100][560/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.107 (0.123)
Train: [100][570/589]	BT 0.362 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.147 (0.123)
Train: [100][580/589]	BT 0.358 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.115 (0.123)
epoch 100, total time 222.80
loss: 0.123315731831574@Epoch: 100
learning_rate: 0.0002,100
Valid: [100][10/88]	BT 0.110 (0.556)	DT 0.000 (0.443)	loss 0.138 (0.141)
Valid: [100][20/88]	BT 0.110 (0.482)	DT 0.000 (0.370)	loss 0.148 (0.142)
Valid: [100][30/88]	BT 0.110 (0.462)	DT 0.000 (0.350)	loss 0.123 (0.140)
Valid: [100][40/88]	BT 0.110 (0.451)	DT 0.000 (0.339)	loss 0.158 (0.140)
Valid: [100][50/88]	BT 0.109 (0.446)	DT 0.000 (0.335)	loss 0.150 (0.141)
Valid: [100][60/88]	BT 0.109 (0.442)	DT 0.000 (0.331)	loss 0.101 (0.139)
Valid: [100][70/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.157 (0.140)
Valid: [100][80/88]	BT 0.109 (0.430)	DT 0.000 (0.319)	loss 0.132 (0.141)
Train: [101][10/589]	BT 0.354 (0.736)	DT 0.000 (0.378)	lr 0.0002	loss 0.121 (0.125)
Train: [101][20/589]	BT 0.358 (0.553)	DT 0.000 (0.195)	lr 0.0002	loss 0.123 (0.123)
Train: [101][30/589]	BT 0.371 (0.496)	DT 0.000 (0.138)	lr 0.0002	loss 0.126 (0.123)
Train: [101][40/589]	BT 0.388 (0.469)	DT 0.000 (0.111)	lr 0.0002	loss 0.119 (0.125)
Train: [101][50/589]	BT 0.363 (0.450)	DT 0.000 (0.092)	lr 0.0002	loss 0.108 (0.123)
Train: [101][60/589]	BT 0.359 (0.436)	DT 0.000 (0.078)	lr 0.0002	loss 0.130 (0.123)
Train: [101][70/589]	BT 0.358 (0.427)	DT 0.000 (0.069)	lr 0.0002	loss 0.117 (0.123)
Train: [101][80/589]	BT 0.358 (0.419)	DT 0.000 (0.061)	lr 0.0002	loss 0.139 (0.123)
Train: [101][90/589]	BT 0.358 (0.414)	DT 0.000 (0.057)	lr 0.0002	loss 0.125 (0.123)
Train: [101][100/589]	BT 0.363 (0.410)	DT 0.000 (0.052)	lr 0.0002	loss 0.112 (0.123)
Train: [101][110/589]	BT 0.358 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.134 (0.123)
Train: [101][120/589]	BT 0.356 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.111 (0.123)
Train: [101][130/589]	BT 0.364 (0.403)	DT 0.000 (0.045)	lr 0.0002	loss 0.092 (0.122)
Train: [101][140/589]	BT 0.356 (0.401)	DT 0.000 (0.043)	lr 0.0002	loss 0.108 (0.122)
Train: [101][150/589]	BT 0.371 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.136 (0.123)
Train: [101][160/589]	BT 0.361 (0.397)	DT 0.000 (0.039)	lr 0.0002	loss 0.118 (0.123)
Train: [101][170/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.126 (0.123)
Train: [101][180/589]	BT 0.377 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.137 (0.122)
Train: [101][190/589]	BT 0.358 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.132 (0.123)
Train: [101][200/589]	BT 0.359 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.122 (0.122)
Train: [101][210/589]	BT 0.375 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.134 (0.122)
Train: [101][220/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.159 (0.123)
Train: [101][230/589]	BT 0.380 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.098 (0.123)
Train: [101][240/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.125 (0.123)
Train: [101][250/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.132 (0.123)
Train: [101][260/589]	BT 0.367 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.110 (0.122)
Train: [101][270/589]	BT 0.395 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.132 (0.123)
Train: [101][280/589]	BT 0.363 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.126 (0.122)
Train: [101][290/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.128 (0.122)
Train: [101][300/589]	BT 0.375 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.107 (0.122)
Train: [101][310/589]	BT 0.392 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.122)
Train: [101][320/589]	BT 0.360 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.111 (0.123)
Train: [101][330/589]	BT 0.362 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.095 (0.122)
Train: [101][340/589]	BT 0.383 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.119 (0.123)
Train: [101][350/589]	BT 0.356 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.141 (0.123)
Train: [101][360/589]	BT 0.361 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.118 (0.123)
Train: [101][370/589]	BT 0.366 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.123)
Train: [101][380/589]	BT 0.369 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.117 (0.123)
Train: [101][390/589]	BT 0.359 (0.381)	DT 0.000 (0.021)	lr 0.0002	loss 0.141 (0.123)
Train: [101][400/589]	BT 0.356 (0.380)	DT 0.000 (0.021)	lr 0.0002	loss 0.128 (0.123)
Train: [101][410/589]	BT 0.375 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.138 (0.123)
Train: [101][420/589]	BT 0.363 (0.380)	DT 0.000 (0.020)	lr 0.0002	loss 0.132 (0.123)
Train: [101][430/589]	BT 0.358 (0.379)	DT 0.000 (0.020)	lr 0.0002	loss 0.147 (0.123)
Train: [101][440/589]	BT 0.357 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.117 (0.123)
Train: [101][450/589]	BT 0.371 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.119 (0.123)
Train: [101][460/589]	BT 0.360 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.109 (0.123)
Train: [101][470/589]	BT 0.372 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.119 (0.123)
Train: [101][480/589]	BT 0.391 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.118 (0.123)
Train: [101][490/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.100 (0.123)
Train: [101][500/589]	BT 0.382 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.149 (0.123)
Train: [101][510/589]	BT 0.357 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.156 (0.123)
Train: [101][520/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.125 (0.123)
Train: [101][530/589]	BT 0.356 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.103 (0.123)
Train: [101][540/589]	BT 0.375 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.115 (0.123)
Train: [101][550/589]	BT 0.359 (0.379)	DT 0.000 (0.019)	lr 0.0002	loss 0.123 (0.123)
Train: [101][560/589]	BT 0.359 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.132 (0.123)
Train: [101][570/589]	BT 0.358 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.135 (0.123)
Train: [101][580/589]	BT 0.373 (0.378)	DT 0.000 (0.019)	lr 0.0002	loss 0.109 (0.123)
epoch 101, total time 222.46
loss: 0.1227560524021665@Epoch: 101
learning_rate: 0.0002,101
Valid: [101][10/88]	BT 0.110 (0.568)	DT 0.000 (0.457)	loss 0.144 (0.139)
Valid: [101][20/88]	BT 0.109 (0.487)	DT 0.000 (0.377)	loss 0.156 (0.142)
Valid: [101][30/88]	BT 0.110 (0.460)	DT 0.000 (0.350)	loss 0.130 (0.141)
Valid: [101][40/88]	BT 0.110 (0.447)	DT 0.000 (0.338)	loss 0.128 (0.139)
Valid: [101][50/88]	BT 0.109 (0.444)	DT 0.000 (0.335)	loss 0.158 (0.142)
Valid: [101][60/88]	BT 0.110 (0.438)	DT 0.000 (0.328)	loss 0.126 (0.143)
Valid: [101][70/88]	BT 0.109 (0.431)	DT 0.000 (0.321)	loss 0.142 (0.142)
Valid: [101][80/88]	BT 0.109 (0.425)	DT 0.000 (0.316)	loss 0.150 (0.142)
Train: [102][10/589]	BT 0.356 (0.762)	DT 0.000 (0.406)	lr 0.0002	loss 0.107 (0.118)
Train: [102][20/589]	BT 0.364 (0.566)	DT 0.000 (0.209)	lr 0.0002	loss 0.123 (0.121)
Train: [102][30/589]	BT 0.364 (0.506)	DT 0.000 (0.148)	lr 0.0002	loss 0.116 (0.121)
Train: [102][40/589]	BT 0.368 (0.472)	DT 0.000 (0.114)	lr 0.0002	loss 0.110 (0.120)
Train: [102][50/589]	BT 0.381 (0.452)	DT 0.000 (0.094)	lr 0.0002	loss 0.116 (0.122)
Train: [102][60/589]	BT 0.379 (0.440)	DT 0.000 (0.082)	lr 0.0002	loss 0.120 (0.122)
Train: [102][70/589]	BT 0.357 (0.432)	DT 0.000 (0.074)	lr 0.0002	loss 0.149 (0.122)
Train: [102][80/589]	BT 0.370 (0.424)	DT 0.000 (0.067)	lr 0.0002	loss 0.124 (0.123)
Train: [102][90/589]	BT 0.357 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.112 (0.123)
Train: [102][100/589]	BT 0.356 (0.416)	DT 0.000 (0.058)	lr 0.0002	loss 0.104 (0.123)
Train: [102][110/589]	BT 0.389 (0.412)	DT 0.000 (0.053)	lr 0.0002	loss 0.125 (0.122)
Train: [102][120/589]	BT 0.373 (0.409)	DT 0.000 (0.050)	lr 0.0002	loss 0.115 (0.122)
Train: [102][130/589]	BT 0.379 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.116 (0.122)
Train: [102][140/589]	BT 0.378 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.129 (0.122)
Train: [102][150/589]	BT 0.354 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.130 (0.122)
Train: [102][160/589]	BT 0.358 (0.401)	DT 0.000 (0.041)	lr 0.0002	loss 0.101 (0.122)
Train: [102][170/589]	BT 0.360 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.136 (0.122)
Train: [102][180/589]	BT 0.358 (0.398)	DT 0.000 (0.038)	lr 0.0002	loss 0.131 (0.122)
Train: [102][190/589]	BT 0.359 (0.396)	DT 0.000 (0.036)	lr 0.0002	loss 0.120 (0.122)
Train: [102][200/589]	BT 0.358 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.127 (0.122)
Train: [102][210/589]	BT 0.357 (0.394)	DT 0.000 (0.034)	lr 0.0002	loss 0.113 (0.122)
Train: [102][220/589]	BT 0.373 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.140 (0.122)
Train: [102][230/589]	BT 0.357 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.106 (0.122)
Train: [102][240/589]	BT 0.363 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.143 (0.122)
Train: [102][250/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.122)
Train: [102][260/589]	BT 0.361 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.127 (0.122)
Train: [102][270/589]	BT 0.359 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.126 (0.122)
Train: [102][280/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.128 (0.122)
Train: [102][290/589]	BT 0.365 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.129 (0.122)
Train: [102][300/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.102 (0.122)
Train: [102][310/589]	BT 0.366 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.119 (0.122)
Train: [102][320/589]	BT 0.357 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.113 (0.122)
Train: [102][330/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.110 (0.123)
Train: [102][340/589]	BT 0.358 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.131 (0.123)
Train: [102][350/589]	BT 0.365 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.123 (0.123)
Train: [102][360/589]	BT 0.371 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.148 (0.123)
Train: [102][370/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.143 (0.123)
Train: [102][380/589]	BT 0.356 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.148 (0.123)
Train: [102][390/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.114 (0.123)
Train: [102][400/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.130 (0.123)
Train: [102][410/589]	BT 0.389 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.123)
Train: [102][420/589]	BT 0.372 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.123)
Train: [102][430/589]	BT 0.362 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.117 (0.123)
Train: [102][440/589]	BT 0.384 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.134 (0.123)
Train: [102][450/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.123 (0.123)
Train: [102][460/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.105 (0.123)
Train: [102][470/589]	BT 0.358 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.102 (0.122)
Train: [102][480/589]	BT 0.384 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.149 (0.123)
Train: [102][490/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.108 (0.123)
Train: [102][500/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.138 (0.123)
Train: [102][510/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.106 (0.123)
Train: [102][520/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.138 (0.123)
Train: [102][530/589]	BT 0.360 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.123 (0.123)
Train: [102][540/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.130 (0.123)
Train: [102][550/589]	BT 0.358 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.137 (0.123)
Train: [102][560/589]	BT 0.387 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.131 (0.123)
Train: [102][570/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.102 (0.123)
Train: [102][580/589]	BT 0.356 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.122)
epoch 102, total time 226.73
loss: 0.12245815829319485@Epoch: 102
learning_rate: 0.0002,102
Valid: [102][10/88]	BT 0.109 (0.590)	DT 0.000 (0.479)	loss 0.131 (0.144)
Valid: [102][20/88]	BT 0.110 (0.504)	DT 0.000 (0.394)	loss 0.122 (0.140)
Valid: [102][30/88]	BT 0.109 (0.480)	DT 0.000 (0.370)	loss 0.143 (0.138)
Valid: [102][40/88]	BT 0.109 (0.465)	DT 0.000 (0.355)	loss 0.128 (0.137)
Valid: [102][50/88]	BT 0.109 (0.453)	DT 0.000 (0.343)	loss 0.167 (0.139)
Valid: [102][60/88]	BT 0.109 (0.450)	DT 0.000 (0.340)	loss 0.133 (0.140)
Valid: [102][70/88]	BT 0.109 (0.446)	DT 0.000 (0.336)	loss 0.120 (0.140)
Valid: [102][80/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.145 (0.140)
Train: [103][10/589]	BT 0.356 (0.770)	DT 0.000 (0.414)	lr 0.0002	loss 0.158 (0.127)
Train: [103][20/589]	BT 0.357 (0.574)	DT 0.000 (0.217)	lr 0.0002	loss 0.123 (0.126)
Train: [103][30/589]	BT 0.356 (0.507)	DT 0.000 (0.149)	lr 0.0002	loss 0.116 (0.126)
Train: [103][40/589]	BT 0.367 (0.480)	DT 0.000 (0.123)	lr 0.0002	loss 0.130 (0.124)
Train: [103][50/589]	BT 0.376 (0.460)	DT 0.000 (0.103)	lr 0.0002	loss 0.132 (0.124)
Train: [103][60/589]	BT 0.374 (0.447)	DT 0.000 (0.090)	lr 0.0002	loss 0.111 (0.124)
Train: [103][70/589]	BT 0.361 (0.435)	DT 0.000 (0.078)	lr 0.0002	loss 0.116 (0.124)
Train: [103][80/589]	BT 0.358 (0.429)	DT 0.000 (0.072)	lr 0.0002	loss 0.092 (0.123)
Train: [103][90/589]	BT 0.371 (0.424)	DT 0.000 (0.066)	lr 0.0002	loss 0.134 (0.123)
Train: [103][100/589]	BT 0.357 (0.417)	DT 0.000 (0.060)	lr 0.0002	loss 0.113 (0.123)
Train: [103][110/589]	BT 0.358 (0.414)	DT 0.000 (0.056)	lr 0.0002	loss 0.135 (0.123)
Train: [103][120/589]	BT 0.378 (0.411)	DT 0.000 (0.054)	lr 0.0002	loss 0.112 (0.124)
Train: [103][130/589]	BT 0.376 (0.408)	DT 0.000 (0.050)	lr 0.0002	loss 0.128 (0.123)
Train: [103][140/589]	BT 0.355 (0.406)	DT 0.000 (0.048)	lr 0.0002	loss 0.135 (0.123)
Train: [103][150/589]	BT 0.357 (0.404)	DT 0.000 (0.047)	lr 0.0002	loss 0.111 (0.123)
Train: [103][160/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.121 (0.123)
Train: [103][170/589]	BT 0.357 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.119 (0.123)
Train: [103][180/589]	BT 0.355 (0.403)	DT 0.000 (0.046)	lr 0.0002	loss 0.114 (0.123)
Train: [103][190/589]	BT 0.370 (0.402)	DT 0.000 (0.044)	lr 0.0002	loss 0.105 (0.122)
Train: [103][200/589]	BT 0.381 (0.400)	DT 0.000 (0.042)	lr 0.0002	loss 0.125 (0.122)
Train: [103][210/589]	BT 0.358 (0.399)	DT 0.000 (0.041)	lr 0.0002	loss 0.112 (0.122)
Train: [103][220/589]	BT 0.359 (0.398)	DT 0.000 (0.040)	lr 0.0002	loss 0.125 (0.122)
Train: [103][230/589]	BT 0.378 (0.396)	DT 0.000 (0.038)	lr 0.0002	loss 0.141 (0.122)
Train: [103][240/589]	BT 0.357 (0.395)	DT 0.000 (0.037)	lr 0.0002	loss 0.127 (0.122)
Train: [103][250/589]	BT 0.365 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.096 (0.122)
Train: [103][260/589]	BT 0.358 (0.394)	DT 0.000 (0.036)	lr 0.0002	loss 0.124 (0.122)
Train: [103][270/589]	BT 0.359 (0.393)	DT 0.000 (0.035)	lr 0.0002	loss 0.106 (0.122)
Train: [103][280/589]	BT 0.362 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.115 (0.122)
Train: [103][290/589]	BT 0.354 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.135 (0.122)
Train: [103][300/589]	BT 0.360 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.122)
Train: [103][310/589]	BT 0.357 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.124 (0.122)
Train: [103][320/589]	BT 0.357 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.115 (0.122)
Train: [103][330/589]	BT 0.359 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.123 (0.122)
Train: [103][340/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.128 (0.122)
Train: [103][350/589]	BT 0.357 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.157 (0.122)
Train: [103][360/589]	BT 0.359 (0.389)	DT 0.000 (0.031)	lr 0.0002	loss 0.136 (0.122)
Train: [103][370/589]	BT 0.358 (0.388)	DT 0.000 (0.030)	lr 0.0002	loss 0.122 (0.122)
Train: [103][380/589]	BT 0.364 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.132 (0.122)
Train: [103][390/589]	BT 0.357 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.136 (0.122)
Train: [103][400/589]	BT 0.358 (0.387)	DT 0.000 (0.029)	lr 0.0002	loss 0.143 (0.122)
Train: [103][410/589]	BT 0.359 (0.387)	DT 0.000 (0.028)	lr 0.0002	loss 0.116 (0.122)
Train: [103][420/589]	BT 0.358 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.105 (0.122)
Train: [103][430/589]	BT 0.379 (0.386)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.122)
Train: [103][440/589]	BT 0.388 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.124 (0.122)
Train: [103][450/589]	BT 0.359 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.113 (0.122)
Train: [103][460/589]	BT 0.385 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.125 (0.122)
Train: [103][470/589]	BT 0.360 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.105 (0.122)
Train: [103][480/589]	BT 0.359 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.112 (0.122)
Train: [103][490/589]	BT 0.360 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.139 (0.123)
Train: [103][500/589]	BT 0.364 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.117 (0.122)
Train: [103][510/589]	BT 0.381 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.129 (0.122)
Train: [103][520/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.146 (0.122)
Train: [103][530/589]	BT 0.360 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.116 (0.122)
Train: [103][540/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.122)
Train: [103][550/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.130 (0.122)
Train: [103][560/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.147 (0.123)
Train: [103][570/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.113 (0.123)
Train: [103][580/589]	BT 0.367 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.124 (0.123)
epoch 103, total time 224.78
loss: 0.12258374413373695@Epoch: 103
learning_rate: 0.0002,103
Valid: [103][10/88]	BT 0.109 (0.546)	DT 0.000 (0.431)	loss 0.144 (0.143)
Valid: [103][20/88]	BT 0.109 (0.477)	DT 0.000 (0.364)	loss 0.116 (0.139)
Valid: [103][30/88]	BT 0.110 (0.451)	DT 0.000 (0.338)	loss 0.140 (0.137)
Valid: [103][40/88]	BT 0.109 (0.444)	DT 0.000 (0.332)	loss 0.151 (0.138)
Valid: [103][50/88]	BT 0.109 (0.435)	DT 0.000 (0.324)	loss 0.116 (0.137)
Valid: [103][60/88]	BT 0.109 (0.429)	DT 0.000 (0.317)	loss 0.153 (0.138)
Valid: [103][70/88]	BT 0.110 (0.427)	DT 0.000 (0.316)	loss 0.147 (0.139)
Valid: [103][80/88]	BT 0.109 (0.427)	DT 0.000 (0.316)	loss 0.131 (0.140)
Train: [104][10/589]	BT 0.356 (0.734)	DT 0.000 (0.378)	lr 0.0002	loss 0.123 (0.122)
Train: [104][20/589]	BT 0.387 (0.566)	DT 0.000 (0.209)	lr 0.0002	loss 0.117 (0.119)
Train: [104][30/589]	BT 0.399 (0.506)	DT 0.000 (0.147)	lr 0.0002	loss 0.133 (0.120)
Train: [104][40/589]	BT 0.370 (0.474)	DT 0.000 (0.115)	lr 0.0002	loss 0.138 (0.120)
Train: [104][50/589]	BT 0.357 (0.456)	DT 0.000 (0.098)	lr 0.0002	loss 0.114 (0.119)
Train: [104][60/589]	BT 0.380 (0.445)	DT 0.000 (0.087)	lr 0.0002	loss 0.153 (0.120)
Train: [104][70/589]	BT 0.358 (0.433)	DT 0.000 (0.074)	lr 0.0002	loss 0.127 (0.119)
Train: [104][80/589]	BT 0.355 (0.424)	DT 0.000 (0.065)	lr 0.0002	loss 0.130 (0.119)
Train: [104][90/589]	BT 0.355 (0.418)	DT 0.000 (0.060)	lr 0.0002	loss 0.134 (0.119)
Train: [104][100/589]	BT 0.354 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.104 (0.119)
Train: [104][110/589]	BT 0.356 (0.411)	DT 0.000 (0.052)	lr 0.0002	loss 0.111 (0.119)
Train: [104][120/589]	BT 0.357 (0.407)	DT 0.000 (0.049)	lr 0.0002	loss 0.126 (0.119)
Train: [104][130/589]	BT 0.355 (0.405)	DT 0.000 (0.046)	lr 0.0002	loss 0.116 (0.120)
Train: [104][140/589]	BT 0.377 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.130 (0.120)
Train: [104][150/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.116 (0.119)
Train: [104][160/589]	BT 0.356 (0.400)	DT 0.000 (0.041)	lr 0.0002	loss 0.125 (0.120)
Train: [104][170/589]	BT 0.376 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.144 (0.120)
Train: [104][180/589]	BT 0.357 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.129 (0.120)
Train: [104][190/589]	BT 0.359 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.124 (0.120)
Train: [104][200/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.125 (0.120)
Train: [104][210/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.119 (0.120)
Train: [104][220/589]	BT 0.357 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.114 (0.120)
Train: [104][230/589]	BT 0.358 (0.392)	DT 0.000 (0.034)	lr 0.0002	loss 0.132 (0.121)
Train: [104][240/589]	BT 0.360 (0.391)	DT 0.000 (0.033)	lr 0.0002	loss 0.120 (0.120)
Train: [104][250/589]	BT 0.356 (0.390)	DT 0.000 (0.032)	lr 0.0002	loss 0.116 (0.120)
Train: [104][260/589]	BT 0.357 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.123 (0.120)
Train: [104][270/589]	BT 0.358 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.130 (0.121)
Train: [104][280/589]	BT 0.373 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.139 (0.121)
Train: [104][290/589]	BT 0.384 (0.389)	DT 0.000 (0.030)	lr 0.0002	loss 0.129 (0.121)
Train: [104][300/589]	BT 0.355 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.110 (0.121)
Train: [104][310/589]	BT 0.355 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.141 (0.121)
Train: [104][320/589]	BT 0.358 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.105 (0.121)
Train: [104][330/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.121)
Train: [104][340/589]	BT 0.371 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.147 (0.121)
Train: [104][350/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.120 (0.121)
Train: [104][360/589]	BT 0.357 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.121)
Train: [104][370/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.136 (0.122)
Train: [104][380/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.122 (0.122)
Train: [104][390/589]	BT 0.382 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.122)
Train: [104][400/589]	BT 0.382 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.133 (0.122)
Train: [104][410/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.122)
Train: [104][420/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.127 (0.122)
Train: [104][430/589]	BT 0.364 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.098 (0.122)
Train: [104][440/589]	BT 0.357 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.117 (0.122)
Train: [104][450/589]	BT 0.360 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.110 (0.122)
Train: [104][460/589]	BT 0.373 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.116 (0.122)
Train: [104][470/589]	BT 0.360 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.133 (0.122)
Train: [104][480/589]	BT 0.363 (0.382)	DT 0.000 (0.023)	lr 0.0002	loss 0.122 (0.122)
Train: [104][490/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.114 (0.122)
Train: [104][500/589]	BT 0.371 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.112 (0.122)
Train: [104][510/589]	BT 0.358 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.131 (0.122)
Train: [104][520/589]	BT 0.359 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.129 (0.122)
Train: [104][530/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.126 (0.122)
Train: [104][540/589]	BT 0.362 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.123 (0.122)
Train: [104][550/589]	BT 0.357 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.110 (0.122)
Train: [104][560/589]	BT 0.360 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.120 (0.122)
Train: [104][570/589]	BT 0.356 (0.382)	DT 0.000 (0.022)	lr 0.0002	loss 0.117 (0.122)
Train: [104][580/589]	BT 0.364 (0.381)	DT 0.000 (0.022)	lr 0.0002	loss 0.132 (0.122)
epoch 104, total time 224.37
loss: 0.12224351214405228@Epoch: 104
learning_rate: 0.0002,104
Valid: [104][10/88]	BT 0.110 (0.555)	DT 0.000 (0.444)	loss 0.142 (0.128)
Valid: [104][20/88]	BT 0.110 (0.488)	DT 0.000 (0.377)	loss 0.150 (0.139)
Valid: [104][30/88]	BT 0.109 (0.465)	DT 0.000 (0.354)	loss 0.142 (0.137)
Valid: [104][40/88]	BT 0.109 (0.453)	DT 0.000 (0.342)	loss 0.170 (0.139)
Valid: [104][50/88]	BT 0.110 (0.446)	DT 0.000 (0.335)	loss 0.152 (0.140)
Valid: [104][60/88]	BT 0.115 (0.437)	DT 0.000 (0.327)	loss 0.127 (0.140)
Valid: [104][70/88]	BT 0.110 (0.435)	DT 0.000 (0.324)	loss 0.131 (0.141)
Valid: [104][80/88]	BT 0.109 (0.431)	DT 0.000 (0.320)	loss 0.155 (0.140)
Train: [105][10/589]	BT 0.388 (0.763)	DT 0.000 (0.405)	lr 0.0002	loss 0.113 (0.122)
Train: [105][20/589]	BT 0.356 (0.573)	DT 0.000 (0.215)	lr 0.0002	loss 0.104 (0.120)
Train: [105][30/589]	BT 0.364 (0.506)	DT 0.000 (0.148)	lr 0.0002	loss 0.108 (0.119)
Train: [105][40/589]	BT 0.363 (0.473)	DT 0.000 (0.115)	lr 0.0002	loss 0.113 (0.118)
Train: [105][50/589]	BT 0.358 (0.456)	DT 0.000 (0.097)	lr 0.0002	loss 0.141 (0.118)
Train: [105][60/589]	BT 0.418 (0.442)	DT 0.000 (0.082)	lr 0.0002	loss 0.097 (0.119)
Train: [105][70/589]	BT 0.365 (0.431)	DT 0.000 (0.071)	lr 0.0002	loss 0.132 (0.120)
Train: [105][80/589]	BT 0.359 (0.422)	DT 0.000 (0.063)	lr 0.0002	loss 0.121 (0.120)
Train: [105][90/589]	BT 0.377 (0.415)	DT 0.000 (0.056)	lr 0.0002	loss 0.119 (0.120)
Train: [105][100/589]	BT 0.362 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.110 (0.120)
Train: [105][110/589]	BT 0.362 (0.410)	DT 0.000 (0.051)	lr 0.0002	loss 0.147 (0.120)
Train: [105][120/589]	BT 0.360 (0.406)	DT 0.000 (0.046)	lr 0.0002	loss 0.126 (0.120)
Train: [105][130/589]	BT 0.357 (0.404)	DT 0.001 (0.045)	lr 0.0002	loss 0.118 (0.120)
Train: [105][140/589]	BT 0.357 (0.401)	DT 0.000 (0.042)	lr 0.0002	loss 0.144 (0.120)
Train: [105][150/589]	BT 0.380 (0.400)	DT 0.000 (0.040)	lr 0.0002	loss 0.115 (0.120)
Train: [105][160/589]	BT 0.359 (0.397)	DT 0.000 (0.038)	lr 0.0002	loss 0.114 (0.120)
Train: [105][170/589]	BT 0.362 (0.395)	DT 0.000 (0.036)	lr 0.0002	loss 0.136 (0.120)
Train: [105][180/589]	BT 0.356 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.122 (0.120)
Train: [105][190/589]	BT 0.381 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.150 (0.121)
Train: [105][200/589]	BT 0.355 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.112 (0.121)
Train: [105][210/589]	BT 0.359 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.123 (0.121)
Train: [105][220/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.138 (0.121)
Train: [105][230/589]	BT 0.363 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.129 (0.121)
Train: [105][240/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.110 (0.121)
Train: [105][250/589]	BT 0.357 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.121 (0.121)
Train: [105][260/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.136 (0.121)
Train: [105][270/589]	BT 0.363 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.106 (0.121)
Train: [105][280/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.146 (0.121)
Train: [105][290/589]	BT 0.355 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.114 (0.121)
Train: [105][300/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.127 (0.121)
Train: [105][310/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.130 (0.121)
Train: [105][320/589]	BT 0.356 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.114 (0.121)
Train: [105][330/589]	BT 0.358 (0.389)	DT 0.000 (0.028)	lr 0.0002	loss 0.134 (0.121)
Train: [105][340/589]	BT 0.358 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.119 (0.121)
Train: [105][350/589]	BT 0.372 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.125 (0.121)
Train: [105][360/589]	BT 0.356 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.127 (0.121)
Train: [105][370/589]	BT 0.361 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.125 (0.121)
Train: [105][380/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.101 (0.121)
Train: [105][390/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.141 (0.121)
Train: [105][400/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.118 (0.121)
Train: [105][410/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.100 (0.121)
Train: [105][420/589]	BT 0.356 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.129 (0.121)
Train: [105][430/589]	BT 0.361 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.101 (0.121)
Train: [105][440/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.112 (0.121)
Train: [105][450/589]	BT 0.360 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.107 (0.121)
Train: [105][460/589]	BT 0.359 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.108 (0.121)
Train: [105][470/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.134 (0.121)
Train: [105][480/589]	BT 0.366 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.123 (0.121)
Train: [105][490/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.158 (0.122)
Train: [105][500/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.103 (0.121)
Train: [105][510/589]	BT 0.357 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.129 (0.122)
Train: [105][520/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.124 (0.122)
Train: [105][530/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.117 (0.122)
Train: [105][540/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.137 (0.122)
Train: [105][550/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.130 (0.122)
Train: [105][560/589]	BT 0.359 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.155 (0.122)
Train: [105][570/589]	BT 0.356 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.128 (0.122)
Train: [105][580/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.116 (0.122)
epoch 105, total time 227.74
loss: 0.12163108309629188@Epoch: 105
learning_rate: 0.0002,105
Valid: [105][10/88]	BT 0.109 (0.572)	DT 0.000 (0.461)	loss 0.151 (0.145)
Valid: [105][20/88]	BT 0.109 (0.485)	DT 0.000 (0.375)	loss 0.160 (0.147)
Valid: [105][30/88]	BT 0.110 (0.464)	DT 0.000 (0.354)	loss 0.126 (0.145)
Valid: [105][40/88]	BT 0.109 (0.448)	DT 0.000 (0.339)	loss 0.139 (0.145)
Valid: [105][50/88]	BT 0.109 (0.441)	DT 0.000 (0.331)	loss 0.148 (0.144)
Valid: [105][60/88]	BT 0.110 (0.439)	DT 0.000 (0.329)	loss 0.150 (0.144)
Valid: [105][70/88]	BT 0.109 (0.432)	DT 0.000 (0.322)	loss 0.128 (0.144)
Valid: [105][80/88]	BT 0.109 (0.427)	DT 0.000 (0.317)	loss 0.133 (0.144)
Train: [106][10/589]	BT 0.369 (0.745)	DT 0.000 (0.388)	lr 0.0002	loss 0.104 (0.115)
Train: [106][20/589]	BT 0.379 (0.556)	DT 0.000 (0.199)	lr 0.0002	loss 0.130 (0.117)
Train: [106][30/589]	BT 0.356 (0.492)	DT 0.000 (0.135)	lr 0.0002	loss 0.107 (0.120)
Train: [106][40/589]	BT 0.356 (0.462)	DT 0.000 (0.105)	lr 0.0002	loss 0.116 (0.121)
Train: [106][50/589]	BT 0.358 (0.445)	DT 0.000 (0.087)	lr 0.0002	loss 0.109 (0.121)
Train: [106][60/589]	BT 0.356 (0.434)	DT 0.000 (0.077)	lr 0.0002	loss 0.103 (0.122)
Train: [106][70/589]	BT 0.356 (0.425)	DT 0.000 (0.068)	lr 0.0002	loss 0.129 (0.121)
Train: [106][80/589]	BT 0.381 (0.420)	DT 0.000 (0.062)	lr 0.0002	loss 0.103 (0.120)
Train: [106][90/589]	BT 0.355 (0.413)	DT 0.000 (0.055)	lr 0.0002	loss 0.135 (0.120)
Train: [106][100/589]	BT 0.373 (0.409)	DT 0.000 (0.051)	lr 0.0002	loss 0.117 (0.120)
Train: [106][110/589]	BT 0.386 (0.408)	DT 0.000 (0.049)	lr 0.0002	loss 0.094 (0.119)
Train: [106][120/589]	BT 0.355 (0.406)	DT 0.000 (0.047)	lr 0.0002	loss 0.129 (0.119)
Train: [106][130/589]	BT 0.385 (0.404)	DT 0.000 (0.045)	lr 0.0002	loss 0.111 (0.120)
Train: [106][140/589]	BT 0.360 (0.403)	DT 0.000 (0.044)	lr 0.0002	loss 0.128 (0.120)
Train: [106][150/589]	BT 0.416 (0.402)	DT 0.000 (0.043)	lr 0.0002	loss 0.128 (0.120)
Train: [106][160/589]	BT 0.379 (0.399)	DT 0.000 (0.040)	lr 0.0002	loss 0.109 (0.120)
Train: [106][170/589]	BT 0.356 (0.398)	DT 0.000 (0.039)	lr 0.0002	loss 0.103 (0.120)
Train: [106][180/589]	BT 0.381 (0.396)	DT 0.000 (0.037)	lr 0.0002	loss 0.110 (0.120)
Train: [106][190/589]	BT 0.375 (0.395)	DT 0.000 (0.035)	lr 0.0002	loss 0.120 (0.119)
Train: [106][200/589]	BT 0.357 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.099 (0.119)
Train: [106][210/589]	BT 0.358 (0.394)	DT 0.000 (0.035)	lr 0.0002	loss 0.106 (0.119)
Train: [106][220/589]	BT 0.356 (0.393)	DT 0.000 (0.034)	lr 0.0002	loss 0.128 (0.119)
Train: [106][230/589]	BT 0.357 (0.393)	DT 0.000 (0.033)	lr 0.0002	loss 0.101 (0.120)
Train: [106][240/589]	BT 0.359 (0.392)	DT 0.000 (0.033)	lr 0.0002	loss 0.118 (0.119)
Train: [106][250/589]	BT 0.357 (0.392)	DT 0.000 (0.032)	lr 0.0002	loss 0.104 (0.120)
Train: [106][260/589]	BT 0.357 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.133 (0.120)
Train: [106][270/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.117 (0.120)
Train: [106][280/589]	BT 0.379 (0.391)	DT 0.000 (0.032)	lr 0.0002	loss 0.123 (0.120)
Train: [106][290/589]	BT 0.357 (0.391)	DT 0.000 (0.031)	lr 0.0002	loss 0.142 (0.120)
Train: [106][300/589]	BT 0.358 (0.390)	DT 0.000 (0.031)	lr 0.0002	loss 0.121 (0.120)
Train: [106][310/589]	BT 0.355 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.107 (0.120)
Train: [106][320/589]	BT 0.358 (0.390)	DT 0.000 (0.030)	lr 0.0002	loss 0.088 (0.120)
Train: [106][330/589]	BT 0.359 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.109 (0.120)
Train: [106][340/589]	BT 0.357 (0.389)	DT 0.000 (0.029)	lr 0.0002	loss 0.134 (0.120)
Train: [106][350/589]	BT 0.359 (0.388)	DT 0.000 (0.029)	lr 0.0002	loss 0.108 (0.121)
Train: [106][360/589]	BT 0.363 (0.388)	DT 0.000 (0.028)	lr 0.0002	loss 0.123 (0.121)
Train: [106][370/589]	BT 0.360 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.139 (0.121)
Train: [106][380/589]	BT 0.358 (0.387)	DT 0.000 (0.027)	lr 0.0002	loss 0.111 (0.121)
Train: [106][390/589]	BT 0.357 (0.386)	DT 0.000 (0.027)	lr 0.0002	loss 0.122 (0.121)
Train: [106][400/589]	BT 0.360 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.102 (0.121)
Train: [106][410/589]	BT 0.359 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.096 (0.121)
Train: [106][420/589]	BT 0.358 (0.386)	DT 0.000 (0.026)	lr 0.0002	loss 0.135 (0.121)
Train: [106][430/589]	BT 0.356 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.112 (0.121)
Train: [106][440/589]	BT 0.359 (0.385)	DT 0.000 (0.026)	lr 0.0002	loss 0.111 (0.121)
Train: [106][450/589]	BT 0.377 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.109 (0.121)
Train: [106][460/589]	BT 0.357 (0.385)	DT 0.000 (0.025)	lr 0.0002	loss 0.119 (0.121)
Train: [106][470/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.136 (0.121)
Train: [106][480/589]	BT 0.358 (0.384)	DT 0.000 (0.025)	lr 0.0002	loss 0.134 (0.121)
Train: [106][490/589]	BT 0.356 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.123 (0.121)
Train: [106][500/589]	BT 0.358 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.126 (0.121)
Train: [106][510/589]	BT 0.361 (0.384)	DT 0.000 (0.024)	lr 0.0002	loss 0.125 (0.121)
Train: [106][520/589]	BT 0.358 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.104 (0.121)
Train: [106][530/589]	BT 0.359 (0.383)	DT 0.000 (0.024)	lr 0.0002	loss 0.104 (0.121)
Train: [106][540/589]	BT 0.355 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.129 (0.121)
Train: [106][550/589]	BT 0.365 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.114 (0.121)
Train: [106][560/589]	BT 0.358 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.106 (0.121)
Train: [106][570/589]	BT 0.359 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.109 (0.121)
Train: [106][580/589]	BT 0.356 (0.383)	DT 0.000 (0.023)	lr 0.0002	loss 0.113 (0.121)
epoch 106, total time 225.47
loss: 0.12104273587623574@Epoch: 106
learning_rate: 0.0002,106
Valid: [106][10/88]	BT 0.109 (0.596)	DT 0.000 (0.484)	loss 0.122 (0.147)
Valid: [106][20/88]	BT 0.110 (0.503)	DT 0.000 (0.393)	loss 0.157 (0.146)
Valid: [106][30/88]	BT 0.109 (0.468)	DT 0.000 (0.358)	loss 0.149 (0.147)
Valid: [106][40/88]	BT 0.110 (0.454)	DT 0.000 (0.344)	loss 0.147 (0.145)
Valid: [106][50/88]	BT 0.109 (0.443)	DT 0.000 (0.333)	loss 0.150 (0.144)
Valid: [106][60/88]	BT 0.109 (0.437)	DT 0.000 (0.328)	loss 0.139 (0.143)
Valid: [106][70/88]	BT 0.109 (0.433)	DT 0.000 (0.324)	loss 0.141 (0.143)
Valid: [106][80/88]	BT 0.109 (0.430)	DT 0.000 (0.320)	loss 0.154 (0.143)
Model does not imporove from 0.13308 for 50 epochs. Early Stop
Loading pretrianed weight from: saved_models/ckpt_epoch_55.pth

Individual Diseases:
>> AUC = [0.7571,0.883,0.8204,0.6925,0.811,0.7371,0.7183,0.8369,0.7463,0.8394
 0.8598,0.8207,0.7581,0.914]
 >> Mean AUC = 0.7996



 
